{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/css/noscript.styl","path":"css/noscript.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon.jpg","path":"images/favicon.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo-algolia-nebula-blue-full.svg","path":"images/logo-algolia-nebula-blue-full.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/bookmark.js","path":"js/bookmark.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/comments.js","path":"js/comments.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/config.js","path":"js/config.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/comments-buttons.js","path":"js/comments-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/next-boot.js","path":"js/next-boot.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/pjax.js","path":"js/pjax.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/schedule.js","path":"js/schedule.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/sidebar.js","path":"js/sidebar.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/addtoany.js","path":"js/third-party/addtoany.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/fancybox.js","path":"js/third-party/fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/quicklink.js","path":"js/third-party/quicklink.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/pace.js","path":"js/third-party/pace.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/baidu-analytics.js","path":"js/third-party/analytics/baidu-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/growingio.js","path":"js/third-party/analytics/growingio.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/matomo.js","path":"js/third-party/analytics/matomo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/chat/chatra.js","path":"js/third-party/chat/chatra.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/chat/tidio.js","path":"js/third-party/chat/tidio.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/changyan.js","path":"js/third-party/comments/changyan.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/disqus.js","path":"js/third-party/comments/disqus.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/disqusjs.js","path":"js/third-party/comments/disqusjs.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/analytics/google-analytics.js","path":"js/third-party/analytics/google-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/gitalk.js","path":"js/third-party/comments/gitalk.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/isso.js","path":"js/third-party/comments/isso.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/livere.js","path":"js/third-party/comments/livere.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/comments/utterances.js","path":"js/third-party/comments/utterances.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/math/katex.js","path":"js/third-party/math/katex.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/math/mathjax.js","path":"js/third-party/math/mathjax.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/statistics/firestore.js","path":"js/third-party/statistics/firestore.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/statistics/lean-analytics.js","path":"js/third-party/statistics/lean-analytics.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/search/algolia-search.js","path":"js/third-party/search/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/search/local-search.js","path":"js/third-party/search/local-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/mermaid.js","path":"js/third-party/tags/mermaid.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/pdf.js","path":"js/third-party/tags/pdf.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/third-party/tags/wavedrom.js","path":"js/third-party/tags/wavedrom.js","modified":1,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/paper/1609.02907v4.pdf","path":"paper/1609.02907v4.pdf","modified":1,"renderable":0},{"_id":"source/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf","path":"paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf","modified":1,"renderable":0},{"_id":"source/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf","path":"paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf","modified":1,"renderable":0},{"_id":"source/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf","path":"paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf","modified":1,"renderable":0},{"_id":"source/img/Attention/AlternatingCo-Attention.png","path":"img/Attention/AlternatingCo-Attention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/AttentionViaAttention.png","path":"img/Attention/AttentionViaAttention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/CapsuleAttention.png","path":"img/Attention/CapsuleAttention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/GeneralAttentionModule.png","path":"img/Attention/GeneralAttentionModule.png","modified":1,"renderable":0},{"_id":"source/img/Attention/HierarchicalAttention.png","path":"img/Attention/HierarchicalAttention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/InteractiveCo-Attention.png","path":"img/Attention/InteractiveCo-Attention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/MultiheadAttention.png","path":"img/Attention/MultiheadAttention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/MultihopAttention.png","path":"img/Attention/MultihopAttention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/ParallelCo-Attention.png","path":"img/Attention/ParallelCo-Attention.png","modified":1,"renderable":0},{"_id":"source/img/Attention/Taxonomy.png","path":"img/Attention/Taxonomy.png","modified":1,"renderable":0},{"_id":"source/img/Attention/TotalModel.png","path":"img/Attention/TotalModel.png","modified":1,"renderable":0},{"_id":"source/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png","path":"img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png","modified":1,"renderable":0},{"_id":"source/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png","path":"img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png","modified":1,"renderable":0},{"_id":"source/img/CDR-data-analysis/gene.png","path":"img/CDR-data-analysis/gene.png","modified":1,"renderable":0},{"_id":"source/nodeppt/test/test_nodeppt.html","path":"nodeppt/test/test_nodeppt.html","modified":1,"renderable":0},{"_id":"source/code/data_analysis/visualize_graph_analysis.py","path":"code/data_analysis/visualize_graph_analysis.py","modified":1,"renderable":0},{"_id":"source/nodeppt/test/css/chunk-vendors.4e4765ff.css","path":"nodeppt/test/css/chunk-vendors.4e4765ff.css","modified":1,"renderable":0},{"_id":"source/nodeppt/test/js/chunk-vendors.js","path":"nodeppt/test/js/chunk-vendors.js","modified":1,"renderable":0},{"_id":"source/nodeppt/test/js/chunk-vendors.js.LICENSE.txt","path":"nodeppt/test/js/chunk-vendors.js.LICENSE.txt","modified":1,"renderable":0},{"_id":"source/nodeppt/test/js/test_nodeppt.js.LICENSE.txt","path":"nodeppt/test/js/test_nodeppt.js.LICENSE.txt","modified":1,"renderable":0},{"_id":"source/nodeppt/test/js/test_nodeppt.js","path":"nodeppt/test/js/test_nodeppt.js","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"9f72a1c93d67b273a3f1b776b7607fca8ecb9800","modified":1752079696958},{"_id":"source/_posts/Attention.md","hash":"e185f328a3f65a52c38f3461875b863394a52748","modified":1752503909037},{"_id":"source/_posts/GNN-and-GCN.md","hash":"ee88582d6b11ede46e8a61b3079d5004248f4c4c","modified":1752303156342},{"_id":"source/_posts/PEP-8.md","hash":"f96ac45169ffe57dd13682067fa26cf947be180c","modified":1752305613250},{"_id":"source/_posts/Feature-Related-Attention.md","hash":"98e822ababaa0a85a60aa697b60662ab3ab8141e","modified":1752597512939},{"_id":"source/_posts/CDR-data-analysis.md","hash":"8644bad2329b52211ff2cb500e250e8520faba0b","modified":1752203256876},{"_id":"source/_posts/GAT.md","hash":"754ff81781e96a4d44e354220c674049e31db8ab","modified":1752503264356},{"_id":"source/_posts/hwadee.md","hash":"7d3609b57c066a91fd3ed0e3bcaec8396bd9172b","modified":1752415131190},{"_id":"source/about/index.md","hash":"d59fba8d07a50609ba30828f459552bfa73cc1cb","modified":1752079696959},{"_id":"source/categories/index.md","hash":"893f97551f11e6bc689619cb961451636f68a0f4","modified":1752079696960},{"_id":"source/tags/index.md","hash":"99e0b192987cfef15ec25ae1040926c14469828f","modified":1752079696989},{"_id":"source/code/data_analysis/visualize_graph_analysis.py","hash":"f7ed9f01a38fe104b17464bf6e2dc7c5093ca7dc","modified":1752203256879},{"_id":"source/nodeppt/test/test_nodeppt.html","hash":"861eec2e1a66ee182a5a8ec962c2ad049e5d7908","modified":1752290420910},{"_id":"source/nodeppt/test/js/chunk-vendors.js","hash":"23c28d1f1615efdfe92ed6c634a9366a4aabb9b1","modified":1752290420908},{"_id":"source/nodeppt/test/js/chunk-vendors.js.LICENSE.txt","hash":"d6fa3279c3fc7ec7562c7dcb614253f886938c32","modified":1752290420909},{"_id":"source/nodeppt/test/js/test_nodeppt.js.LICENSE.txt","hash":"d6fa3279c3fc7ec7562c7dcb614253f886938c32","modified":1752290420910},{"_id":"source/img/CDR-data-analysis/gene.png","hash":"dac1e1481add33e6e471f62deb153719ff929a3a","modified":1752124411429},{"_id":"source/nodeppt/test/js/test_nodeppt.js","hash":"a0d1819335072875ac9197f43d7c09511722a9c8","modified":1752290420909},{"_id":"source/img/Attention/AlternatingCo-Attention.png","hash":"514aa65627d99a19c982ec47a9ebd8a66029d07f","modified":1752505028735},{"_id":"source/img/Attention/AttentionViaAttention.png","hash":"eee60186ed279182176b247f00e6243b707c54a6","modified":1752290420881},{"_id":"source/img/Attention/InteractiveCo-Attention.png","hash":"d66ad9309b6851348104b591f7a265f55ba4aae4","modified":1752290420892},{"_id":"source/img/Attention/MultiheadAttention.png","hash":"1d61e6a59d33b5b70521acf9b1e8b191d04a7278","modified":1752290420894},{"_id":"source/img/Attention/ParallelCo-Attention.png","hash":"1389f902e31640d6ff97a4375804b5b443706c02","modified":1752290420898},{"_id":"source/img/Attention/TotalModel.png","hash":"b9c32980245dcf7bb4e9e54b04b59ccaa14bf265","modified":1752290420905},{"_id":"source/nodeppt/test/css/chunk-vendors.4e4765ff.css","hash":"cb37dab7a01358273812ab41d4325c5c8e3c5af9","modified":1752290420907},{"_id":"source/img/Attention/GeneralAttentionModule.png","hash":"9e9b439faf1e0e38564fc8eab3364f8e6938cf6e","modified":1752290420888},{"_id":"source/img/Attention/HierarchicalAttention.png","hash":"ddad89428142f48353d6338f6d69402ec9b0d95e","modified":1752290420890},{"_id":"source/img/Attention/MultihopAttention.png","hash":"9bb72595c6b04f2157d01b069d004eaa94d71efa","modified":1752290420896},{"_id":"source/img/Attention/CapsuleAttention.png","hash":"8d29b9e962f65aea416727e5e0d321cf00e718f1","modified":1752290420886},{"_id":"themes/next/.gitattributes","hash":"aeeca2f1e987d83232d7870d1435a4e3ed66b648","modified":1752079696991},{"_id":"themes/next/LICENSE.md","hash":"8cfb03967dd4cbaf3b825271ffce0039aa3fc22a","modified":1752079697000},{"_id":"themes/next/_config.yml","hash":"6eebbc6c763bf07971f201edeaa548701b2c7f73","modified":1752310086668},{"_id":"themes/next/.editorconfig","hash":"731c650ddad6eb0fc7c3d4a91cad1698fe7ad311","modified":1752079696991},{"_id":"themes/next/.stylelintrc","hash":"20f46858e47aba6b3fc47e9b43e9f7531fa66e33","modified":1752079697000},{"_id":"themes/next/_vendors.yml","hash":"0c3c1b4e3e5f89985aca0e24cc8dad496e737634","modified":1752079697000},{"_id":"themes/next/crowdin.yml","hash":"4a53f5985e545c635cb56b2a57ed290cb8cf8942","modified":1752079697000},{"_id":"themes/next/README.md","hash":"cfafa81c8df2c64b0db6a14c7f5e0bb014936b36","modified":1752079697000},{"_id":"themes/next/eslint.config.js","hash":"e35570c8e7ef9ea4adad7bafb3558dfd8e928e48","modified":1752079697006},{"_id":"themes/next/.gitignore","hash":"087b7677078303acb2acb47432165950e4d29b43","modified":1752079697000},{"_id":"themes/next/package.json","hash":"761cf8d5dd2a376b18a088d9e908ea75d9270b58","modified":1752079697041},{"_id":"themes/next/renovate.json","hash":"767b077c7b615e20af3cf865813cd64674a9bea6","modified":1752079697041},{"_id":"themes/next/.github/CODE_OF_CONDUCT.md","hash":"82a3d202da8fe6ce765715bd5b7571676e90364d","modified":1752079696992},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"2fdca1040427cabfe27cae6754ec5e027ec7092e","modified":1752079696993},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"610675119f83cdbf3f19d7996b17e33062e3b165","modified":1752079696995},{"_id":"themes/next/.github/config.yml","hash":"0956bf71b6f36632b63b14d26580458041a5abd2","modified":1752079696995},{"_id":"themes/next/.github/issue_label_bot.yaml","hash":"533fbe6b2f87d7e7ec6949063bb7ea7eb4fbe52d","modified":1752079696995},{"_id":"themes/next/.github/labeler.yml","hash":"35da1a37e9a6bdee1eeae30a8816cd75c9a04b3b","modified":1752079696996},{"_id":"themes/next/.github/label-commenter-config.yml","hash":"d403cbbbd0c554563e9e678ff82120ef9451d98a","modified":1752079696996},{"_id":"themes/next/.github/release.yml","hash":"83b4dae3f8d76619e208d2110a247b3ccadd64d8","modified":1752079696996},{"_id":"themes/next/.githooks/install.js","hash":"72757c6827909a5f2c217ddbbdf6034ca6fab74a","modified":1752079696992},{"_id":"themes/next/.githooks/pre-commit","hash":"b69b9d0b51e27d5d4c87c3242f5067c2cda26e44","modified":1752079696992},{"_id":"themes/next/docs/AGPL3.md","hash":"f463f95b169d64983f59fa6f3e4b6760290a0e6b","modified":1752079697000},{"_id":"themes/next/docs/AUTHORS.md","hash":"579014d47f45b27fd1618b9709f0efe9585c7449","modified":1752079697000},{"_id":"themes/next/docs/LICENSE.txt","hash":"d1cd5a8e83d3bbdb50f902d2b487813da95ddfd3","modified":1752079697000},{"_id":"themes/next/languages/README.md","hash":"b1c96465b3bc139bf5ba6200974b66581d8ff85a","modified":1752079697007},{"_id":"themes/next/languages/ar.yml","hash":"c77fc13e0431e71eeb0f767a0a436284fc81df90","modified":1752079697007},{"_id":"themes/next/languages/de.yml","hash":"5101612f7cac38884206d28319532f1aab32fbe6","modified":1752079697008},{"_id":"themes/next/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1752079697009},{"_id":"themes/next/languages/bn.yml","hash":"30ffd43588ddf2cd39432d964087242e1c3e5407","modified":1752079697008},{"_id":"themes/next/languages/en.yml","hash":"5ca2c0b3c95dd87485f2d2b3477f88810ad1a63b","modified":1752079697009},{"_id":"themes/next/languages/es.yml","hash":"31c2a47d14cd5b804cae0c0b44d43bece069d3aa","modified":1752079697010},{"_id":"themes/next/languages/eo.yml","hash":"7bd0124c2d1dcdbfde350fce335e130556ebcee8","modified":1752079697009},{"_id":"themes/next/languages/fr.yml","hash":"3a7469446f77e5d1a12eee828ebc49ecb43b6c35","modified":1752079697011},{"_id":"themes/next/languages/fa.yml","hash":"cc6ef3144b954daa29ce7d42f08191eafe052fab","modified":1752079697010},{"_id":"themes/next/languages/id.yml","hash":"bd2c30def05a37c66653900ca07952d52a142961","modified":1752079697011},{"_id":"themes/next/languages/it.yml","hash":"4969c4f17d88003135218de72ddf0bf8d894dc07","modified":1752079697011},{"_id":"themes/next/languages/ja.yml","hash":"e660ec12b9eade103492aba7aa9b23ef06d353a9","modified":1752079697011},{"_id":"themes/next/languages/ko.yml","hash":"04927e331652ee13f9c8a110fe12d7f936a6b0e6","modified":1752079697012},{"_id":"themes/next/languages/pt-BR.yml","hash":"ff9aa6a6549d07b7dc667094f34a06945e2c21b4","modified":1752079697013},{"_id":"themes/next/languages/nl.yml","hash":"4575f93c4ee4383bdfaca01ad6ffff5664cbbbae","modified":1752079697012},{"_id":"themes/next/languages/pt.yml","hash":"2c86b3235de9539df2119e52e913d847ecf782c0","modified":1752079697013},{"_id":"themes/next/languages/ru.yml","hash":"d726265bc5cf8bd4fb64f85b2d07b3326439bb00","modified":1752079697013},{"_id":"themes/next/languages/tk.yml","hash":"7b9115e0520dc81a95a7c8e4f56a01fc84f74017","modified":1752079697015},{"_id":"themes/next/languages/si.yml","hash":"07f98d6ca99bceef35254c60fc0e4401ff608557","modified":1752079697014},{"_id":"themes/next/languages/th.yml","hash":"dc434da945d52dc7a8d26acc80b23e6922712f89","modified":1752079697014},{"_id":"themes/next/languages/uk.yml","hash":"10a2f2e7183410d1d10fa937e3e0198b46bf4930","modified":1752079697015},{"_id":"themes/next/languages/vi.yml","hash":"8344cb90ee92a21a398faff3317c025a43446db5","modified":1752079697016},{"_id":"themes/next/languages/zh-CN.yml","hash":"c06c95121b3e5bd5abe01848073fbe7f9d6dcda9","modified":1752079697016},{"_id":"themes/next/languages/zh-TW.yml","hash":"664ebfa09503d29d6f33a5ffadaa16989785e0fe","modified":1752079697017},{"_id":"themes/next/languages/zh-HK.yml","hash":"293009343786f9b460412b7032e694755e5edc8d","modified":1752079697016},{"_id":"themes/next/layout/_layout.njk","hash":"e8dd48352cbdb8ade0fb4f9380c5fe3dab0a995e","modified":1752079697017},{"_id":"themes/next/layout/archive.njk","hash":"aa491dba8f746e626c273a920effedf7d0b32170","modified":1752079697034},{"_id":"themes/next/languages/tr.yml","hash":"822ec400a0a2bb2245abf31e9ed4f3af77b2814e","modified":1752079697015},{"_id":"themes/next/layout/index.njk","hash":"fa52c3049871e879980cb6abccdea3792ca4ce70","modified":1752079697034},{"_id":"themes/next/layout/category.njk","hash":"82f541452cae76a94ee15cb8d8a888f44260a0fd","modified":1752079697034},{"_id":"themes/next/layout/page.njk","hash":"d24238eea91a347050a663c7a7de8cebaab4c595","modified":1752079697034},{"_id":"themes/next/layout/tag.njk","hash":"b6c017d30d08ddd30d66e9c6f3a71aa65d214eac","modified":1752079697041},{"_id":"themes/next/layout/post.njk","hash":"6767de9702a07a2a4e16a8a6bc9c5919536c1e3f","modified":1752079697041},{"_id":"themes/next/test/index.js","hash":"c0723bd61aed6872f184aa743b782dc0b9a172e1","modified":1752079697104},{"_id":"themes/next/.github/ISSUE_TEMPLATE/bug-report.yml","hash":"3f19cbf0c2b2fee6bf3788870b842c9ccc1425ca","modified":1752079696993},{"_id":"themes/next/.github/ISSUE_TEMPLATE/other.yml","hash":"10eca518b91a19984f6a5a912d41222042f61d63","modified":1752079696994},{"_id":"themes/next/.github/workflows/codeql.yml","hash":"82a2df4c676ae45b2768c71c724b188475c88ca5","modified":1752079696997},{"_id":"themes/next/.github/workflows/label-commenter.yml","hash":"dc4809131c54a1d9f8e7392aeaf53b13c6befd90","modified":1752079696997},{"_id":"themes/next/.github/ISSUE_TEMPLATE/feature-request.yml","hash":"fbc3062cd4591c8329fab9db72803746f0d11920","modified":1752079696994},{"_id":"themes/next/.github/ISSUE_TEMPLATE/config.yml","hash":"daeedc5da2ee74ac31cf71846b766ca6499e9fc6","modified":1752079696994},{"_id":"themes/next/.github/workflows/labeler.yml","hash":"e8ca602587b3abe08b60fc1bdc1c2d62aeeb85bb","modified":1752079696997},{"_id":"themes/next/.github/workflows/lock.yml","hash":"80dc185dfaeb2927db72a44ff2382e05f47a2df5","modified":1752079696998},{"_id":"themes/next/.github/workflows/linter.yml","hash":"294660e1b6275a0fe4db2a44e5b6b679467d29fc","modified":1752079696998},{"_id":"themes/next/.github/workflows/tester.yml","hash":"dba3f1d4bc4d2fab51d73d134ed5c7448a0976dc","modified":1752079697000},{"_id":"themes/next/.github/workflows/npm-publish.yml","hash":"4154828f8fcc37011e636fc1c3448f3b15350d44","modified":1752079696998},{"_id":"themes/next/docs/ru/README.md","hash":"2c22c6f8c77cd22d57b4a556826fa9cbd4034f85","modified":1752079697000},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"e077bebf4fb89b159b840b30f0230b95ff7db8a5","modified":1752079697000},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"a09ceb82b45dd8b7da76c227f3d0bb7eebe7d5d1","modified":1752079697006},{"_id":"themes/next/docs/zh-CN/README.md","hash":"45481be96a710e53498721d7d1db1edb36318606","modified":1752079697006},{"_id":"themes/next/layout/_macro/post.njk","hash":"775f264e8deb66653153117c8bd43854594cb36c","modified":1752079697018},{"_id":"themes/next/layout/_macro/post-collapse.njk","hash":"a60b386c7889f25f811182cae76e6474cb3254d1","modified":1752079697018},{"_id":"themes/next/layout/_macro/sidebar.njk","hash":"b9fc0a6b02f0380de939d1ea2a7c7d2e6be9f462","modified":1752079697019},{"_id":"themes/next/layout/_partials/comments.njk","hash":"60f4620dd479da6d86d1d493440e9e2a28b6e132","modified":1752079697019},{"_id":"themes/next/layout/_partials/footer.njk","hash":"cc51596980560ab60626da76260b7f5e83df8a33","modified":1752310612259},{"_id":"themes/next/layout/_partials/languages.njk","hash":"537026fc120adeef9148c98ebf074207e3810538","modified":1752079697023},{"_id":"themes/next/layout/_partials/pagination.njk","hash":"c55167bc0dbe7e104d4f4d782e98fcabc7e07a35","modified":1752079697025},{"_id":"themes/next/layout/_partials/widgets.njk","hash":"bb5d32170b469dc018ceaa10a5b7cb892c9b85a4","modified":1752079697028},{"_id":"themes/next/layout/_scripts/vendors.njk","hash":"71691096a1a034f6af68403730a1589c0d7fabaa","modified":1752079697028},{"_id":"themes/next/layout/_scripts/index.njk","hash":"6379fb7776ba2a93eb0220e5fa2adee1e3c5d9b0","modified":1752079697028},{"_id":"themes/next/layout/_third-party/addtoany.njk","hash":"9ef81adb0c35ebdb4499602155e87611aee0762a","modified":1752079697029},{"_id":"themes/next/layout/_third-party/fancybox.njk","hash":"53ad3c31762b74e5d29787b37d5e494cc4fded9b","modified":1752079697034},{"_id":"themes/next/layout/_third-party/index.njk","hash":"9bab629e2971b029545511b48f397445858ac7f0","modified":1752079697034},{"_id":"themes/next/layout/_third-party/pace.njk","hash":"13b2a77b4858a127f458ea092b6f713b052befac","modified":1752079697034},{"_id":"themes/next/layout/_third-party/quicklink.njk","hash":"73bc15a9c3c5c239ab90efa19a1e721f41f3cb93","modified":1752079697034},{"_id":"themes/next/source/css/_colors.styl","hash":"9354013ea89c8e3874a44929c394db39ae04f36a","modified":1752079697055},{"_id":"themes/next/source/css/_mixins.styl","hash":"bb868086bf28029d2fb9f6d4abe620c382d66568","modified":1752079697078},{"_id":"themes/next/source/css/main.styl","hash":"cb3bb1f96ab67e31ce4326159e22ba22cee14c4e","modified":1752310770645},{"_id":"themes/next/source/css/noscript.styl","hash":"64b378a4d2f0b36bf666fba13b57c59da3a8ac83","modified":1752079697089},{"_id":"themes/next/source/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1752079697089},{"_id":"themes/next/source/images/logo-algolia-nebula-blue-full.svg","hash":"5a81f1c5d66561b3bcb05dae48148088a3fb5c79","modified":1752079697091},{"_id":"themes/next/source/js/bookmark.js","hash":"e2fd71f2876531f4c8bf1f38828aae35dd82cca4","modified":1752079697091},{"_id":"themes/next/source/js/comments.js","hash":"0b4daf0ce610760bd52e95d423f61f3e1c72442a","modified":1752079697092},{"_id":"themes/next/source/images/logo.svg","hash":"099e11ab995a2c8981427a85476d082609848c77","modified":1752079697091},{"_id":"themes/next/source/js/comments-buttons.js","hash":"81ea6cbcdf0357094753d7523919c1eafa38e79f","modified":1752079697092},{"_id":"themes/next/source/js/config.js","hash":"211a9ab35205ccfa6b7c74394bade84da0d00af7","modified":1752079697092},{"_id":"themes/next/source/js/motion.js","hash":"a2abc7279723aee459b4c7a357fc84d5215affcf","modified":1752079697093},{"_id":"themes/next/source/js/next-boot.js","hash":"feafaa8cd1305b773f793bd36dee71fd832044a2","modified":1752079697093},{"_id":"themes/next/source/js/schedule.js","hash":"4858233224756e3cadfabd8135f7c4b1e3673b44","modified":1752079697094},{"_id":"themes/next/source/js/pjax.js","hash":"ca513ae9aa3ab3dfe46668f0717d9d37b571c5b7","modified":1752079697093},{"_id":"themes/next/source/js/sidebar.js","hash":"f3052996408a09233ffaf8d631fd930443ccd781","modified":1752079697094},{"_id":"themes/next/source/js/utils.js","hash":"381223fa6bba40d973550deb05bc409c3962338b","modified":1752079697104},{"_id":"themes/next/test/helpers/font.js","hash":"f61d3a1de5261728398d2de57e33452cf7d93383","modified":1752079697104},{"_id":"themes/next/test/helpers/index.js","hash":"2fb58dca3df2fe53116ee2b1232fa26ebe7b2ce5","modified":1752079697104},{"_id":"themes/next/test/helpers/next-url.js","hash":"4f39453286113d3d1e64bcc1934b5f974a33102d","modified":1752079697104},{"_id":"themes/next/test/tags/button.js","hash":"68b2f363286ce08e6b64d5d0d90aad6960e13a93","modified":1752079697104},{"_id":"themes/next/test/tags/center-quote.js","hash":"c073b7ee0f72d1c304522030a8eea68878adfcba","modified":1752079697104},{"_id":"themes/next/test/tags/caniuse.js","hash":"32f1ae9d49fcf0a1ebaa07f1f274aaf6f85b4699","modified":1752079697104},{"_id":"themes/next/test/tags/group-pictures.js","hash":"1232c69689eee53b5b5926beb66f402a3bec5581","modified":1752079697104},{"_id":"themes/next/test/tags/label.js","hash":"11c90db85fd373b08fd4241c3adfb19057e34025","modified":1752079697104},{"_id":"themes/next/test/tags/mermaid.js","hash":"ff6751c3e77db4c80be9c03b896451b1fd1b185f","modified":1752079697104},{"_id":"themes/next/test/tags/note.js","hash":"2c4127a43850d89fe13064ae26e3b45bc72b525d","modified":1752079697104},{"_id":"themes/next/test/tags/link-grid.js","hash":"8b0ce804b53329c0e76259a94a24c60a66b9f77b","modified":1752079697104},{"_id":"themes/next/test/tags/index.js","hash":"5cad001936a694bf32d59751cc2b68a66199f976","modified":1752079697104},{"_id":"themes/next/test/tags/pdf.js","hash":"4303175f1702adabd445aec58101d48df8c1a3ba","modified":1752079697104},{"_id":"themes/next/test/tags/tabs.js","hash":"2f809f250a0445671912ae0fd54bbb6c0f5e9880","modified":1752079697104},{"_id":"themes/next/test/tags/video.js","hash":"6ab9deb1d702bda3132e6c45fa5e6b51c79a7151","modified":1752079697110},{"_id":"themes/next/test/validate/index.js","hash":"9d44aff73371402574a8b61dda1037a58e382b52","modified":1752079697110},{"_id":"themes/next/scripts/events/index.js","hash":"8ae618d4436dab49928c2bebc0837e5310dbe7de","modified":1752079697042},{"_id":"themes/next/scripts/filters/default-injects.js","hash":"0c9a1fe9906672724dbf274154a37bac1915ca2c","modified":1752079697047},{"_id":"themes/next/scripts/filters/locals.js","hash":"87f3bff03fa9fd96cf0787a6442464a7ff57f76b","modified":1752079697048},{"_id":"themes/next/scripts/filters/minify.js","hash":"0f6b9b0eb41f6319e75ff86f9254cf1a9d3333b8","modified":1752079697048},{"_id":"themes/next/scripts/filters/post.js","hash":"e6cf4c94fc2291215a3345134ddbbc74d5091b00","modified":1752079697048},{"_id":"themes/next/scripts/helpers/engine.js","hash":"b69e324ae9750cb35a4609c41b73d52177cc94e9","modified":1752079697049},{"_id":"themes/next/scripts/helpers/font.js","hash":"dd76be4927a77c27292a4790bcc659c10518a219","modified":1752079697049},{"_id":"themes/next/scripts/helpers/navigation.js","hash":"82f6e81bacf23d10cac71b09cff8708e47891ef3","modified":1752079697049},{"_id":"themes/next/scripts/helpers/next-config.js","hash":"2a10b4b8879ccd7ea8b36253fe7a27f4161e6b82","modified":1752079697049},{"_id":"themes/next/scripts/helpers/next-paginator.js","hash":"2e8dcc12a52517bb4e00ea611720bcd298624112","modified":1752079697050},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"ceff5e76564a5d6ed3e0222bccf581e106d80f3c","modified":1752079697050},{"_id":"themes/next/scripts/helpers/next-vendors.js","hash":"12814eb1845830204e3a398eb93a2c15e0ff8d94","modified":1752079697051},{"_id":"themes/next/scripts/tags/caniuse.js","hash":"8e912c715702addaf0cefe63e580e45b97ae8c3f","modified":1752079697051},{"_id":"themes/next/scripts/tags/button.js","hash":"86c71c73a63744efbbbb367612871fede0d69529","modified":1752079697051},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"652140814527db74bcde9110142824dc727be889","modified":1752079697052},{"_id":"themes/next/scripts/tags/index.js","hash":"1a680bb01e14152905efe3ef624621dd74cf27c3","modified":1752079697052},{"_id":"themes/next/scripts/tags/label.js","hash":"c18b0e619a779ed40be7f014db92af18f45fbd5c","modified":1752079697053},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"b4d12e6fe29089be0f43bafc9eea736602cd16bf","modified":1752079697052},{"_id":"themes/next/scripts/tags/mermaid.js","hash":"b139224ff2cc668f4d95bde184934833e05b29df","modified":1752079697053},{"_id":"themes/next/scripts/tags/pdf.js","hash":"317ba4611020cc840854386dde098dbbe452777e","modified":1752079697054},{"_id":"themes/next/scripts/tags/link-grid.js","hash":"3f358bb78c5c6fdf45de287f3ead553e3a6a93c2","modified":1752079697053},{"_id":"themes/next/scripts/tags/note.js","hash":"a12fd53e421400836a3722ae69130969558d6ac0","modified":1752079697053},{"_id":"themes/next/scripts/tags/tabs.js","hash":"e0ed5fe1bc9d2957952a1aacdf3252d6ef3f9743","modified":1752079697054},{"_id":"themes/next/scripts/tags/wavedrom.js","hash":"188c1dd5d7dbc566cac00946da86aa76fff1c682","modified":1752079697055},{"_id":"themes/next/scripts/tags/video.js","hash":"f6ad3f52779f0636251238d3cbdc5b6f91cc5aba","modified":1752079697054},{"_id":"themes/next/layout/_partials/head/head-unique.njk","hash":"c2ee46d744afa78d95c6bca5dfcbb2fbc38474c2","modified":1752079697021},{"_id":"themes/next/layout/_partials/head/head.njk","hash":"e016c3f80db433f17781caf26e44f2089a71550a","modified":1752079697021},{"_id":"themes/next/layout/_partials/post/post-followme.njk","hash":"ebe45ab38ace03ea74eed3f676ec1cb5805a3c8a","modified":1752079697026},{"_id":"themes/next/layout/_partials/post/post-copyright.njk","hash":"22c922214982c4bb78ea92fa2ff1de93d98216a3","modified":1752079697025},{"_id":"themes/next/layout/_partials/post/post-related.njk","hash":"9a7eda45ad0753d5f624c51a56e00277ba97c93d","modified":1752079697026},{"_id":"themes/next/layout/_partials/post/post-meta.njk","hash":"9a9c4fb7e7c4fe4b7d474bdfdb4ed2b0a5423df2","modified":1752079697026},{"_id":"themes/next/layout/_partials/post/post-reward.njk","hash":"fd6fde597ea2fb7b80cffd0a3553c8e73acb8ab2","modified":1752079697027},{"_id":"themes/next/layout/_partials/post/post-share.njk","hash":"8a6414987474592e82b3e57eeb0bd526ae42d235","modified":1752079697027},{"_id":"themes/next/layout/_partials/search/index.njk","hash":"10145ae7ef87b502d20bfa08beb2b899228f1419","modified":1752079697027},{"_id":"themes/next/layout/_partials/header/brand.njk","hash":"7bf2b6ab499775355bbf8f3ae597ff7bc00e89e4","modified":1752079697022},{"_id":"themes/next/layout/_partials/header/index.njk","hash":"1b2ae17f3c394ce310fe2d9ed5f4d07d8cc74ae7","modified":1752079697022},{"_id":"themes/next/layout/_partials/header/menu-item.njk","hash":"62513f08e9e7f4abeaeedca91fd0af0861a2540f","modified":1752079697022},{"_id":"themes/next/layout/_partials/header/menu.njk","hash":"828700af2a2f273d3e3e0554ffc60706d889d539","modified":1752079697023},{"_id":"themes/next/layout/_partials/header/sub-menu.njk","hash":"20cb9c39bcdcfa3f710df7bc5838d6e62d4dd674","modified":1752079697023},{"_id":"themes/next/layout/_partials/sidebar/site-overview.njk","hash":"8d76300e31178e790400a37adfaf9bc0e5f8fae7","modified":1752079697027},{"_id":"themes/next/layout/_partials/page/breadcrumb.njk","hash":"1fe44a1e156cd30e3e9fd8313e1011ad30970f83","modified":1752079697024},{"_id":"themes/next/layout/_partials/page/categories.njk","hash":"b352346dd2cb42f7eeaec5e39d9a2a353b029775","modified":1752079697024},{"_id":"themes/next/layout/_partials/page/page-header.njk","hash":"92553feb26f30f7fc9147bc4ef122908a9da06be","modified":1752079697024},{"_id":"themes/next/layout/_partials/page/schedule.njk","hash":"6ec9c97e91c793cc2eb5ac0f7c3c36fdaaf637d1","modified":1752079697025},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.njk","hash":"52ad137450f7b3d6a330e16b3ed1c6174290f0eb","modified":1752079697030},{"_id":"themes/next/layout/_third-party/analytics/growingio.njk","hash":"9ff9ec05c2037beea229a6bb698f9e3546973220","modified":1752079697030},{"_id":"themes/next/layout/_third-party/analytics/cloudflare.njk","hash":"17173c45f0b740669ef45aaae1fe96eeb0a0ff52","modified":1752079697030},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.njk","hash":"3e80332f88b101141be69f2a07f54ed8c053eabb","modified":1752079697030},{"_id":"themes/next/layout/_third-party/analytics/index.njk","hash":"81abcf790cf97395cde9e3cd6d5d1aa5656bd134","modified":1752079697031},{"_id":"themes/next/layout/_partials/page/tags.njk","hash":"752df7d12360a077c51a25609916a3ecc1763bb3","modified":1752079697025},{"_id":"themes/next/layout/_third-party/analytics/plausible.njk","hash":"64ed6fecae79f9f9c61e956d2bd077792473e069","modified":1752079697031},{"_id":"themes/next/layout/_third-party/analytics/microsoft-clarity.njk","hash":"2129a017a1b1ab751aca9c70e76461ad91b2a81e","modified":1752079697031},{"_id":"themes/next/layout/_third-party/analytics/umami.njk","hash":"c8b8c10dcf5c4ffa4a8aec5ba5892842ec204ac0","modified":1752079697032},{"_id":"themes/next/layout/_third-party/chat/tidio.njk","hash":"3fbc72427c1211e5dcfd269af1a74852a7ba5c1a","modified":1752079697032},{"_id":"themes/next/layout/_third-party/chat/chatra.njk","hash":"09d2c9487d75894d45a823e3237ae9f90fd6ee01","modified":1752079697032},{"_id":"themes/next/layout/_third-party/comments/changyan.njk","hash":"5f7967bd946060f4102263a552ddfbae9975e7ea","modified":1752079697033},{"_id":"themes/next/layout/_third-party/analytics/matomo.njk","hash":"43238bc1bc2e88d707f8097814ef3ff830cbe641","modified":1752079697031},{"_id":"themes/next/layout/_third-party/comments/isso.njk","hash":"38badcc7624a13961381c2465478056b9602aee5","modified":1752079697034},{"_id":"themes/next/layout/_third-party/comments/disqusjs.njk","hash":"c5086b4c35f730f82c99c4a8317f2f153ebde869","modified":1752079697033},{"_id":"themes/next/layout/_third-party/comments/gitalk.njk","hash":"6fd4df5c21cfe530dbb0c012bc0b202f2c362b9c","modified":1752079697034},{"_id":"themes/next/layout/_third-party/comments/disqus.njk","hash":"b0828dd1b1fd66ecd612d9e886a08e7579e9a4f7","modified":1752079697033},{"_id":"themes/next/layout/_third-party/comments/livere.njk","hash":"b8e0d5de584cece5e05b03db5b86145aa1e422b4","modified":1752079697034},{"_id":"themes/next/layout/_third-party/math/index.njk","hash":"1856c4b035c5b8e64300a11af0461b519dfc4cf4","modified":1752079697034},{"_id":"themes/next/layout/_third-party/comments/utterances.njk","hash":"a7921be7328e1509d33b435175f5333a9aada66f","modified":1752079697034},{"_id":"themes/next/layout/_third-party/search/localsearch.njk","hash":"210c32b654adae3d8076c4417d370b42af258cea","modified":1752079697034},{"_id":"themes/next/layout/_third-party/math/katex.njk","hash":"1df65b1390add93b86ae3f9423d96a130b0ece04","modified":1752079697034},{"_id":"themes/next/layout/_third-party/math/mathjax.njk","hash":"a62aa1ed4e35b8d0451d83f341bf0a97538bc9a4","modified":1752079697034},{"_id":"themes/next/layout/_third-party/statistics/busuanzi-counter.njk","hash":"442df8a04f1967779cdd7599156496bdac8f1f23","modified":1752079697034},{"_id":"themes/next/layout/_third-party/statistics/firestore.njk","hash":"af5336e8bbdc4638435971da115bb7443d374ade","modified":1752079697034},{"_id":"themes/next/layout/_third-party/statistics/lean-analytics.njk","hash":"8703d1855bb8d251c9b7c2940b7e3be525e53000","modified":1752079697034},{"_id":"themes/next/layout/_third-party/statistics/index.njk","hash":"866ffa15a3250678eb8a90aa6f609fa965db90fd","modified":1752079697034},{"_id":"themes/next/layout/_third-party/search/algolia-search.njk","hash":"599f3f5e4385501d0010edc02ed9ca547d2467f7","modified":1752079697034},{"_id":"themes/next/layout/_third-party/tags/wavedrom.njk","hash":"baec18165d767094ecb2dda7141ca3bd8c6f2eb9","modified":1752079697034},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"c4537fa2de33d98baff2c87a73801770414e0b69","modified":1752079697087},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"54c52744898eb5d2073b83f98bb1a61759da92dc","modified":1752079697088},{"_id":"themes/next/layout/_third-party/tags/pdf.njk","hash":"0386c708975cc5faea4f782611c5d2c6b8ac2850","modified":1752079697034},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"9f1424e0b0314fc540c33ff59959fc3b75b18c34","modified":1752311854222},{"_id":"themes/next/layout/_third-party/tags/mermaid.njk","hash":"dd8f963acd5a3685be46fd5319c06df0308d99b2","modified":1752079697034},{"_id":"themes/next/source/css/_variables/base.styl","hash":"c4fda1066a429e77828f457aea5d5b06be3eeda6","modified":1752079697088},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"9cd228d5de7c2e49a231be072c9ef13af2dd95ff","modified":1752079697087},{"_id":"themes/next/source/js/third-party/addtoany.js","hash":"5cff12a5c9fc55a68f0f57a291494cd738301ba4","modified":1752079697094},{"_id":"themes/next/source/js/third-party/quicklink.js","hash":"5b0197e061f57e00875be3636ba372a67693abe0","modified":1752079697100},{"_id":"themes/next/source/js/third-party/pace.js","hash":"0ebee77b2307bf4b260afb06c060171ef42b7141","modified":1752079697100},{"_id":"themes/next/scripts/events/lib/config.js","hash":"b4944b3272edecceedc3935f8606e810f9ff237e","modified":1752079697043},{"_id":"themes/next/source/js/third-party/fancybox.js","hash":"e3022c2ea60409a82a3e2a0d3615e4a25c684551","modified":1752079697099},{"_id":"themes/next/scripts/events/lib/navigation.js","hash":"0a2df7d40d64c61ce7e730bb8269b848b03526d1","modified":1752079697043},{"_id":"themes/next/scripts/events/lib/injects.js","hash":"1f1ea7b579a49f17574c31d78d663c54896133eb","modified":1752079697043},{"_id":"themes/next/scripts/events/lib/highlight.js","hash":"df360f546d59b1fee8926806268754433dfa5de7","modified":1752079697043},{"_id":"themes/next/scripts/events/lib/utils.js","hash":"da22c6008fc8d214ba8561b412233380a06c40f9","modified":1752079697044},{"_id":"themes/next/scripts/events/lib/vendors.js","hash":"af3e7066a7a8d87448aadde3bc9c848077aae418","modified":1752079697044},{"_id":"themes/next/scripts/filters/comment/changyan.js","hash":"761760031e49edb77277bd4a8582774959240d6b","modified":1752079697045},{"_id":"themes/next/scripts/filters/comment/common.js","hash":"550cc7f57bc3ab3d093e34741e7860222851d4d4","modified":1752079697045},{"_id":"themes/next/scripts/filters/comment/disqus.js","hash":"3283bdd6e5ac7d10376df8ddd5faaec5dc1bd667","modified":1752079697046},{"_id":"themes/next/scripts/filters/comment/disqusjs.js","hash":"4dbe9652ae53a181c86eb7e9005a5255f0540055","modified":1752079697046},{"_id":"themes/next/scripts/filters/comment/default-config.js","hash":"1cb58aa6b88f7461c3c3f9605273686adcc30979","modified":1752079697045},{"_id":"themes/next/scripts/filters/comment/isso.js","hash":"c22cbccd7d514947e084eeac6a3af1aa41ec857a","modified":1752079697047},{"_id":"themes/next/scripts/filters/comment/utterances.js","hash":"a50718c081685fd35ff8ea9ca13682c284399ed8","modified":1752079697047},{"_id":"themes/next/scripts/filters/comment/gitalk.js","hash":"96e58efba0dc76af409cc7d2db225f0fe4526ea8","modified":1752079697046},{"_id":"themes/next/scripts/filters/comment/livere.js","hash":"bb8ebb541c40362c0cbbd8e83d3b777302bb6c40","modified":1752079697047},{"_id":"themes/next/source/css/_common/outline/index.styl","hash":"7782dfae7a0f8cd61b936fa8ac980440a7bbd3bb","modified":1752079697067},{"_id":"themes/next/source/css/_common/outline/mobile.styl","hash":"883a4f42badb7b206604eb2805ae582c3a511403","modified":1752079697067},{"_id":"themes/next/source/css/_common/components/index.styl","hash":"49c3063b46d65796003a822deed971abee41675e","modified":1752079697056},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"f882924c7b99afc23106e39164516888b2972c7b","modified":1752079697056},{"_id":"themes/next/source/css/_common/components/reading-progress.styl","hash":"f3defd56be33dba4866a695396d96c767ce63182","modified":1752079697062},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"ce25cb35779f29d01f7b7fc51ee09e68987ad318","modified":1752079697079},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"0951dfc96a5c4aca904142e7f1e57e2ad2dd2e10","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/buttons.styl","hash":"f768ecb2fe3e9384777c1c115cd7409e9155edd7","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/comments.styl","hash":"cf8446f4378dcab27b55ede1635c608ae6b8a5c8","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/index.styl","hash":"43045d115f8fe95732c446aa45bf1c97609ff2a5","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"6d740699fb6a7640647a8fd77c4ea4992d8d6437","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/pagination.styl","hash":"fd4a2d2303f107a021837aa6e3d977c2f9d14c42","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/toggles.styl","hash":"b9322d644b2090d793521555646673322f2dd5e8","modified":1752079697078},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"b9388016f8d9274703e77e306a1feaad1b7b9d6c","modified":1752079697075},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"be9d0e9493802c22f16a0645a59d0c2b556c1c3c","modified":1752079697080},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"0bf248d61593fbcdfd83b018b92199f4da3699b1","modified":1752079697080},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expand.styl","hash":"68f8d30071516913a7a958e01d010e8a93f7aa24","modified":1752079697081},{"_id":"themes/next/source/css/_schemes/Mist/_layout.styl","hash":"2db5ada757f7ffb9a36b06400cf30d80ec039b6e","modified":1752079697080},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"89bf3f6b82cb0fafbbd483431df8f450857c5a0b","modified":1752079697081},{"_id":"themes/next/source/css/_schemes/Muse/_header.styl","hash":"2f19fe2aba8f63fc99641e50bcb96cc9a4feb8a4","modified":1752079697081},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"e6e8892fccb02bff163d9b574984e0440a00d756","modified":1752079697082},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"b26770e09de9b51c851bb90fae19b27860e7fc9f","modified":1752079697082},{"_id":"themes/next/source/css/_schemes/Muse/_sidebar.styl","hash":"2fb4b3f88e34a8544436a05634690217f9483419","modified":1752079697082},{"_id":"themes/next/source/css/_schemes/Muse/_sub-menu.styl","hash":"2d3e05015796a790abd9d68957a5c698c0c9f9b6","modified":1752079697084},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"25c2a7930da14f023329df20f38df2728057fb4d","modified":1752079697084},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"3ab87229f9a8357446f77f05a0c6854fb5363fd5","modified":1752079697085},{"_id":"themes/next/source/css/_schemes/Pisces/_header.styl","hash":"36438f7b47d7ebd250a25f97c743fda484283046","modified":1752079697084},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"7a3b5cd21bc35d92358abb07fc0986722dd10881","modified":1752079697085},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"7125fb0dba920e89c3f7c1c07e2f7cce1fbdb703","modified":1752079697086},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b5c3dd08c520a16ee49f85fa12b4935e725ef261","modified":1752079697086},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"7905f428b46d100ac5928875cb1e2b99fa86fc0b","modified":1752079697086},{"_id":"themes/next/source/js/third-party/analytics/baidu-analytics.js","hash":"f9579a02599de063ccff336177ba964a2931a6e9","modified":1752079697095},{"_id":"themes/next/source/js/third-party/analytics/matomo.js","hash":"f24604710002234f18a7b5cfe9ccdf3ed6e725a8","modified":1752079697096},{"_id":"themes/next/source/js/third-party/chat/chatra.js","hash":"72e0766752b78a723fb30e92d533a8b353104e2d","modified":1752079697096},{"_id":"themes/next/source/js/third-party/analytics/growingio.js","hash":"f755e8537ccbbb0bd84c26923f320d4e206e7428","modified":1752079697096},{"_id":"themes/next/source/js/third-party/chat/tidio.js","hash":"77c231bcd64f1c09bd9989909e9fee703b65f47f","modified":1752079697096},{"_id":"themes/next/source/js/third-party/comments/changyan.js","hash":"b4cb06fdf531292e2361398a98d75a4ca2b8473a","modified":1752079697096},{"_id":"themes/next/source/js/third-party/comments/disqusjs.js","hash":"5673d28509a8e837a512da490a88b7bf5162fc49","modified":1752079697097},{"_id":"themes/next/source/js/third-party/analytics/google-analytics.js","hash":"27a27de3d4e0d33e9c647f7ae78e1dd6d36d2463","modified":1752079697095},{"_id":"themes/next/source/js/third-party/comments/gitalk.js","hash":"1e8509356fb027d948d118ab220d9631f4d482fa","modified":1752079697097},{"_id":"themes/next/source/js/third-party/comments/disqus.js","hash":"07e0038b221b9a4fd8ccac75093de3dee1f8315e","modified":1752079697097},{"_id":"themes/next/source/js/third-party/comments/isso.js","hash":"b9b9fd2f0e098a123b34a4932da912a9485ffe6c","modified":1752079697098},{"_id":"themes/next/source/js/third-party/comments/utterances.js","hash":"ec44d7f1c8b51b0aa3cccba099a78f3575ac828c","modified":1752079697098},{"_id":"themes/next/source/js/third-party/math/katex.js","hash":"5c63ec71458b4fe0cd98fd4a04e11c3746764f11","modified":1752079697099},{"_id":"themes/next/source/js/third-party/comments/livere.js","hash":"68892d74ef5fc308c6e7e6b4f190826d79f3055d","modified":1752079697098},{"_id":"themes/next/source/js/third-party/math/mathjax.js","hash":"d93556184b2c0aa1dbc4a6fb892d2f77b80d7d9f","modified":1752079697099},{"_id":"themes/next/source/js/third-party/statistics/firestore.js","hash":"ce12b5007c9aa997738641c06a1c081c357e27bd","modified":1752079697102},{"_id":"themes/next/source/js/third-party/statistics/lean-analytics.js","hash":"7db3233f0b33870943ce1547326a67f9e628b411","modified":1752079697103},{"_id":"themes/next/source/js/third-party/search/algolia-search.js","hash":"9486f0ba64182ce1a5b2524c10d02e0b992c7300","modified":1752079697101},{"_id":"themes/next/source/js/third-party/search/local-search.js","hash":"9f07ea758044afea0a293d75e6585ad65888fb71","modified":1752079697102},{"_id":"themes/next/source/js/third-party/tags/mermaid.js","hash":"5ef9da034f3ec3b5b66137101ddcff0b2687ed69","modified":1752079697103},{"_id":"themes/next/source/js/third-party/tags/pdf.js","hash":"e109c2d6828f527f0289d5fa3bb02fce63ee6d93","modified":1752079697103},{"_id":"themes/next/source/js/third-party/tags/wavedrom.js","hash":"9cafc8f751581d496f1f3c056b95f3b8e1ebbf4e","modified":1752079697104},{"_id":"themes/next/source/css/_common/outline/header/bookmark.styl","hash":"c8648c8ea3105556be0068d9fb2735261d0d94bc","modified":1752079697065},{"_id":"themes/next/source/css/_common/outline/header/index.styl","hash":"038625515ba4760e4dda6792549bddc0db5a3d20","modified":1752079697066},{"_id":"themes/next/source/css/_common/outline/footer/index.styl","hash":"39066b4e2e914d85736c9c33fa51f21a3f86c0e4","modified":1752079697065},{"_id":"themes/next/source/css/_common/outline/header/menu.styl","hash":"f4de9eb94bebdf7790522e103de51205a64cae9e","modified":1752079697066},{"_id":"themes/next/source/css/_common/outline/header/site-meta.styl","hash":"dce8ea62d7d7b08a0444fbb2f617be30bfcfc152","modified":1752079697067},{"_id":"themes/next/source/css/_common/outline/header/github-banner.styl","hash":"05af22f3edc2383a3d97ec4c05e9ac43b014bead","modified":1752079697066},{"_id":"themes/next/source/css/_common/outline/header/site-nav.styl","hash":"d9bc2b520636b9df7f946295cd430593df4118ff","modified":1752079697067},{"_id":"themes/next/source/css/_common/outline/sidebar/related-posts.styl","hash":"b3689beb90cda64cafecaf6b25981fe8a9525992","modified":1752079697068},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author-links.styl","hash":"63fb6d36d9ea62c7e39274c666e102b12f64ff77","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/index.styl","hash":"7a47adf10809dff5cbaa6732cf6aa273e4673fd0","modified":1752079697068},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-author.styl","hash":"d8a028f532d562e6a86bb3b9c7b992e4b6dbbb51","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-blogroll.styl","hash":"69869f1e317d78c03b3ef3a13e553d2c4ad04caf","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-button.styl","hash":"f5c1a6afcd2d460ccd5987ef1af747fc99d3ea72","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-copyright.styl","hash":"a6fbede106afe30a9a7918b52ea8233e020b1382","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-nav.styl","hash":"8f82d5141a18f6319e0609a3f6e4fcca6d442203","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toc.styl","hash":"cbc6b0938a2e60f35a5df32210904fb16e4938da","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/sidebar-toggle.styl","hash":"794eabec62d6070255fa10516487cff70e0030bf","modified":1752079697069},{"_id":"themes/next/source/css/_common/outline/sidebar/site-state.styl","hash":"2de038def2cb91da143b14696366c14a66e0e569","modified":1752079697071},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"f9fe39bef5fb2565abbffcb26390868c13d18359","modified":1752079697057},{"_id":"themes/next/source/css/_common/components/pages/index.styl","hash":"6cf78a379bb656cc0abb4ab80fcae60152ce41ad","modified":1752079697057},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"fde10ce94e9ae21a03b60d41d532835b54abdcb1","modified":1752079697057},{"_id":"themes/next/source/css/_common/components/pages/tag-cloud.styl","hash":"56d719bcdcba3d725141c55bbd4b168f3942f912","modified":1752079697058},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"091b8c763e43447d087c122a86538f290f83136a","modified":1752079697058},{"_id":"themes/next/source/css/_common/components/post/index.styl","hash":"aa04527f76de7646573ea327d4f6145200d6070d","modified":1752079697058},{"_id":"themes/next/source/css/_common/components/post/post-body.styl","hash":"9fe9eb46d11cc772e37c067fcffe1b8e7ae10c31","modified":1752079697059},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"c524d5990a8e7ed9caf17978cf372bb0646f7b9f","modified":1752079697059},{"_id":"themes/next/source/css/_common/components/post/post-followme.styl","hash":"a87245394f946b607852ddcffb6ef8d5ff9f6561","modified":1752079697059},{"_id":"themes/next/source/css/_common/components/post/post-footer.styl","hash":"8aff582c5b8e17b99ad61298192a9e6564409211","modified":1752079697060},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"c34936a17c3d8af6c0988ac6746d7509dc0b50eb","modified":1752079697060},{"_id":"themes/next/source/css/_common/components/post/post-header.styl","hash":"8798669728f20843b100dbea65c70247fe978efc","modified":1752079697060},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"69dff7cf231d01f85671758455726dd666664a73","modified":1752079697061},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"6ad0da4a5585508abbe78342a680607face98e19","modified":1752079697061},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"0a698c3adba896a46e26850967cb73295c521940","modified":1752079697062},{"_id":"themes/next/source/css/_common/components/third-party/disqusjs.styl","hash":"a2ffaa06c963514a79fda52665e707af6e8e2f5e","modified":1752079697063},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"406c03be3cf8a8411227bc1fecf942ca368f7e2a","modified":1752079697063},{"_id":"themes/next/source/css/_common/components/third-party/math.styl","hash":"1e5776ad4c5c8bcf7596ac74dcabc30704b3f5a0","modified":1752079697064},{"_id":"themes/next/source/css/_common/components/third-party/index.styl","hash":"8a7b70ef14c7110aaceb30ea2f7eb4b202f0f0cd","modified":1752079697063},{"_id":"themes/next/source/css/_common/components/third-party/search.styl","hash":"9394674b2c1e256ba93235c0dae492a8a3e850bb","modified":1752079697064},{"_id":"themes/next/source/css/_common/components/third-party/utterances.styl","hash":"d28856f365a9373c4ae6fe1e5673d63df2dfd65f","modified":1752079697064},{"_id":"themes/next/source/css/_common/scaffolding/highlight/copy-code.styl","hash":"4d674c513300187bd3c08ecaf60358107e91c41d","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/highlight/fold.styl","hash":"41c0516f76513036e30a70509a6d33e8a79bdba2","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/highlight/index.styl","hash":"79e246b65cef7e32bfe4b9d32516bad1f1eabda0","modified":1752079697072},{"_id":"themes/next/source/css/_common/scaffolding/tags/group-pictures.styl","hash":"8d9218980e185210ce034e9769ab639b9630fd88","modified":1752079697075},{"_id":"themes/next/source/css/_common/scaffolding/tags/index.styl","hash":"1772ade171aa6bd806909d69003cfc498c3af019","modified":1752079697075},{"_id":"themes/next/source/css/_common/scaffolding/tags/label.styl","hash":"531daf2612c6217950677a2d03924459ce57c291","modified":1752079697077},{"_id":"themes/next/source/css/_common/scaffolding/tags/link-grid.styl","hash":"7efdc07cf0311108c34fb8815eb890954757d351","modified":1752079697077},{"_id":"themes/next/source/css/_common/scaffolding/tags/mermaid.styl","hash":"c7754dc6c866928b538f0863a05b96ec44b5e986","modified":1752079697077},{"_id":"themes/next/source/css/_common/scaffolding/tags/note.styl","hash":"63910d15fa2b1df112aee0c4629955f157a077a4","modified":1752079697078},{"_id":"themes/next/source/css/_common/scaffolding/tags/blockquote-center.styl","hash":"6b3680e0dbea8e14c1cec24ef63b7fae5e37f7ef","modified":1752079697075},{"_id":"themes/next/source/css/_common/scaffolding/tags/pdf.styl","hash":"77122986509a6b4968bae2729417b7016137534c","modified":1752079697078},{"_id":"themes/next/source/css/_common/scaffolding/tags/tabs.styl","hash":"bcc0d3482f2faa4552d38de51480ea7f92f6c821","modified":1752079697078},{"_id":"themes/next/source/css/_common/scaffolding/tags/wavedrom.styl","hash":"2f4c791b5999b2e1a707bd473c1db7c21d206a27","modified":1752079697078},{"_id":"themes/next/source/images/favicon.jpg","hash":"ef2f732cc5072d26347e115d45d3899a9524d1a4","modified":1752079697089},{"_id":"source/img/Attention/Taxonomy.png","hash":"66d9f2b6baff13a690fecf3304ecad76fbfd354c","modified":1752290420903},{"_id":"source/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png","hash":"368e93a9832443fc2cdeedea46465d1ec1c2b94e","modified":1752079696968},{"_id":"source/paper/1609.02907v4.pdf","hash":"1762baa638866a13dcc6d146fd5a49b36cbd9c30","modified":1752203256886},{"_id":"source/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf","hash":"cc23c580b7d8063415fb6eb512053d1079b849de","modified":1752203256925},{"_id":"source/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png","hash":"860912fd44247e81e0a8c54b1ff3844d3ef41e0f","modified":1752079696989},{"_id":"source/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf","hash":"0c926dd126aa2e32816348ce95767a274e55d8ef","modified":1746022290566},{"_id":"source/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf","hash":"73f96bdf97da1cef4b43d9ee7e0d08a7900ab2fc","modified":1752203256919},{"_id":"public/search.xml","hash":"8de08217992b0581401e79113b987de3f2336d3f","modified":1752597551271},{"_id":"public/about/index.html","hash":"79a4ce9a042ec802277b846a88672f0dd7c80a89","modified":1752597551271},{"_id":"public/categories/index.html","hash":"c1ff6f9537444faa083e98b2832d959440460865","modified":1752597551271},{"_id":"public/tags/index.html","hash":"392c572d68cb286819966baba8c32f7f9daf2a2b","modified":1752597551271},{"_id":"public/2025/07/14/Feature-Related-Attention/index.html","hash":"556470b5fb2493217f307287f0f4c140b0e46aef","modified":1752597551271},{"_id":"public/2025/07/14/GAT/index.html","hash":"c579bd0135e8d3f1c55ef362d617e0414f21b53b","modified":1752597551271},{"_id":"public/2025/07/13/hwadee/index.html","hash":"f8ed8109061bafc5be915f1393e55544c037cae7","modified":1752597551271},{"_id":"public/2025/07/10/Attention/index.html","hash":"554a2d4bf8ed066b38bcb1ccaad2abc4100d7eeb","modified":1752597551271},{"_id":"public/2025/07/10/GNN-and-GCN/index.html","hash":"758f1519b287bc72b65a2c5aaf8192b78811bcdb","modified":1752597551271},{"_id":"public/2025/07/09/CDR-data-analysis/index.html","hash":"b247b9cb161236a664fdbacbc55e0cf632ff605d","modified":1752597551271},{"_id":"public/2025/07/08/PEP-8/index.html","hash":"a49fb91a9a2c3e382d34c5a180485956c1071997","modified":1752597551271},{"_id":"public/archives/index.html","hash":"71d3f27d4527b4319c30eed94c8b9fec2afede9d","modified":1752597551271},{"_id":"public/archives/2025/index.html","hash":"c88819998a750eb637fecd3fcb40389daad4be15","modified":1752597551271},{"_id":"public/archives/2025/07/index.html","hash":"24a6011584d547ae292d7470ae00742c7e559706","modified":1752597551271},{"_id":"public/index.html","hash":"eaf4751a71c5b5b4384517b8ace459fbdb846513","modified":1752597551271},{"_id":"public/categories/CDR/index.html","hash":"973be3ab27b2f0293832158198e6a705ac3f30b2","modified":1752597551271},{"_id":"public/categories/CDR/model/index.html","hash":"9c374b4be1730d460af9b5e97a1730a310c009b4","modified":1752597551271},{"_id":"public/categories/CDR/model/attention/index.html","hash":"44a39d9900814d70229d6be5aef03501ae3d57f1","modified":1752597551271},{"_id":"public/categories/CDR/model/GNN/index.html","hash":"72a2081528a5c9dcd9600cf1c38f81498eed85cf","modified":1752597551271},{"_id":"public/categories/CDR/model/attention/feature-related/index.html","hash":"dc8e14190c03f768a9236b6ce2fdc2ada8e8a0e6","modified":1752597551271},{"_id":"public/categories/Python/index.html","hash":"1e2728414776190adf2243afcdb848524c48374f","modified":1752597551271},{"_id":"public/categories/CDR/Data-Analysis/index.html","hash":"79cc3188e7dbf0379455d3ce9fe46fa2cd39e2d8","modified":1752597551271},{"_id":"public/tags/CDR/index.html","hash":"9d0e3f4b9010de689c0f4f9ccc677367f38fa5cb","modified":1752597551271},{"_id":"public/tags/model/index.html","hash":"e2b625200d5e992c9dd034afb6dd9c1857940668","modified":1752597551271},{"_id":"public/tags/Basic/index.html","hash":"67e3291b6ebf17e708f9e6e31d56e1b07a40bce6","modified":1752597551271},{"_id":"public/tags/deep-learning/index.html","hash":"8264ad463d20b154710b428f5a26bdf9d707c791","modified":1752597551271},{"_id":"public/tags/还没写完捏/index.html","hash":"8b3390bdc2947715e151c8970e968768f8cb6bce","modified":1752597551271},{"_id":"public/tags/embedding/index.html","hash":"7a6da8db517c10432724762fcbad494e4cee760d","modified":1752597551271},{"_id":"public/tags/PyTorch/index.html","hash":"409bfbd5b1a7e41c3f87f7828c7ba4b2b8fc6807","modified":1752597551271},{"_id":"public/tags/graph-theory/index.html","hash":"96b8e3341e573e3b0f44dfcde55df8b8a46c7a5f","modified":1752597551271},{"_id":"public/tags/Python/index.html","hash":"a2bbee7ff72a66cc22ea5c70b207ef325f1a380e","modified":1752597551271},{"_id":"public/tags/PEP/index.html","hash":"0991d7a6f36726cb20ee02e070d7f64798781f64","modified":1752597551271},{"_id":"public/tags/闲🉐无聊/index.html","hash":"ee38c869cb8e208cf34d7e999de7ed0d8dbf3349","modified":1752597551271},{"_id":"public/tags/大概率没用/index.html","hash":"e5b4bf5c611106c41b02912d61ae8b6d85352a77","modified":1752597551271},{"_id":"public/tags/Data-Analysis/index.html","hash":"e24412f9599c66aa3182c51d24884ae873449515","modified":1752597551271},{"_id":"public/tags/可能有点用/index.html","hash":"7719f14f6713d20eaf897f920d757b8f606755a0","modified":1752597551271},{"_id":"public/images/logo-algolia-nebula-blue-full.svg","hash":"5a81f1c5d66561b3bcb05dae48148088a3fb5c79","modified":1752597551271},{"_id":"public/images/avatar.gif","hash":"2dbc3e2f2d624b2ca1afe6edc2ca17307f1950c8","modified":1752597551271},{"_id":"public/CNAME","hash":"9f72a1c93d67b273a3f1b776b7607fca8ecb9800","modified":1752597551271},{"_id":"public/images/logo.svg","hash":"099e11ab995a2c8981427a85476d082609848c77","modified":1752597551271},{"_id":"public/images/favicon.jpg","hash":"ef2f732cc5072d26347e115d45d3899a9524d1a4","modified":1752597551271},{"_id":"public/img/CDR-data-analysis/gene.png","hash":"dac1e1481add33e6e471f62deb153719ff929a3a","modified":1752597551271},{"_id":"public/code/data_analysis/visualize_graph_analysis.py","hash":"f7ed9f01a38fe104b17464bf6e2dc7c5093ca7dc","modified":1752597551271},{"_id":"public/nodeppt/test/test_nodeppt.html","hash":"861eec2e1a66ee182a5a8ec962c2ad049e5d7908","modified":1752597551271},{"_id":"public/nodeppt/test/js/test_nodeppt.js.LICENSE.txt","hash":"d6fa3279c3fc7ec7562c7dcb614253f886938c32","modified":1752597551271},{"_id":"public/nodeppt/test/js/chunk-vendors.js","hash":"23c28d1f1615efdfe92ed6c634a9366a4aabb9b1","modified":1752597551271},{"_id":"public/nodeppt/test/js/chunk-vendors.js.LICENSE.txt","hash":"d6fa3279c3fc7ec7562c7dcb614253f886938c32","modified":1752597551271},{"_id":"public/nodeppt/test/js/test_nodeppt.js","hash":"a0d1819335072875ac9197f43d7c09511722a9c8","modified":1752597551271},{"_id":"public/css/main.css","hash":"32dc987f526288434e68c2ec2dbdd3e99a808bb4","modified":1752597551271},{"_id":"public/js/comments.js","hash":"66ae2e26ea36a41b72c638ea8b220296638ae952","modified":1752597551271},{"_id":"public/css/noscript.css","hash":"4cd5301e478e0e0d4b176740ec314087ec5cb707","modified":1752597551271},{"_id":"public/js/bookmark.js","hash":"9ba4cceafd12c6d5ba8a6b986a046ef8319a7811","modified":1752597551271},{"_id":"public/js/comments-buttons.js","hash":"1a7344440321713426a0b2ab17e276b5bdf85ade","modified":1752597551271},{"_id":"public/js/motion.js","hash":"6f751f5c9499a39d7c5e1d323db3260342dd9431","modified":1752597551271},{"_id":"public/js/next-boot.js","hash":"523bbaeda463e82ab0be428cc0005717038ec63e","modified":1752597551271},{"_id":"public/js/config.js","hash":"4c4ebbe3b3f3841a26f9d5af6d0ba8bc6da01c54","modified":1752597551271},{"_id":"public/js/sidebar.js","hash":"2ee359ae48273b01ba1e0768704524e08702c7eb","modified":1752597551271},{"_id":"public/js/utils.js","hash":"345a8158e6c34e19245a07c778f5699c8673f1b1","modified":1752597551271},{"_id":"public/js/third-party/fancybox.js","hash":"819f382c561fe5ec23c67cc5fabd63dd1cc22dc1","modified":1752597551271},{"_id":"public/js/third-party/addtoany.js","hash":"5276c8f78ee562a8965216dc67d762e59cb4a9f2","modified":1752597551271},{"_id":"public/js/schedule.js","hash":"a1333258726caf84f368a8f8454639c7dc1626bb","modified":1752597551271},{"_id":"public/js/pjax.js","hash":"694b271819aab37ce473b15db9e6aded971d82e5","modified":1752597551271},{"_id":"public/js/third-party/pace.js","hash":"0ef04218b93561ba4d0ff420d556c3d90a756d32","modified":1752597551271},{"_id":"public/js/third-party/analytics/baidu-analytics.js","hash":"f629acc46ff40c071ffd31b77d5c7616f0fdd778","modified":1752597551271},{"_id":"public/js/third-party/analytics/growingio.js","hash":"78dd3cf04082b7dbe6246e404b2aa8e726922402","modified":1752597551271},{"_id":"public/js/third-party/analytics/matomo.js","hash":"c6a25b26a1443caa70b47fd3dfa282271574deb5","modified":1752597551271},{"_id":"public/js/third-party/quicklink.js","hash":"eed02e6fced8e5a653077205d4d4d7834ca71472","modified":1752597551271},{"_id":"public/js/third-party/chat/tidio.js","hash":"b0079f6a4601e06ca6fe46e83a2f5af553e9bc3c","modified":1752597551271},{"_id":"public/js/third-party/comments/changyan.js","hash":"260d1a77d6a3bb33a579d3e4cca1997003e799b5","modified":1752597551271},{"_id":"public/js/third-party/chat/chatra.js","hash":"c32180522788c10e51df1803aa6842ef0432ddc9","modified":1752597551271},{"_id":"public/js/third-party/analytics/google-analytics.js","hash":"def07bcc7c17d8a0caad177fb1dd2f3a5e5b3536","modified":1752597551271},{"_id":"public/js/third-party/comments/gitalk.js","hash":"0ec038cf83e8ec067534f16a54041e47a3c1e59a","modified":1752597551271},{"_id":"public/js/third-party/comments/disqusjs.js","hash":"1e826dea3f684c0515f362dc1352447a1f0eae71","modified":1752597551271},{"_id":"public/js/third-party/comments/isso.js","hash":"753a873b6f566aff5ba77ca23f91b78eb880ca64","modified":1752597551271},{"_id":"public/js/third-party/comments/disqus.js","hash":"da361917d65e5dca8362f8cdeb6c8cc0e8316cec","modified":1752597551271},{"_id":"public/js/third-party/comments/utterances.js","hash":"f67f90eb03e284c82da2b8cf2f1e31801813c16d","modified":1752597551271},{"_id":"public/js/third-party/math/mathjax.js","hash":"5c749b9c1c3bb738122d0516211ecff6496d4907","modified":1752597551271},{"_id":"public/js/third-party/comments/livere.js","hash":"2247d88c934c765c43013337860774aaa99f0b31","modified":1752597551271},{"_id":"public/js/third-party/statistics/firestore.js","hash":"6e0682bb42170d61b13b786295f45f9c785f8b73","modified":1752597551271},{"_id":"public/js/third-party/statistics/lean-analytics.js","hash":"835cbf54c49ef1327f47df70ff2636ad36b6f57d","modified":1752597551271},{"_id":"public/js/third-party/search/algolia-search.js","hash":"1905978ef587bf08fe088ce4693a4c08db07cfbb","modified":1752597551271},{"_id":"public/js/third-party/tags/mermaid.js","hash":"df01075f52302873f7de36050b5408c8d1afb452","modified":1752597551271},{"_id":"public/js/third-party/math/katex.js","hash":"83c54ee536e487a1031783443fe0cb63b1b4767e","modified":1752597551271},{"_id":"public/js/third-party/search/local-search.js","hash":"3968d972f47b79acc6c3fe44028bad77c9c5aab7","modified":1752597551271},{"_id":"public/js/third-party/tags/pdf.js","hash":"af78c22f0e61c8c8aa8794e585e0d632c6d4fcb8","modified":1752597551271},{"_id":"public/js/third-party/tags/wavedrom.js","hash":"40dcd10df6edf124088c329346e0cc0bdac74ef1","modified":1752597551271},{"_id":"public/img/Attention/AttentionViaAttention.png","hash":"eee60186ed279182176b247f00e6243b707c54a6","modified":1752597551271},{"_id":"public/img/Attention/AlternatingCo-Attention.png","hash":"514aa65627d99a19c982ec47a9ebd8a66029d07f","modified":1752597551271},{"_id":"public/img/Attention/InteractiveCo-Attention.png","hash":"d66ad9309b6851348104b591f7a265f55ba4aae4","modified":1752597551271},{"_id":"public/img/Attention/MultiheadAttention.png","hash":"1d61e6a59d33b5b70521acf9b1e8b191d04a7278","modified":1752597551271},{"_id":"public/img/Attention/ParallelCo-Attention.png","hash":"1389f902e31640d6ff97a4375804b5b443706c02","modified":1752597551271},{"_id":"public/img/Attention/TotalModel.png","hash":"b9c32980245dcf7bb4e9e54b04b59ccaa14bf265","modified":1752597551271},{"_id":"public/nodeppt/test/css/chunk-vendors.4e4765ff.css","hash":"cb37dab7a01358273812ab41d4325c5c8e3c5af9","modified":1752597551271},{"_id":"public/img/Attention/HierarchicalAttention.png","hash":"ddad89428142f48353d6338f6d69402ec9b0d95e","modified":1752597551271},{"_id":"public/img/Attention/GeneralAttentionModule.png","hash":"9e9b439faf1e0e38564fc8eab3364f8e6938cf6e","modified":1752597551271},{"_id":"public/img/Attention/MultihopAttention.png","hash":"9bb72595c6b04f2157d01b069d004eaa94d71efa","modified":1752597551271},{"_id":"public/img/Attention/CapsuleAttention.png","hash":"8d29b9e962f65aea416727e5e0d321cf00e718f1","modified":1752597551271},{"_id":"public/img/Attention/Taxonomy.png","hash":"66d9f2b6baff13a690fecf3304ecad76fbfd354c","modified":1752597551271},{"_id":"public/paper/1609.02907v4.pdf","hash":"1762baa638866a13dcc6d146fd5a49b36cbd9c30","modified":1752597551271},{"_id":"public/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png","hash":"368e93a9832443fc2cdeedea46465d1ec1c2b94e","modified":1752597551271},{"_id":"public/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf","hash":"cc23c580b7d8063415fb6eb512053d1079b849de","modified":1752597551271},{"_id":"public/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png","hash":"860912fd44247e81e0a8c54b1ff3844d3ef41e0f","modified":1752597551271},{"_id":"public/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf","hash":"0c926dd126aa2e32816348ce95767a274e55d8ef","modified":1752597551271},{"_id":"public/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf","hash":"73f96bdf97da1cef4b43d9ee7e0d08a7900ab2fc","modified":1752597551271}],"Category":[{"name":"CDR","_id":"cmd4rbxvo0004k841gmbb2odl"},{"name":"model","parent":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxvr000bk841ea5c4at0"},{"name":"attention","parent":"cmd4rbxvr000bk841ea5c4at0","_id":"cmd4rbxvt000ik841glsz2ph2"},{"name":"GNN","parent":"cmd4rbxvr000bk841ea5c4at0","_id":"cmd4rbxvt000mk841h6ko6e9n"},{"name":"feature related","parent":"cmd4rbxvt000ik841glsz2ph2","_id":"cmd4rbxvu000sk841fpgc720o"},{"name":"Python","_id":"cmd4rbxvy001qk841f99m205s"},{"name":"Data Analysis","parent":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxw0001vk841cykw32ba"}],"Data":[],"Page":[{"title":"What is it","date":"2025-07-07T08:26:04.000Z","_content":"\n> ——为了纪念自己已经死去的表达能力\n\n这是一个什么都有可能往里面塞的博客，但本人的意愿大致如下：\n\n1. 记录自己的 *CDR奇妙生活*\n2. 发现有 *大病* 的东西记录以绷住\n3. 作为 *UESTCer* 记录一些难绷小事","source":"about/index.md","raw":"---\ntitle: What is it\ndate: 2025-07-07 16:26:04\n---\n\n> ——为了纪念自己已经死去的表达能力\n\n这是一个什么都有可能往里面塞的博客，但本人的意愿大致如下：\n\n1. 记录自己的 *CDR奇妙生活*\n2. 发现有 *大病* 的东西记录以绷住\n3. 作为 *UESTCer* 记录一些难绷小事","updated":"2025-07-09T16:48:16.959Z","path":"about/index.html","comments":1,"layout":"page","_id":"cmd4rbxvj0000k8413hzi3lfh","content":"<blockquote>\n<p>——为了纪念自己已经死去的表达能力</p>\n</blockquote>\n<p>这是一个什么都有可能往里面塞的博客，但本人的意愿大致如下：</p>\n<ol>\n<li>记录自己的 <em>CDR奇妙生活</em></li>\n<li>发现有 <em>大病</em> 的东西记录以绷住</li>\n<li>作为 <em>UESTCer</em> 记录一些难绷小事</li>\n</ol>\n","length":79,"excerpt":"","more":"<blockquote>\n<p>——为了纪念自己已经死去的表达能力</p>\n</blockquote>\n<p>这是一个什么都有可能往里面塞的博客，但本人的意愿大致如下：</p>\n<ol>\n<li>记录自己的 <em>CDR奇妙生活</em></li>\n<li>发现有 <em>大病</em> 的东西记录以绷住</li>\n<li>作为 <em>UESTCer</em> 记录一些难绷小事</li>\n</ol>\n"},{"title":"categories","date":"2025-07-05T16:25:00.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2025-07-06 00:25:00\ntype: \"categories\"\n---\n","updated":"2025-07-09T16:48:16.960Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cmd4rbxvm0002k84122khat8a","content":"","length":0,"excerpt":"","more":""},{"title":"tags","date":"2025-07-09T16:33:53.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2025-07-10 00:33:53\ntype: \"tags\"\n---\n","updated":"2025-07-09T16:48:16.989Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cmd4rbxvy001ok841el56ckcx","content":"","length":0,"excerpt":"","more":""}],"Post":[{"title":"Feature-Related Attention","date":"2025-07-14T14:30:57.000Z","_content":"\n# 在输入特征上做文章的 Attention\n\n本文将接着详细说明一种基于输入特征分类 Attention 的方式，并介绍在这种分类方式下关注到的不同的 Attention 的架构。\n\n具体来说，本文主要探讨了基于输入特征特性的注意力机制变体。本节根据输入特征的不同特性，将特征相关的注意力机制分为三类：特征多重性(Multiplicity of Features)、特征层级(Levels of Features)和特征表示(Feature Representations)。\n\n在阅读这篇博客前请先阅读 {% post_link Attention %}\n\n<!-- more -->\n\n## 特征多重性(Multiplicity of Features)\n\n这部分讨论了如何处理多个输入源的特征，主要分为单一特征注意力和多特征注意力机制。\n\n### 单一特征注意力(Singular Features Attention)\n\n大多数任务模型只处理单一输入(如图像、句子或声音序列)，使用单一特征注意力机制。这种机制直接对单个输入的特征向量进行注意力计算。\n\n### 多特征注意力机制\n\n当模型需要同时处理多个输入源时，需要特殊的多特征注意力机制：\n\n**协同注意力(Co-attention)**\n\n- 分为 **粗科粒度(Coarse-grained)** 和 **细颗粒度(Fine-grained)** 两种\n- **粗颗粒度协同**注意力使用一个输入的*紧凑表示*作为查询来关注另一个输入\n- **细颗粒度协同**注意力使用一个输入的所有特征向量作为查询\n\n#### 粗颗粒度协同\n\n论文给出的粗颗粒度协同的实例是**alternating co-attention**\n\n##### alternating co-attention\n\n<img src=\"/img/Attention/AlternatingCo-Attention.png\" alt=\"alternating co-attention\" width=\"60%\" height=\"auto\">\n\n如上图所示，这是 alternating co-attention 的架构图，该机制交替使用两个输入的特征矩阵，先计算第一个输入的注意力，将其上下文向量作为查询计算第二个输入的注意力，然后再用第二个输入的上下文向量重新计算第一个输入的注意力。\n\n这里现给出他的 score 函数\n\n对于有序列输入的 Attention：\n\n$$\n\\mathrm{score}(\\underset{d\\_{q}\\times1}{\\boldsymbol{q}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{l}})=\\underset{1\\times d\\_{w}}{\\boldsymbol{w}^{T}}\\times\\mathrm{act}(\\underset{d\\_{w}\\times d\\_{q}}{\\boldsymbol{W}\\_{1}}\\times\\underset{d\\_{q}\\times1}{\\boldsymbol{q}}+\\underset{d\\_{w}\\times d\\_{k}}{\\boldsymbol{W}\\_{2}}\\times\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{l}}+\\underset{d\\_{w}\\times1}{\\boldsymbol{b}})\n$$\n\n对于无序列输入的 Attention ~~（这是一种自注意力机制，后面会提到）~~ ：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(0)}}=\\underset{1\\times d\\_{w}}{\\boldsymbol{w}^{(1)T}}\\times\\operatorname{act}(\\underset{d\\_{w}\\times d\\_{k}^{(1)}}{\\boldsymbol{W}^{(1)}}\\times\\underset{d\\_{k}^{(1)}\\times1}{\\boldsymbol{k}\\_{l}^{(1)}}+\\underset{d\\_{w}\\times1}{\\boldsymbol{b}^{(1)}})\n$$\n\n对于第二层 Attention：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(2)}}=\\mathrm{score}(\\underset{d\\_{v}^{(1)}\\times 1}{\\boldsymbol{c}^{(0)}},\\underset{d\\_{k}^{(2)}\\times1}{\\boldsymbol{k}\\_{l}^{(2)}})\n$$\n\n对于第三层 Attention：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(1)}}=\\mathrm{score}(\\underset{d\\_{v}^{(2)}\\times 1}{\\boldsymbol{c}^{(2)}},\\underset{d\\_{k}^{(1)}\\times1}{\\boldsymbol{k}\\_{l}^{(1)}})\n$$\n\n生成的上下文向量$\\boldsymbol{c}^{(1)}$和$\\boldsymbol{c}^{(2)}$被连接起来，并在输出模型中用于预测。交替协同注意力由于需要一个接一个地计算上下文向量，因此本质上包含了*一种顺序性*。这可能会带来计算上的劣势，因为*无法并行*化。\n\n##### interactive co-attention\n\n<img src=\"/img/Attention/InteractiveCo-Attention.png\" alt=\"interactive co-attention\" width=\"60%\" height=\"auto\">\n\n- 并行计算两个输入的注意力\n- 使用未加权平均的关键向量作为查询\n- 计算效率更高，可以并行处理\n\n$$\n\\underset{d\\_k^{(i)}\\times1}{\\bar{\\boldsymbol{k}}^{(i)}}=\\frac{1}{n\\_f^{(i)}}\\sum\\limits\\_{l=1}^{n\\_f^{(i)}}\\underset{d\\_k^{(i)}\\times1}{\\boldsymbol{k}\\_l^{(i)}}, \\quad \\underset{1\\times1}{e\\_{l}^{(i)}}=\\mathrm{score}(\\underset{d\\_{k}^{(3-i)}\\times1}{\\bar{\\boldsymbol{k}}^{(3-i)}},\\underset{d\\_{k}^{(i)}\\times1}{\\boldsymbol{k}\\_{l}^{(i)}}) , \\qquad i=1,2\n$$\n\n#### 细颗粒度协同\n\n虽然粗粒度的共同注意力机制使用一个输入的紧凑表示作为查询，以计算另一个输入的注意力，但细粒度的共同注意力在计算注意力分数时会单独考虑每个输入的每个元素。在这种情况下，查询变成了一个矩阵。\n\n##### 并行协同注意力(Parallel Co-attention)\n\n<img src=\"/img/Attention/ParallelCo-Attention.png\" alt=\"parallel co-attention\" width=\"60%\" height=\"auto\">\n\n- 同时计算两个输入的注意力\n- 使用亲和矩阵(Affinity Matrix)转换关键向量空间\n- 通过聚合形式计算注意力分数\n\n我们有两种方式生成矩阵 $\\mathbf{A}$\n\n$$\n\\underset{n\\_{f}^{(1)}\\times n\\_{f}^{(2)}}{\\mathbf{A}}=\\operatorname{act}(\\underset{n\\_{f}^{(1)}\\times d\\_{k}^{(1)}}{\\begin{array}{c}K^{(1)^{T}}\\end{array}}\\times\\underset{d\\_{k}^{(1)}\\times d\\_{k}^{(2)}}{\\begin{array}{c}W\\_{A}\\end{array}}\\times\\underset{d\\_{k}^{(2)}\\times n\\_{f}^{(2)}}{\\begin{array}{c}K^{(2)}\\end{array}})\n$$\n\n$$\n\\underset{1\\times1}{A\\_{i,j}}=\\underset{1\\times3d\\_{k}}{\\boldsymbol{w}\\_{A}^{T}}\\times\\mathrm{concat}(\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{i}^{(1)}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{j}^{(2)}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{i}^{(1)}}\\circ\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{j}^{(2)}})\n$$\n\n其中，$\\circ$表示哈德曼积\n\nAffinity Matrix 可以解释为两个键矩阵列的相似性矩阵，并有助于将图像键转换到与句子中单词的键相同的空间，反之亦然。\n\n由于现在查询由向量变成了矩阵，因此 score 函数也发生了变化\n\n$$\ne^{(1)} =\\boldsymbol{w}\\_{1}\\times\\mathrm{act}(\\boldsymbol{W}\\_{2}\\times\\boldsymbol{K}^{(2)}\\times\\boldsymbol{A}^{T}+\\boldsymbol{W}\\_{1}\\times\\boldsymbol{K}^{(1)})\n$$\n\n$$\ne^{(2)} =\\boldsymbol{w}\\_{2}\\times\\mathrm{act}(\\boldsymbol{W}\\_{1}\\times\\boldsymbol{K}^{(1)}\\times\\boldsymbol{A}^{\\:\\:}+\\boldsymbol{W}\\_{2}\\times\\boldsymbol{K}^{(2)})\n$$\n\n值得一提的是，之前的 score 函数实际是现在这一形式的特殊表达，也就是说，这个表达更具一般性\n\n如前所述，亲和矩阵本质上是两个注意力模块 1 和 2 的关键向量的相似性矩阵。这个意味着一种不同的确定注意力分数的方法。即，可以将一行或一列中的最大相似度值作为注意力分数。\n\n$$\ne\\_{i}^{(1)}=\\max\\_{j=1,\\ldots,n\\_{f}^{(2)}}A\\_{i,j},\\quad e\\_{j}^{(2)}=\\max\\_{i=1,\\ldots,n\\_{f}^{(1)}}A\\_{i,j}.\n$$\n\n##### 旋转注意力(Rotatory Attention)\n\nRotatory Attention 是一种用于处理多输入数据的注意力机制，特别适用于情感分析任务中同时考虑目标短语、左上下文和右上下文的场景。该机制通过交替关注不同输入来构建更丰富的表示。\n\n- 主要用于情感分析任务\n- 处理三个输入：目标短语 $\\boldsymbol{F}^{t} = [ \\boldsymbol{f}\\_{1}^{t}, \\ldots , \\boldsymbol{f}\\_{n\\_{f}^{t}}^{t}] \\in \\mathbb{R} ^{d\\_{f}^{t}\\times n\\_{f}^{t}}$ 、左上下文 $F^{l} = [ f\\_{1}^{l}, \\ldots , f\\_{n\\_{f}^{l}}^{l}]\\in\\mathbb{R} ^{d\\_{f}^{l}\\times n\\_{f}^{l}}$ 和右上下文 $F^{r} = [ f\\_{1}^{r}, \\ldots , f\\_{n\\_{f}^{r}}^{r}]\\in\\mathbb{R}^{d\\_f^r\\times n\\_f^r}$\n- 通过注意力机制迭代改进表示\n\n其大致的过程如下：\n\n1. **初始特征提取**\n\n   首先，模型从三个输入中提取特征向量：\n\n   - 目标短语特征矩阵：$F^{t}=[f\\_{1}^{t},\\ldots,f\\_{n\\_{f}^{t}}^{t}]\\in R^{d\\_{f}^{t}\\times n\\_{f}^{t}}$\n   - 左上下文特征矩阵：$F^{l}=[f\\_{1}^{l},\\ldots,f\\_{n\\_{f}^{l}}^{l}]\\in R^{d\\_{f}^{l}\\times n\\_{f}^{l}}$\n   - 右上下文特征矩阵：$F^{r}=[f\\_{1}^{r},\\ldots,f\\_{n\\_{f}^{r}}^{r}]\\in R^{d\\_{f}^{r}\\times n\\_{f}^{r}}$\n\n2. **目标短语初始表示**\n\n   计算目标短语的初始表示向量$r^{t}$，通过对特征向量取平均：\n\n   $$\n   r^{t}=\\frac{1}{n\\_{f}^{t}}\\sum\\_{i=1}^{n\\_{f}^{t}} f\\_{i}^{t}\n   $$\n\n3. **左上下文注意力计算**\n\n   使用$r^{t}$作为查询，计算左上下文的注意力：\n\n   1. 提取键向量 $k\\_{1}^{l},\\ldots,k\\_{n\\_{f}^{l}}^{l}\\in R^{d\\_{k}^{l}}$ 和值向量 $v\\_{1}^{l},\\ldots,v\\_{n\\_{f}^{l}}^{l}\\in R^{d\\_{v}^{l}}$\n\n   2. 计算注意力分数 $e\\_{i}^{l}=\\operatorname{score}\\left(r^{t}, k\\_{i}^{l}\\right)$\n\n   3. 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{l}$\n\n   4. 计算左上下文表示向量 $r^{l}=\\sum\\_{i=1}^{n\\_{f}^{l}} a\\_{i}^{l}v\\_{i}^{l}$\n\n4. **右上下文注意力计算**\n\n   类似地，计算右上下文的表示向量$r^{r}$：\n\n   1. 提取键向量 $k\\_{1}^{r},\\ldots,k\\_{n\\_{f}^{r}}^{r}\\in R^{d\\_{k}^{r}}$ 和值向量 $v\\_{1}^{r},\\ldots,v\\_{n\\_{f}^{r}}^{r}\\in R^{d\\_{v}^{r}}$\n\n   2. 计算注意力分数 $e\\_{i}^{r}=\\operatorname{score}\\left(r^{t}, k\\_{i}^{r}\\right)$\n\n   3. 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{r}$\n\n   4. 计算右上下文表示向量 $r^{r}=\\sum\\_{i=1}^{n\\_{f}^{r}} a\\_{i}^{r}v\\_{i}^{r}$\n\n5. **目标短语更新表示**\n\n   使用左上下文表示$r^{l}$和右上下文表示$r^{r}$来更新目标短语的表示：\n\n   1. 提取目标短语的键向量 $k\\_{1}^{t},\\ldots,k\\_{n\\_{f}^{t}}^{t}\\in R^{d\\_{k}^{t}}$ 和值向量 $v\\_{1}^{t},\\ldots,v\\_{n\\_{f}^{t}}^{t}\\in R^{d\\_{v}^{t}}$\n\n   2. 计算左感知目标表示$r^{l\\_{t}}$：\n\n      - 注意力分数：$e\\_{i}^{l\\_{t}}=\\operatorname{score}\\left(r^{l}, k\\_{i}^{t}\\right)$\n      - 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{l\\_{t}}$\n      - 计算表示向量：$r^{l\\_{t}}=\\sum\\_{i=1}^{n\\_{f}^{t}} a\\_{i}^{l\\_{t}}v\\_{i}^{t}$\n\n   3. 计算右感知目标表示$r^{r\\_{t}}$：\n\n      - 注意力分数：$e\\_{i}^{r\\_{t}}=\\operatorname{score}\\left(r^{r}, k\\_{i}^{t}\\right)$\n      - 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{r\\_{t}}$\n      - 计算表示向量：$r^{r\\_{t}}=\\sum\\_{i=1}^{n\\_{f}^{t}} a\\_{i}^{r\\_{t}}v\\_{i}^{t}$\n\n6. 最终表示为 $r=\\operatorname{concat}\\left(r^{l},r^{r},r^{l\\_{t}},r^{r\\_{t}}\\right)$\n\nRotatory Attention 具有以下特点：\n\n1. **双向信息流动**：通过从目标短语到上下文，再从上下文回到目标短语的信息流动，实现了双向的信息交互。\n\n2. **层次化表示**：构建了多层次的特征表示，从原始特征到上下文感知特征。\n\n3. **特定任务优化**：特别适合情感分析任务，能够捕捉目标短语与上下文之间的复杂关系。\n\nRotatory Attention 通过这种交替关注的方式，能够更好地理解目标短语在特定上下文中的情感倾向，从而提高了情感分类的准确性。\n\n## 特征层级(Levels of Features)\n\n这部分讨论了如何处理具有层级结构的特征，主要分为单层级注意力和多层级注意力机制。\n\n### 单层级注意力(Single-Level Attention)\n\n传统注意力机制通常在单一层级上处理特征，如只关注单词级别或句子级别。\n\n### 多层级注意力机制\n\n1. **注意力叠加(Attention-via-Attention)**\n\n<img src=\"img/Attention/AttentionViaAttention.png\" alt=\"attention-via-attention\" width=\"60%\" height=\"auto\">\n\n- 同时处理字符级和词级特征\n- 先计算词级注意力，用其上下文向量辅助计算字符级注意力\n- 最终拼接两个层级的上下文向量\n\n2. **层级注意力(Hierarchical Attention)**\n\n<img src=\"img/Attention/HierarchicalAttention.png\" alt=\"hierarchical attention\" width=\"60%\" height=\"auto\">\n\n- 从最低层级开始，逐步构建高层级表示\n- 常用于文档分类：词 → 句 → 文档\n- 每个层级通过注意力机制生成摘要表示\n\n## 特征表示(Feature Representations)\n\n这部分讨论了特征表示方式的注意力机制变体，主要分为单一表示注意力和多表示注意力。\n\n### 单一表示注意力(Single-Representational Attention)\n\n传统方法使用单一嵌入或表示模型生成特征表示。\n\n### 多表示注意力(Multi-Representational Attention)\n\n1. **元嵌入(Meta-embeddings)**\n\n   - 整合多个嵌入表示\n   - 通过注意力机制加权平均不同表示\n   - 生成更高质量的特征表示\n\n2. **自注意力机制**\n   - 学习特征向量之间的关系\n   - 通过注意力改进特征表示\n   - 常用于 Transformer 架构中\n\n## 应用领域\n\n3.1 节讨论的特征相关注意力机制在多个领域有广泛应用：\n\n- 医学数据分析(多特征协同注意力)\n- 推荐系统(多层级注意力)\n- 情感分析(旋转注意力)\n- 文档分类(层级注意力)\n- 多语言处理(多表示注意力)\n\n## 总结\n\n3.1 节系统性地分类了基于输入特征特性的注意力机制变体，为研究者提供了清晰的框架来选择适合特定任务和数据类型的最佳注意力机制。这些机制通过充分利用输入特征的多重性、层级结构和表示多样性，显著提升了模型在各种任务上的表现。\n\n图 3 展示了完整的注意力机制分类体系，其中 3.1 节讨论的特征相关注意力机制是该体系的重要组成部分。\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers 和 Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>\n\n{% post_link Attention %}\n","source":"_posts/Feature-Related-Attention.md","raw":"---\ntitle: Feature-Related Attention\ndate: 2025-07-14 22:30:57\ncategories:\n  - CDR\n  - model\n  - attention\n  - feature related\ntags:\n  - CDR\n  - model\n  - Basic\n  - deep learning\n  - 还没写完捏\n---\n\n# 在输入特征上做文章的 Attention\n\n本文将接着详细说明一种基于输入特征分类 Attention 的方式，并介绍在这种分类方式下关注到的不同的 Attention 的架构。\n\n具体来说，本文主要探讨了基于输入特征特性的注意力机制变体。本节根据输入特征的不同特性，将特征相关的注意力机制分为三类：特征多重性(Multiplicity of Features)、特征层级(Levels of Features)和特征表示(Feature Representations)。\n\n在阅读这篇博客前请先阅读 {% post_link Attention %}\n\n<!-- more -->\n\n## 特征多重性(Multiplicity of Features)\n\n这部分讨论了如何处理多个输入源的特征，主要分为单一特征注意力和多特征注意力机制。\n\n### 单一特征注意力(Singular Features Attention)\n\n大多数任务模型只处理单一输入(如图像、句子或声音序列)，使用单一特征注意力机制。这种机制直接对单个输入的特征向量进行注意力计算。\n\n### 多特征注意力机制\n\n当模型需要同时处理多个输入源时，需要特殊的多特征注意力机制：\n\n**协同注意力(Co-attention)**\n\n- 分为 **粗科粒度(Coarse-grained)** 和 **细颗粒度(Fine-grained)** 两种\n- **粗颗粒度协同**注意力使用一个输入的*紧凑表示*作为查询来关注另一个输入\n- **细颗粒度协同**注意力使用一个输入的所有特征向量作为查询\n\n#### 粗颗粒度协同\n\n论文给出的粗颗粒度协同的实例是**alternating co-attention**\n\n##### alternating co-attention\n\n<img src=\"/img/Attention/AlternatingCo-Attention.png\" alt=\"alternating co-attention\" width=\"60%\" height=\"auto\">\n\n如上图所示，这是 alternating co-attention 的架构图，该机制交替使用两个输入的特征矩阵，先计算第一个输入的注意力，将其上下文向量作为查询计算第二个输入的注意力，然后再用第二个输入的上下文向量重新计算第一个输入的注意力。\n\n这里现给出他的 score 函数\n\n对于有序列输入的 Attention：\n\n$$\n\\mathrm{score}(\\underset{d\\_{q}\\times1}{\\boldsymbol{q}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{l}})=\\underset{1\\times d\\_{w}}{\\boldsymbol{w}^{T}}\\times\\mathrm{act}(\\underset{d\\_{w}\\times d\\_{q}}{\\boldsymbol{W}\\_{1}}\\times\\underset{d\\_{q}\\times1}{\\boldsymbol{q}}+\\underset{d\\_{w}\\times d\\_{k}}{\\boldsymbol{W}\\_{2}}\\times\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{l}}+\\underset{d\\_{w}\\times1}{\\boldsymbol{b}})\n$$\n\n对于无序列输入的 Attention ~~（这是一种自注意力机制，后面会提到）~~ ：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(0)}}=\\underset{1\\times d\\_{w}}{\\boldsymbol{w}^{(1)T}}\\times\\operatorname{act}(\\underset{d\\_{w}\\times d\\_{k}^{(1)}}{\\boldsymbol{W}^{(1)}}\\times\\underset{d\\_{k}^{(1)}\\times1}{\\boldsymbol{k}\\_{l}^{(1)}}+\\underset{d\\_{w}\\times1}{\\boldsymbol{b}^{(1)}})\n$$\n\n对于第二层 Attention：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(2)}}=\\mathrm{score}(\\underset{d\\_{v}^{(1)}\\times 1}{\\boldsymbol{c}^{(0)}},\\underset{d\\_{k}^{(2)}\\times1}{\\boldsymbol{k}\\_{l}^{(2)}})\n$$\n\n对于第三层 Attention：\n\n$$\n\\underset{1\\times1}{e\\_{l}^{(1)}}=\\mathrm{score}(\\underset{d\\_{v}^{(2)}\\times 1}{\\boldsymbol{c}^{(2)}},\\underset{d\\_{k}^{(1)}\\times1}{\\boldsymbol{k}\\_{l}^{(1)}})\n$$\n\n生成的上下文向量$\\boldsymbol{c}^{(1)}$和$\\boldsymbol{c}^{(2)}$被连接起来，并在输出模型中用于预测。交替协同注意力由于需要一个接一个地计算上下文向量，因此本质上包含了*一种顺序性*。这可能会带来计算上的劣势，因为*无法并行*化。\n\n##### interactive co-attention\n\n<img src=\"/img/Attention/InteractiveCo-Attention.png\" alt=\"interactive co-attention\" width=\"60%\" height=\"auto\">\n\n- 并行计算两个输入的注意力\n- 使用未加权平均的关键向量作为查询\n- 计算效率更高，可以并行处理\n\n$$\n\\underset{d\\_k^{(i)}\\times1}{\\bar{\\boldsymbol{k}}^{(i)}}=\\frac{1}{n\\_f^{(i)}}\\sum\\limits\\_{l=1}^{n\\_f^{(i)}}\\underset{d\\_k^{(i)}\\times1}{\\boldsymbol{k}\\_l^{(i)}}, \\quad \\underset{1\\times1}{e\\_{l}^{(i)}}=\\mathrm{score}(\\underset{d\\_{k}^{(3-i)}\\times1}{\\bar{\\boldsymbol{k}}^{(3-i)}},\\underset{d\\_{k}^{(i)}\\times1}{\\boldsymbol{k}\\_{l}^{(i)}}) , \\qquad i=1,2\n$$\n\n#### 细颗粒度协同\n\n虽然粗粒度的共同注意力机制使用一个输入的紧凑表示作为查询，以计算另一个输入的注意力，但细粒度的共同注意力在计算注意力分数时会单独考虑每个输入的每个元素。在这种情况下，查询变成了一个矩阵。\n\n##### 并行协同注意力(Parallel Co-attention)\n\n<img src=\"/img/Attention/ParallelCo-Attention.png\" alt=\"parallel co-attention\" width=\"60%\" height=\"auto\">\n\n- 同时计算两个输入的注意力\n- 使用亲和矩阵(Affinity Matrix)转换关键向量空间\n- 通过聚合形式计算注意力分数\n\n我们有两种方式生成矩阵 $\\mathbf{A}$\n\n$$\n\\underset{n\\_{f}^{(1)}\\times n\\_{f}^{(2)}}{\\mathbf{A}}=\\operatorname{act}(\\underset{n\\_{f}^{(1)}\\times d\\_{k}^{(1)}}{\\begin{array}{c}K^{(1)^{T}}\\end{array}}\\times\\underset{d\\_{k}^{(1)}\\times d\\_{k}^{(2)}}{\\begin{array}{c}W\\_{A}\\end{array}}\\times\\underset{d\\_{k}^{(2)}\\times n\\_{f}^{(2)}}{\\begin{array}{c}K^{(2)}\\end{array}})\n$$\n\n$$\n\\underset{1\\times1}{A\\_{i,j}}=\\underset{1\\times3d\\_{k}}{\\boldsymbol{w}\\_{A}^{T}}\\times\\mathrm{concat}(\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{i}^{(1)}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{j}^{(2)}},\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{i}^{(1)}}\\circ\\underset{d\\_{k}\\times1}{\\boldsymbol{k}\\_{j}^{(2)}})\n$$\n\n其中，$\\circ$表示哈德曼积\n\nAffinity Matrix 可以解释为两个键矩阵列的相似性矩阵，并有助于将图像键转换到与句子中单词的键相同的空间，反之亦然。\n\n由于现在查询由向量变成了矩阵，因此 score 函数也发生了变化\n\n$$\ne^{(1)} =\\boldsymbol{w}\\_{1}\\times\\mathrm{act}(\\boldsymbol{W}\\_{2}\\times\\boldsymbol{K}^{(2)}\\times\\boldsymbol{A}^{T}+\\boldsymbol{W}\\_{1}\\times\\boldsymbol{K}^{(1)})\n$$\n\n$$\ne^{(2)} =\\boldsymbol{w}\\_{2}\\times\\mathrm{act}(\\boldsymbol{W}\\_{1}\\times\\boldsymbol{K}^{(1)}\\times\\boldsymbol{A}^{\\:\\:}+\\boldsymbol{W}\\_{2}\\times\\boldsymbol{K}^{(2)})\n$$\n\n值得一提的是，之前的 score 函数实际是现在这一形式的特殊表达，也就是说，这个表达更具一般性\n\n如前所述，亲和矩阵本质上是两个注意力模块 1 和 2 的关键向量的相似性矩阵。这个意味着一种不同的确定注意力分数的方法。即，可以将一行或一列中的最大相似度值作为注意力分数。\n\n$$\ne\\_{i}^{(1)}=\\max\\_{j=1,\\ldots,n\\_{f}^{(2)}}A\\_{i,j},\\quad e\\_{j}^{(2)}=\\max\\_{i=1,\\ldots,n\\_{f}^{(1)}}A\\_{i,j}.\n$$\n\n##### 旋转注意力(Rotatory Attention)\n\nRotatory Attention 是一种用于处理多输入数据的注意力机制，特别适用于情感分析任务中同时考虑目标短语、左上下文和右上下文的场景。该机制通过交替关注不同输入来构建更丰富的表示。\n\n- 主要用于情感分析任务\n- 处理三个输入：目标短语 $\\boldsymbol{F}^{t} = [ \\boldsymbol{f}\\_{1}^{t}, \\ldots , \\boldsymbol{f}\\_{n\\_{f}^{t}}^{t}] \\in \\mathbb{R} ^{d\\_{f}^{t}\\times n\\_{f}^{t}}$ 、左上下文 $F^{l} = [ f\\_{1}^{l}, \\ldots , f\\_{n\\_{f}^{l}}^{l}]\\in\\mathbb{R} ^{d\\_{f}^{l}\\times n\\_{f}^{l}}$ 和右上下文 $F^{r} = [ f\\_{1}^{r}, \\ldots , f\\_{n\\_{f}^{r}}^{r}]\\in\\mathbb{R}^{d\\_f^r\\times n\\_f^r}$\n- 通过注意力机制迭代改进表示\n\n其大致的过程如下：\n\n1. **初始特征提取**\n\n   首先，模型从三个输入中提取特征向量：\n\n   - 目标短语特征矩阵：$F^{t}=[f\\_{1}^{t},\\ldots,f\\_{n\\_{f}^{t}}^{t}]\\in R^{d\\_{f}^{t}\\times n\\_{f}^{t}}$\n   - 左上下文特征矩阵：$F^{l}=[f\\_{1}^{l},\\ldots,f\\_{n\\_{f}^{l}}^{l}]\\in R^{d\\_{f}^{l}\\times n\\_{f}^{l}}$\n   - 右上下文特征矩阵：$F^{r}=[f\\_{1}^{r},\\ldots,f\\_{n\\_{f}^{r}}^{r}]\\in R^{d\\_{f}^{r}\\times n\\_{f}^{r}}$\n\n2. **目标短语初始表示**\n\n   计算目标短语的初始表示向量$r^{t}$，通过对特征向量取平均：\n\n   $$\n   r^{t}=\\frac{1}{n\\_{f}^{t}}\\sum\\_{i=1}^{n\\_{f}^{t}} f\\_{i}^{t}\n   $$\n\n3. **左上下文注意力计算**\n\n   使用$r^{t}$作为查询，计算左上下文的注意力：\n\n   1. 提取键向量 $k\\_{1}^{l},\\ldots,k\\_{n\\_{f}^{l}}^{l}\\in R^{d\\_{k}^{l}}$ 和值向量 $v\\_{1}^{l},\\ldots,v\\_{n\\_{f}^{l}}^{l}\\in R^{d\\_{v}^{l}}$\n\n   2. 计算注意力分数 $e\\_{i}^{l}=\\operatorname{score}\\left(r^{t}, k\\_{i}^{l}\\right)$\n\n   3. 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{l}$\n\n   4. 计算左上下文表示向量 $r^{l}=\\sum\\_{i=1}^{n\\_{f}^{l}} a\\_{i}^{l}v\\_{i}^{l}$\n\n4. **右上下文注意力计算**\n\n   类似地，计算右上下文的表示向量$r^{r}$：\n\n   1. 提取键向量 $k\\_{1}^{r},\\ldots,k\\_{n\\_{f}^{r}}^{r}\\in R^{d\\_{k}^{r}}$ 和值向量 $v\\_{1}^{r},\\ldots,v\\_{n\\_{f}^{r}}^{r}\\in R^{d\\_{v}^{r}}$\n\n   2. 计算注意力分数 $e\\_{i}^{r}=\\operatorname{score}\\left(r^{t}, k\\_{i}^{r}\\right)$\n\n   3. 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{r}$\n\n   4. 计算右上下文表示向量 $r^{r}=\\sum\\_{i=1}^{n\\_{f}^{r}} a\\_{i}^{r}v\\_{i}^{r}$\n\n5. **目标短语更新表示**\n\n   使用左上下文表示$r^{l}$和右上下文表示$r^{r}$来更新目标短语的表示：\n\n   1. 提取目标短语的键向量 $k\\_{1}^{t},\\ldots,k\\_{n\\_{f}^{t}}^{t}\\in R^{d\\_{k}^{t}}$ 和值向量 $v\\_{1}^{t},\\ldots,v\\_{n\\_{f}^{t}}^{t}\\in R^{d\\_{v}^{t}}$\n\n   2. 计算左感知目标表示$r^{l\\_{t}}$：\n\n      - 注意力分数：$e\\_{i}^{l\\_{t}}=\\operatorname{score}\\left(r^{l}, k\\_{i}^{t}\\right)$\n      - 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{l\\_{t}}$\n      - 计算表示向量：$r^{l\\_{t}}=\\sum\\_{i=1}^{n\\_{f}^{t}} a\\_{i}^{l\\_{t}}v\\_{i}^{t}$\n\n   3. 计算右感知目标表示$r^{r\\_{t}}$：\n\n      - 注意力分数：$e\\_{i}^{r\\_{t}}=\\operatorname{score}\\left(r^{r}, k\\_{i}^{t}\\right)$\n      - 使用 softmax 对齐函数计算注意力权重$a\\_{i}^{r\\_{t}}$\n      - 计算表示向量：$r^{r\\_{t}}=\\sum\\_{i=1}^{n\\_{f}^{t}} a\\_{i}^{r\\_{t}}v\\_{i}^{t}$\n\n6. 最终表示为 $r=\\operatorname{concat}\\left(r^{l},r^{r},r^{l\\_{t}},r^{r\\_{t}}\\right)$\n\nRotatory Attention 具有以下特点：\n\n1. **双向信息流动**：通过从目标短语到上下文，再从上下文回到目标短语的信息流动，实现了双向的信息交互。\n\n2. **层次化表示**：构建了多层次的特征表示，从原始特征到上下文感知特征。\n\n3. **特定任务优化**：特别适合情感分析任务，能够捕捉目标短语与上下文之间的复杂关系。\n\nRotatory Attention 通过这种交替关注的方式，能够更好地理解目标短语在特定上下文中的情感倾向，从而提高了情感分类的准确性。\n\n## 特征层级(Levels of Features)\n\n这部分讨论了如何处理具有层级结构的特征，主要分为单层级注意力和多层级注意力机制。\n\n### 单层级注意力(Single-Level Attention)\n\n传统注意力机制通常在单一层级上处理特征，如只关注单词级别或句子级别。\n\n### 多层级注意力机制\n\n1. **注意力叠加(Attention-via-Attention)**\n\n<img src=\"img/Attention/AttentionViaAttention.png\" alt=\"attention-via-attention\" width=\"60%\" height=\"auto\">\n\n- 同时处理字符级和词级特征\n- 先计算词级注意力，用其上下文向量辅助计算字符级注意力\n- 最终拼接两个层级的上下文向量\n\n2. **层级注意力(Hierarchical Attention)**\n\n<img src=\"img/Attention/HierarchicalAttention.png\" alt=\"hierarchical attention\" width=\"60%\" height=\"auto\">\n\n- 从最低层级开始，逐步构建高层级表示\n- 常用于文档分类：词 → 句 → 文档\n- 每个层级通过注意力机制生成摘要表示\n\n## 特征表示(Feature Representations)\n\n这部分讨论了特征表示方式的注意力机制变体，主要分为单一表示注意力和多表示注意力。\n\n### 单一表示注意力(Single-Representational Attention)\n\n传统方法使用单一嵌入或表示模型生成特征表示。\n\n### 多表示注意力(Multi-Representational Attention)\n\n1. **元嵌入(Meta-embeddings)**\n\n   - 整合多个嵌入表示\n   - 通过注意力机制加权平均不同表示\n   - 生成更高质量的特征表示\n\n2. **自注意力机制**\n   - 学习特征向量之间的关系\n   - 通过注意力改进特征表示\n   - 常用于 Transformer 架构中\n\n## 应用领域\n\n3.1 节讨论的特征相关注意力机制在多个领域有广泛应用：\n\n- 医学数据分析(多特征协同注意力)\n- 推荐系统(多层级注意力)\n- 情感分析(旋转注意力)\n- 文档分类(层级注意力)\n- 多语言处理(多表示注意力)\n\n## 总结\n\n3.1 节系统性地分类了基于输入特征特性的注意力机制变体，为研究者提供了清晰的框架来选择适合特定任务和数据类型的最佳注意力机制。这些机制通过充分利用输入特征的多重性、层级结构和表示多样性，显著提升了模型在各种任务上的表现。\n\n图 3 展示了完整的注意力机制分类体系，其中 3.1 节讨论的特征相关注意力机制是该体系的重要组成部分。\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers 和 Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>\n\n{% post_link Attention %}\n","slug":"Feature-Related-Attention","published":1,"updated":"2025-07-15T16:38:32.939Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvk0001k8419og6gjhk","content":"<h1 id=\"在输入特征上做文章的-Attention\"><a href=\"#在输入特征上做文章的-Attention\" class=\"headerlink\" title=\"在输入特征上做文章的 Attention\"></a>在输入特征上做文章的 Attention</h1><p>本文将接着详细说明一种基于输入特征分类 Attention 的方式，并介绍在这种分类方式下关注到的不同的 Attention 的架构。</p>\n<p>具体来说，本文主要探讨了基于输入特征特性的注意力机制变体。本节根据输入特征的不同特性，将特征相关的注意力机制分为三类：特征多重性(Multiplicity of Features)、特征层级(Levels of Features)和特征表示(Feature Representations)。</p>\n<p>在阅读这篇博客前请先阅读 <a href=\"/2025/07/10/Attention/\" title=\"Attention Overview\">Attention Overview</a></p>\n<span id=\"more\"></span>\n\n<h2 id=\"特征多重性-Multiplicity-of-Features\"><a href=\"#特征多重性-Multiplicity-of-Features\" class=\"headerlink\" title=\"特征多重性(Multiplicity of Features)\"></a>特征多重性(Multiplicity of Features)</h2><p>这部分讨论了如何处理多个输入源的特征，主要分为单一特征注意力和多特征注意力机制。</p>\n<h3 id=\"单一特征注意力-Singular-Features-Attention\"><a href=\"#单一特征注意力-Singular-Features-Attention\" class=\"headerlink\" title=\"单一特征注意力(Singular Features Attention)\"></a>单一特征注意力(Singular Features Attention)</h3><p>大多数任务模型只处理单一输入(如图像、句子或声音序列)，使用单一特征注意力机制。这种机制直接对单个输入的特征向量进行注意力计算。</p>\n<h3 id=\"多特征注意力机制\"><a href=\"#多特征注意力机制\" class=\"headerlink\" title=\"多特征注意力机制\"></a>多特征注意力机制</h3><p>当模型需要同时处理多个输入源时，需要特殊的多特征注意力机制：</p>\n<p><strong>协同注意力(Co-attention)</strong></p>\n<ul>\n<li>分为 <strong>粗科粒度(Coarse-grained)</strong> 和 <strong>细颗粒度(Fine-grained)</strong> 两种</li>\n<li><strong>粗颗粒度协同</strong>注意力使用一个输入的<em>紧凑表示</em>作为查询来关注另一个输入</li>\n<li><strong>细颗粒度协同</strong>注意力使用一个输入的所有特征向量作为查询</li>\n</ul>\n<h4 id=\"粗颗粒度协同\"><a href=\"#粗颗粒度协同\" class=\"headerlink\" title=\"粗颗粒度协同\"></a>粗颗粒度协同</h4><p>论文给出的粗颗粒度协同的实例是<strong>alternating co-attention</strong></p>\n<h5 id=\"alternating-co-attention\"><a href=\"#alternating-co-attention\" class=\"headerlink\" title=\"alternating co-attention\"></a>alternating co-attention</h5><img src=\"/img/Attention/AlternatingCo-Attention.png\" alt=\"alternating co-attention\" width=\"60%\" height=\"auto\">\n\n<p>如上图所示，这是 alternating co-attention 的架构图，该机制交替使用两个输入的特征矩阵，先计算第一个输入的注意力，将其上下文向量作为查询计算第二个输入的注意力，然后再用第二个输入的上下文向量重新计算第一个输入的注意力。</p>\n<p>这里现给出他的 score 函数</p>\n<p>对于有序列输入的 Attention：</p>\n<p>$$<br>\\mathrm{score}(\\underset{d_{q}\\times1}{\\boldsymbol{q}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{l}})&#x3D;\\underset{1\\times d_{w}}{\\boldsymbol{w}^{T}}\\times\\mathrm{act}(\\underset{d_{w}\\times d_{q}}{\\boldsymbol{W}_{1}}\\times\\underset{d_{q}\\times1}{\\boldsymbol{q}}+\\underset{d_{w}\\times d_{k}}{\\boldsymbol{W}_{2}}\\times\\underset{d_{k}\\times1}{\\boldsymbol{k}_{l}}+\\underset{d_{w}\\times1}{\\boldsymbol{b}})<br>$$</p>\n<p>对于无序列输入的 Attention <del>（这是一种自注意力机制，后面会提到）</del> ：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(0)}}&#x3D;\\underset{1\\times d_{w}}{\\boldsymbol{w}^{(1)T}}\\times\\operatorname{act}(\\underset{d_{w}\\times d_{k}^{(1)}}{\\boldsymbol{W}^{(1)}}\\times\\underset{d_{k}^{(1)}\\times1}{\\boldsymbol{k}_{l}^{(1)}}+\\underset{d_{w}\\times1}{\\boldsymbol{b}^{(1)}})<br>$$</p>\n<p>对于第二层 Attention：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(2)}}&#x3D;\\mathrm{score}(\\underset{d_{v}^{(1)}\\times 1}{\\boldsymbol{c}^{(0)}},\\underset{d_{k}^{(2)}\\times1}{\\boldsymbol{k}_{l}^{(2)}})<br>$$</p>\n<p>对于第三层 Attention：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(1)}}&#x3D;\\mathrm{score}(\\underset{d_{v}^{(2)}\\times 1}{\\boldsymbol{c}^{(2)}},\\underset{d_{k}^{(1)}\\times1}{\\boldsymbol{k}_{l}^{(1)}})<br>$$</p>\n<p>生成的上下文向量$\\boldsymbol{c}^{(1)}$和$\\boldsymbol{c}^{(2)}$被连接起来，并在输出模型中用于预测。交替协同注意力由于需要一个接一个地计算上下文向量，因此本质上包含了<em>一种顺序性</em>。这可能会带来计算上的劣势，因为<em>无法并行</em>化。</p>\n<h5 id=\"interactive-co-attention\"><a href=\"#interactive-co-attention\" class=\"headerlink\" title=\"interactive co-attention\"></a>interactive co-attention</h5><img src=\"/img/Attention/InteractiveCo-Attention.png\" alt=\"interactive co-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>并行计算两个输入的注意力</li>\n<li>使用未加权平均的关键向量作为查询</li>\n<li>计算效率更高，可以并行处理</li>\n</ul>\n<p>$$<br>\\underset{d_k^{(i)}\\times1}{\\bar{\\boldsymbol{k}}^{(i)}}&#x3D;\\frac{1}{n_f^{(i)}}\\sum\\limits_{l&#x3D;1}^{n_f^{(i)}}\\underset{d_k^{(i)}\\times1}{\\boldsymbol{k}_l^{(i)}}, \\quad \\underset{1\\times1}{e_{l}^{(i)}}&#x3D;\\mathrm{score}(\\underset{d_{k}^{(3-i)}\\times1}{\\bar{\\boldsymbol{k}}^{(3-i)}},\\underset{d_{k}^{(i)}\\times1}{\\boldsymbol{k}_{l}^{(i)}}) , \\qquad i&#x3D;1,2<br>$$</p>\n<h4 id=\"细颗粒度协同\"><a href=\"#细颗粒度协同\" class=\"headerlink\" title=\"细颗粒度协同\"></a>细颗粒度协同</h4><p>虽然粗粒度的共同注意力机制使用一个输入的紧凑表示作为查询，以计算另一个输入的注意力，但细粒度的共同注意力在计算注意力分数时会单独考虑每个输入的每个元素。在这种情况下，查询变成了一个矩阵。</p>\n<h5 id=\"并行协同注意力-Parallel-Co-attention\"><a href=\"#并行协同注意力-Parallel-Co-attention\" class=\"headerlink\" title=\"并行协同注意力(Parallel Co-attention)\"></a>并行协同注意力(Parallel Co-attention)</h5><img src=\"/img/Attention/ParallelCo-Attention.png\" alt=\"parallel co-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>同时计算两个输入的注意力</li>\n<li>使用亲和矩阵(Affinity Matrix)转换关键向量空间</li>\n<li>通过聚合形式计算注意力分数</li>\n</ul>\n<p>我们有两种方式生成矩阵 $\\mathbf{A}$</p>\n<p>$$<br>\\underset{n_{f}^{(1)}\\times n_{f}^{(2)}}{\\mathbf{A}}&#x3D;\\operatorname{act}(\\underset{n_{f}^{(1)}\\times d_{k}^{(1)}}{\\begin{array}{c}K^{(1)^{T}}\\end{array}}\\times\\underset{d_{k}^{(1)}\\times d_{k}^{(2)}}{\\begin{array}{c}W_{A}\\end{array}}\\times\\underset{d_{k}^{(2)}\\times n_{f}^{(2)}}{\\begin{array}{c}K^{(2)}\\end{array}})<br>$$</p>\n<p>$$<br>\\underset{1\\times1}{A_{i,j}}&#x3D;\\underset{1\\times3d_{k}}{\\boldsymbol{w}_{A}^{T}}\\times\\mathrm{concat}(\\underset{d_{k}\\times1}{\\boldsymbol{k}_{i}^{(1)}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{j}^{(2)}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{i}^{(1)}}\\circ\\underset{d_{k}\\times1}{\\boldsymbol{k}_{j}^{(2)}})<br>$$</p>\n<p>其中，$\\circ$表示哈德曼积</p>\n<p>Affinity Matrix 可以解释为两个键矩阵列的相似性矩阵，并有助于将图像键转换到与句子中单词的键相同的空间，反之亦然。</p>\n<p>由于现在查询由向量变成了矩阵，因此 score 函数也发生了变化</p>\n<p>$$<br>e^{(1)} &#x3D;\\boldsymbol{w}_{1}\\times\\mathrm{act}(\\boldsymbol{W}_{2}\\times\\boldsymbol{K}^{(2)}\\times\\boldsymbol{A}^{T}+\\boldsymbol{W}_{1}\\times\\boldsymbol{K}^{(1)})<br>$$</p>\n<p>$$<br>e^{(2)} &#x3D;\\boldsymbol{w}_{2}\\times\\mathrm{act}(\\boldsymbol{W}_{1}\\times\\boldsymbol{K}^{(1)}\\times\\boldsymbol{A}^{::}+\\boldsymbol{W}_{2}\\times\\boldsymbol{K}^{(2)})<br>$$</p>\n<p>值得一提的是，之前的 score 函数实际是现在这一形式的特殊表达，也就是说，这个表达更具一般性</p>\n<p>如前所述，亲和矩阵本质上是两个注意力模块 1 和 2 的关键向量的相似性矩阵。这个意味着一种不同的确定注意力分数的方法。即，可以将一行或一列中的最大相似度值作为注意力分数。</p>\n<p>$$<br>e_{i}^{(1)}&#x3D;\\max_{j&#x3D;1,\\ldots,n_{f}^{(2)}}A_{i,j},\\quad e_{j}^{(2)}&#x3D;\\max_{i&#x3D;1,\\ldots,n_{f}^{(1)}}A_{i,j}.<br>$$</p>\n<h5 id=\"旋转注意力-Rotatory-Attention\"><a href=\"#旋转注意力-Rotatory-Attention\" class=\"headerlink\" title=\"旋转注意力(Rotatory Attention)\"></a>旋转注意力(Rotatory Attention)</h5><p>Rotatory Attention 是一种用于处理多输入数据的注意力机制，特别适用于情感分析任务中同时考虑目标短语、左上下文和右上下文的场景。该机制通过交替关注不同输入来构建更丰富的表示。</p>\n<ul>\n<li>主要用于情感分析任务</li>\n<li>处理三个输入：目标短语 $\\boldsymbol{F}^{t} &#x3D; [ \\boldsymbol{f}_{1}^{t}, \\ldots , \\boldsymbol{f}_{n_{f}^{t}}^{t}] \\in \\mathbb{R} ^{d_{f}^{t}\\times n_{f}^{t}}$ 、左上下文 $F^{l} &#x3D; [ f_{1}^{l}, \\ldots , f_{n_{f}^{l}}^{l}]\\in\\mathbb{R} ^{d_{f}^{l}\\times n_{f}^{l}}$ 和右上下文 $F^{r} &#x3D; [ f_{1}^{r}, \\ldots , f_{n_{f}^{r}}^{r}]\\in\\mathbb{R}^{d_f^r\\times n_f^r}$</li>\n<li>通过注意力机制迭代改进表示</li>\n</ul>\n<p>其大致的过程如下：</p>\n<ol>\n<li><p><strong>初始特征提取</strong></p>\n<p>首先，模型从三个输入中提取特征向量：</p>\n<ul>\n<li>目标短语特征矩阵：$F^{t}&#x3D;[f_{1}^{t},\\ldots,f_{n_{f}^{t}}^{t}]\\in R^{d_{f}^{t}\\times n_{f}^{t}}$</li>\n<li>左上下文特征矩阵：$F^{l}&#x3D;[f_{1}^{l},\\ldots,f_{n_{f}^{l}}^{l}]\\in R^{d_{f}^{l}\\times n_{f}^{l}}$</li>\n<li>右上下文特征矩阵：$F^{r}&#x3D;[f_{1}^{r},\\ldots,f_{n_{f}^{r}}^{r}]\\in R^{d_{f}^{r}\\times n_{f}^{r}}$</li>\n</ul>\n</li>\n<li><p><strong>目标短语初始表示</strong></p>\n<p>计算目标短语的初始表示向量$r^{t}$，通过对特征向量取平均：</p>\n<p>$$<br>r^{t}&#x3D;\\frac{1}{n_{f}^{t}}\\sum_{i&#x3D;1}^{n_{f}^{t}} f_{i}^{t}<br>$$</p>\n</li>\n<li><p><strong>左上下文注意力计算</strong></p>\n<p>使用$r^{t}$作为查询，计算左上下文的注意力：</p>\n<ol>\n<li><p>提取键向量 $k_{1}^{l},\\ldots,k_{n_{f}^{l}}^{l}\\in R^{d_{k}^{l}}$ 和值向量 $v_{1}^{l},\\ldots,v_{n_{f}^{l}}^{l}\\in R^{d_{v}^{l}}$</p>\n</li>\n<li><p>计算注意力分数 $e_{i}^{l}&#x3D;\\operatorname{score}\\left(r^{t}, k_{i}^{l}\\right)$</p>\n</li>\n<li><p>使用 softmax 对齐函数计算注意力权重$a_{i}^{l}$</p>\n</li>\n<li><p>计算左上下文表示向量 $r^{l}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{l}} a_{i}^{l}v_{i}^{l}$</p>\n</li>\n</ol>\n</li>\n<li><p><strong>右上下文注意力计算</strong></p>\n<p>类似地，计算右上下文的表示向量$r^{r}$：</p>\n<ol>\n<li><p>提取键向量 $k_{1}^{r},\\ldots,k_{n_{f}^{r}}^{r}\\in R^{d_{k}^{r}}$ 和值向量 $v_{1}^{r},\\ldots,v_{n_{f}^{r}}^{r}\\in R^{d_{v}^{r}}$</p>\n</li>\n<li><p>计算注意力分数 $e_{i}^{r}&#x3D;\\operatorname{score}\\left(r^{t}, k_{i}^{r}\\right)$</p>\n</li>\n<li><p>使用 softmax 对齐函数计算注意力权重$a_{i}^{r}$</p>\n</li>\n<li><p>计算右上下文表示向量 $r^{r}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{r}} a_{i}^{r}v_{i}^{r}$</p>\n</li>\n</ol>\n</li>\n<li><p><strong>目标短语更新表示</strong></p>\n<p>使用左上下文表示$r^{l}$和右上下文表示$r^{r}$来更新目标短语的表示：</p>\n<ol>\n<li><p>提取目标短语的键向量 $k_{1}^{t},\\ldots,k_{n_{f}^{t}}^{t}\\in R^{d_{k}^{t}}$ 和值向量 $v_{1}^{t},\\ldots,v_{n_{f}^{t}}^{t}\\in R^{d_{v}^{t}}$</p>\n</li>\n<li><p>计算左感知目标表示$r^{l_{t}}$：</p>\n<ul>\n<li>注意力分数：$e_{i}^{l_{t}}&#x3D;\\operatorname{score}\\left(r^{l}, k_{i}^{t}\\right)$</li>\n<li>使用 softmax 对齐函数计算注意力权重$a_{i}^{l_{t}}$</li>\n<li>计算表示向量：$r^{l_{t}}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{l_{t}}v_{i}^{t}$</li>\n</ul>\n</li>\n<li><p>计算右感知目标表示$r^{r_{t}}$：</p>\n<ul>\n<li>注意力分数：$e_{i}^{r_{t}}&#x3D;\\operatorname{score}\\left(r^{r}, k_{i}^{t}\\right)$</li>\n<li>使用 softmax 对齐函数计算注意力权重$a_{i}^{r_{t}}$</li>\n<li>计算表示向量：$r^{r_{t}}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{r_{t}}v_{i}^{t}$</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>最终表示为 $r&#x3D;\\operatorname{concat}\\left(r^{l},r^{r},r^{l_{t}},r^{r_{t}}\\right)$</p>\n</li>\n</ol>\n<p>Rotatory Attention 具有以下特点：</p>\n<ol>\n<li><p><strong>双向信息流动</strong>：通过从目标短语到上下文，再从上下文回到目标短语的信息流动，实现了双向的信息交互。</p>\n</li>\n<li><p><strong>层次化表示</strong>：构建了多层次的特征表示，从原始特征到上下文感知特征。</p>\n</li>\n<li><p><strong>特定任务优化</strong>：特别适合情感分析任务，能够捕捉目标短语与上下文之间的复杂关系。</p>\n</li>\n</ol>\n<p>Rotatory Attention 通过这种交替关注的方式，能够更好地理解目标短语在特定上下文中的情感倾向，从而提高了情感分类的准确性。</p>\n<h2 id=\"特征层级-Levels-of-Features\"><a href=\"#特征层级-Levels-of-Features\" class=\"headerlink\" title=\"特征层级(Levels of Features)\"></a>特征层级(Levels of Features)</h2><p>这部分讨论了如何处理具有层级结构的特征，主要分为单层级注意力和多层级注意力机制。</p>\n<h3 id=\"单层级注意力-Single-Level-Attention\"><a href=\"#单层级注意力-Single-Level-Attention\" class=\"headerlink\" title=\"单层级注意力(Single-Level Attention)\"></a>单层级注意力(Single-Level Attention)</h3><p>传统注意力机制通常在单一层级上处理特征，如只关注单词级别或句子级别。</p>\n<h3 id=\"多层级注意力机制\"><a href=\"#多层级注意力机制\" class=\"headerlink\" title=\"多层级注意力机制\"></a>多层级注意力机制</h3><ol>\n<li><strong>注意力叠加(Attention-via-Attention)</strong></li>\n</ol>\n<img src=\"img/Attention/AttentionViaAttention.png\" alt=\"attention-via-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>同时处理字符级和词级特征</li>\n<li>先计算词级注意力，用其上下文向量辅助计算字符级注意力</li>\n<li>最终拼接两个层级的上下文向量</li>\n</ul>\n<ol start=\"2\">\n<li><strong>层级注意力(Hierarchical Attention)</strong></li>\n</ol>\n<img src=\"img/Attention/HierarchicalAttention.png\" alt=\"hierarchical attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>从最低层级开始，逐步构建高层级表示</li>\n<li>常用于文档分类：词 → 句 → 文档</li>\n<li>每个层级通过注意力机制生成摘要表示</li>\n</ul>\n<h2 id=\"特征表示-Feature-Representations\"><a href=\"#特征表示-Feature-Representations\" class=\"headerlink\" title=\"特征表示(Feature Representations)\"></a>特征表示(Feature Representations)</h2><p>这部分讨论了特征表示方式的注意力机制变体，主要分为单一表示注意力和多表示注意力。</p>\n<h3 id=\"单一表示注意力-Single-Representational-Attention\"><a href=\"#单一表示注意力-Single-Representational-Attention\" class=\"headerlink\" title=\"单一表示注意力(Single-Representational Attention)\"></a>单一表示注意力(Single-Representational Attention)</h3><p>传统方法使用单一嵌入或表示模型生成特征表示。</p>\n<h3 id=\"多表示注意力-Multi-Representational-Attention\"><a href=\"#多表示注意力-Multi-Representational-Attention\" class=\"headerlink\" title=\"多表示注意力(Multi-Representational Attention)\"></a>多表示注意力(Multi-Representational Attention)</h3><ol>\n<li><p><strong>元嵌入(Meta-embeddings)</strong></p>\n<ul>\n<li>整合多个嵌入表示</li>\n<li>通过注意力机制加权平均不同表示</li>\n<li>生成更高质量的特征表示</li>\n</ul>\n</li>\n<li><p><strong>自注意力机制</strong></p>\n<ul>\n<li>学习特征向量之间的关系</li>\n<li>通过注意力改进特征表示</li>\n<li>常用于 Transformer 架构中</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"应用领域\"><a href=\"#应用领域\" class=\"headerlink\" title=\"应用领域\"></a>应用领域</h2><p>3.1 节讨论的特征相关注意力机制在多个领域有广泛应用：</p>\n<ul>\n<li>医学数据分析(多特征协同注意力)</li>\n<li>推荐系统(多层级注意力)</li>\n<li>情感分析(旋转注意力)</li>\n<li>文档分类(层级注意力)</li>\n<li>多语言处理(多表示注意力)</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>3.1 节系统性地分类了基于输入特征特性的注意力机制变体，为研究者提供了清晰的框架来选择适合特定任务和数据类型的最佳注意力机制。这些机制通过充分利用输入特征的多重性、层级结构和表示多样性，显著提升了模型在各种任务上的表现。</p>\n<p>图 3 展示了完整的注意力机制分类体系，其中 3.1 节讨论的特征相关注意力机制是该体系的重要组成部分。</p>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers 和 Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>\n<a href=\"/2025/07/10/Attention/\" title=\"Attention Overview\">Attention Overview</a>\n","length":3170,"excerpt":"<h1 id=\"在输入特征上做文章的-Attention\"><a href=\"#在输入特征上做文章的-Attention\" class=\"headerlink\" title=\"在输入特征上做文章的 Attention\"></a>在输入特征上做文章的 Attention</h1><p>本文将接着详细说明一种基于输入特征分类 Attention 的方式，并介绍在这种分类方式下关注到的不同的 Attention 的架构。</p>\n<p>具体来说，本文主要探讨了基于输入特征特性的注意力机制变体。本节根据输入特征的不同特性，将特征相关的注意力机制分为三类：特征多重性(Multiplicity of Features)、特征层级(Levels of Features)和特征表示(Feature Representations)。</p>\n<p>在阅读这篇博客前请先阅读 <a href=\"/2025/07/10/Attention/\" title=\"Attention Overview\">Attention Overview</a></p>","more":"<h2 id=\"特征多重性-Multiplicity-of-Features\"><a href=\"#特征多重性-Multiplicity-of-Features\" class=\"headerlink\" title=\"特征多重性(Multiplicity of Features)\"></a>特征多重性(Multiplicity of Features)</h2><p>这部分讨论了如何处理多个输入源的特征，主要分为单一特征注意力和多特征注意力机制。</p>\n<h3 id=\"单一特征注意力-Singular-Features-Attention\"><a href=\"#单一特征注意力-Singular-Features-Attention\" class=\"headerlink\" title=\"单一特征注意力(Singular Features Attention)\"></a>单一特征注意力(Singular Features Attention)</h3><p>大多数任务模型只处理单一输入(如图像、句子或声音序列)，使用单一特征注意力机制。这种机制直接对单个输入的特征向量进行注意力计算。</p>\n<h3 id=\"多特征注意力机制\"><a href=\"#多特征注意力机制\" class=\"headerlink\" title=\"多特征注意力机制\"></a>多特征注意力机制</h3><p>当模型需要同时处理多个输入源时，需要特殊的多特征注意力机制：</p>\n<p><strong>协同注意力(Co-attention)</strong></p>\n<ul>\n<li>分为 <strong>粗科粒度(Coarse-grained)</strong> 和 <strong>细颗粒度(Fine-grained)</strong> 两种</li>\n<li><strong>粗颗粒度协同</strong>注意力使用一个输入的<em>紧凑表示</em>作为查询来关注另一个输入</li>\n<li><strong>细颗粒度协同</strong>注意力使用一个输入的所有特征向量作为查询</li>\n</ul>\n<h4 id=\"粗颗粒度协同\"><a href=\"#粗颗粒度协同\" class=\"headerlink\" title=\"粗颗粒度协同\"></a>粗颗粒度协同</h4><p>论文给出的粗颗粒度协同的实例是<strong>alternating co-attention</strong></p>\n<h5 id=\"alternating-co-attention\"><a href=\"#alternating-co-attention\" class=\"headerlink\" title=\"alternating co-attention\"></a>alternating co-attention</h5><img src=\"/img/Attention/AlternatingCo-Attention.png\" alt=\"alternating co-attention\" width=\"60%\" height=\"auto\">\n\n<p>如上图所示，这是 alternating co-attention 的架构图，该机制交替使用两个输入的特征矩阵，先计算第一个输入的注意力，将其上下文向量作为查询计算第二个输入的注意力，然后再用第二个输入的上下文向量重新计算第一个输入的注意力。</p>\n<p>这里现给出他的 score 函数</p>\n<p>对于有序列输入的 Attention：</p>\n<p>$$<br>\\mathrm{score}(\\underset{d_{q}\\times1}{\\boldsymbol{q}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{l}})&#x3D;\\underset{1\\times d_{w}}{\\boldsymbol{w}^{T}}\\times\\mathrm{act}(\\underset{d_{w}\\times d_{q}}{\\boldsymbol{W}_{1}}\\times\\underset{d_{q}\\times1}{\\boldsymbol{q}}+\\underset{d_{w}\\times d_{k}}{\\boldsymbol{W}_{2}}\\times\\underset{d_{k}\\times1}{\\boldsymbol{k}_{l}}+\\underset{d_{w}\\times1}{\\boldsymbol{b}})<br>$$</p>\n<p>对于无序列输入的 Attention <del>（这是一种自注意力机制，后面会提到）</del> ：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(0)}}&#x3D;\\underset{1\\times d_{w}}{\\boldsymbol{w}^{(1)T}}\\times\\operatorname{act}(\\underset{d_{w}\\times d_{k}^{(1)}}{\\boldsymbol{W}^{(1)}}\\times\\underset{d_{k}^{(1)}\\times1}{\\boldsymbol{k}_{l}^{(1)}}+\\underset{d_{w}\\times1}{\\boldsymbol{b}^{(1)}})<br>$$</p>\n<p>对于第二层 Attention：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(2)}}&#x3D;\\mathrm{score}(\\underset{d_{v}^{(1)}\\times 1}{\\boldsymbol{c}^{(0)}},\\underset{d_{k}^{(2)}\\times1}{\\boldsymbol{k}_{l}^{(2)}})<br>$$</p>\n<p>对于第三层 Attention：</p>\n<p>$$<br>\\underset{1\\times1}{e_{l}^{(1)}}&#x3D;\\mathrm{score}(\\underset{d_{v}^{(2)}\\times 1}{\\boldsymbol{c}^{(2)}},\\underset{d_{k}^{(1)}\\times1}{\\boldsymbol{k}_{l}^{(1)}})<br>$$</p>\n<p>生成的上下文向量$\\boldsymbol{c}^{(1)}$和$\\boldsymbol{c}^{(2)}$被连接起来，并在输出模型中用于预测。交替协同注意力由于需要一个接一个地计算上下文向量，因此本质上包含了<em>一种顺序性</em>。这可能会带来计算上的劣势，因为<em>无法并行</em>化。</p>\n<h5 id=\"interactive-co-attention\"><a href=\"#interactive-co-attention\" class=\"headerlink\" title=\"interactive co-attention\"></a>interactive co-attention</h5><img src=\"/img/Attention/InteractiveCo-Attention.png\" alt=\"interactive co-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>并行计算两个输入的注意力</li>\n<li>使用未加权平均的关键向量作为查询</li>\n<li>计算效率更高，可以并行处理</li>\n</ul>\n<p>$$<br>\\underset{d_k^{(i)}\\times1}{\\bar{\\boldsymbol{k}}^{(i)}}&#x3D;\\frac{1}{n_f^{(i)}}\\sum\\limits_{l&#x3D;1}^{n_f^{(i)}}\\underset{d_k^{(i)}\\times1}{\\boldsymbol{k}_l^{(i)}}, \\quad \\underset{1\\times1}{e_{l}^{(i)}}&#x3D;\\mathrm{score}(\\underset{d_{k}^{(3-i)}\\times1}{\\bar{\\boldsymbol{k}}^{(3-i)}},\\underset{d_{k}^{(i)}\\times1}{\\boldsymbol{k}_{l}^{(i)}}) , \\qquad i&#x3D;1,2<br>$$</p>\n<h4 id=\"细颗粒度协同\"><a href=\"#细颗粒度协同\" class=\"headerlink\" title=\"细颗粒度协同\"></a>细颗粒度协同</h4><p>虽然粗粒度的共同注意力机制使用一个输入的紧凑表示作为查询，以计算另一个输入的注意力，但细粒度的共同注意力在计算注意力分数时会单独考虑每个输入的每个元素。在这种情况下，查询变成了一个矩阵。</p>\n<h5 id=\"并行协同注意力-Parallel-Co-attention\"><a href=\"#并行协同注意力-Parallel-Co-attention\" class=\"headerlink\" title=\"并行协同注意力(Parallel Co-attention)\"></a>并行协同注意力(Parallel Co-attention)</h5><img src=\"/img/Attention/ParallelCo-Attention.png\" alt=\"parallel co-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>同时计算两个输入的注意力</li>\n<li>使用亲和矩阵(Affinity Matrix)转换关键向量空间</li>\n<li>通过聚合形式计算注意力分数</li>\n</ul>\n<p>我们有两种方式生成矩阵 $\\mathbf{A}$</p>\n<p>$$<br>\\underset{n_{f}^{(1)}\\times n_{f}^{(2)}}{\\mathbf{A}}&#x3D;\\operatorname{act}(\\underset{n_{f}^{(1)}\\times d_{k}^{(1)}}{\\begin{array}{c}K^{(1)^{T}}\\end{array}}\\times\\underset{d_{k}^{(1)}\\times d_{k}^{(2)}}{\\begin{array}{c}W_{A}\\end{array}}\\times\\underset{d_{k}^{(2)}\\times n_{f}^{(2)}}{\\begin{array}{c}K^{(2)}\\end{array}})<br>$$</p>\n<p>$$<br>\\underset{1\\times1}{A_{i,j}}&#x3D;\\underset{1\\times3d_{k}}{\\boldsymbol{w}_{A}^{T}}\\times\\mathrm{concat}(\\underset{d_{k}\\times1}{\\boldsymbol{k}_{i}^{(1)}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{j}^{(2)}},\\underset{d_{k}\\times1}{\\boldsymbol{k}_{i}^{(1)}}\\circ\\underset{d_{k}\\times1}{\\boldsymbol{k}_{j}^{(2)}})<br>$$</p>\n<p>其中，$\\circ$表示哈德曼积</p>\n<p>Affinity Matrix 可以解释为两个键矩阵列的相似性矩阵，并有助于将图像键转换到与句子中单词的键相同的空间，反之亦然。</p>\n<p>由于现在查询由向量变成了矩阵，因此 score 函数也发生了变化</p>\n<p>$$<br>e^{(1)} &#x3D;\\boldsymbol{w}_{1}\\times\\mathrm{act}(\\boldsymbol{W}_{2}\\times\\boldsymbol{K}^{(2)}\\times\\boldsymbol{A}^{T}+\\boldsymbol{W}_{1}\\times\\boldsymbol{K}^{(1)})<br>$$</p>\n<p>$$<br>e^{(2)} &#x3D;\\boldsymbol{w}_{2}\\times\\mathrm{act}(\\boldsymbol{W}_{1}\\times\\boldsymbol{K}^{(1)}\\times\\boldsymbol{A}^{::}+\\boldsymbol{W}_{2}\\times\\boldsymbol{K}^{(2)})<br>$$</p>\n<p>值得一提的是，之前的 score 函数实际是现在这一形式的特殊表达，也就是说，这个表达更具一般性</p>\n<p>如前所述，亲和矩阵本质上是两个注意力模块 1 和 2 的关键向量的相似性矩阵。这个意味着一种不同的确定注意力分数的方法。即，可以将一行或一列中的最大相似度值作为注意力分数。</p>\n<p>$$<br>e_{i}^{(1)}&#x3D;\\max_{j&#x3D;1,\\ldots,n_{f}^{(2)}}A_{i,j},\\quad e_{j}^{(2)}&#x3D;\\max_{i&#x3D;1,\\ldots,n_{f}^{(1)}}A_{i,j}.<br>$$</p>\n<h5 id=\"旋转注意力-Rotatory-Attention\"><a href=\"#旋转注意力-Rotatory-Attention\" class=\"headerlink\" title=\"旋转注意力(Rotatory Attention)\"></a>旋转注意力(Rotatory Attention)</h5><p>Rotatory Attention 是一种用于处理多输入数据的注意力机制，特别适用于情感分析任务中同时考虑目标短语、左上下文和右上下文的场景。该机制通过交替关注不同输入来构建更丰富的表示。</p>\n<ul>\n<li>主要用于情感分析任务</li>\n<li>处理三个输入：目标短语 $\\boldsymbol{F}^{t} &#x3D; [ \\boldsymbol{f}_{1}^{t}, \\ldots , \\boldsymbol{f}_{n_{f}^{t}}^{t}] \\in \\mathbb{R} ^{d_{f}^{t}\\times n_{f}^{t}}$ 、左上下文 $F^{l} &#x3D; [ f_{1}^{l}, \\ldots , f_{n_{f}^{l}}^{l}]\\in\\mathbb{R} ^{d_{f}^{l}\\times n_{f}^{l}}$ 和右上下文 $F^{r} &#x3D; [ f_{1}^{r}, \\ldots , f_{n_{f}^{r}}^{r}]\\in\\mathbb{R}^{d_f^r\\times n_f^r}$</li>\n<li>通过注意力机制迭代改进表示</li>\n</ul>\n<p>其大致的过程如下：</p>\n<ol>\n<li><p><strong>初始特征提取</strong></p>\n<p>首先，模型从三个输入中提取特征向量：</p>\n<ul>\n<li>目标短语特征矩阵：$F^{t}&#x3D;[f_{1}^{t},\\ldots,f_{n_{f}^{t}}^{t}]\\in R^{d_{f}^{t}\\times n_{f}^{t}}$</li>\n<li>左上下文特征矩阵：$F^{l}&#x3D;[f_{1}^{l},\\ldots,f_{n_{f}^{l}}^{l}]\\in R^{d_{f}^{l}\\times n_{f}^{l}}$</li>\n<li>右上下文特征矩阵：$F^{r}&#x3D;[f_{1}^{r},\\ldots,f_{n_{f}^{r}}^{r}]\\in R^{d_{f}^{r}\\times n_{f}^{r}}$</li>\n</ul>\n</li>\n<li><p><strong>目标短语初始表示</strong></p>\n<p>计算目标短语的初始表示向量$r^{t}$，通过对特征向量取平均：</p>\n<p>$$<br>r^{t}&#x3D;\\frac{1}{n_{f}^{t}}\\sum_{i&#x3D;1}^{n_{f}^{t}} f_{i}^{t}<br>$$</p>\n</li>\n<li><p><strong>左上下文注意力计算</strong></p>\n<p>使用$r^{t}$作为查询，计算左上下文的注意力：</p>\n<ol>\n<li><p>提取键向量 $k_{1}^{l},\\ldots,k_{n_{f}^{l}}^{l}\\in R^{d_{k}^{l}}$ 和值向量 $v_{1}^{l},\\ldots,v_{n_{f}^{l}}^{l}\\in R^{d_{v}^{l}}$</p>\n</li>\n<li><p>计算注意力分数 $e_{i}^{l}&#x3D;\\operatorname{score}\\left(r^{t}, k_{i}^{l}\\right)$</p>\n</li>\n<li><p>使用 softmax 对齐函数计算注意力权重$a_{i}^{l}$</p>\n</li>\n<li><p>计算左上下文表示向量 $r^{l}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{l}} a_{i}^{l}v_{i}^{l}$</p>\n</li>\n</ol>\n</li>\n<li><p><strong>右上下文注意力计算</strong></p>\n<p>类似地，计算右上下文的表示向量$r^{r}$：</p>\n<ol>\n<li><p>提取键向量 $k_{1}^{r},\\ldots,k_{n_{f}^{r}}^{r}\\in R^{d_{k}^{r}}$ 和值向量 $v_{1}^{r},\\ldots,v_{n_{f}^{r}}^{r}\\in R^{d_{v}^{r}}$</p>\n</li>\n<li><p>计算注意力分数 $e_{i}^{r}&#x3D;\\operatorname{score}\\left(r^{t}, k_{i}^{r}\\right)$</p>\n</li>\n<li><p>使用 softmax 对齐函数计算注意力权重$a_{i}^{r}$</p>\n</li>\n<li><p>计算右上下文表示向量 $r^{r}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{r}} a_{i}^{r}v_{i}^{r}$</p>\n</li>\n</ol>\n</li>\n<li><p><strong>目标短语更新表示</strong></p>\n<p>使用左上下文表示$r^{l}$和右上下文表示$r^{r}$来更新目标短语的表示：</p>\n<ol>\n<li><p>提取目标短语的键向量 $k_{1}^{t},\\ldots,k_{n_{f}^{t}}^{t}\\in R^{d_{k}^{t}}$ 和值向量 $v_{1}^{t},\\ldots,v_{n_{f}^{t}}^{t}\\in R^{d_{v}^{t}}$</p>\n</li>\n<li><p>计算左感知目标表示$r^{l_{t}}$：</p>\n<ul>\n<li>注意力分数：$e_{i}^{l_{t}}&#x3D;\\operatorname{score}\\left(r^{l}, k_{i}^{t}\\right)$</li>\n<li>使用 softmax 对齐函数计算注意力权重$a_{i}^{l_{t}}$</li>\n<li>计算表示向量：$r^{l_{t}}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{l_{t}}v_{i}^{t}$</li>\n</ul>\n</li>\n<li><p>计算右感知目标表示$r^{r_{t}}$：</p>\n<ul>\n<li>注意力分数：$e_{i}^{r_{t}}&#x3D;\\operatorname{score}\\left(r^{r}, k_{i}^{t}\\right)$</li>\n<li>使用 softmax 对齐函数计算注意力权重$a_{i}^{r_{t}}$</li>\n<li>计算表示向量：$r^{r_{t}}&#x3D;\\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{r_{t}}v_{i}^{t}$</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p>最终表示为 $r&#x3D;\\operatorname{concat}\\left(r^{l},r^{r},r^{l_{t}},r^{r_{t}}\\right)$</p>\n</li>\n</ol>\n<p>Rotatory Attention 具有以下特点：</p>\n<ol>\n<li><p><strong>双向信息流动</strong>：通过从目标短语到上下文，再从上下文回到目标短语的信息流动，实现了双向的信息交互。</p>\n</li>\n<li><p><strong>层次化表示</strong>：构建了多层次的特征表示，从原始特征到上下文感知特征。</p>\n</li>\n<li><p><strong>特定任务优化</strong>：特别适合情感分析任务，能够捕捉目标短语与上下文之间的复杂关系。</p>\n</li>\n</ol>\n<p>Rotatory Attention 通过这种交替关注的方式，能够更好地理解目标短语在特定上下文中的情感倾向，从而提高了情感分类的准确性。</p>\n<h2 id=\"特征层级-Levels-of-Features\"><a href=\"#特征层级-Levels-of-Features\" class=\"headerlink\" title=\"特征层级(Levels of Features)\"></a>特征层级(Levels of Features)</h2><p>这部分讨论了如何处理具有层级结构的特征，主要分为单层级注意力和多层级注意力机制。</p>\n<h3 id=\"单层级注意力-Single-Level-Attention\"><a href=\"#单层级注意力-Single-Level-Attention\" class=\"headerlink\" title=\"单层级注意力(Single-Level Attention)\"></a>单层级注意力(Single-Level Attention)</h3><p>传统注意力机制通常在单一层级上处理特征，如只关注单词级别或句子级别。</p>\n<h3 id=\"多层级注意力机制\"><a href=\"#多层级注意力机制\" class=\"headerlink\" title=\"多层级注意力机制\"></a>多层级注意力机制</h3><ol>\n<li><strong>注意力叠加(Attention-via-Attention)</strong></li>\n</ol>\n<img src=\"img/Attention/AttentionViaAttention.png\" alt=\"attention-via-attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>同时处理字符级和词级特征</li>\n<li>先计算词级注意力，用其上下文向量辅助计算字符级注意力</li>\n<li>最终拼接两个层级的上下文向量</li>\n</ul>\n<ol start=\"2\">\n<li><strong>层级注意力(Hierarchical Attention)</strong></li>\n</ol>\n<img src=\"img/Attention/HierarchicalAttention.png\" alt=\"hierarchical attention\" width=\"60%\" height=\"auto\">\n\n<ul>\n<li>从最低层级开始，逐步构建高层级表示</li>\n<li>常用于文档分类：词 → 句 → 文档</li>\n<li>每个层级通过注意力机制生成摘要表示</li>\n</ul>\n<h2 id=\"特征表示-Feature-Representations\"><a href=\"#特征表示-Feature-Representations\" class=\"headerlink\" title=\"特征表示(Feature Representations)\"></a>特征表示(Feature Representations)</h2><p>这部分讨论了特征表示方式的注意力机制变体，主要分为单一表示注意力和多表示注意力。</p>\n<h3 id=\"单一表示注意力-Single-Representational-Attention\"><a href=\"#单一表示注意力-Single-Representational-Attention\" class=\"headerlink\" title=\"单一表示注意力(Single-Representational Attention)\"></a>单一表示注意力(Single-Representational Attention)</h3><p>传统方法使用单一嵌入或表示模型生成特征表示。</p>\n<h3 id=\"多表示注意力-Multi-Representational-Attention\"><a href=\"#多表示注意力-Multi-Representational-Attention\" class=\"headerlink\" title=\"多表示注意力(Multi-Representational Attention)\"></a>多表示注意力(Multi-Representational Attention)</h3><ol>\n<li><p><strong>元嵌入(Meta-embeddings)</strong></p>\n<ul>\n<li>整合多个嵌入表示</li>\n<li>通过注意力机制加权平均不同表示</li>\n<li>生成更高质量的特征表示</li>\n</ul>\n</li>\n<li><p><strong>自注意力机制</strong></p>\n<ul>\n<li>学习特征向量之间的关系</li>\n<li>通过注意力改进特征表示</li>\n<li>常用于 Transformer 架构中</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"应用领域\"><a href=\"#应用领域\" class=\"headerlink\" title=\"应用领域\"></a>应用领域</h2><p>3.1 节讨论的特征相关注意力机制在多个领域有广泛应用：</p>\n<ul>\n<li>医学数据分析(多特征协同注意力)</li>\n<li>推荐系统(多层级注意力)</li>\n<li>情感分析(旋转注意力)</li>\n<li>文档分类(层级注意力)</li>\n<li>多语言处理(多表示注意力)</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>3.1 节系统性地分类了基于输入特征特性的注意力机制变体，为研究者提供了清晰的框架来选择适合特定任务和数据类型的最佳注意力机制。这些机制通过充分利用输入特征的多重性、层级结构和表示多样性，显著提升了模型在各种任务上的表现。</p>\n<p>图 3 展示了完整的注意力机制分类体系，其中 3.1 节讨论的特征相关注意力机制是该体系的重要组成部分。</p>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers 和 Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>\n<a href=\"/2025/07/10/Attention/\" title=\"Attention Overview\">Attention Overview</a>"},{"title":"What Is GNN and GCN ?","date":"2025-07-10T07:36:46.000Z","_content":"\n# GNN 与 GCN\n\n> 图神经网络（Graph Neural Networks, GNN）和图卷积网络（Graph Convolutional Networks, GCN）是处理图数据的强大工具。本文将从理论到实践，全面介绍这两种重要的深度学习模型。\n\n本文主要介绍了*GNN和GCN的大致原理*，*GCN在PyG和PyTorch的实现* 以及它们在*DRP中的应用*\n\n<!-- more -->\n\n## 🎯 Intro\n\n在深度学习领域，处理图结构数据一直是一个具有挑战性的任务。传统的深度学习模型（如CNN、RNN）在处理欧几里得空间中的数据表现出色，但对于图这种非欧几里得结构的数据却显得力不从心。GNN和GCN的出现，为我们提供了处理图数据的有力工具。\n\n而在DRP领域，由于涉及到大量的Embedding，GCN现在几乎已经成为了必不可少的模块。\n\n但在开始各种各样的奇形怪状的GCN之前，了解GNN和GCN本身的实现仍然是非常必要的。~~于鼠鼠而言~~大致有以下理由：\n1. 部分抽象的基于GCN的模块第三方库不一定支持\n2. 由于反应表示数据的不平衡，我们可以构建的模型的层数是非常有限的（因为会过平滑）。因此对层内的改造就显得非常必要了。而这一切的前提便是理解原理捏\n\n在这里强烈建议去看一下[Distill](https://distill.pub/)的两篇有关图神经网络的博客，非常易懂。\n\n---\n\n## 📚 理论基础\n\n### 图的基本概念\n\n在开始之前，我们需要理解图的基本表示：\n- 图 $G = (V, E)$，其中 $V$ 是节点集合，$E$ 是边集合\n- 邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$\n- 度矩阵 $D = diag(d_1,...,d_n)$，其中 $d_i = \\sum_j A_{ij}$\n- 节点特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$\n\n### GNN框架\n\nGNN的基本框架遵循消息传递范式（Message Passing Neural Network, MPNN），可以用以下数学公式表示：\n\n1. **消息传递阶段**（Message Passing）：\n   \n   对于节点 $v$，从其邻居节点 $u \\in \\mathcal{N}(v)$ 收集信息：\n   \n   $$m_v^{(l)} = \\sum_{u \\in \\mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$\n\n   其中：\n   - $h_v^{(l-1)}$ 是节点 $v$ 在第 $l-1$ 层的特征\n   - $e_{uv}$ 是边 $(u,v)$ 的特征\n   - $M_l$ 是可学习的消息函数\n\n2. **消息聚合阶段**（Aggregation）：\n   \n   将收集到的消息进行聚合：\n\n   $$a_v^{(l)} = AGG(\\{m_v^{(l)} | u \\in \\mathcal{N}(v)\\})$$\n\n   常见的聚合函数包括：\n   - 求和：$AGG_{sum} = \\sum_{u \\in \\mathcal{N}(v)} m_u$\n   - 平均：$AGG_{mean} = \\frac{1}{|\\mathcal{N}(v)|} \\sum_{u \\in \\mathcal{N}(v)} m_u$\n   - 最大：$AGG_{max} = max_{u \\in \\mathcal{N}(v)} m_u$\n\n3. **节点更新阶段**（Update）：\n   \n   更新节点的表示：\n\n   $$h_v^{(l)} = U_l(h_v^{(l-1)}, a_v^{(l)})$$\n\n   其中 $U_l$ 是可学习的更新函数，通常是MLP或其他神经网络。\n\n### GCN实现\n\n#### 拉普拉斯矩阵 🔍\n\n拉普拉斯矩阵是图信号处理中的核心概念，有多种形式：\n\n1. **组合拉普拉斯矩阵**：$L = D - A$\n\n2. **标准化拉普拉斯矩阵**：$L_{sym} = D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} = I - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$\n\n3. **随机游走拉普拉斯矩阵**：$L_{rw} = D^{-1}L = I - D^{-1}A$\n\n拉普拉斯矩阵的特性：\n- 对称性：$L = L^T$\n- 半正定性：所有特征值非负\n- 最小特征值为0，对应的特征向量是常数向量\n- 特征值的重数对应图的连通分量数\n\n#### 从传统卷积到图卷积 🔄\n\n##### 传统卷积回顾\n\n在欧几里得空间中，卷积操作定义为：\n\n$$(f * g)(p) = \\sum_{q \\in \\mathcal{N}(p)} f(q) \\cdot g(p-q)$$\n\n这里的关键特点是：\n- 平移不变性\n- 局部性\n- 参数共享\n\n##### 图上的卷积定义\n\n在图域中，我们需要重新定义这些特性：\n\n1. **空间域卷积**：\n   $$h_v = \\sum_{u \\in \\mathcal{N}(v)} W(e_{u,v})h_u$$\n   其中 $W(e_{u,v})$ 是边的权重函数\n\n2. **谱域卷积**：\n   $$g_\\theta * x = Ug_\\theta U^T x$$\n   其中 $U$ 是拉普拉斯矩阵的特征向量矩阵\n\n#### GCN的数学推导 ⚙️\n\nKipf & Welling提出的GCN模型中，单层传播规则为：\n\n$$H^{(l+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$$\n\n其中：\n- $\\tilde{A} = A + I_N$ 是添加了自环的邻接矩阵\n- $\\tilde{D}\\_{ii} = \\sum\\_{j} \\tilde{A}\\_{ij}$ 是对应的度矩阵\n- $H^{(l)}$ 是第 $l$ 层的激活值\n- $W^{(l)}$ 是可学习的权重矩阵\n- $\\sigma$ 是非线性激活函数\n\n~~一些自己的理解~~\n1. 引入$L_{sym} = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$作为聚合（AGG）部分\n   - 添加自环：$\\tilde{A} = A + I_N$\n   - 计算归一化系数：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$\n2. 特征变换：$H^{(l)}W^{(l)}$\n3. 邻域聚合：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}$\n4. 非线性变换：$\\sigma(\\cdot)$\n\n---\n\n## 💻 实现细节\n\n基于这个理论框架的简单实现如下：\n\n```python\ndef message_passing(nodes, edges):\n    messages = {}\n    for edge in edges:\n        src, dst = edge\n        msg = compute_message(nodes[src], nodes[dst])\n        messages.setdefault(dst, []).append(msg)\n    return messages\n\ndef aggregate_messages(messages):\n    aggregated = {}\n    for node, msgs in messages.items():\n        aggregated[node] = sum(msgs) / len(msgs)  # 平均聚合\n    return aggregated\n\ndef update_nodes(nodes, aggregated):\n    updated = {}\n    for node, agg_msg in aggregated.items():\n        updated[node] = nodes[node] + agg_msg  # 残差连接\n    return updated\n```\n\n### PyTorch Geometric实现 🚀\n\n> 本节代码基于 PyTorch 2.1.0 和 PyTorch Geometric 2.4.0 版本\n\n使用PyTorch Geometric库的GCN实现：\n\n```python\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GCN(torch.nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(GCN, self).__init__()\n        self.conv1 = GCNConv(num_features, 16)\n        self.conv2 = GCNConv(16, num_classes)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n```\n\n### 原生PyTorch实现 🔧\n\n> 本节代码基于 PyTorch 2.1.0、NumPy 1.24.0 和 SciPy 1.11.0 版本\n\n不使用PyG，手动实现GCN~~主要是目前不太清楚主流的HGCN的实现方式捏~~：\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport scipy.sparse as sp\nimport numpy as np\n\nclass GCNLayer(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(GCNLayer, self).__init__()\n        self.W = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.W)\n\n    def forward(self, x, adj):\n        # adj: 归一化的邻接矩阵\n        support = torch.mm(x, self.W)\n        output = torch.sparse.mm(adj, support)\n        return output\n\nclass GCN(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout):\n        super(GCN, self).__init__()\n        self.gc1 = GCNLayer(nfeat, nhid)\n        self.gc2 = GCNLayer(nhid, nclass)\n        self.dropout = dropout\n\n    def forward(self, x, adj):\n        x = F.relu(self.gc1(x, adj))\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = self.gc2(x, adj)\n        return F.log_softmax(x, dim=1)\n\ndef normalize_adj(adj):\n    \"\"\"归一化邻接矩阵\"\"\"\n    adj = sp.coo_matrix(adj)\n    rowsum = np.array(adj.sum(1))\n    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n```\n\n---\n\n\n## 🎮 应用场景\n\n~~由于鼠鼠就是个臭写DRP的捏~~ 这里只给出GNN在DRP中的应用\n\n\n1. **药物表示**\n   - *分子图构建*：将药物SMILES字符串转换为图结构，节点表示原子（含原子类型、电荷等特征），边表示化学键（如键类型、距离）。  \n   - *GNN编码*：使用图卷积网络（GCN）、图注意力网络（GAT）或图同构网络（GIN）等层迭代聚合邻域信息，生成药物嵌入（embedding）。例如，GraTransDRP（2022）结合GAT和Transformer提升药物表征能力。\n\n2. **癌症表示**\n   - *生物网络构建*：基于基因互作（如STRING数据库的蛋白-蛋白互作）、基因共表达或通路信息构建异质图。例如，AGMI（2021）整合多组学数据和PPI网络，通过GNN学习癌症样本的联合表征。  \n   - *多组学融合*：部分模型（如TGSA）利用GNN整合基因组、转录组等数据，通过跨模态注意力机制增强特征交互。\n\n3. **异构图与联合建模**\n   - *细胞系-药物异构图*：如GraphCDR（2021）将细胞系和药物作为两类节点，通过边连接已知响应对，直接学习跨实体关系。  \n   - *知识增强*：预训练GNN于大规模生物化学属性预测（如Zhu et al., 2021），再迁移至DRP任务，提升泛化性。\n\n## 🎯 总结与展望\n\n- **动态图建模**：捕捉治疗过程中动态变化的生物网络。  \n- **三维分子图**：结合几何深度学习（如SchNet）提升立体化学感知。  \n- **基准测试**：需统一评估协议（如固定数据集和指标）以公平比较GNN与其他方法。\n\n~~之后应该会写一些具体模型的博客，有相关的会直接上链接的捏jrm~~\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n<a href=\"/paper/1609.02907v4.pdf\" target=\"_blank\">📄 Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a>\n<a href=\"https://pytorch-geometric.readthedocs.io/\" target=\"_blank\">PyTorch Geometric 官方文档</a>\n<a href=\"https://distill.pub/2021/gnn-intro/\" target=\"_blank\">Distill: A Gentle Introduction to Graph Neural Networks</a>\n<a href=\"https://distill.pub/2021/understanding-gnns/\" target=\"_blank\">Distill: Understanding Convolutions on Graphs</a>\n<a href=\"https://www.zhihu.com/tardis/zm/art/107162772\" target=\"_blank\">知乎：图卷积网络（GCN）入门详解</a>\n<a href=\"https://github.com/tkipf/gcn\" target=\"_blank\">GCN 论文官方代码（GitHub）</a>","source":"_posts/GNN-and-GCN.md","raw":"---\ntitle: What Is GNN and GCN ?\ndate: 2025-07-10 15:36:46\ncategories:\n  - CDR\n  - model\n  - GNN\ntags:\n  - CDR\n  - model\n  - embedding\n  - PyTorch\n  - graph theory\n  - Basic\n---\n\n# GNN 与 GCN\n\n> 图神经网络（Graph Neural Networks, GNN）和图卷积网络（Graph Convolutional Networks, GCN）是处理图数据的强大工具。本文将从理论到实践，全面介绍这两种重要的深度学习模型。\n\n本文主要介绍了*GNN和GCN的大致原理*，*GCN在PyG和PyTorch的实现* 以及它们在*DRP中的应用*\n\n<!-- more -->\n\n## 🎯 Intro\n\n在深度学习领域，处理图结构数据一直是一个具有挑战性的任务。传统的深度学习模型（如CNN、RNN）在处理欧几里得空间中的数据表现出色，但对于图这种非欧几里得结构的数据却显得力不从心。GNN和GCN的出现，为我们提供了处理图数据的有力工具。\n\n而在DRP领域，由于涉及到大量的Embedding，GCN现在几乎已经成为了必不可少的模块。\n\n但在开始各种各样的奇形怪状的GCN之前，了解GNN和GCN本身的实现仍然是非常必要的。~~于鼠鼠而言~~大致有以下理由：\n1. 部分抽象的基于GCN的模块第三方库不一定支持\n2. 由于反应表示数据的不平衡，我们可以构建的模型的层数是非常有限的（因为会过平滑）。因此对层内的改造就显得非常必要了。而这一切的前提便是理解原理捏\n\n在这里强烈建议去看一下[Distill](https://distill.pub/)的两篇有关图神经网络的博客，非常易懂。\n\n---\n\n## 📚 理论基础\n\n### 图的基本概念\n\n在开始之前，我们需要理解图的基本表示：\n- 图 $G = (V, E)$，其中 $V$ 是节点集合，$E$ 是边集合\n- 邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$\n- 度矩阵 $D = diag(d_1,...,d_n)$，其中 $d_i = \\sum_j A_{ij}$\n- 节点特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$\n\n### GNN框架\n\nGNN的基本框架遵循消息传递范式（Message Passing Neural Network, MPNN），可以用以下数学公式表示：\n\n1. **消息传递阶段**（Message Passing）：\n   \n   对于节点 $v$，从其邻居节点 $u \\in \\mathcal{N}(v)$ 收集信息：\n   \n   $$m_v^{(l)} = \\sum_{u \\in \\mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$\n\n   其中：\n   - $h_v^{(l-1)}$ 是节点 $v$ 在第 $l-1$ 层的特征\n   - $e_{uv}$ 是边 $(u,v)$ 的特征\n   - $M_l$ 是可学习的消息函数\n\n2. **消息聚合阶段**（Aggregation）：\n   \n   将收集到的消息进行聚合：\n\n   $$a_v^{(l)} = AGG(\\{m_v^{(l)} | u \\in \\mathcal{N}(v)\\})$$\n\n   常见的聚合函数包括：\n   - 求和：$AGG_{sum} = \\sum_{u \\in \\mathcal{N}(v)} m_u$\n   - 平均：$AGG_{mean} = \\frac{1}{|\\mathcal{N}(v)|} \\sum_{u \\in \\mathcal{N}(v)} m_u$\n   - 最大：$AGG_{max} = max_{u \\in \\mathcal{N}(v)} m_u$\n\n3. **节点更新阶段**（Update）：\n   \n   更新节点的表示：\n\n   $$h_v^{(l)} = U_l(h_v^{(l-1)}, a_v^{(l)})$$\n\n   其中 $U_l$ 是可学习的更新函数，通常是MLP或其他神经网络。\n\n### GCN实现\n\n#### 拉普拉斯矩阵 🔍\n\n拉普拉斯矩阵是图信号处理中的核心概念，有多种形式：\n\n1. **组合拉普拉斯矩阵**：$L = D - A$\n\n2. **标准化拉普拉斯矩阵**：$L_{sym} = D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} = I - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$\n\n3. **随机游走拉普拉斯矩阵**：$L_{rw} = D^{-1}L = I - D^{-1}A$\n\n拉普拉斯矩阵的特性：\n- 对称性：$L = L^T$\n- 半正定性：所有特征值非负\n- 最小特征值为0，对应的特征向量是常数向量\n- 特征值的重数对应图的连通分量数\n\n#### 从传统卷积到图卷积 🔄\n\n##### 传统卷积回顾\n\n在欧几里得空间中，卷积操作定义为：\n\n$$(f * g)(p) = \\sum_{q \\in \\mathcal{N}(p)} f(q) \\cdot g(p-q)$$\n\n这里的关键特点是：\n- 平移不变性\n- 局部性\n- 参数共享\n\n##### 图上的卷积定义\n\n在图域中，我们需要重新定义这些特性：\n\n1. **空间域卷积**：\n   $$h_v = \\sum_{u \\in \\mathcal{N}(v)} W(e_{u,v})h_u$$\n   其中 $W(e_{u,v})$ 是边的权重函数\n\n2. **谱域卷积**：\n   $$g_\\theta * x = Ug_\\theta U^T x$$\n   其中 $U$ 是拉普拉斯矩阵的特征向量矩阵\n\n#### GCN的数学推导 ⚙️\n\nKipf & Welling提出的GCN模型中，单层传播规则为：\n\n$$H^{(l+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$$\n\n其中：\n- $\\tilde{A} = A + I_N$ 是添加了自环的邻接矩阵\n- $\\tilde{D}\\_{ii} = \\sum\\_{j} \\tilde{A}\\_{ij}$ 是对应的度矩阵\n- $H^{(l)}$ 是第 $l$ 层的激活值\n- $W^{(l)}$ 是可学习的权重矩阵\n- $\\sigma$ 是非线性激活函数\n\n~~一些自己的理解~~\n1. 引入$L_{sym} = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$作为聚合（AGG）部分\n   - 添加自环：$\\tilde{A} = A + I_N$\n   - 计算归一化系数：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$\n2. 特征变换：$H^{(l)}W^{(l)}$\n3. 邻域聚合：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}$\n4. 非线性变换：$\\sigma(\\cdot)$\n\n---\n\n## 💻 实现细节\n\n基于这个理论框架的简单实现如下：\n\n```python\ndef message_passing(nodes, edges):\n    messages = {}\n    for edge in edges:\n        src, dst = edge\n        msg = compute_message(nodes[src], nodes[dst])\n        messages.setdefault(dst, []).append(msg)\n    return messages\n\ndef aggregate_messages(messages):\n    aggregated = {}\n    for node, msgs in messages.items():\n        aggregated[node] = sum(msgs) / len(msgs)  # 平均聚合\n    return aggregated\n\ndef update_nodes(nodes, aggregated):\n    updated = {}\n    for node, agg_msg in aggregated.items():\n        updated[node] = nodes[node] + agg_msg  # 残差连接\n    return updated\n```\n\n### PyTorch Geometric实现 🚀\n\n> 本节代码基于 PyTorch 2.1.0 和 PyTorch Geometric 2.4.0 版本\n\n使用PyTorch Geometric库的GCN实现：\n\n```python\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GCN(torch.nn.Module):\n    def __init__(self, num_features, num_classes):\n        super(GCN, self).__init__()\n        self.conv1 = GCNConv(num_features, 16)\n        self.conv2 = GCNConv(16, num_classes)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n        return F.log_softmax(x, dim=1)\n```\n\n### 原生PyTorch实现 🔧\n\n> 本节代码基于 PyTorch 2.1.0、NumPy 1.24.0 和 SciPy 1.11.0 版本\n\n不使用PyG，手动实现GCN~~主要是目前不太清楚主流的HGCN的实现方式捏~~：\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport scipy.sparse as sp\nimport numpy as np\n\nclass GCNLayer(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(GCNLayer, self).__init__()\n        self.W = nn.Parameter(torch.FloatTensor(in_features, out_features))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        nn.init.kaiming_uniform_(self.W)\n\n    def forward(self, x, adj):\n        # adj: 归一化的邻接矩阵\n        support = torch.mm(x, self.W)\n        output = torch.sparse.mm(adj, support)\n        return output\n\nclass GCN(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout):\n        super(GCN, self).__init__()\n        self.gc1 = GCNLayer(nfeat, nhid)\n        self.gc2 = GCNLayer(nhid, nclass)\n        self.dropout = dropout\n\n    def forward(self, x, adj):\n        x = F.relu(self.gc1(x, adj))\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = self.gc2(x, adj)\n        return F.log_softmax(x, dim=1)\n\ndef normalize_adj(adj):\n    \"\"\"归一化邻接矩阵\"\"\"\n    adj = sp.coo_matrix(adj)\n    rowsum = np.array(adj.sum(1))\n    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n```\n\n---\n\n\n## 🎮 应用场景\n\n~~由于鼠鼠就是个臭写DRP的捏~~ 这里只给出GNN在DRP中的应用\n\n\n1. **药物表示**\n   - *分子图构建*：将药物SMILES字符串转换为图结构，节点表示原子（含原子类型、电荷等特征），边表示化学键（如键类型、距离）。  \n   - *GNN编码*：使用图卷积网络（GCN）、图注意力网络（GAT）或图同构网络（GIN）等层迭代聚合邻域信息，生成药物嵌入（embedding）。例如，GraTransDRP（2022）结合GAT和Transformer提升药物表征能力。\n\n2. **癌症表示**\n   - *生物网络构建*：基于基因互作（如STRING数据库的蛋白-蛋白互作）、基因共表达或通路信息构建异质图。例如，AGMI（2021）整合多组学数据和PPI网络，通过GNN学习癌症样本的联合表征。  \n   - *多组学融合*：部分模型（如TGSA）利用GNN整合基因组、转录组等数据，通过跨模态注意力机制增强特征交互。\n\n3. **异构图与联合建模**\n   - *细胞系-药物异构图*：如GraphCDR（2021）将细胞系和药物作为两类节点，通过边连接已知响应对，直接学习跨实体关系。  \n   - *知识增强*：预训练GNN于大规模生物化学属性预测（如Zhu et al., 2021），再迁移至DRP任务，提升泛化性。\n\n## 🎯 总结与展望\n\n- **动态图建模**：捕捉治疗过程中动态变化的生物网络。  \n- **三维分子图**：结合几何深度学习（如SchNet）提升立体化学感知。  \n- **基准测试**：需统一评估协议（如固定数据集和指标）以公平比较GNN与其他方法。\n\n~~之后应该会写一些具体模型的博客，有相关的会直接上链接的捏jrm~~\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n<a href=\"/paper/1609.02907v4.pdf\" target=\"_blank\">📄 Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a>\n<a href=\"https://pytorch-geometric.readthedocs.io/\" target=\"_blank\">PyTorch Geometric 官方文档</a>\n<a href=\"https://distill.pub/2021/gnn-intro/\" target=\"_blank\">Distill: A Gentle Introduction to Graph Neural Networks</a>\n<a href=\"https://distill.pub/2021/understanding-gnns/\" target=\"_blank\">Distill: Understanding Convolutions on Graphs</a>\n<a href=\"https://www.zhihu.com/tardis/zm/art/107162772\" target=\"_blank\">知乎：图卷积网络（GCN）入门详解</a>\n<a href=\"https://github.com/tkipf/gcn\" target=\"_blank\">GCN 论文官方代码（GitHub）</a>","slug":"GNN-and-GCN","published":1,"updated":"2025-07-12T06:52:36.342Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvm0003k84157b5gpja","content":"<h1 id=\"GNN-与-GCN\"><a href=\"#GNN-与-GCN\" class=\"headerlink\" title=\"GNN 与 GCN\"></a>GNN 与 GCN</h1><blockquote>\n<p>图神经网络（Graph Neural Networks, GNN）和图卷积网络（Graph Convolutional Networks, GCN）是处理图数据的强大工具。本文将从理论到实践，全面介绍这两种重要的深度学习模型。</p>\n</blockquote>\n<p>本文主要介绍了<em>GNN和GCN的大致原理</em>，<em>GCN在PyG和PyTorch的实现</em> 以及它们在<em>DRP中的应用</em></p>\n<span id=\"more\"></span>\n\n<h2 id=\"🎯-Intro\"><a href=\"#🎯-Intro\" class=\"headerlink\" title=\"🎯 Intro\"></a>🎯 Intro</h2><p>在深度学习领域，处理图结构数据一直是一个具有挑战性的任务。传统的深度学习模型（如CNN、RNN）在处理欧几里得空间中的数据表现出色，但对于图这种非欧几里得结构的数据却显得力不从心。GNN和GCN的出现，为我们提供了处理图数据的有力工具。</p>\n<p>而在DRP领域，由于涉及到大量的Embedding，GCN现在几乎已经成为了必不可少的模块。</p>\n<p>但在开始各种各样的奇形怪状的GCN之前，了解GNN和GCN本身的实现仍然是非常必要的。<del>于鼠鼠而言</del>大致有以下理由：</p>\n<ol>\n<li>部分抽象的基于GCN的模块第三方库不一定支持</li>\n<li>由于反应表示数据的不平衡，我们可以构建的模型的层数是非常有限的（因为会过平滑）。因此对层内的改造就显得非常必要了。而这一切的前提便是理解原理捏</li>\n</ol>\n<p>在这里强烈建议去看一下<a href=\"https://distill.pub/\">Distill</a>的两篇有关图神经网络的博客，非常易懂。</p>\n<hr>\n<h2 id=\"📚-理论基础\"><a href=\"#📚-理论基础\" class=\"headerlink\" title=\"📚 理论基础\"></a>📚 理论基础</h2><h3 id=\"图的基本概念\"><a href=\"#图的基本概念\" class=\"headerlink\" title=\"图的基本概念\"></a>图的基本概念</h3><p>在开始之前，我们需要理解图的基本表示：</p>\n<ul>\n<li>图 $G &#x3D; (V, E)$，其中 $V$ 是节点集合，$E$ 是边集合</li>\n<li>邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$</li>\n<li>度矩阵 $D &#x3D; diag(d_1,…,d_n)$，其中 $d_i &#x3D; \\sum_j A_{ij}$</li>\n<li>节点特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$</li>\n</ul>\n<h3 id=\"GNN框架\"><a href=\"#GNN框架\" class=\"headerlink\" title=\"GNN框架\"></a>GNN框架</h3><p>GNN的基本框架遵循消息传递范式（Message Passing Neural Network, MPNN），可以用以下数学公式表示：</p>\n<ol>\n<li><p><strong>消息传递阶段</strong>（Message Passing）：</p>\n<p>对于节点 $v$，从其邻居节点 $u \\in \\mathcal{N}(v)$ 收集信息：</p>\n<p>$$m_v^{(l)} &#x3D; \\sum_{u \\in \\mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$</p>\n<p>其中：</p>\n<ul>\n<li>$h_v^{(l-1)}$ 是节点 $v$ 在第 $l-1$ 层的特征</li>\n<li>$e_{uv}$ 是边 $(u,v)$ 的特征</li>\n<li>$M_l$ 是可学习的消息函数</li>\n</ul>\n</li>\n<li><p><strong>消息聚合阶段</strong>（Aggregation）：</p>\n<p>将收集到的消息进行聚合：</p>\n<p>$$a_v^{(l)} &#x3D; AGG({m_v^{(l)} | u \\in \\mathcal{N}(v)})$$</p>\n<p>常见的聚合函数包括：</p>\n<ul>\n<li>求和：$AGG_{sum} &#x3D; \\sum_{u \\in \\mathcal{N}(v)} m_u$</li>\n<li>平均：$AGG_{mean} &#x3D; \\frac{1}{|\\mathcal{N}(v)|} \\sum_{u \\in \\mathcal{N}(v)} m_u$</li>\n<li>最大：$AGG_{max} &#x3D; max_{u \\in \\mathcal{N}(v)} m_u$</li>\n</ul>\n</li>\n<li><p><strong>节点更新阶段</strong>（Update）：</p>\n<p>更新节点的表示：</p>\n<p>$$h_v^{(l)} &#x3D; U_l(h_v^{(l-1)}, a_v^{(l)})$$</p>\n<p>其中 $U_l$ 是可学习的更新函数，通常是MLP或其他神经网络。</p>\n</li>\n</ol>\n<h3 id=\"GCN实现\"><a href=\"#GCN实现\" class=\"headerlink\" title=\"GCN实现\"></a>GCN实现</h3><h4 id=\"拉普拉斯矩阵-🔍\"><a href=\"#拉普拉斯矩阵-🔍\" class=\"headerlink\" title=\"拉普拉斯矩阵 🔍\"></a>拉普拉斯矩阵 🔍</h4><p>拉普拉斯矩阵是图信号处理中的核心概念，有多种形式：</p>\n<ol>\n<li><p><strong>组合拉普拉斯矩阵</strong>：$L &#x3D; D - A$</p>\n</li>\n<li><p><strong>标准化拉普拉斯矩阵</strong>：$L_{sym} &#x3D; D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} &#x3D; I - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$</p>\n</li>\n<li><p><strong>随机游走拉普拉斯矩阵</strong>：$L_{rw} &#x3D; D^{-1}L &#x3D; I - D^{-1}A$</p>\n</li>\n</ol>\n<p>拉普拉斯矩阵的特性：</p>\n<ul>\n<li>对称性：$L &#x3D; L^T$</li>\n<li>半正定性：所有特征值非负</li>\n<li>最小特征值为0，对应的特征向量是常数向量</li>\n<li>特征值的重数对应图的连通分量数</li>\n</ul>\n<h4 id=\"从传统卷积到图卷积-🔄\"><a href=\"#从传统卷积到图卷积-🔄\" class=\"headerlink\" title=\"从传统卷积到图卷积 🔄\"></a>从传统卷积到图卷积 🔄</h4><h5 id=\"传统卷积回顾\"><a href=\"#传统卷积回顾\" class=\"headerlink\" title=\"传统卷积回顾\"></a>传统卷积回顾</h5><p>在欧几里得空间中，卷积操作定义为：</p>\n<p>$$(f * g)(p) &#x3D; \\sum_{q \\in \\mathcal{N}(p)} f(q) \\cdot g(p-q)$$</p>\n<p>这里的关键特点是：</p>\n<ul>\n<li>平移不变性</li>\n<li>局部性</li>\n<li>参数共享</li>\n</ul>\n<h5 id=\"图上的卷积定义\"><a href=\"#图上的卷积定义\" class=\"headerlink\" title=\"图上的卷积定义\"></a>图上的卷积定义</h5><p>在图域中，我们需要重新定义这些特性：</p>\n<ol>\n<li><p><strong>空间域卷积</strong>：<br>$$h_v &#x3D; \\sum_{u \\in \\mathcal{N}(v)} W(e_{u,v})h_u$$<br>其中 $W(e_{u,v})$ 是边的权重函数</p>\n</li>\n<li><p><strong>谱域卷积</strong>：<br>$$g_\\theta * x &#x3D; Ug_\\theta U^T x$$<br>其中 $U$ 是拉普拉斯矩阵的特征向量矩阵</p>\n</li>\n</ol>\n<h4 id=\"GCN的数学推导-⚙️\"><a href=\"#GCN的数学推导-⚙️\" class=\"headerlink\" title=\"GCN的数学推导 ⚙️\"></a>GCN的数学推导 ⚙️</h4><p>Kipf &amp; Welling提出的GCN模型中，单层传播规则为：</p>\n<p>$$H^{(l+1)} &#x3D; \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$$</p>\n<p>其中：</p>\n<ul>\n<li>$\\tilde{A} &#x3D; A + I_N$ 是添加了自环的邻接矩阵</li>\n<li>$\\tilde{D}_{ii} &#x3D; \\sum_{j} \\tilde{A}_{ij}$ 是对应的度矩阵</li>\n<li>$H^{(l)}$ 是第 $l$ 层的激活值</li>\n<li>$W^{(l)}$ 是可学习的权重矩阵</li>\n<li>$\\sigma$ 是非线性激活函数</li>\n</ul>\n<p><del>一些自己的理解</del></p>\n<ol>\n<li>引入$L_{sym} &#x3D; \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$作为聚合（AGG）部分<ul>\n<li>添加自环：$\\tilde{A} &#x3D; A + I_N$</li>\n<li>计算归一化系数：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$</li>\n</ul>\n</li>\n<li>特征变换：$H^{(l)}W^{(l)}$</li>\n<li>邻域聚合：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}$</li>\n<li>非线性变换：$\\sigma(\\cdot)$</li>\n</ol>\n<hr>\n<h2 id=\"💻-实现细节\"><a href=\"#💻-实现细节\" class=\"headerlink\" title=\"💻 实现细节\"></a>💻 实现细节</h2><p>基于这个理论框架的简单实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">message_passing</span>(<span class=\"params\">nodes, edges</span>):</span><br><span class=\"line\">    messages = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> edge <span class=\"keyword\">in</span> edges:</span><br><span class=\"line\">        src, dst = edge</span><br><span class=\"line\">        msg = compute_message(nodes[src], nodes[dst])</span><br><span class=\"line\">        messages.setdefault(dst, []).append(msg)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> messages</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">aggregate_messages</span>(<span class=\"params\">messages</span>):</span><br><span class=\"line\">    aggregated = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> node, msgs <span class=\"keyword\">in</span> messages.items():</span><br><span class=\"line\">        aggregated[node] = <span class=\"built_in\">sum</span>(msgs) / <span class=\"built_in\">len</span>(msgs)  <span class=\"comment\"># 平均聚合</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> aggregated</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">update_nodes</span>(<span class=\"params\">nodes, aggregated</span>):</span><br><span class=\"line\">    updated = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> node, agg_msg <span class=\"keyword\">in</span> aggregated.items():</span><br><span class=\"line\">        updated[node] = nodes[node] + agg_msg  <span class=\"comment\"># 残差连接</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> updated</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"PyTorch-Geometric实现-🚀\"><a href=\"#PyTorch-Geometric实现-🚀\" class=\"headerlink\" title=\"PyTorch Geometric实现 🚀\"></a>PyTorch Geometric实现 🚀</h3><blockquote>\n<p>本节代码基于 PyTorch 2.1.0 和 PyTorch Geometric 2.4.0 版本</p>\n</blockquote>\n<p>使用PyTorch Geometric库的GCN实现：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch_geometric.nn <span class=\"keyword\">import</span> GCNConv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCN</span>(torch.nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_features, num_classes</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCN, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = GCNConv(num_features, <span class=\"number\">16</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv2 = GCNConv(<span class=\"number\">16</span>, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, edge_index</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv1(x, edge_index)</span><br><span class=\"line\">        x = F.relu(x)</span><br><span class=\"line\">        x = F.dropout(x, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv2(x, edge_index)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"原生PyTorch实现-🔧\"><a href=\"#原生PyTorch实现-🔧\" class=\"headerlink\" title=\"原生PyTorch实现 🔧\"></a>原生PyTorch实现 🔧</h3><blockquote>\n<p>本节代码基于 PyTorch 2.1.0、NumPy 1.24.0 和 SciPy 1.11.0 版本</p>\n</blockquote>\n<p>不使用PyG，手动实现GCN<del>主要是目前不太清楚主流的HGCN的实现方式捏</del>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.sparse <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCNLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCNLayer, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W = nn.Parameter(torch.FloatTensor(in_features, out_features))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.reset_parameters()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">reset_parameters</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        nn.init.kaiming_uniform_(<span class=\"variable language_\">self</span>.W)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        <span class=\"comment\"># adj: 归一化的邻接矩阵</span></span><br><span class=\"line\">        support = torch.mm(x, <span class=\"variable language_\">self</span>.W)</span><br><span class=\"line\">        output = torch.sparse.mm(adj, support)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCN</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, nfeat, nhid, nclass, dropout</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCN, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.gc1 = GCNLayer(nfeat, nhid)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.gc2 = GCNLayer(nhid, nclass)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        x = F.relu(<span class=\"variable language_\">self</span>.gc1(x, adj))</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.gc2(x, adj)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">normalize_adj</span>(<span class=\"params\">adj</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;归一化邻接矩阵&quot;&quot;&quot;</span></span><br><span class=\"line\">    adj = sp.coo_matrix(adj)</span><br><span class=\"line\">    rowsum = np.array(adj.<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>))</span><br><span class=\"line\">    d_inv_sqrt = np.power(rowsum, -<span class=\"number\">0.5</span>).flatten()</span><br><span class=\"line\">    d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class=\"number\">0.</span></span><br><span class=\"line\">    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"🎮-应用场景\"><a href=\"#🎮-应用场景\" class=\"headerlink\" title=\"🎮 应用场景\"></a>🎮 应用场景</h2><p><del>由于鼠鼠就是个臭写DRP的捏</del> 这里只给出GNN在DRP中的应用</p>\n<ol>\n<li><p><strong>药物表示</strong></p>\n<ul>\n<li><em>分子图构建</em>：将药物SMILES字符串转换为图结构，节点表示原子（含原子类型、电荷等特征），边表示化学键（如键类型、距离）。  </li>\n<li><em>GNN编码</em>：使用图卷积网络（GCN）、图注意力网络（GAT）或图同构网络（GIN）等层迭代聚合邻域信息，生成药物嵌入（embedding）。例如，GraTransDRP（2022）结合GAT和Transformer提升药物表征能力。</li>\n</ul>\n</li>\n<li><p><strong>癌症表示</strong></p>\n<ul>\n<li><em>生物网络构建</em>：基于基因互作（如STRING数据库的蛋白-蛋白互作）、基因共表达或通路信息构建异质图。例如，AGMI（2021）整合多组学数据和PPI网络，通过GNN学习癌症样本的联合表征。  </li>\n<li><em>多组学融合</em>：部分模型（如TGSA）利用GNN整合基因组、转录组等数据，通过跨模态注意力机制增强特征交互。</li>\n</ul>\n</li>\n<li><p><strong>异构图与联合建模</strong></p>\n<ul>\n<li><em>细胞系-药物异构图</em>：如GraphCDR（2021）将细胞系和药物作为两类节点，通过边连接已知响应对，直接学习跨实体关系。  </li>\n<li><em>知识增强</em>：预训练GNN于大规模生物化学属性预测（如Zhu et al., 2021），再迁移至DRP任务，提升泛化性。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"🎯-总结与展望\"><a href=\"#🎯-总结与展望\" class=\"headerlink\" title=\"🎯 总结与展望\"></a>🎯 总结与展望</h2><ul>\n<li><strong>动态图建模</strong>：捕捉治疗过程中动态变化的生物网络。  </li>\n<li><strong>三维分子图</strong>：结合几何深度学习（如SchNet）提升立体化学感知。  </li>\n<li><strong>基准测试</strong>：需统一评估协议（如固定数据集和指标）以公平比较GNN与其他方法。</li>\n</ul>\n<p><del>之后应该会写一些具体模型的博客，有相关的会直接上链接的捏jrm</del></p>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/1609.02907v4.pdf\" target=\"_blank\">📄 Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a><br><a href=\"https://pytorch-geometric.readthedocs.io/\" target=\"_blank\">PyTorch Geometric 官方文档</a><br><a href=\"https://distill.pub/2021/gnn-intro/\" target=\"_blank\">Distill: A Gentle Introduction to Graph Neural Networks</a><br><a href=\"https://distill.pub/2021/understanding-gnns/\" target=\"_blank\">Distill: Understanding Convolutions on Graphs</a><br><a href=\"https://www.zhihu.com/tardis/zm/art/107162772\" target=\"_blank\">知乎：图卷积网络（GCN）入门详解</a><br><a href=\"https://github.com/tkipf/gcn\" target=\"_blank\">GCN 论文官方代码（GitHub）</a></p>\n","length":2131,"excerpt":"<h1 id=\"GNN-与-GCN\"><a href=\"#GNN-与-GCN\" class=\"headerlink\" title=\"GNN 与 GCN\"></a>GNN 与 GCN</h1><blockquote>\n<p>图神经网络（Graph Neural Networks, GNN）和图卷积网络（Graph Convolutional Networks, GCN）是处理图数据的强大工具。本文将从理论到实践，全面介绍这两种重要的深度学习模型。</p>\n</blockquote>\n<p>本文主要介绍了<em>GNN和GCN的大致原理</em>，<em>GCN在PyG和PyTorch的实现</em> 以及它们在<em>DRP中的应用</em></p>","more":"<h2 id=\"🎯-Intro\"><a href=\"#🎯-Intro\" class=\"headerlink\" title=\"🎯 Intro\"></a>🎯 Intro</h2><p>在深度学习领域，处理图结构数据一直是一个具有挑战性的任务。传统的深度学习模型（如CNN、RNN）在处理欧几里得空间中的数据表现出色，但对于图这种非欧几里得结构的数据却显得力不从心。GNN和GCN的出现，为我们提供了处理图数据的有力工具。</p>\n<p>而在DRP领域，由于涉及到大量的Embedding，GCN现在几乎已经成为了必不可少的模块。</p>\n<p>但在开始各种各样的奇形怪状的GCN之前，了解GNN和GCN本身的实现仍然是非常必要的。<del>于鼠鼠而言</del>大致有以下理由：</p>\n<ol>\n<li>部分抽象的基于GCN的模块第三方库不一定支持</li>\n<li>由于反应表示数据的不平衡，我们可以构建的模型的层数是非常有限的（因为会过平滑）。因此对层内的改造就显得非常必要了。而这一切的前提便是理解原理捏</li>\n</ol>\n<p>在这里强烈建议去看一下<a href=\"https://distill.pub/\">Distill</a>的两篇有关图神经网络的博客，非常易懂。</p>\n<hr>\n<h2 id=\"📚-理论基础\"><a href=\"#📚-理论基础\" class=\"headerlink\" title=\"📚 理论基础\"></a>📚 理论基础</h2><h3 id=\"图的基本概念\"><a href=\"#图的基本概念\" class=\"headerlink\" title=\"图的基本概念\"></a>图的基本概念</h3><p>在开始之前，我们需要理解图的基本表示：</p>\n<ul>\n<li>图 $G &#x3D; (V, E)$，其中 $V$ 是节点集合，$E$ 是边集合</li>\n<li>邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$</li>\n<li>度矩阵 $D &#x3D; diag(d_1,…,d_n)$，其中 $d_i &#x3D; \\sum_j A_{ij}$</li>\n<li>节点特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$</li>\n</ul>\n<h3 id=\"GNN框架\"><a href=\"#GNN框架\" class=\"headerlink\" title=\"GNN框架\"></a>GNN框架</h3><p>GNN的基本框架遵循消息传递范式（Message Passing Neural Network, MPNN），可以用以下数学公式表示：</p>\n<ol>\n<li><p><strong>消息传递阶段</strong>（Message Passing）：</p>\n<p>对于节点 $v$，从其邻居节点 $u \\in \\mathcal{N}(v)$ 收集信息：</p>\n<p>$$m_v^{(l)} &#x3D; \\sum_{u \\in \\mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$</p>\n<p>其中：</p>\n<ul>\n<li>$h_v^{(l-1)}$ 是节点 $v$ 在第 $l-1$ 层的特征</li>\n<li>$e_{uv}$ 是边 $(u,v)$ 的特征</li>\n<li>$M_l$ 是可学习的消息函数</li>\n</ul>\n</li>\n<li><p><strong>消息聚合阶段</strong>（Aggregation）：</p>\n<p>将收集到的消息进行聚合：</p>\n<p>$$a_v^{(l)} &#x3D; AGG({m_v^{(l)} | u \\in \\mathcal{N}(v)})$$</p>\n<p>常见的聚合函数包括：</p>\n<ul>\n<li>求和：$AGG_{sum} &#x3D; \\sum_{u \\in \\mathcal{N}(v)} m_u$</li>\n<li>平均：$AGG_{mean} &#x3D; \\frac{1}{|\\mathcal{N}(v)|} \\sum_{u \\in \\mathcal{N}(v)} m_u$</li>\n<li>最大：$AGG_{max} &#x3D; max_{u \\in \\mathcal{N}(v)} m_u$</li>\n</ul>\n</li>\n<li><p><strong>节点更新阶段</strong>（Update）：</p>\n<p>更新节点的表示：</p>\n<p>$$h_v^{(l)} &#x3D; U_l(h_v^{(l-1)}, a_v^{(l)})$$</p>\n<p>其中 $U_l$ 是可学习的更新函数，通常是MLP或其他神经网络。</p>\n</li>\n</ol>\n<h3 id=\"GCN实现\"><a href=\"#GCN实现\" class=\"headerlink\" title=\"GCN实现\"></a>GCN实现</h3><h4 id=\"拉普拉斯矩阵-🔍\"><a href=\"#拉普拉斯矩阵-🔍\" class=\"headerlink\" title=\"拉普拉斯矩阵 🔍\"></a>拉普拉斯矩阵 🔍</h4><p>拉普拉斯矩阵是图信号处理中的核心概念，有多种形式：</p>\n<ol>\n<li><p><strong>组合拉普拉斯矩阵</strong>：$L &#x3D; D - A$</p>\n</li>\n<li><p><strong>标准化拉普拉斯矩阵</strong>：$L_{sym} &#x3D; D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} &#x3D; I - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$</p>\n</li>\n<li><p><strong>随机游走拉普拉斯矩阵</strong>：$L_{rw} &#x3D; D^{-1}L &#x3D; I - D^{-1}A$</p>\n</li>\n</ol>\n<p>拉普拉斯矩阵的特性：</p>\n<ul>\n<li>对称性：$L &#x3D; L^T$</li>\n<li>半正定性：所有特征值非负</li>\n<li>最小特征值为0，对应的特征向量是常数向量</li>\n<li>特征值的重数对应图的连通分量数</li>\n</ul>\n<h4 id=\"从传统卷积到图卷积-🔄\"><a href=\"#从传统卷积到图卷积-🔄\" class=\"headerlink\" title=\"从传统卷积到图卷积 🔄\"></a>从传统卷积到图卷积 🔄</h4><h5 id=\"传统卷积回顾\"><a href=\"#传统卷积回顾\" class=\"headerlink\" title=\"传统卷积回顾\"></a>传统卷积回顾</h5><p>在欧几里得空间中，卷积操作定义为：</p>\n<p>$$(f * g)(p) &#x3D; \\sum_{q \\in \\mathcal{N}(p)} f(q) \\cdot g(p-q)$$</p>\n<p>这里的关键特点是：</p>\n<ul>\n<li>平移不变性</li>\n<li>局部性</li>\n<li>参数共享</li>\n</ul>\n<h5 id=\"图上的卷积定义\"><a href=\"#图上的卷积定义\" class=\"headerlink\" title=\"图上的卷积定义\"></a>图上的卷积定义</h5><p>在图域中，我们需要重新定义这些特性：</p>\n<ol>\n<li><p><strong>空间域卷积</strong>：<br>$$h_v &#x3D; \\sum_{u \\in \\mathcal{N}(v)} W(e_{u,v})h_u$$<br>其中 $W(e_{u,v})$ 是边的权重函数</p>\n</li>\n<li><p><strong>谱域卷积</strong>：<br>$$g_\\theta * x &#x3D; Ug_\\theta U^T x$$<br>其中 $U$ 是拉普拉斯矩阵的特征向量矩阵</p>\n</li>\n</ol>\n<h4 id=\"GCN的数学推导-⚙️\"><a href=\"#GCN的数学推导-⚙️\" class=\"headerlink\" title=\"GCN的数学推导 ⚙️\"></a>GCN的数学推导 ⚙️</h4><p>Kipf &amp; Welling提出的GCN模型中，单层传播规则为：</p>\n<p>$$H^{(l+1)} &#x3D; \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$$</p>\n<p>其中：</p>\n<ul>\n<li>$\\tilde{A} &#x3D; A + I_N$ 是添加了自环的邻接矩阵</li>\n<li>$\\tilde{D}_{ii} &#x3D; \\sum_{j} \\tilde{A}_{ij}$ 是对应的度矩阵</li>\n<li>$H^{(l)}$ 是第 $l$ 层的激活值</li>\n<li>$W^{(l)}$ 是可学习的权重矩阵</li>\n<li>$\\sigma$ 是非线性激活函数</li>\n</ul>\n<p><del>一些自己的理解</del></p>\n<ol>\n<li>引入$L_{sym} &#x3D; \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$作为聚合（AGG）部分<ul>\n<li>添加自环：$\\tilde{A} &#x3D; A + I_N$</li>\n<li>计算归一化系数：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$</li>\n</ul>\n</li>\n<li>特征变换：$H^{(l)}W^{(l)}$</li>\n<li>邻域聚合：$\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)}$</li>\n<li>非线性变换：$\\sigma(\\cdot)$</li>\n</ol>\n<hr>\n<h2 id=\"💻-实现细节\"><a href=\"#💻-实现细节\" class=\"headerlink\" title=\"💻 实现细节\"></a>💻 实现细节</h2><p>基于这个理论框架的简单实现如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">message_passing</span>(<span class=\"params\">nodes, edges</span>):</span><br><span class=\"line\">    messages = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> edge <span class=\"keyword\">in</span> edges:</span><br><span class=\"line\">        src, dst = edge</span><br><span class=\"line\">        msg = compute_message(nodes[src], nodes[dst])</span><br><span class=\"line\">        messages.setdefault(dst, []).append(msg)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> messages</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">aggregate_messages</span>(<span class=\"params\">messages</span>):</span><br><span class=\"line\">    aggregated = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> node, msgs <span class=\"keyword\">in</span> messages.items():</span><br><span class=\"line\">        aggregated[node] = <span class=\"built_in\">sum</span>(msgs) / <span class=\"built_in\">len</span>(msgs)  <span class=\"comment\"># 平均聚合</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> aggregated</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">update_nodes</span>(<span class=\"params\">nodes, aggregated</span>):</span><br><span class=\"line\">    updated = &#123;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> node, agg_msg <span class=\"keyword\">in</span> aggregated.items():</span><br><span class=\"line\">        updated[node] = nodes[node] + agg_msg  <span class=\"comment\"># 残差连接</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> updated</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"PyTorch-Geometric实现-🚀\"><a href=\"#PyTorch-Geometric实现-🚀\" class=\"headerlink\" title=\"PyTorch Geometric实现 🚀\"></a>PyTorch Geometric实现 🚀</h3><blockquote>\n<p>本节代码基于 PyTorch 2.1.0 和 PyTorch Geometric 2.4.0 版本</p>\n</blockquote>\n<p>使用PyTorch Geometric库的GCN实现：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch_geometric.nn <span class=\"keyword\">import</span> GCNConv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCN</span>(torch.nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, num_features, num_classes</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCN, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = GCNConv(num_features, <span class=\"number\">16</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv2 = GCNConv(<span class=\"number\">16</span>, num_classes)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, edge_index</span>):</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv1(x, edge_index)</span><br><span class=\"line\">        x = F.relu(x)</span><br><span class=\"line\">        x = F.dropout(x, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.conv2(x, edge_index)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"原生PyTorch实现-🔧\"><a href=\"#原生PyTorch实现-🔧\" class=\"headerlink\" title=\"原生PyTorch实现 🔧\"></a>原生PyTorch实现 🔧</h3><blockquote>\n<p>本节代码基于 PyTorch 2.1.0、NumPy 1.24.0 和 SciPy 1.11.0 版本</p>\n</blockquote>\n<p>不使用PyG，手动实现GCN<del>主要是目前不太清楚主流的HGCN的实现方式捏</del>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.sparse <span class=\"keyword\">as</span> sp</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCNLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCNLayer, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W = nn.Parameter(torch.FloatTensor(in_features, out_features))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.reset_parameters()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">reset_parameters</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        nn.init.kaiming_uniform_(<span class=\"variable language_\">self</span>.W)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        <span class=\"comment\"># adj: 归一化的邻接矩阵</span></span><br><span class=\"line\">        support = torch.mm(x, <span class=\"variable language_\">self</span>.W)</span><br><span class=\"line\">        output = torch.sparse.mm(adj, support)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GCN</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, nfeat, nhid, nclass, dropout</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GCN, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.gc1 = GCNLayer(nfeat, nhid)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.gc2 = GCNLayer(nhid, nclass)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        x = F.relu(<span class=\"variable language_\">self</span>.gc1(x, adj))</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.gc2(x, adj)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">normalize_adj</span>(<span class=\"params\">adj</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;归一化邻接矩阵&quot;&quot;&quot;</span></span><br><span class=\"line\">    adj = sp.coo_matrix(adj)</span><br><span class=\"line\">    rowsum = np.array(adj.<span class=\"built_in\">sum</span>(<span class=\"number\">1</span>))</span><br><span class=\"line\">    d_inv_sqrt = np.power(rowsum, -<span class=\"number\">0.5</span>).flatten()</span><br><span class=\"line\">    d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class=\"number\">0.</span></span><br><span class=\"line\">    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"🎮-应用场景\"><a href=\"#🎮-应用场景\" class=\"headerlink\" title=\"🎮 应用场景\"></a>🎮 应用场景</h2><p><del>由于鼠鼠就是个臭写DRP的捏</del> 这里只给出GNN在DRP中的应用</p>\n<ol>\n<li><p><strong>药物表示</strong></p>\n<ul>\n<li><em>分子图构建</em>：将药物SMILES字符串转换为图结构，节点表示原子（含原子类型、电荷等特征），边表示化学键（如键类型、距离）。  </li>\n<li><em>GNN编码</em>：使用图卷积网络（GCN）、图注意力网络（GAT）或图同构网络（GIN）等层迭代聚合邻域信息，生成药物嵌入（embedding）。例如，GraTransDRP（2022）结合GAT和Transformer提升药物表征能力。</li>\n</ul>\n</li>\n<li><p><strong>癌症表示</strong></p>\n<ul>\n<li><em>生物网络构建</em>：基于基因互作（如STRING数据库的蛋白-蛋白互作）、基因共表达或通路信息构建异质图。例如，AGMI（2021）整合多组学数据和PPI网络，通过GNN学习癌症样本的联合表征。  </li>\n<li><em>多组学融合</em>：部分模型（如TGSA）利用GNN整合基因组、转录组等数据，通过跨模态注意力机制增强特征交互。</li>\n</ul>\n</li>\n<li><p><strong>异构图与联合建模</strong></p>\n<ul>\n<li><em>细胞系-药物异构图</em>：如GraphCDR（2021）将细胞系和药物作为两类节点，通过边连接已知响应对，直接学习跨实体关系。  </li>\n<li><em>知识增强</em>：预训练GNN于大规模生物化学属性预测（如Zhu et al., 2021），再迁移至DRP任务，提升泛化性。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"🎯-总结与展望\"><a href=\"#🎯-总结与展望\" class=\"headerlink\" title=\"🎯 总结与展望\"></a>🎯 总结与展望</h2><ul>\n<li><strong>动态图建模</strong>：捕捉治疗过程中动态变化的生物网络。  </li>\n<li><strong>三维分子图</strong>：结合几何深度学习（如SchNet）提升立体化学感知。  </li>\n<li><strong>基准测试</strong>：需统一评估协议（如固定数据集和指标）以公平比较GNN与其他方法。</li>\n</ul>\n<p><del>之后应该会写一些具体模型的博客，有相关的会直接上链接的捏jrm</del></p>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/1609.02907v4.pdf\" target=\"_blank\">📄 Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a><br><a href=\"https://pytorch-geometric.readthedocs.io/\" target=\"_blank\">PyTorch Geometric 官方文档</a><br><a href=\"https://distill.pub/2021/gnn-intro/\" target=\"_blank\">Distill: A Gentle Introduction to Graph Neural Networks</a><br><a href=\"https://distill.pub/2021/understanding-gnns/\" target=\"_blank\">Distill: Understanding Convolutions on Graphs</a><br><a href=\"https://www.zhihu.com/tardis/zm/art/107162772\" target=\"_blank\">知乎：图卷积网络（GCN）入门详解</a><br><a href=\"https://github.com/tkipf/gcn\" target=\"_blank\">GCN 论文官方代码（GitHub）</a></p>"},{"title":"Attention Overview","date":"2025-07-10T11:56:23.000Z","_content":"\n# Is Attention All My Need ?\n\n> 注意力机制在图神经网络中扮演着越来越重要的角色。~~但鼠鼠现在连正常的Attention有哪些都不清楚捏~~本文鼠鼠将从一般的Attention出发，给出Attention的总体结构，然后按分类介绍现有的主要的Attention\n\n本文主要来自于一篇论文，基本可以看作[那篇论文](/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf)的阅读笔记\n\n<!-- more -->\n\n## 🎯 引言\n\n在深度学习领域，注意力机制已经成为一个革命性的创新，特别是在处理序列数据和图像数据方面取得了巨大成功。而在图神经网络中，注意力机制的引入不仅提高了模型的表现力，还增强了模型的可解释性。\n\n在图结构数据中应用注意力机制主要有以下优势：\n1. 自适应性：能够根据任务动态调整不同邻居节点的重要性\n2. 可解释性：通过注意力权重可以直观理解模型的决策过程\n3. 长程依赖：有效缓解了传统GNN中的过平滑问题\n4. 异质性处理：更好地处理异质图中的不同类型节点和边\n\n## 📚 总览Attention\n\n本章节主要参考了论文[📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning](/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf)有兴趣的话可以看看原文捏\n\n<embed src=\"/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\" width=\"45%\" height=\"400\" type=\"application/pdf\">\n\n### Attention的一般结构\n\n<img src=\"/img/Attention/TotalModel.png\" alt=\"TotalModel\" width=\"60%\" height=\"auto\">\n\n上图是从总体上看Attention在整个任务模型框架中的位置\n\n框架包含四个核心组件：\n1. **特征模型**：负责输入数据的特征提取\n2. **查询模型**：生成注意力查询向量\n3. **注意力模型**：计算注意力权重\n4. **输出模型**：生成最终预测结果\n\n接下来，我们会从 *输入* 的角度来看**特征模型**和**查询模型**，从 *输出* 的角度来看**注意力模型**和**输出模型**\n\n#### 输入处理机制\n\n1. **特征模型**，即将任务的输入进行embedding\n   \n    对于输入矩阵$ X \\in \\mathbb{R}^{d_x \\times n_x} $，特征模型提取特征向量：$\\boldsymbol{F} = [f_1, \\ldots, f_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$\n\n2. **查询模型**，查询模型产生查询向量$ \\boldsymbol{q} \\in \\mathbb{R}^{d_q} $，用以告诉注意力模型哪一个特征是重要的\n\n一般情况下，这两个模型可以用CNN或RNN\n\n#### 输出计算机制\n\n<img src=\"/img/Attention/GeneralAttentionModule.png\" alt=\"GeneralAttentionModule\" width=\"50%\" height=\"auto\">\n\n上图是Attention模型总体结构的说明，下面对这张图进行详细的说明\n\n1. 特征矩阵$\\boldsymbol{F} = [\\boldsymbol{f}\\_1, \\ldots, \\boldsymbol{f}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_f \\times n\\_f}$，通过*某些方法*将其分为Keys矩阵$\\boldsymbol{K} = [\\boldsymbol{k}\\_1, \\ldots, \\boldsymbol{k}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_k \\times n\\_f}$和Values矩阵$\\boldsymbol{V} = [\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_v \\times n\\_f}$，这里的*某些方法*，一般情况下，按以下的方式通过**线性变换**得到：\n\n$$\n\\underset{d\\_{k} \\times n\\_{f}}{\\boldsymbol{K}}=\\underset{d\\_{k} \\times d\\_{f}}{\\boldsymbol{W}\\_{K}} \\times \\underset{d\\_{f} \\times n\\_{f}}{\\boldsymbol{F}}, \\quad \\underset{d\\_{v} \\times n\\_{f}}{\\boldsymbol{V}}=\\underset{d\\_{v} \\times d\\_{f}}{\\boldsymbol{W}\\_{V}} \\times \\underset{d\\_{f} \\times n\\_{f}}{\\boldsymbol{F}} .\n$$\n\n2. `Attention Scores`模块根据 $\\boldsymbol{q}$ 计算每一个key向量对应的分数$\\boldsymbol{e} = [e_1, \\ldots, e_{n_f}] \\in \\mathbb{R}^{n_f}$：\n\n    $$\n    \\underset{1\\times 1}{e\\_l} = \\text{score}(\\underset{d\\_q \\times 1}{\\boldsymbol{q}}, \\underset{d\\_k \\times 1}{\\boldsymbol{k}\\_l}) \n    $$\n\n    如前所述，查询象征着对信息的请求。注意力分数$e_l$表示根据查询，关键向量$\\boldsymbol{k}_l$中包含的信息的重要性。如果查询和关键向量的维度相同，则得分函数的一个例子是取向量的点积。\n\n3. 由于经过这么一堆操作之后，分数有很大的可能已经飞起来了捏，这个时候就需要`Attention Alignment`模块对其进行**归一化**之类的操作了捏\n\n    $$\n    \\underset{1\\times 1}{a\\_l} = \\text{align}(\\underset{d\\_q \\times 1}{\\boldsymbol{e\\_l}}, \\underset{n\\_f \\times 1}{\\boldsymbol{e}}) \n    $$\n\n注意力权重$\\boldsymbol{a} = [a_1, \\ldots, a_{n_f}] \\in \\mathbb{R}^{n_f}$为注意力模块提供了一个相当直观的解释。每个权重直接表明了每个特征向量相对于其他特征向量对于这个问题的重要性。 \n\n4. 在`Weight Average`模块完成**上下文生成**：\n\n    $$\n    \\underset{d\\_v \\times 1}{\\boldsymbol{c}} = \\sum\\_{l = 1}^{n\\_f} \\underset{1 \\times 1}{a\\_l}\\times \\underset{d\\_v \\times 1}{\\boldsymbol{v}\\_l}\n    $$\n\n5. 输出处理就想怎么搞就怎么搞了捏，例如 用于分类\n\n    $$\n    \\underset{d\\_y \\times 1}{\\hat{\\boldsymbol{y}}} = \\text{softmax}( \\underset{d\\_y \\times d\\_v}{\\boldsymbol{W}\\_c}\\times \\underset{d\\_v \\times 1}{\\boldsymbol{c}} + \\underset{d\\_y \\times 1}{\\boldsymbol{b}\\_c})\n    $$\n\n### Attention分类\n\n<img src=\"/img/Attention/Taxonomy.png\" style=\"max-width: 100%; height: auto;\">\n\n论文按照上图的方式给Attention进行了分类\n\n由于篇幅限制，这里决定重开几个博文来分别介绍这些Attention，链接如下：\n\n{% post_link 'Feature-Related-Attention' %}\n\n\n\n\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n<a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>","source":"_posts/Attention.md","raw":"---\ntitle: Attention Overview\ndate: 2025-07-10 19:56:23\ncategories:\n  - CDR\n  - model\n  - attention\ntags:\n  - CDR\n  - model\n  - Basic\n  - 还没写完捏\n  - deep learning\n  - PyTorch\n---\n\n# Is Attention All My Need ?\n\n> 注意力机制在图神经网络中扮演着越来越重要的角色。~~但鼠鼠现在连正常的Attention有哪些都不清楚捏~~本文鼠鼠将从一般的Attention出发，给出Attention的总体结构，然后按分类介绍现有的主要的Attention\n\n本文主要来自于一篇论文，基本可以看作[那篇论文](/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf)的阅读笔记\n\n<!-- more -->\n\n## 🎯 引言\n\n在深度学习领域，注意力机制已经成为一个革命性的创新，特别是在处理序列数据和图像数据方面取得了巨大成功。而在图神经网络中，注意力机制的引入不仅提高了模型的表现力，还增强了模型的可解释性。\n\n在图结构数据中应用注意力机制主要有以下优势：\n1. 自适应性：能够根据任务动态调整不同邻居节点的重要性\n2. 可解释性：通过注意力权重可以直观理解模型的决策过程\n3. 长程依赖：有效缓解了传统GNN中的过平滑问题\n4. 异质性处理：更好地处理异质图中的不同类型节点和边\n\n## 📚 总览Attention\n\n本章节主要参考了论文[📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning](/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf)有兴趣的话可以看看原文捏\n\n<embed src=\"/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\" width=\"45%\" height=\"400\" type=\"application/pdf\">\n\n### Attention的一般结构\n\n<img src=\"/img/Attention/TotalModel.png\" alt=\"TotalModel\" width=\"60%\" height=\"auto\">\n\n上图是从总体上看Attention在整个任务模型框架中的位置\n\n框架包含四个核心组件：\n1. **特征模型**：负责输入数据的特征提取\n2. **查询模型**：生成注意力查询向量\n3. **注意力模型**：计算注意力权重\n4. **输出模型**：生成最终预测结果\n\n接下来，我们会从 *输入* 的角度来看**特征模型**和**查询模型**，从 *输出* 的角度来看**注意力模型**和**输出模型**\n\n#### 输入处理机制\n\n1. **特征模型**，即将任务的输入进行embedding\n   \n    对于输入矩阵$ X \\in \\mathbb{R}^{d_x \\times n_x} $，特征模型提取特征向量：$\\boldsymbol{F} = [f_1, \\ldots, f_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$\n\n2. **查询模型**，查询模型产生查询向量$ \\boldsymbol{q} \\in \\mathbb{R}^{d_q} $，用以告诉注意力模型哪一个特征是重要的\n\n一般情况下，这两个模型可以用CNN或RNN\n\n#### 输出计算机制\n\n<img src=\"/img/Attention/GeneralAttentionModule.png\" alt=\"GeneralAttentionModule\" width=\"50%\" height=\"auto\">\n\n上图是Attention模型总体结构的说明，下面对这张图进行详细的说明\n\n1. 特征矩阵$\\boldsymbol{F} = [\\boldsymbol{f}\\_1, \\ldots, \\boldsymbol{f}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_f \\times n\\_f}$，通过*某些方法*将其分为Keys矩阵$\\boldsymbol{K} = [\\boldsymbol{k}\\_1, \\ldots, \\boldsymbol{k}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_k \\times n\\_f}$和Values矩阵$\\boldsymbol{V} = [\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}\\_{n\\_f}] \\in \\mathbb{R}^{d\\_v \\times n\\_f}$，这里的*某些方法*，一般情况下，按以下的方式通过**线性变换**得到：\n\n$$\n\\underset{d\\_{k} \\times n\\_{f}}{\\boldsymbol{K}}=\\underset{d\\_{k} \\times d\\_{f}}{\\boldsymbol{W}\\_{K}} \\times \\underset{d\\_{f} \\times n\\_{f}}{\\boldsymbol{F}}, \\quad \\underset{d\\_{v} \\times n\\_{f}}{\\boldsymbol{V}}=\\underset{d\\_{v} \\times d\\_{f}}{\\boldsymbol{W}\\_{V}} \\times \\underset{d\\_{f} \\times n\\_{f}}{\\boldsymbol{F}} .\n$$\n\n2. `Attention Scores`模块根据 $\\boldsymbol{q}$ 计算每一个key向量对应的分数$\\boldsymbol{e} = [e_1, \\ldots, e_{n_f}] \\in \\mathbb{R}^{n_f}$：\n\n    $$\n    \\underset{1\\times 1}{e\\_l} = \\text{score}(\\underset{d\\_q \\times 1}{\\boldsymbol{q}}, \\underset{d\\_k \\times 1}{\\boldsymbol{k}\\_l}) \n    $$\n\n    如前所述，查询象征着对信息的请求。注意力分数$e_l$表示根据查询，关键向量$\\boldsymbol{k}_l$中包含的信息的重要性。如果查询和关键向量的维度相同，则得分函数的一个例子是取向量的点积。\n\n3. 由于经过这么一堆操作之后，分数有很大的可能已经飞起来了捏，这个时候就需要`Attention Alignment`模块对其进行**归一化**之类的操作了捏\n\n    $$\n    \\underset{1\\times 1}{a\\_l} = \\text{align}(\\underset{d\\_q \\times 1}{\\boldsymbol{e\\_l}}, \\underset{n\\_f \\times 1}{\\boldsymbol{e}}) \n    $$\n\n注意力权重$\\boldsymbol{a} = [a_1, \\ldots, a_{n_f}] \\in \\mathbb{R}^{n_f}$为注意力模块提供了一个相当直观的解释。每个权重直接表明了每个特征向量相对于其他特征向量对于这个问题的重要性。 \n\n4. 在`Weight Average`模块完成**上下文生成**：\n\n    $$\n    \\underset{d\\_v \\times 1}{\\boldsymbol{c}} = \\sum\\_{l = 1}^{n\\_f} \\underset{1 \\times 1}{a\\_l}\\times \\underset{d\\_v \\times 1}{\\boldsymbol{v}\\_l}\n    $$\n\n5. 输出处理就想怎么搞就怎么搞了捏，例如 用于分类\n\n    $$\n    \\underset{d\\_y \\times 1}{\\hat{\\boldsymbol{y}}} = \\text{softmax}( \\underset{d\\_y \\times d\\_v}{\\boldsymbol{W}\\_c}\\times \\underset{d\\_v \\times 1}{\\boldsymbol{c}} + \\underset{d\\_y \\times 1}{\\boldsymbol{b}\\_c})\n    $$\n\n### Attention分类\n\n<img src=\"/img/Attention/Taxonomy.png\" style=\"max-width: 100%; height: auto;\">\n\n论文按照上图的方式给Attention进行了分类\n\n由于篇幅限制，这里决定重开几个博文来分别介绍这些Attention，链接如下：\n\n{% post_link 'Feature-Related-Attention' %}\n\n\n\n\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n<a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>","slug":"Attention","published":1,"updated":"2025-07-14T14:38:29.037Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvp0006k841g5i01rie","content":"<h1 id=\"Is-Attention-All-My-Need\"><a href=\"#Is-Attention-All-My-Need\" class=\"headerlink\" title=\"Is Attention All My Need ?\"></a>Is Attention All My Need ?</h1><blockquote>\n<p>注意力机制在图神经网络中扮演着越来越重要的角色。<del>但鼠鼠现在连正常的Attention有哪些都不清楚捏</del>本文鼠鼠将从一般的Attention出发，给出Attention的总体结构，然后按分类介绍现有的主要的Attention</p>\n</blockquote>\n<p>本文主要来自于一篇论文，基本可以看作<a href=\"/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\">那篇论文</a>的阅读笔记</p>\n<span id=\"more\"></span>\n\n<h2 id=\"🎯-引言\"><a href=\"#🎯-引言\" class=\"headerlink\" title=\"🎯 引言\"></a>🎯 引言</h2><p>在深度学习领域，注意力机制已经成为一个革命性的创新，特别是在处理序列数据和图像数据方面取得了巨大成功。而在图神经网络中，注意力机制的引入不仅提高了模型的表现力，还增强了模型的可解释性。</p>\n<p>在图结构数据中应用注意力机制主要有以下优势：</p>\n<ol>\n<li>自适应性：能够根据任务动态调整不同邻居节点的重要性</li>\n<li>可解释性：通过注意力权重可以直观理解模型的决策过程</li>\n<li>长程依赖：有效缓解了传统GNN中的过平滑问题</li>\n<li>异质性处理：更好地处理异质图中的不同类型节点和边</li>\n</ol>\n<h2 id=\"📚-总览Attention\"><a href=\"#📚-总览Attention\" class=\"headerlink\" title=\"📚 总览Attention\"></a>📚 总览Attention</h2><p>本章节主要参考了论文<a href=\"/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>有兴趣的话可以看看原文捏</p>\n<embed src=\"/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\" width=\"45%\" height=\"400\" type=\"application/pdf\">\n\n<h3 id=\"Attention的一般结构\"><a href=\"#Attention的一般结构\" class=\"headerlink\" title=\"Attention的一般结构\"></a>Attention的一般结构</h3><img src=\"/img/Attention/TotalModel.png\" alt=\"TotalModel\" width=\"60%\" height=\"auto\">\n\n<p>上图是从总体上看Attention在整个任务模型框架中的位置</p>\n<p>框架包含四个核心组件：</p>\n<ol>\n<li><strong>特征模型</strong>：负责输入数据的特征提取</li>\n<li><strong>查询模型</strong>：生成注意力查询向量</li>\n<li><strong>注意力模型</strong>：计算注意力权重</li>\n<li><strong>输出模型</strong>：生成最终预测结果</li>\n</ol>\n<p>接下来，我们会从 <em>输入</em> 的角度来看<strong>特征模型</strong>和<strong>查询模型</strong>，从 <em>输出</em> 的角度来看<strong>注意力模型</strong>和<strong>输出模型</strong></p>\n<h4 id=\"输入处理机制\"><a href=\"#输入处理机制\" class=\"headerlink\" title=\"输入处理机制\"></a>输入处理机制</h4><ol>\n<li><p><strong>特征模型</strong>，即将任务的输入进行embedding</p>\n<p> 对于输入矩阵$ X \\in \\mathbb{R}^{d_x \\times n_x} $，特征模型提取特征向量：$\\boldsymbol{F} &#x3D; [f_1, \\ldots, f_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$</p>\n</li>\n<li><p><strong>查询模型</strong>，查询模型产生查询向量$ \\boldsymbol{q} \\in \\mathbb{R}^{d_q} $，用以告诉注意力模型哪一个特征是重要的</p>\n</li>\n</ol>\n<p>一般情况下，这两个模型可以用CNN或RNN</p>\n<h4 id=\"输出计算机制\"><a href=\"#输出计算机制\" class=\"headerlink\" title=\"输出计算机制\"></a>输出计算机制</h4><img src=\"/img/Attention/GeneralAttentionModule.png\" alt=\"GeneralAttentionModule\" width=\"50%\" height=\"auto\">\n\n<p>上图是Attention模型总体结构的说明，下面对这张图进行详细的说明</p>\n<ol>\n<li>特征矩阵$\\boldsymbol{F} &#x3D; [\\boldsymbol{f}_1, \\ldots, \\boldsymbol{f}_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$，通过<em>某些方法</em>将其分为Keys矩阵$\\boldsymbol{K} &#x3D; [\\boldsymbol{k}_1, \\ldots, \\boldsymbol{k}_{n_f}] \\in \\mathbb{R}^{d_k \\times n_f}$和Values矩阵$\\boldsymbol{V} &#x3D; [\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_{n_f}] \\in \\mathbb{R}^{d_v \\times n_f}$，这里的<em>某些方法</em>，一般情况下，按以下的方式通过<strong>线性变换</strong>得到：</li>\n</ol>\n<p>$$<br>\\underset{d_{k} \\times n_{f}}{\\boldsymbol{K}}&#x3D;\\underset{d_{k} \\times d_{f}}{\\boldsymbol{W}_{K}} \\times \\underset{d_{f} \\times n_{f}}{\\boldsymbol{F}}, \\quad \\underset{d_{v} \\times n_{f}}{\\boldsymbol{V}}&#x3D;\\underset{d_{v} \\times d_{f}}{\\boldsymbol{W}_{V}} \\times \\underset{d_{f} \\times n_{f}}{\\boldsymbol{F}} .<br>$$</p>\n<ol start=\"2\">\n<li><p><code>Attention Scores</code>模块根据 $\\boldsymbol{q}$ 计算每一个key向量对应的分数$\\boldsymbol{e} &#x3D; [e_1, \\ldots, e_{n_f}] \\in \\mathbb{R}^{n_f}$：</p>\n<p> $$<br> \\underset{1\\times 1}{e_l} &#x3D; \\text{score}(\\underset{d_q \\times 1}{\\boldsymbol{q}}, \\underset{d_k \\times 1}{\\boldsymbol{k}_l})<br> $$</p>\n<p> 如前所述，查询象征着对信息的请求。注意力分数$e_l$表示根据查询，关键向量$\\boldsymbol{k}_l$中包含的信息的重要性。如果查询和关键向量的维度相同，则得分函数的一个例子是取向量的点积。</p>\n</li>\n<li><p>由于经过这么一堆操作之后，分数有很大的可能已经飞起来了捏，这个时候就需要<code>Attention Alignment</code>模块对其进行<strong>归一化</strong>之类的操作了捏</p>\n<p> $$<br> \\underset{1\\times 1}{a_l} &#x3D; \\text{align}(\\underset{d_q \\times 1}{\\boldsymbol{e_l}}, \\underset{n_f \\times 1}{\\boldsymbol{e}})<br> $$</p>\n</li>\n</ol>\n<p>注意力权重$\\boldsymbol{a} &#x3D; [a_1, \\ldots, a_{n_f}] \\in \\mathbb{R}^{n_f}$为注意力模块提供了一个相当直观的解释。每个权重直接表明了每个特征向量相对于其他特征向量对于这个问题的重要性。 </p>\n<ol start=\"4\">\n<li><p>在<code>Weight Average</code>模块完成<strong>上下文生成</strong>：</p>\n<p> $$<br> \\underset{d_v \\times 1}{\\boldsymbol{c}} &#x3D; \\sum_{l &#x3D; 1}^{n_f} \\underset{1 \\times 1}{a_l}\\times \\underset{d_v \\times 1}{\\boldsymbol{v}_l}<br> $$</p>\n</li>\n<li><p>输出处理就想怎么搞就怎么搞了捏，例如 用于分类</p>\n<p> $$<br> \\underset{d_y \\times 1}{\\hat{\\boldsymbol{y}}} &#x3D; \\text{softmax}( \\underset{d_y \\times d_v}{\\boldsymbol{W}_c}\\times \\underset{d_v \\times 1}{\\boldsymbol{c}} + \\underset{d_y \\times 1}{\\boldsymbol{b}_c})<br> $$</p>\n</li>\n</ol>\n<h3 id=\"Attention分类\"><a href=\"#Attention分类\" class=\"headerlink\" title=\"Attention分类\"></a>Attention分类</h3><img src=\"/img/Attention/Taxonomy.png\" style=\"max-width: 100%; height: auto;\">\n\n<p>论文按照上图的方式给Attention进行了分类</p>\n<p>由于篇幅限制，这里决定重开几个博文来分别介绍这些Attention，链接如下：</p>\n<a href=\"/2025/07/14/Feature-Related-Attention/\" title=\"Feature-Related Attention\">Feature-Related Attention</a>\n\n\n\n\n\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>\n","length":1293,"excerpt":"<h1 id=\"Is-Attention-All-My-Need\"><a href=\"#Is-Attention-All-My-Need\" class=\"headerlink\" title=\"Is Attention All My Need ?\"></a>Is Attention All My Need ?</h1><blockquote>\n<p>注意力机制在图神经网络中扮演着越来越重要的角色。<del>但鼠鼠现在连正常的Attention有哪些都不清楚捏</del>本文鼠鼠将从一般的Attention出发，给出Attention的总体结构，然后按分类介绍现有的主要的Attention</p>\n</blockquote>\n<p>本文主要来自于一篇论文，基本可以看作<a href=\"/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\">那篇论文</a>的阅读笔记</p>","more":"<h2 id=\"🎯-引言\"><a href=\"#🎯-引言\" class=\"headerlink\" title=\"🎯 引言\"></a>🎯 引言</h2><p>在深度学习领域，注意力机制已经成为一个革命性的创新，特别是在处理序列数据和图像数据方面取得了巨大成功。而在图神经网络中，注意力机制的引入不仅提高了模型的表现力，还增强了模型的可解释性。</p>\n<p>在图结构数据中应用注意力机制主要有以下优势：</p>\n<ol>\n<li>自适应性：能够根据任务动态调整不同邻居节点的重要性</li>\n<li>可解释性：通过注意力权重可以直观理解模型的决策过程</li>\n<li>长程依赖：有效缓解了传统GNN中的过平滑问题</li>\n<li>异质性处理：更好地处理异质图中的不同类型节点和边</li>\n</ol>\n<h2 id=\"📚-总览Attention\"><a href=\"#📚-总览Attention\" class=\"headerlink\" title=\"📚 总览Attention\"></a>📚 总览Attention</h2><p>本章节主要参考了论文<a href=\"/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>有兴趣的话可以看看原文捏</p>\n<embed src=\"/paper/Brauwers和Frasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf\" width=\"45%\" height=\"400\" type=\"application/pdf\">\n\n<h3 id=\"Attention的一般结构\"><a href=\"#Attention的一般结构\" class=\"headerlink\" title=\"Attention的一般结构\"></a>Attention的一般结构</h3><img src=\"/img/Attention/TotalModel.png\" alt=\"TotalModel\" width=\"60%\" height=\"auto\">\n\n<p>上图是从总体上看Attention在整个任务模型框架中的位置</p>\n<p>框架包含四个核心组件：</p>\n<ol>\n<li><strong>特征模型</strong>：负责输入数据的特征提取</li>\n<li><strong>查询模型</strong>：生成注意力查询向量</li>\n<li><strong>注意力模型</strong>：计算注意力权重</li>\n<li><strong>输出模型</strong>：生成最终预测结果</li>\n</ol>\n<p>接下来，我们会从 <em>输入</em> 的角度来看<strong>特征模型</strong>和<strong>查询模型</strong>，从 <em>输出</em> 的角度来看<strong>注意力模型</strong>和<strong>输出模型</strong></p>\n<h4 id=\"输入处理机制\"><a href=\"#输入处理机制\" class=\"headerlink\" title=\"输入处理机制\"></a>输入处理机制</h4><ol>\n<li><p><strong>特征模型</strong>，即将任务的输入进行embedding</p>\n<p> 对于输入矩阵$ X \\in \\mathbb{R}^{d_x \\times n_x} $，特征模型提取特征向量：$\\boldsymbol{F} &#x3D; [f_1, \\ldots, f_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$</p>\n</li>\n<li><p><strong>查询模型</strong>，查询模型产生查询向量$ \\boldsymbol{q} \\in \\mathbb{R}^{d_q} $，用以告诉注意力模型哪一个特征是重要的</p>\n</li>\n</ol>\n<p>一般情况下，这两个模型可以用CNN或RNN</p>\n<h4 id=\"输出计算机制\"><a href=\"#输出计算机制\" class=\"headerlink\" title=\"输出计算机制\"></a>输出计算机制</h4><img src=\"/img/Attention/GeneralAttentionModule.png\" alt=\"GeneralAttentionModule\" width=\"50%\" height=\"auto\">\n\n<p>上图是Attention模型总体结构的说明，下面对这张图进行详细的说明</p>\n<ol>\n<li>特征矩阵$\\boldsymbol{F} &#x3D; [\\boldsymbol{f}_1, \\ldots, \\boldsymbol{f}_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f}$，通过<em>某些方法</em>将其分为Keys矩阵$\\boldsymbol{K} &#x3D; [\\boldsymbol{k}_1, \\ldots, \\boldsymbol{k}_{n_f}] \\in \\mathbb{R}^{d_k \\times n_f}$和Values矩阵$\\boldsymbol{V} &#x3D; [\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_{n_f}] \\in \\mathbb{R}^{d_v \\times n_f}$，这里的<em>某些方法</em>，一般情况下，按以下的方式通过<strong>线性变换</strong>得到：</li>\n</ol>\n<p>$$<br>\\underset{d_{k} \\times n_{f}}{\\boldsymbol{K}}&#x3D;\\underset{d_{k} \\times d_{f}}{\\boldsymbol{W}_{K}} \\times \\underset{d_{f} \\times n_{f}}{\\boldsymbol{F}}, \\quad \\underset{d_{v} \\times n_{f}}{\\boldsymbol{V}}&#x3D;\\underset{d_{v} \\times d_{f}}{\\boldsymbol{W}_{V}} \\times \\underset{d_{f} \\times n_{f}}{\\boldsymbol{F}} .<br>$$</p>\n<ol start=\"2\">\n<li><p><code>Attention Scores</code>模块根据 $\\boldsymbol{q}$ 计算每一个key向量对应的分数$\\boldsymbol{e} &#x3D; [e_1, \\ldots, e_{n_f}] \\in \\mathbb{R}^{n_f}$：</p>\n<p> $$<br> \\underset{1\\times 1}{e_l} &#x3D; \\text{score}(\\underset{d_q \\times 1}{\\boldsymbol{q}}, \\underset{d_k \\times 1}{\\boldsymbol{k}_l})<br> $$</p>\n<p> 如前所述，查询象征着对信息的请求。注意力分数$e_l$表示根据查询，关键向量$\\boldsymbol{k}_l$中包含的信息的重要性。如果查询和关键向量的维度相同，则得分函数的一个例子是取向量的点积。</p>\n</li>\n<li><p>由于经过这么一堆操作之后，分数有很大的可能已经飞起来了捏，这个时候就需要<code>Attention Alignment</code>模块对其进行<strong>归一化</strong>之类的操作了捏</p>\n<p> $$<br> \\underset{1\\times 1}{a_l} &#x3D; \\text{align}(\\underset{d_q \\times 1}{\\boldsymbol{e_l}}, \\underset{n_f \\times 1}{\\boldsymbol{e}})<br> $$</p>\n</li>\n</ol>\n<p>注意力权重$\\boldsymbol{a} &#x3D; [a_1, \\ldots, a_{n_f}] \\in \\mathbb{R}^{n_f}$为注意力模块提供了一个相当直观的解释。每个权重直接表明了每个特征向量相对于其他特征向量对于这个问题的重要性。 </p>\n<ol start=\"4\">\n<li><p>在<code>Weight Average</code>模块完成<strong>上下文生成</strong>：</p>\n<p> $$<br> \\underset{d_v \\times 1}{\\boldsymbol{c}} &#x3D; \\sum_{l &#x3D; 1}^{n_f} \\underset{1 \\times 1}{a_l}\\times \\underset{d_v \\times 1}{\\boldsymbol{v}_l}<br> $$</p>\n</li>\n<li><p>输出处理就想怎么搞就怎么搞了捏，例如 用于分类</p>\n<p> $$<br> \\underset{d_y \\times 1}{\\hat{\\boldsymbol{y}}} &#x3D; \\text{softmax}( \\underset{d_y \\times d_v}{\\boldsymbol{W}_c}\\times \\underset{d_v \\times 1}{\\boldsymbol{c}} + \\underset{d_y \\times 1}{\\boldsymbol{b}_c})<br> $$</p>\n</li>\n</ol>\n<h3 id=\"Attention分类\"><a href=\"#Attention分类\" class=\"headerlink\" title=\"Attention分类\"></a>Attention分类</h3><img src=\"/img/Attention/Taxonomy.png\" style=\"max-width: 100%; height: auto;\">\n\n<p>论文按照上图的方式给Attention进行了分类</p>\n<p>由于篇幅限制，这里决定重开几个博文来分别介绍这些Attention，链接如下：</p>\n<a href=\"/2025/07/14/Feature-Related-Attention/\" title=\"Feature-Related Attention\">Feature-Related Attention</a>\n\n\n\n\n\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf\" target=\"_blank\">📄 Brauwers和Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>"},{"title":"PEP 8","date":"2025-07-08T03:41:30.000Z","_content":"\n# Style Guide for Python Code\n\n> [PEP8](https://peps.python.org/pep-0008/) 是 Python 社群共通的風格指南，一開始是 Python 之父 Guido van Rossum 自己的撰碼風格，慢慢後來演變至今，目的在於幫助開發者寫出可讀性高且風格一致的程式。許多開源計畫，例如 Django 、 OpenStack 等都是以 PEP8 為基礎再加上自己的風格建議。\n\n这篇博客主要是为了在搭建自己的模型之前学习一下一些统一的规范是做的记录 ~~主要是目前读到的大多数论文的源码目命名没有规律~~ ，以加强之后搭建模型时代码的可读性\n\n另外，本博客只展示本人不太熟悉的捏\n\n<!-- more -->\n\n## 代码布局\n\n### 缩进\n\n**每个缩进级别使用 4 个空格**\n\n对于比较臭长的函数，可以使用*悬挂缩进*\n\n```Python\n# Correct:\n\n# Aligned with opening delimiter.\nfoo = long_function_name(var_one, var_two,\n                         var_three, var_four)\n\n# Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.\ndef long_function_name(\n        var_one, var_two, var_three,\n        var_four):\n    print(var_one)\n\n# Hanging indents should add a level.\nfoo = long_function_name(\n    var_one, var_two,\n    var_three, var_four)\n```\n\n```Python\n# Wrong:\n\n# Arguments on first line forbidden when not using vertical alignment.\nfoo = long_function_name(var_one, var_two,\n    var_three, var_four)\n\n# Further indentation required as indentation is not distinguishable.\ndef long_function_name(\n    var_one, var_two, var_three,\n    var_four):\n    print(var_one)\n```\n\n优先使用 _Tabs_ 进行缩进， _Tabs_ 和 _Spaces_ 不能混用\n\n### 每行最多字符数量\n\n**79** 个\n\n合理使用反斜杠\n\n```Python\nwith open('/path/to/some/file/you/want/to/read') as file_1, \\\n     open('/path/to/some/file/being/written', 'w') as file_2:\n    file_2.write(file_1.read())\n```\n\n### 二元运算符之前换行\n\n为了更好的确定该 `item` 采取的是什么运算\n\n```Python\n# Wrong:\n# operators sit far away from their operands\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n```\n\n```Python\n# Correct:\n# easy to match operators with operands\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n```\n\n### 如何空行（Blank Lines）\n\n_顶级函数_ 和 _类_ 之间空 **2** 行\n\n_类中的函数_ 空 **1** 行\n\n### import\n\n- 通常每一个库 **单独一行**（也有例外）\n\n```Python\nimport os\nimport sys\n\nfrom subprocess import Popen, PIPE\n```\n\n- 按以下顺序分组，每组间空行\n  1. **标准库**导入\n  2. **相关第三方库**导入\n  3. **特定的本地库**导入\n\n## 注释\n\n> Comments that contradict the code are worse than no comments.\n\n## 命名约定\n\n1. **类名** 用 **大驼峰**\n2. **函数名** 用 **小写下划线**\n3. 关于 _下划线_\n\n   - _单下划线_ 用于占位\n\n   ```Python\n   for _ in range(10):\n       print(random.randint(1, 100))\n   ```\n\n   - _单下划线_ 用于变量前表示该变量为 **弱私有** （语义上的 private），能调用但不能 import\n   - _双下划线_ 用于变量前表示该变量为 **强私有** （实际上也不能调用~~实现方式是重名名~~）\n     为了更好的说明这两点，给出以下两个测试程序\n\n   ```Python\n    \"\"\"\n    test_private_vars.py\n    This file is used to test the private variables in Python.\n    \"\"\"\n    class TestClass:\n        def __init__(self):\n            self.public_var = \"这是公有变量\"\n            self._weak_private = \"这是弱私有变量\"\n            self.__strong_private = \"这是强私有变量\"\n\n        def print_all_vars(self):\n            print(f\"从内部访问:\")\n            print(f\"公有变量: {self.public_var}\")\n            print(f\"弱私有变量: {self._weak_private}\")\n            print(f\"强私有变量: {self.__strong_private}\")\n\n    # 创建测试实例\n    test = TestClass()\n\n    # 1. 测试从类内部访问（通过方法）\n    print(\"\\n=== 测试1: 从类内部访问所有变量 ===\")\n    test.print_all_vars()\n\n    # 2. 测试从外部直接访问\n    print(\"\\n=== 测试2: 从外部访问变量 ===\")\n    print(f\"访问公有变量: {test.public_var}\")\n    print(f\"访问弱私有变量: {test._weak_private}\")  # 能访问，但IDE会警告\n    try:\n        print(f\"访问强私有变量: {test.__strong_private}\")\n    except AttributeError as e:\n        print(f\"访问强私有变量失败: {e}\")\n\n    # 3. 测试名称改写机制\n    print(\"\\n=== 测试3: 验证强私有变量的名称改写机制 ===\")\n    # 实际上Python会将__strong_private改写为_TestClass__strong_private\n    print(f\"通过改写后的名称访问强私有变量: {test._TestClass__strong_private}\")\n\n    # 4. 测试导入行为\n    if __name__ == \"__main__\":\n        print(\"\\n=== 测试4: 创建第二个文件并尝试导入 ===\")\n        print(\"请创建 test_import.py 并运行来测试导入行为\")\n   ```\n\n   ```Python\n   \"\"\"\n   test_import.py\n   This file is used to test the import of private variables in Python.\n   \"\"\"\n   from test_private_vars import TestClass\n\n   print(\"=== 测试导入后的访问行为 ===\")\n   test = TestClass()\n\n   # 测试访问公有变量\n   print(f\"访问公有变量: {test.public_var}\")\n\n   # 测试访问弱私有变量\n   try:\n       print(f\"访问弱私有变量: {test._weak_private}\")\n       print(\"注意：虽然能访问弱私有变量，但这违反了Python的约定\")\n   except AttributeError as e:\n       print(f\"访问弱私有变量失败: {e}\")\n\n   # 测试访问强私有变量\n   try:\n       print(f\"访问强私有变量: {test.__strong_private}\")\n   except AttributeError as e:\n       print(f\"访问强私有变量失败: {e}\")\n\n   # 测试通过名称改写访问强私有变量\n   try:\n       print(f\"通过改写后的名称访问强私有变量: {test._TestClass__strong_private}\")\n       print(\"注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法\")\n   except AttributeError as e:\n       print(f\"通过改写名称访问强私有变量失败: {e}\")\n   ```\n\n   以下是运行 `python test_private_vars.py` 的结果\n\n   ```bash\n   === 测试1: 从类内部访问所有变量 ===\n   从内部访问:\n   公有变量: 这是公有变量\n   弱私有变量: 这是弱私有变量\n   强私有变量: 这是强私有变量\n\n   === 测试2: 从外部访问变量 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n\n   === 测试3: 验证强私有变量的名称改写机制 ===\n   通过改写后的名称访问强私有变量: 这是强私有变量\n\n   === 测试4: 创建第二个文件并尝试导入 ===\n   请创建 test_import.py 并运行来测试导入行为\n   ```\n\n   以下是运行 `python test_import.py` 的结果\n\n   ```bash\n   === 测试1: 从类内部访问所有变量 ===\n   从内部访问:\n   公有变量: 这是公有变量\n   弱私有变量: 这是弱私有变量\n   强私有变量: 这是强私有变量\n\n   === 测试2: 从外部访问变量 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n\n   === 测试3: 验证强私有变量的名称改写机制 ===\n   通过改写后的名称访问强私有变量: 这是强私有变量\n   === 测试导入后的访问行为 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   注意：虽然能访问弱私有变量，但这违反了Python的约定\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n   通过改写后的名称访问强私有变量: 这是强私有变量\n   注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法\n   ```\n","source":"_posts/PEP-8.md","raw":"---\ntitle: PEP 8\ndate: 2025-07-08 11:41:30\ntags:\n  - CDR\n  - Python\n  - PEP\n  - 闲🉐无聊\n  - 大概率没用\ncategories:\n  - Python\n---\n\n# Style Guide for Python Code\n\n> [PEP8](https://peps.python.org/pep-0008/) 是 Python 社群共通的風格指南，一開始是 Python 之父 Guido van Rossum 自己的撰碼風格，慢慢後來演變至今，目的在於幫助開發者寫出可讀性高且風格一致的程式。許多開源計畫，例如 Django 、 OpenStack 等都是以 PEP8 為基礎再加上自己的風格建議。\n\n这篇博客主要是为了在搭建自己的模型之前学习一下一些统一的规范是做的记录 ~~主要是目前读到的大多数论文的源码目命名没有规律~~ ，以加强之后搭建模型时代码的可读性\n\n另外，本博客只展示本人不太熟悉的捏\n\n<!-- more -->\n\n## 代码布局\n\n### 缩进\n\n**每个缩进级别使用 4 个空格**\n\n对于比较臭长的函数，可以使用*悬挂缩进*\n\n```Python\n# Correct:\n\n# Aligned with opening delimiter.\nfoo = long_function_name(var_one, var_two,\n                         var_three, var_four)\n\n# Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.\ndef long_function_name(\n        var_one, var_two, var_three,\n        var_four):\n    print(var_one)\n\n# Hanging indents should add a level.\nfoo = long_function_name(\n    var_one, var_two,\n    var_three, var_four)\n```\n\n```Python\n# Wrong:\n\n# Arguments on first line forbidden when not using vertical alignment.\nfoo = long_function_name(var_one, var_two,\n    var_three, var_four)\n\n# Further indentation required as indentation is not distinguishable.\ndef long_function_name(\n    var_one, var_two, var_three,\n    var_four):\n    print(var_one)\n```\n\n优先使用 _Tabs_ 进行缩进， _Tabs_ 和 _Spaces_ 不能混用\n\n### 每行最多字符数量\n\n**79** 个\n\n合理使用反斜杠\n\n```Python\nwith open('/path/to/some/file/you/want/to/read') as file_1, \\\n     open('/path/to/some/file/being/written', 'w') as file_2:\n    file_2.write(file_1.read())\n```\n\n### 二元运算符之前换行\n\n为了更好的确定该 `item` 采取的是什么运算\n\n```Python\n# Wrong:\n# operators sit far away from their operands\nincome = (gross_wages +\n          taxable_interest +\n          (dividends - qualified_dividends) -\n          ira_deduction -\n          student_loan_interest)\n```\n\n```Python\n# Correct:\n# easy to match operators with operands\nincome = (gross_wages\n          + taxable_interest\n          + (dividends - qualified_dividends)\n          - ira_deduction\n          - student_loan_interest)\n```\n\n### 如何空行（Blank Lines）\n\n_顶级函数_ 和 _类_ 之间空 **2** 行\n\n_类中的函数_ 空 **1** 行\n\n### import\n\n- 通常每一个库 **单独一行**（也有例外）\n\n```Python\nimport os\nimport sys\n\nfrom subprocess import Popen, PIPE\n```\n\n- 按以下顺序分组，每组间空行\n  1. **标准库**导入\n  2. **相关第三方库**导入\n  3. **特定的本地库**导入\n\n## 注释\n\n> Comments that contradict the code are worse than no comments.\n\n## 命名约定\n\n1. **类名** 用 **大驼峰**\n2. **函数名** 用 **小写下划线**\n3. 关于 _下划线_\n\n   - _单下划线_ 用于占位\n\n   ```Python\n   for _ in range(10):\n       print(random.randint(1, 100))\n   ```\n\n   - _单下划线_ 用于变量前表示该变量为 **弱私有** （语义上的 private），能调用但不能 import\n   - _双下划线_ 用于变量前表示该变量为 **强私有** （实际上也不能调用~~实现方式是重名名~~）\n     为了更好的说明这两点，给出以下两个测试程序\n\n   ```Python\n    \"\"\"\n    test_private_vars.py\n    This file is used to test the private variables in Python.\n    \"\"\"\n    class TestClass:\n        def __init__(self):\n            self.public_var = \"这是公有变量\"\n            self._weak_private = \"这是弱私有变量\"\n            self.__strong_private = \"这是强私有变量\"\n\n        def print_all_vars(self):\n            print(f\"从内部访问:\")\n            print(f\"公有变量: {self.public_var}\")\n            print(f\"弱私有变量: {self._weak_private}\")\n            print(f\"强私有变量: {self.__strong_private}\")\n\n    # 创建测试实例\n    test = TestClass()\n\n    # 1. 测试从类内部访问（通过方法）\n    print(\"\\n=== 测试1: 从类内部访问所有变量 ===\")\n    test.print_all_vars()\n\n    # 2. 测试从外部直接访问\n    print(\"\\n=== 测试2: 从外部访问变量 ===\")\n    print(f\"访问公有变量: {test.public_var}\")\n    print(f\"访问弱私有变量: {test._weak_private}\")  # 能访问，但IDE会警告\n    try:\n        print(f\"访问强私有变量: {test.__strong_private}\")\n    except AttributeError as e:\n        print(f\"访问强私有变量失败: {e}\")\n\n    # 3. 测试名称改写机制\n    print(\"\\n=== 测试3: 验证强私有变量的名称改写机制 ===\")\n    # 实际上Python会将__strong_private改写为_TestClass__strong_private\n    print(f\"通过改写后的名称访问强私有变量: {test._TestClass__strong_private}\")\n\n    # 4. 测试导入行为\n    if __name__ == \"__main__\":\n        print(\"\\n=== 测试4: 创建第二个文件并尝试导入 ===\")\n        print(\"请创建 test_import.py 并运行来测试导入行为\")\n   ```\n\n   ```Python\n   \"\"\"\n   test_import.py\n   This file is used to test the import of private variables in Python.\n   \"\"\"\n   from test_private_vars import TestClass\n\n   print(\"=== 测试导入后的访问行为 ===\")\n   test = TestClass()\n\n   # 测试访问公有变量\n   print(f\"访问公有变量: {test.public_var}\")\n\n   # 测试访问弱私有变量\n   try:\n       print(f\"访问弱私有变量: {test._weak_private}\")\n       print(\"注意：虽然能访问弱私有变量，但这违反了Python的约定\")\n   except AttributeError as e:\n       print(f\"访问弱私有变量失败: {e}\")\n\n   # 测试访问强私有变量\n   try:\n       print(f\"访问强私有变量: {test.__strong_private}\")\n   except AttributeError as e:\n       print(f\"访问强私有变量失败: {e}\")\n\n   # 测试通过名称改写访问强私有变量\n   try:\n       print(f\"通过改写后的名称访问强私有变量: {test._TestClass__strong_private}\")\n       print(\"注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法\")\n   except AttributeError as e:\n       print(f\"通过改写名称访问强私有变量失败: {e}\")\n   ```\n\n   以下是运行 `python test_private_vars.py` 的结果\n\n   ```bash\n   === 测试1: 从类内部访问所有变量 ===\n   从内部访问:\n   公有变量: 这是公有变量\n   弱私有变量: 这是弱私有变量\n   强私有变量: 这是强私有变量\n\n   === 测试2: 从外部访问变量 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n\n   === 测试3: 验证强私有变量的名称改写机制 ===\n   通过改写后的名称访问强私有变量: 这是强私有变量\n\n   === 测试4: 创建第二个文件并尝试导入 ===\n   请创建 test_import.py 并运行来测试导入行为\n   ```\n\n   以下是运行 `python test_import.py` 的结果\n\n   ```bash\n   === 测试1: 从类内部访问所有变量 ===\n   从内部访问:\n   公有变量: 这是公有变量\n   弱私有变量: 这是弱私有变量\n   强私有变量: 这是强私有变量\n\n   === 测试2: 从外部访问变量 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n\n   === 测试3: 验证强私有变量的名称改写机制 ===\n   通过改写后的名称访问强私有变量: 这是强私有变量\n   === 测试导入后的访问行为 ===\n   访问公有变量: 这是公有变量\n   访问弱私有变量: 这是弱私有变量\n   注意：虽然能访问弱私有变量，但这违反了Python的约定\n   访问强私有变量失败: 'TestClass' object has no attribute '__strong_private'\n   通过改写后的名称访问强私有变量: 这是强私有变量\n   注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法\n   ```\n","slug":"PEP-8","published":1,"updated":"2025-07-12T07:33:33.250Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvx001nk8415kwo9s83","content":"<h1 id=\"Style-Guide-for-Python-Code\"><a href=\"#Style-Guide-for-Python-Code\" class=\"headerlink\" title=\"Style Guide for Python Code\"></a>Style Guide for Python Code</h1><blockquote>\n<p><a href=\"https://peps.python.org/pep-0008/\">PEP8</a> 是 Python 社群共通的風格指南，一開始是 Python 之父 Guido van Rossum 自己的撰碼風格，慢慢後來演變至今，目的在於幫助開發者寫出可讀性高且風格一致的程式。許多開源計畫，例如 Django 、 OpenStack 等都是以 PEP8 為基礎再加上自己的風格建議。</p>\n</blockquote>\n<p>这篇博客主要是为了在搭建自己的模型之前学习一下一些统一的规范是做的记录 <del>主要是目前读到的大多数论文的源码目命名没有规律</del> ，以加强之后搭建模型时代码的可读性</p>\n<p>另外，本博客只展示本人不太熟悉的捏</p>\n<span id=\"more\"></span>\n\n<h2 id=\"代码布局\"><a href=\"#代码布局\" class=\"headerlink\" title=\"代码布局\"></a>代码布局</h2><h3 id=\"缩进\"><a href=\"#缩进\" class=\"headerlink\" title=\"缩进\"></a>缩进</h3><p><strong>每个缩进级别使用 4 个空格</strong></p>\n<p>对于比较臭长的函数，可以使用<em>悬挂缩进</em></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Correct:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Aligned with opening delimiter.</span></span><br><span class=\"line\">foo = long_function_name(var_one, var_two,</span><br><span class=\"line\">                         var_three, var_four)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">long_function_name</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">        var_one, var_two, var_three,</span></span><br><span class=\"line\"><span class=\"params\">        var_four</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(var_one)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hanging indents should add a level.</span></span><br><span class=\"line\">foo = long_function_name(</span><br><span class=\"line\">    var_one, var_two,</span><br><span class=\"line\">    var_three, var_four)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wrong:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Arguments on first line forbidden when not using vertical alignment.</span></span><br><span class=\"line\">foo = long_function_name(var_one, var_two,</span><br><span class=\"line\">    var_three, var_four)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Further indentation required as indentation is not distinguishable.</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">long_function_name</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">    var_one, var_two, var_three,</span></span><br><span class=\"line\"><span class=\"params\">    var_four</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(var_one)</span><br></pre></td></tr></table></figure>\n\n<p>优先使用 <em>Tabs</em> 进行缩进， <em>Tabs</em> 和 <em>Spaces</em> 不能混用</p>\n<h3 id=\"每行最多字符数量\"><a href=\"#每行最多字符数量\" class=\"headerlink\" title=\"每行最多字符数量\"></a>每行最多字符数量</h3><p><strong>79</strong> 个</p>\n<p>合理使用反斜杠</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/path/to/some/file/you/want/to/read&#x27;</span>) <span class=\"keyword\">as</span> file_1, \\</span><br><span class=\"line\">     <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/path/to/some/file/being/written&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> file_2:</span><br><span class=\"line\">    file_2.write(file_1.read())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二元运算符之前换行\"><a href=\"#二元运算符之前换行\" class=\"headerlink\" title=\"二元运算符之前换行\"></a>二元运算符之前换行</h3><p>为了更好的确定该 <code>item</code> 采取的是什么运算</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wrong:</span></span><br><span class=\"line\"><span class=\"comment\"># operators sit far away from their operands</span></span><br><span class=\"line\">income = (gross_wages +</span><br><span class=\"line\">          taxable_interest +</span><br><span class=\"line\">          (dividends - qualified_dividends) -</span><br><span class=\"line\">          ira_deduction -</span><br><span class=\"line\">          student_loan_interest)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Correct:</span></span><br><span class=\"line\"><span class=\"comment\"># easy to match operators with operands</span></span><br><span class=\"line\">income = (gross_wages</span><br><span class=\"line\">          + taxable_interest</span><br><span class=\"line\">          + (dividends - qualified_dividends)</span><br><span class=\"line\">          - ira_deduction</span><br><span class=\"line\">          - student_loan_interest)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如何空行（Blank-Lines）\"><a href=\"#如何空行（Blank-Lines）\" class=\"headerlink\" title=\"如何空行（Blank Lines）\"></a>如何空行（Blank Lines）</h3><p><em>顶级函数</em> 和 <em>类</em> 之间空 <strong>2</strong> 行</p>\n<p><em>类中的函数</em> 空 <strong>1</strong> 行</p>\n<h3 id=\"import\"><a href=\"#import\" class=\"headerlink\" title=\"import\"></a>import</h3><ul>\n<li>通常每一个库 <strong>单独一行</strong>（也有例外）</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> subprocess <span class=\"keyword\">import</span> Popen, PIPE</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>按以下顺序分组，每组间空行<ol>\n<li><strong>标准库</strong>导入</li>\n<li><strong>相关第三方库</strong>导入</li>\n<li><strong>特定的本地库</strong>导入</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h2><blockquote>\n<p>Comments that contradict the code are worse than no comments.</p>\n</blockquote>\n<h2 id=\"命名约定\"><a href=\"#命名约定\" class=\"headerlink\" title=\"命名约定\"></a>命名约定</h2><ol>\n<li><p><strong>类名</strong> 用 <strong>大驼峰</strong></p>\n</li>\n<li><p><strong>函数名</strong> 用 <strong>小写下划线</strong></p>\n</li>\n<li><p>关于 <em>下划线</em></p>\n<ul>\n<li><em>单下划线</em> 用于占位</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(random.randint(<span class=\"number\">1</span>, <span class=\"number\">100</span>))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><em>单下划线</em> 用于变量前表示该变量为 <strong>弱私有</strong> （语义上的 private），能调用但不能 import</li>\n<li><em>双下划线</em> 用于变量前表示该变量为 <strong>强私有</strong> （实际上也不能调用<del>实现方式是重名名</del>）<br>为了更好的说明这两点，给出以下两个测试程序</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">test_private_vars.py</span></span><br><span class=\"line\"><span class=\"string\">This file is used to test the private variables in Python.</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">TestClass</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.public_var = <span class=\"string\">&quot;这是公有变量&quot;</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>._weak_private = <span class=\"string\">&quot;这是弱私有变量&quot;</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.__strong_private = <span class=\"string\">&quot;这是强私有变量&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">print_all_vars</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;从内部访问:&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;公有变量: <span class=\"subst\">&#123;self.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;弱私有变量: <span class=\"subst\">&#123;self._weak_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;强私有变量: <span class=\"subst\">&#123;self.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建测试实例</span></span><br><span class=\"line\">test = TestClass()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 测试从类内部访问（通过方法）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试1: 从类内部访问所有变量 ===&quot;</span>)</span><br><span class=\"line\">test.print_all_vars()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 测试从外部直接访问</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试2: 从外部访问变量 ===&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问公有变量: <span class=\"subst\">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量: <span class=\"subst\">&#123;test._weak_private&#125;</span>&quot;</span>)  <span class=\"comment\"># 能访问，但IDE会警告</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量: <span class=\"subst\">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 测试名称改写机制</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试3: 验证强私有变量的名称改写机制 ===&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 实际上Python会将__strong_private改写为_TestClass__strong_private</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写后的名称访问强私有变量: <span class=\"subst\">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 测试导入行为</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试4: 创建第二个文件并尝试导入 ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;请创建 test_import.py 并运行来测试导入行为&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">test_import.py</span></span><br><span class=\"line\"><span class=\"string\">This file is used to test the import of private variables in Python.</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> test_private_vars <span class=\"keyword\">import</span> TestClass</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;=== 测试导入后的访问行为 ===&quot;</span>)</span><br><span class=\"line\">test = TestClass()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问公有变量</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问公有变量: <span class=\"subst\">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问弱私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量: <span class=\"subst\">&#123;test._weak_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;注意：虽然能访问弱私有变量，但这违反了Python的约定&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问强私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量: <span class=\"subst\">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试通过名称改写访问强私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写后的名称访问强私有变量: <span class=\"subst\">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写名称访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>以下是运行 <code>python test_private_vars.py</code> 的结果</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">=== 测试1: 从类内部访问所有变量 ===</span><br><span class=\"line\">从内部访问:</span><br><span class=\"line\">公有变量: 这是公有变量</span><br><span class=\"line\">弱私有变量: 这是弱私有变量</span><br><span class=\"line\">强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试2: 从外部访问变量 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试3: 验证强私有变量的名称改写机制 ===</span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试4: 创建第二个文件并尝试导入 ===</span><br><span class=\"line\">请创建 test_import.py 并运行来测试导入行为</span><br></pre></td></tr></table></figure>\n\n<p>以下是运行 <code>python test_import.py</code> 的结果</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">=== 测试1: 从类内部访问所有变量 ===</span><br><span class=\"line\">从内部访问:</span><br><span class=\"line\">公有变量: 这是公有变量</span><br><span class=\"line\">弱私有变量: 这是弱私有变量</span><br><span class=\"line\">强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试2: 从外部访问变量 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试3: 验证强私有变量的名称改写机制 ===</span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\">=== 测试导入后的访问行为 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">注意：虽然能访问弱私有变量，但这违反了Python的约定</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\">注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法</span><br></pre></td></tr></table></figure></li>\n</ol>\n","length":1625,"excerpt":"<h1 id=\"Style-Guide-for-Python-Code\"><a href=\"#Style-Guide-for-Python-Code\" class=\"headerlink\" title=\"Style Guide for Python Code\"></a>Style Guide for Python Code</h1><blockquote>\n<p><a href=\"https://peps.python.org/pep-0008/\">PEP8</a> 是 Python 社群共通的風格指南，一開始是 Python 之父 Guido van Rossum 自己的撰碼風格，慢慢後來演變至今，目的在於幫助開發者寫出可讀性高且風格一致的程式。許多開源計畫，例如 Django 、 OpenStack 等都是以 PEP8 為基礎再加上自己的風格建議。</p>\n</blockquote>\n<p>这篇博客主要是为了在搭建自己的模型之前学习一下一些统一的规范是做的记录 <del>主要是目前读到的大多数论文的源码目命名没有规律</del> ，以加强之后搭建模型时代码的可读性</p>\n<p>另外，本博客只展示本人不太熟悉的捏</p>","more":"<h2 id=\"代码布局\"><a href=\"#代码布局\" class=\"headerlink\" title=\"代码布局\"></a>代码布局</h2><h3 id=\"缩进\"><a href=\"#缩进\" class=\"headerlink\" title=\"缩进\"></a>缩进</h3><p><strong>每个缩进级别使用 4 个空格</strong></p>\n<p>对于比较臭长的函数，可以使用<em>悬挂缩进</em></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Correct:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Aligned with opening delimiter.</span></span><br><span class=\"line\">foo = long_function_name(var_one, var_two,</span><br><span class=\"line\">                         var_three, var_four)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">long_function_name</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">        var_one, var_two, var_three,</span></span><br><span class=\"line\"><span class=\"params\">        var_four</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(var_one)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hanging indents should add a level.</span></span><br><span class=\"line\">foo = long_function_name(</span><br><span class=\"line\">    var_one, var_two,</span><br><span class=\"line\">    var_three, var_four)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wrong:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Arguments on first line forbidden when not using vertical alignment.</span></span><br><span class=\"line\">foo = long_function_name(var_one, var_two,</span><br><span class=\"line\">    var_three, var_four)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Further indentation required as indentation is not distinguishable.</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">long_function_name</span>(<span class=\"params\"></span></span><br><span class=\"line\"><span class=\"params\">    var_one, var_two, var_three,</span></span><br><span class=\"line\"><span class=\"params\">    var_four</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(var_one)</span><br></pre></td></tr></table></figure>\n\n<p>优先使用 <em>Tabs</em> 进行缩进， <em>Tabs</em> 和 <em>Spaces</em> 不能混用</p>\n<h3 id=\"每行最多字符数量\"><a href=\"#每行最多字符数量\" class=\"headerlink\" title=\"每行最多字符数量\"></a>每行最多字符数量</h3><p><strong>79</strong> 个</p>\n<p>合理使用反斜杠</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/path/to/some/file/you/want/to/read&#x27;</span>) <span class=\"keyword\">as</span> file_1, \\</span><br><span class=\"line\">     <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;/path/to/some/file/being/written&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>) <span class=\"keyword\">as</span> file_2:</span><br><span class=\"line\">    file_2.write(file_1.read())</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"二元运算符之前换行\"><a href=\"#二元运算符之前换行\" class=\"headerlink\" title=\"二元运算符之前换行\"></a>二元运算符之前换行</h3><p>为了更好的确定该 <code>item</code> 采取的是什么运算</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wrong:</span></span><br><span class=\"line\"><span class=\"comment\"># operators sit far away from their operands</span></span><br><span class=\"line\">income = (gross_wages +</span><br><span class=\"line\">          taxable_interest +</span><br><span class=\"line\">          (dividends - qualified_dividends) -</span><br><span class=\"line\">          ira_deduction -</span><br><span class=\"line\">          student_loan_interest)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Correct:</span></span><br><span class=\"line\"><span class=\"comment\"># easy to match operators with operands</span></span><br><span class=\"line\">income = (gross_wages</span><br><span class=\"line\">          + taxable_interest</span><br><span class=\"line\">          + (dividends - qualified_dividends)</span><br><span class=\"line\">          - ira_deduction</span><br><span class=\"line\">          - student_loan_interest)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"如何空行（Blank-Lines）\"><a href=\"#如何空行（Blank-Lines）\" class=\"headerlink\" title=\"如何空行（Blank Lines）\"></a>如何空行（Blank Lines）</h3><p><em>顶级函数</em> 和 <em>类</em> 之间空 <strong>2</strong> 行</p>\n<p><em>类中的函数</em> 空 <strong>1</strong> 行</p>\n<h3 id=\"import\"><a href=\"#import\" class=\"headerlink\" title=\"import\"></a>import</h3><ul>\n<li>通常每一个库 <strong>单独一行</strong>（也有例外）</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> subprocess <span class=\"keyword\">import</span> Popen, PIPE</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>按以下顺序分组，每组间空行<ol>\n<li><strong>标准库</strong>导入</li>\n<li><strong>相关第三方库</strong>导入</li>\n<li><strong>特定的本地库</strong>导入</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h2><blockquote>\n<p>Comments that contradict the code are worse than no comments.</p>\n</blockquote>\n<h2 id=\"命名约定\"><a href=\"#命名约定\" class=\"headerlink\" title=\"命名约定\"></a>命名约定</h2><ol>\n<li><p><strong>类名</strong> 用 <strong>大驼峰</strong></p>\n</li>\n<li><p><strong>函数名</strong> 用 <strong>小写下划线</strong></p>\n</li>\n<li><p>关于 <em>下划线</em></p>\n<ul>\n<li><em>单下划线</em> 用于占位</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">10</span>):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(random.randint(<span class=\"number\">1</span>, <span class=\"number\">100</span>))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><em>单下划线</em> 用于变量前表示该变量为 <strong>弱私有</strong> （语义上的 private），能调用但不能 import</li>\n<li><em>双下划线</em> 用于变量前表示该变量为 <strong>强私有</strong> （实际上也不能调用<del>实现方式是重名名</del>）<br>为了更好的说明这两点，给出以下两个测试程序</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">test_private_vars.py</span></span><br><span class=\"line\"><span class=\"string\">This file is used to test the private variables in Python.</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">TestClass</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.public_var = <span class=\"string\">&quot;这是公有变量&quot;</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>._weak_private = <span class=\"string\">&quot;这是弱私有变量&quot;</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.__strong_private = <span class=\"string\">&quot;这是强私有变量&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">print_all_vars</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;从内部访问:&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;公有变量: <span class=\"subst\">&#123;self.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;弱私有变量: <span class=\"subst\">&#123;self._weak_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;强私有变量: <span class=\"subst\">&#123;self.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建测试实例</span></span><br><span class=\"line\">test = TestClass()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 1. 测试从类内部访问（通过方法）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试1: 从类内部访问所有变量 ===&quot;</span>)</span><br><span class=\"line\">test.print_all_vars()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 测试从外部直接访问</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试2: 从外部访问变量 ===&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问公有变量: <span class=\"subst\">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量: <span class=\"subst\">&#123;test._weak_private&#125;</span>&quot;</span>)  <span class=\"comment\"># 能访问，但IDE会警告</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量: <span class=\"subst\">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 测试名称改写机制</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试3: 验证强私有变量的名称改写机制 ===&quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 实际上Python会将__strong_private改写为_TestClass__strong_private</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写后的名称访问强私有变量: <span class=\"subst\">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 测试导入行为</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">&quot;__main__&quot;</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;\\n=== 测试4: 创建第二个文件并尝试导入 ===&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;请创建 test_import.py 并运行来测试导入行为&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">test_import.py</span></span><br><span class=\"line\"><span class=\"string\">This file is used to test the import of private variables in Python.</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> test_private_vars <span class=\"keyword\">import</span> TestClass</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;=== 测试导入后的访问行为 ===&quot;</span>)</span><br><span class=\"line\">test = TestClass()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问公有变量</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问公有变量: <span class=\"subst\">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问弱私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量: <span class=\"subst\">&#123;test._weak_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;注意：虽然能访问弱私有变量，但这违反了Python的约定&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问弱私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试访问强私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量: <span class=\"subst\">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试通过名称改写访问强私有变量</span></span><br><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写后的名称访问强私有变量: <span class=\"subst\">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">except</span> AttributeError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;通过改写名称访问强私有变量失败: <span class=\"subst\">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<p>以下是运行 <code>python test_private_vars.py</code> 的结果</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">=== 测试1: 从类内部访问所有变量 ===</span><br><span class=\"line\">从内部访问:</span><br><span class=\"line\">公有变量: 这是公有变量</span><br><span class=\"line\">弱私有变量: 这是弱私有变量</span><br><span class=\"line\">强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试2: 从外部访问变量 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试3: 验证强私有变量的名称改写机制 ===</span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试4: 创建第二个文件并尝试导入 ===</span><br><span class=\"line\">请创建 test_import.py 并运行来测试导入行为</span><br></pre></td></tr></table></figure>\n\n<p>以下是运行 <code>python test_import.py</code> 的结果</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">=== 测试1: 从类内部访问所有变量 ===</span><br><span class=\"line\">从内部访问:</span><br><span class=\"line\">公有变量: 这是公有变量</span><br><span class=\"line\">弱私有变量: 这是弱私有变量</span><br><span class=\"line\">强私有变量: 这是强私有变量</span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试2: 从外部访问变量 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">=== 测试3: 验证强私有变量的名称改写机制 ===</span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\">=== 测试导入后的访问行为 ===</span><br><span class=\"line\">访问公有变量: 这是公有变量</span><br><span class=\"line\">访问弱私有变量: 这是弱私有变量</span><br><span class=\"line\">注意：虽然能访问弱私有变量，但这违反了Python的约定</span><br><span class=\"line\">访问强私有变量失败: <span class=\"string\">&#x27;TestClass&#x27;</span> object has no attribute <span class=\"string\">&#x27;__strong_private&#x27;</span></span><br><span class=\"line\">通过改写后的名称访问强私有变量: 这是强私有变量</span><br><span class=\"line\">注意：虽然能通过名称改写访问强私有变量，但这是一个不推荐的做法</span><br></pre></td></tr></table></figure></li>\n</ol>"},{"title":"hwadee","date":"2025-07-13T13:56:45.000Z","_content":"\n# \n先放在这里，懒得喷，以下是鼠鼠和室友在争论某问题时问的AI\n<!-- more -->\n\n# 甲醛有气味吗\nQus:\n甲醛有气味吗\nAns:\n- 引用 7 篇资料作为参考\n    1. [甲醛（有机化合物）_百度百科](https://baike.baidu.com/item/甲醛/167033?fr=aladdin)\n    2. [汞（是常温常压下唯一以液态存在的金属）_百度百科](http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink)\n    3. [【甲醛有味吗】_徐信群_主任医师 - 大众养生网](https://www.cndzys.com/ylcore/wendanew_info/11es473224.html)\n    4. [装修完的新家闻不见味儿，就是没甲醛了？](http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd)\n    5. [甲醛有味道吗，甲醛的气味像什么？](http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd)\n    6. [甲醛有味还是无味-有来医生](https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html)\n    7. [装修的味道是甲醛吗_齐家网](https://m.jia.com/zixun/article/1144566.html)\n甲醛的气味特性与其浓度密切相关，具体表现如下：\n### 1. 低浓度时通常无味\n- 甲醛在极低浓度（如低于0.08毫克/立方米）时，是一种无色无味的气体，难以通过嗅觉直接察觉。\n- 许多人误以为“没味道=没甲醛”，但实际上低浓度甲醛可能仍然存在，只是不易被闻到。\n### 2. 高浓度时有强烈刺激性气味\n- 当甲醛浓度超过0.1毫克/立方米时，会与空气中的水、氧气反应，生成具有刺鼻气味的化合物，常被描述为：\n    - 类似燃烧塑料或化学药品的味道；\n    - 锯木屑混合酸味（家具中甲醛）；\n    - 汽油味或烧焦塑料味（布料、窗帘中甲醛）；\n    - 部分人可能感知到淡淡的甜味，但主要仍是刺激性。\n### 3. 个体差异显著\n- 不同人对甲醛气味的敏感度差异较大，有些人可能在较低浓度就能察觉，而另一些人需要更高浓度才会感到不适。\n### 4. 与其他装修气味的区别\n- 装修后的刺鼻气味常被误认为全是甲醛，但实际上可能混合了**苯系物（油漆味）、氨气（厕所味）、TVOC（化学溶剂味）**等。\n- 甲醛的刺激性更偏向黏膜反应（如眼痒、喉咙痛），而苯系物等可能带有更明显的“化学香味”。\n### 5. 注意事项\n- 不能依赖嗅觉判断甲醛安全性：即使闻不到，甲醛仍可能超标（尤其来自人造板材的长期释放）。\n- 科学检测更可靠：家用检测仪易受环境干扰，建议通过专业机构检测。\n总结：甲醛在低浓度下无味，高浓度时呈现刺鼻气味，但气味并非判断其存在的唯一标准，需结合专业检测和通风措施保障健康。\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒","source":"_posts/hwadee.md","raw":"---\ntitle: hwadee\ndate: 2025-07-13 21:56:45\ncategories:\ntags:\n---\n\n# \n先放在这里，懒得喷，以下是鼠鼠和室友在争论某问题时问的AI\n<!-- more -->\n\n# 甲醛有气味吗\nQus:\n甲醛有气味吗\nAns:\n- 引用 7 篇资料作为参考\n    1. [甲醛（有机化合物）_百度百科](https://baike.baidu.com/item/甲醛/167033?fr=aladdin)\n    2. [汞（是常温常压下唯一以液态存在的金属）_百度百科](http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink)\n    3. [【甲醛有味吗】_徐信群_主任医师 - 大众养生网](https://www.cndzys.com/ylcore/wendanew_info/11es473224.html)\n    4. [装修完的新家闻不见味儿，就是没甲醛了？](http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd)\n    5. [甲醛有味道吗，甲醛的气味像什么？](http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd)\n    6. [甲醛有味还是无味-有来医生](https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html)\n    7. [装修的味道是甲醛吗_齐家网](https://m.jia.com/zixun/article/1144566.html)\n甲醛的气味特性与其浓度密切相关，具体表现如下：\n### 1. 低浓度时通常无味\n- 甲醛在极低浓度（如低于0.08毫克/立方米）时，是一种无色无味的气体，难以通过嗅觉直接察觉。\n- 许多人误以为“没味道=没甲醛”，但实际上低浓度甲醛可能仍然存在，只是不易被闻到。\n### 2. 高浓度时有强烈刺激性气味\n- 当甲醛浓度超过0.1毫克/立方米时，会与空气中的水、氧气反应，生成具有刺鼻气味的化合物，常被描述为：\n    - 类似燃烧塑料或化学药品的味道；\n    - 锯木屑混合酸味（家具中甲醛）；\n    - 汽油味或烧焦塑料味（布料、窗帘中甲醛）；\n    - 部分人可能感知到淡淡的甜味，但主要仍是刺激性。\n### 3. 个体差异显著\n- 不同人对甲醛气味的敏感度差异较大，有些人可能在较低浓度就能察觉，而另一些人需要更高浓度才会感到不适。\n### 4. 与其他装修气味的区别\n- 装修后的刺鼻气味常被误认为全是甲醛，但实际上可能混合了**苯系物（油漆味）、氨气（厕所味）、TVOC（化学溶剂味）**等。\n- 甲醛的刺激性更偏向黏膜反应（如眼痒、喉咙痛），而苯系物等可能带有更明显的“化学香味”。\n### 5. 注意事项\n- 不能依赖嗅觉判断甲醛安全性：即使闻不到，甲醛仍可能超标（尤其来自人造板材的长期释放）。\n- 科学检测更可靠：家用检测仪易受环境干扰，建议通过专业机构检测。\n总结：甲醛在低浓度下无味，高浓度时呈现刺鼻气味，但气味并非判断其存在的唯一标准，需结合专业检测和通风措施保障健康。\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒","slug":"hwadee","published":1,"updated":"2025-07-13T13:58:51.190Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvy001pk841a1yt737b","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>先放在这里，懒得喷，以下是鼠鼠和室友在争论某问题时问的AI</p>\n<span id=\"more\"></span>\n\n<h1 id=\"甲醛有气味吗\"><a href=\"#甲醛有气味吗\" class=\"headerlink\" title=\"甲醛有气味吗\"></a>甲醛有气味吗</h1><p>Qus:<br>甲醛有气味吗<br>Ans:</p>\n<ul>\n<li>引用 7 篇资料作为参考<ol>\n<li><a href=\"https://baike.baidu.com/item/%E7%94%B2%E9%86%9B/167033?fr=aladdin\">甲醛（有机化合物）_百度百科</a></li>\n<li><a href=\"http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink\">汞（是常温常压下唯一以液态存在的金属）_百度百科</a></li>\n<li><a href=\"https://www.cndzys.com/ylcore/wendanew_info/11es473224.html\">【甲醛有味吗】_徐信群_主任医师 - 大众养生网</a></li>\n<li><a href=\"http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd\">装修完的新家闻不见味儿，就是没甲醛了？</a></li>\n<li><a href=\"http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd\">甲醛有味道吗，甲醛的气味像什么？</a></li>\n<li><a href=\"https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html\">甲醛有味还是无味-有来医生</a></li>\n<li><a href=\"https://m.jia.com/zixun/article/1144566.html\">装修的味道是甲醛吗_齐家网</a><br>甲醛的气味特性与其浓度密切相关，具体表现如下：</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"1-低浓度时通常无味\"><a href=\"#1-低浓度时通常无味\" class=\"headerlink\" title=\"1. 低浓度时通常无味\"></a>1. 低浓度时通常无味</h3><ul>\n<li>甲醛在极低浓度（如低于0.08毫克&#x2F;立方米）时，是一种无色无味的气体，难以通过嗅觉直接察觉。</li>\n<li>许多人误以为“没味道&#x3D;没甲醛”，但实际上低浓度甲醛可能仍然存在，只是不易被闻到。</li>\n</ul>\n<h3 id=\"2-高浓度时有强烈刺激性气味\"><a href=\"#2-高浓度时有强烈刺激性气味\" class=\"headerlink\" title=\"2. 高浓度时有强烈刺激性气味\"></a>2. 高浓度时有强烈刺激性气味</h3><ul>\n<li>当甲醛浓度超过0.1毫克&#x2F;立方米时，会与空气中的水、氧气反应，生成具有刺鼻气味的化合物，常被描述为：<ul>\n<li>类似燃烧塑料或化学药品的味道；</li>\n<li>锯木屑混合酸味（家具中甲醛）；</li>\n<li>汽油味或烧焦塑料味（布料、窗帘中甲醛）；</li>\n<li>部分人可能感知到淡淡的甜味，但主要仍是刺激性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-个体差异显著\"><a href=\"#3-个体差异显著\" class=\"headerlink\" title=\"3. 个体差异显著\"></a>3. 个体差异显著</h3><ul>\n<li>不同人对甲醛气味的敏感度差异较大，有些人可能在较低浓度就能察觉，而另一些人需要更高浓度才会感到不适。</li>\n</ul>\n<h3 id=\"4-与其他装修气味的区别\"><a href=\"#4-与其他装修气味的区别\" class=\"headerlink\" title=\"4. 与其他装修气味的区别\"></a>4. 与其他装修气味的区别</h3><ul>\n<li>装修后的刺鼻气味常被误认为全是甲醛，但实际上可能混合了**苯系物（油漆味）、氨气（厕所味）、TVOC（化学溶剂味）**等。</li>\n<li>甲醛的刺激性更偏向黏膜反应（如眼痒、喉咙痛），而苯系物等可能带有更明显的“化学香味”。</li>\n</ul>\n<h3 id=\"5-注意事项\"><a href=\"#5-注意事项\" class=\"headerlink\" title=\"5. 注意事项\"></a>5. 注意事项</h3><ul>\n<li>不能依赖嗅觉判断甲醛安全性：即使闻不到，甲醛仍可能超标（尤其来自人造板材的长期释放）。</li>\n<li>科学检测更可靠：家用检测仪易受环境干扰，建议通过专业机构检测。<br>总结：甲醛在低浓度下无味，高浓度时呈现刺鼻气味，但气味并非判断其存在的唯一标准，需结合专业检测和通风措施保障健康。</li>\n</ul>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1>","length":650,"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>先放在这里，懒得喷，以下是鼠鼠和室友在争论某问题时问的AI</p>","more":"<h1 id=\"甲醛有气味吗\"><a href=\"#甲醛有气味吗\" class=\"headerlink\" title=\"甲醛有气味吗\"></a>甲醛有气味吗</h1><p>Qus:<br>甲醛有气味吗<br>Ans:</p>\n<ul>\n<li>引用 7 篇资料作为参考<ol>\n<li><a href=\"https://baike.baidu.com/item/%E7%94%B2%E9%86%9B/167033?fr=aladdin\">甲醛（有机化合物）_百度百科</a></li>\n<li><a href=\"http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink\">汞（是常温常压下唯一以液态存在的金属）_百度百科</a></li>\n<li><a href=\"https://www.cndzys.com/ylcore/wendanew_info/11es473224.html\">【甲醛有味吗】_徐信群_主任医师 - 大众养生网</a></li>\n<li><a href=\"http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd\">装修完的新家闻不见味儿，就是没甲醛了？</a></li>\n<li><a href=\"http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd\">甲醛有味道吗，甲醛的气味像什么？</a></li>\n<li><a href=\"https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html\">甲醛有味还是无味-有来医生</a></li>\n<li><a href=\"https://m.jia.com/zixun/article/1144566.html\">装修的味道是甲醛吗_齐家网</a><br>甲醛的气味特性与其浓度密切相关，具体表现如下：</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"1-低浓度时通常无味\"><a href=\"#1-低浓度时通常无味\" class=\"headerlink\" title=\"1. 低浓度时通常无味\"></a>1. 低浓度时通常无味</h3><ul>\n<li>甲醛在极低浓度（如低于0.08毫克&#x2F;立方米）时，是一种无色无味的气体，难以通过嗅觉直接察觉。</li>\n<li>许多人误以为“没味道&#x3D;没甲醛”，但实际上低浓度甲醛可能仍然存在，只是不易被闻到。</li>\n</ul>\n<h3 id=\"2-高浓度时有强烈刺激性气味\"><a href=\"#2-高浓度时有强烈刺激性气味\" class=\"headerlink\" title=\"2. 高浓度时有强烈刺激性气味\"></a>2. 高浓度时有强烈刺激性气味</h3><ul>\n<li>当甲醛浓度超过0.1毫克&#x2F;立方米时，会与空气中的水、氧气反应，生成具有刺鼻气味的化合物，常被描述为：<ul>\n<li>类似燃烧塑料或化学药品的味道；</li>\n<li>锯木屑混合酸味（家具中甲醛）；</li>\n<li>汽油味或烧焦塑料味（布料、窗帘中甲醛）；</li>\n<li>部分人可能感知到淡淡的甜味，但主要仍是刺激性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-个体差异显著\"><a href=\"#3-个体差异显著\" class=\"headerlink\" title=\"3. 个体差异显著\"></a>3. 个体差异显著</h3><ul>\n<li>不同人对甲醛气味的敏感度差异较大，有些人可能在较低浓度就能察觉，而另一些人需要更高浓度才会感到不适。</li>\n</ul>\n<h3 id=\"4-与其他装修气味的区别\"><a href=\"#4-与其他装修气味的区别\" class=\"headerlink\" title=\"4. 与其他装修气味的区别\"></a>4. 与其他装修气味的区别</h3><ul>\n<li>装修后的刺鼻气味常被误认为全是甲醛，但实际上可能混合了**苯系物（油漆味）、氨气（厕所味）、TVOC（化学溶剂味）**等。</li>\n<li>甲醛的刺激性更偏向黏膜反应（如眼痒、喉咙痛），而苯系物等可能带有更明显的“化学香味”。</li>\n</ul>\n<h3 id=\"5-注意事项\"><a href=\"#5-注意事项\" class=\"headerlink\" title=\"5. 注意事项\"></a>5. 注意事项</h3><ul>\n<li>不能依赖嗅觉判断甲醛安全性：即使闻不到，甲醛仍可能超标（尤其来自人造板材的长期释放）。</li>\n<li>科学检测更可靠：家用检测仪易受环境干扰，建议通过专业机构检测。<br>总结：甲醛在低浓度下无味，高浓度时呈现刺鼻气味，但气味并非判断其存在的唯一标准，需结合专业检测和通风措施保障健康。</li>\n</ul>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1>"},{"title":"GAT","date":"2025-07-14T14:26:58.000Z","_content":"\n# \n\n<!-- more -->\n\n### 图注意力机制\n\n#### GAT（Graph Attention Networks）\n\nGAT通过引入注意力机制来加权邻居节点的特征。对于节点i，其更新公式为：\n\n$$h\\_i^{(l+1)} = \\sigma(\\sum\\_{j \\in \\mathcal{N}\\_i} \\alpha\\_{ij}W^{(l)}h\\_j^{(l)})$$\n\n其中注意力系数$\\alpha_{ij}$的计算：\n\n$$\\alpha_{ij} = \\frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\\sum_{k \\in \\mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$\n\n#### 多头注意力\n\n为了提高模型的稳定性和表达能力，GAT使用了多头注意力机制：\n\n$$h\\_i^{(l+1)} = \\sigma(\\frac{1}{K} \\sum\\_{k=1}^K \\sum\\_{j \\in \\mathcal{N}\\_i} \\alpha\\_{ij}^k W^k h\\_j^{(l)})$$\n\n### 变体与扩展\n\n#### 边注意力\n\n除了节点之间的注意力，一些模型还引入了边注意力机制：\n\n$$e_{ij} = a^T[Wh_i || Wh_j || We_{ij}]$$\n\n其中$e_{ij}$是边的特征。\n\n#### 全局注意力\n\n通过引入全局节点或池化操作，可以实现全局注意力：\n\n$$g = \\sum_{i \\in V} \\beta_i h_i$$\n\n其中$\\beta_i$是全局注意力权重。\n\n## 💻 实现细节\n\n### PyTorch实现的GAT层\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GATLayer(nn.Module):\n    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n        super(GATLayer, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.dropout = dropout\n        self.alpha = alpha\n        self.concat = concat\n\n        # 变换矩阵\n        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n        \n        # 注意力向量\n        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n\n        self.leakyrelu = nn.LeakyReLU(self.alpha)\n\n    def forward(self, x, adj):\n        # x: 节点特征矩阵 [N, in_features]\n        # adj: 邻接矩阵 [N, N]\n        \n        # 线性变换\n        h = torch.mm(x, self.W)  # [N, out_features]\n        N = h.size()[0]\n\n        # 计算注意力分数\n        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1)\n        a_input = a_input.view(N, N, 2 * self.out_features)\n        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n\n        # 掩码机制\n        zero_vec = -9e15 * torch.ones_like(e)\n        attention = torch.where(adj > 0, e, zero_vec)\n        attention = F.softmax(attention, dim=1)\n        attention = F.dropout(attention, self.dropout, training=self.training)\n\n        # 聚合特征\n        h_prime = torch.matmul(attention, h)\n\n        if self.concat:\n            return F.elu(h_prime)\n        else:\n            return h_prime\n\nclass GAT(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n        super(GAT, self).__init__()\n        self.dropout = dropout\n        \n        # 多头注意力层\n        self.attentions = nn.ModuleList([\n            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) \n            for _ in range(nheads)\n        ])\n        \n        # 输出层\n        self.out_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n\n    def forward(self, x, adj):\n        x = F.dropout(x, self.dropout, training=self.training)\n        # 多头注意力\n        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = self.out_att(x, adj)\n        return F.log_softmax(x, dim=1)\n```\n\n### 实际应用示例\n\n```python\n# 模型初始化\nmodel = GAT(nfeat=input_dim,\n           nhid=8,\n           nclass=num_classes,\n           dropout=0.6,\n           alpha=0.2,\n           nheads=8)\n\n# 优化器\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n\n# 训练循环\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    output = model(features, adj)\n    loss = F.nll_loss(output[idx_train], labels[idx_train])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n```\n\n## 🔍 注意事项与最佳实践\n\n\n## 📈 未来展望\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf\" target=\"_blank\">📄 Lee 等 - 2018 - Attention Models in Graphs A Survey</a>\n<a href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\" target=\"_blank\">github: External-Attention-pytorch</a> ","source":"_posts/GAT.md","raw":"---\ntitle: GAT\ndate: 2025-07-14 22:26:58\ncategories:\ntags:\n---\n\n# \n\n<!-- more -->\n\n### 图注意力机制\n\n#### GAT（Graph Attention Networks）\n\nGAT通过引入注意力机制来加权邻居节点的特征。对于节点i，其更新公式为：\n\n$$h\\_i^{(l+1)} = \\sigma(\\sum\\_{j \\in \\mathcal{N}\\_i} \\alpha\\_{ij}W^{(l)}h\\_j^{(l)})$$\n\n其中注意力系数$\\alpha_{ij}$的计算：\n\n$$\\alpha_{ij} = \\frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\\sum_{k \\in \\mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$\n\n#### 多头注意力\n\n为了提高模型的稳定性和表达能力，GAT使用了多头注意力机制：\n\n$$h\\_i^{(l+1)} = \\sigma(\\frac{1}{K} \\sum\\_{k=1}^K \\sum\\_{j \\in \\mathcal{N}\\_i} \\alpha\\_{ij}^k W^k h\\_j^{(l)})$$\n\n### 变体与扩展\n\n#### 边注意力\n\n除了节点之间的注意力，一些模型还引入了边注意力机制：\n\n$$e_{ij} = a^T[Wh_i || Wh_j || We_{ij}]$$\n\n其中$e_{ij}$是边的特征。\n\n#### 全局注意力\n\n通过引入全局节点或池化操作，可以实现全局注意力：\n\n$$g = \\sum_{i \\in V} \\beta_i h_i$$\n\n其中$\\beta_i$是全局注意力权重。\n\n## 💻 实现细节\n\n### PyTorch实现的GAT层\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass GATLayer(nn.Module):\n    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n        super(GATLayer, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.dropout = dropout\n        self.alpha = alpha\n        self.concat = concat\n\n        # 变换矩阵\n        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n        \n        # 注意力向量\n        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n\n        self.leakyrelu = nn.LeakyReLU(self.alpha)\n\n    def forward(self, x, adj):\n        # x: 节点特征矩阵 [N, in_features]\n        # adj: 邻接矩阵 [N, N]\n        \n        # 线性变换\n        h = torch.mm(x, self.W)  # [N, out_features]\n        N = h.size()[0]\n\n        # 计算注意力分数\n        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1)\n        a_input = a_input.view(N, N, 2 * self.out_features)\n        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n\n        # 掩码机制\n        zero_vec = -9e15 * torch.ones_like(e)\n        attention = torch.where(adj > 0, e, zero_vec)\n        attention = F.softmax(attention, dim=1)\n        attention = F.dropout(attention, self.dropout, training=self.training)\n\n        # 聚合特征\n        h_prime = torch.matmul(attention, h)\n\n        if self.concat:\n            return F.elu(h_prime)\n        else:\n            return h_prime\n\nclass GAT(nn.Module):\n    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n        super(GAT, self).__init__()\n        self.dropout = dropout\n        \n        # 多头注意力层\n        self.attentions = nn.ModuleList([\n            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) \n            for _ in range(nheads)\n        ])\n        \n        # 输出层\n        self.out_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n\n    def forward(self, x, adj):\n        x = F.dropout(x, self.dropout, training=self.training)\n        # 多头注意力\n        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = self.out_att(x, adj)\n        return F.log_softmax(x, dim=1)\n```\n\n### 实际应用示例\n\n```python\n# 模型初始化\nmodel = GAT(nfeat=input_dim,\n           nhid=8,\n           nclass=num_classes,\n           dropout=0.6,\n           alpha=0.2,\n           nheads=8)\n\n# 优化器\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n\n# 训练循环\ndef train():\n    model.train()\n    optimizer.zero_grad()\n    output = model(features, adj)\n    loss = F.nll_loss(output[idx_train], labels[idx_train])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n```\n\n## 🔍 注意事项与最佳实践\n\n\n## 📈 未来展望\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf\" target=\"_blank\">📄 Lee 等 - 2018 - Attention Models in Graphs A Survey</a>\n<a href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\" target=\"_blank\">github: External-Attention-pytorch</a> ","slug":"GAT","published":1,"updated":"2025-07-14T14:27:44.356Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvz001sk84186epd3q0","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><span id=\"more\"></span>\n\n<h3 id=\"图注意力机制\"><a href=\"#图注意力机制\" class=\"headerlink\" title=\"图注意力机制\"></a>图注意力机制</h3><h4 id=\"GAT（Graph-Attention-Networks）\"><a href=\"#GAT（Graph-Attention-Networks）\" class=\"headerlink\" title=\"GAT（Graph Attention Networks）\"></a>GAT（Graph Attention Networks）</h4><p>GAT通过引入注意力机制来加权邻居节点的特征。对于节点i，其更新公式为：</p>\n<p>$$h_i^{(l+1)} &#x3D; \\sigma(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}W^{(l)}h_j^{(l)})$$</p>\n<p>其中注意力系数$\\alpha_{ij}$的计算：</p>\n<p>$$\\alpha_{ij} &#x3D; \\frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\\sum_{k \\in \\mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$</p>\n<h4 id=\"多头注意力\"><a href=\"#多头注意力\" class=\"headerlink\" title=\"多头注意力\"></a>多头注意力</h4><p>为了提高模型的稳定性和表达能力，GAT使用了多头注意力机制：</p>\n<p>$$h_i^{(l+1)} &#x3D; \\sigma(\\frac{1}{K} \\sum_{k&#x3D;1}^K \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^k W^k h_j^{(l)})$$</p>\n<h3 id=\"变体与扩展\"><a href=\"#变体与扩展\" class=\"headerlink\" title=\"变体与扩展\"></a>变体与扩展</h3><h4 id=\"边注意力\"><a href=\"#边注意力\" class=\"headerlink\" title=\"边注意力\"></a>边注意力</h4><p>除了节点之间的注意力，一些模型还引入了边注意力机制：</p>\n<p>$$e_{ij} &#x3D; a^T[Wh_i || Wh_j || We_{ij}]$$</p>\n<p>其中$e_{ij}$是边的特征。</p>\n<h4 id=\"全局注意力\"><a href=\"#全局注意力\" class=\"headerlink\" title=\"全局注意力\"></a>全局注意力</h4><p>通过引入全局节点或池化操作，可以实现全局注意力：</p>\n<p>$$g &#x3D; \\sum_{i \\in V} \\beta_i h_i$$</p>\n<p>其中$\\beta_i$是全局注意力权重。</p>\n<h2 id=\"💻-实现细节\"><a href=\"#💻-实现细节\" class=\"headerlink\" title=\"💻 实现细节\"></a>💻 实现细节</h2><h3 id=\"PyTorch实现的GAT层\"><a href=\"#PyTorch实现的GAT层\" class=\"headerlink\" title=\"PyTorch实现的GAT层\"></a>PyTorch实现的GAT层</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GATLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features, dropout, alpha, concat=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GATLayer, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.in_features = in_features</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_features = out_features</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.alpha = alpha</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.concat = concat</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 变换矩阵</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))</span><br><span class=\"line\">        nn.init.xavier_uniform_(<span class=\"variable language_\">self</span>.W.data, gain=<span class=\"number\">1.414</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 注意力向量</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.a = nn.Parameter(torch.zeros(size=(<span class=\"number\">2</span>*out_features, <span class=\"number\">1</span>)))</span><br><span class=\"line\">        nn.init.xavier_uniform_(<span class=\"variable language_\">self</span>.a.data, gain=<span class=\"number\">1.414</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.leakyrelu = nn.LeakyReLU(<span class=\"variable language_\">self</span>.alpha)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        <span class=\"comment\"># x: 节点特征矩阵 [N, in_features]</span></span><br><span class=\"line\">        <span class=\"comment\"># adj: 邻接矩阵 [N, N]</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 线性变换</span></span><br><span class=\"line\">        h = torch.mm(x, <span class=\"variable language_\">self</span>.W)  <span class=\"comment\"># [N, out_features]</span></span><br><span class=\"line\">        N = h.size()[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算注意力分数</span></span><br><span class=\"line\">        a_input = torch.cat([h.repeat(<span class=\"number\">1</span>, N).view(N * N, -<span class=\"number\">1</span>), h.repeat(N, <span class=\"number\">1</span>)], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        a_input = a_input.view(N, N, <span class=\"number\">2</span> * <span class=\"variable language_\">self</span>.out_features)</span><br><span class=\"line\">        e = <span class=\"variable language_\">self</span>.leakyrelu(torch.matmul(a_input, <span class=\"variable language_\">self</span>.a).squeeze(<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 掩码机制</span></span><br><span class=\"line\">        zero_vec = -<span class=\"number\">9e15</span> * torch.ones_like(e)</span><br><span class=\"line\">        attention = torch.where(adj &gt; <span class=\"number\">0</span>, e, zero_vec)</span><br><span class=\"line\">        attention = F.softmax(attention, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        attention = F.dropout(attention, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 聚合特征</span></span><br><span class=\"line\">        h_prime = torch.matmul(attention, h)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.concat:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> F.elu(h_prime)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> h_prime</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GAT</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, nfeat, nhid, nclass, dropout, alpha, nheads</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GAT, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 多头注意力层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attentions = nn.ModuleList([</span><br><span class=\"line\">            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=<span class=\"literal\">True</span>) </span><br><span class=\"line\">            <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nheads)</span><br><span class=\"line\">        ])</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 输出层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        <span class=\"comment\"># 多头注意力</span></span><br><span class=\"line\">        x = torch.cat([att(x, adj) <span class=\"keyword\">for</span> att <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.attentions], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.out_att(x, adj)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"实际应用示例\"><a href=\"#实际应用示例\" class=\"headerlink\" title=\"实际应用示例\"></a>实际应用示例</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模型初始化</span></span><br><span class=\"line\">model = GAT(nfeat=input_dim,</span><br><span class=\"line\">           nhid=<span class=\"number\">8</span>,</span><br><span class=\"line\">           nclass=num_classes,</span><br><span class=\"line\">           dropout=<span class=\"number\">0.6</span>,</span><br><span class=\"line\">           alpha=<span class=\"number\">0.2</span>,</span><br><span class=\"line\">           nheads=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 优化器</span></span><br><span class=\"line\">optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.005</span>, weight_decay=<span class=\"number\">5e-4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练循环</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>():</span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    output = model(features, adj)</span><br><span class=\"line\">    loss = F.nll_loss(output[idx_train], labels[idx_train])</span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss.item()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"🔍-注意事项与最佳实践\"><a href=\"#🔍-注意事项与最佳实践\" class=\"headerlink\" title=\"🔍 注意事项与最佳实践\"></a>🔍 注意事项与最佳实践</h2><h2 id=\"📈-未来展望\"><a href=\"#📈-未来展望\" class=\"headerlink\" title=\"📈 未来展望\"></a>📈 未来展望</h2><h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf\" target=\"_blank\">📄 Lee 等 - 2018 - Attention Models in Graphs A Survey</a><br><a href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\" target=\"_blank\">github: External-Attention-pytorch</a> </p>\n","length":642,"excerpt":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","more":"<h3 id=\"图注意力机制\"><a href=\"#图注意力机制\" class=\"headerlink\" title=\"图注意力机制\"></a>图注意力机制</h3><h4 id=\"GAT（Graph-Attention-Networks）\"><a href=\"#GAT（Graph-Attention-Networks）\" class=\"headerlink\" title=\"GAT（Graph Attention Networks）\"></a>GAT（Graph Attention Networks）</h4><p>GAT通过引入注意力机制来加权邻居节点的特征。对于节点i，其更新公式为：</p>\n<p>$$h_i^{(l+1)} &#x3D; \\sigma(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}W^{(l)}h_j^{(l)})$$</p>\n<p>其中注意力系数$\\alpha_{ij}$的计算：</p>\n<p>$$\\alpha_{ij} &#x3D; \\frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\\sum_{k \\in \\mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$</p>\n<h4 id=\"多头注意力\"><a href=\"#多头注意力\" class=\"headerlink\" title=\"多头注意力\"></a>多头注意力</h4><p>为了提高模型的稳定性和表达能力，GAT使用了多头注意力机制：</p>\n<p>$$h_i^{(l+1)} &#x3D; \\sigma(\\frac{1}{K} \\sum_{k&#x3D;1}^K \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^k W^k h_j^{(l)})$$</p>\n<h3 id=\"变体与扩展\"><a href=\"#变体与扩展\" class=\"headerlink\" title=\"变体与扩展\"></a>变体与扩展</h3><h4 id=\"边注意力\"><a href=\"#边注意力\" class=\"headerlink\" title=\"边注意力\"></a>边注意力</h4><p>除了节点之间的注意力，一些模型还引入了边注意力机制：</p>\n<p>$$e_{ij} &#x3D; a^T[Wh_i || Wh_j || We_{ij}]$$</p>\n<p>其中$e_{ij}$是边的特征。</p>\n<h4 id=\"全局注意力\"><a href=\"#全局注意力\" class=\"headerlink\" title=\"全局注意力\"></a>全局注意力</h4><p>通过引入全局节点或池化操作，可以实现全局注意力：</p>\n<p>$$g &#x3D; \\sum_{i \\in V} \\beta_i h_i$$</p>\n<p>其中$\\beta_i$是全局注意力权重。</p>\n<h2 id=\"💻-实现细节\"><a href=\"#💻-实现细节\" class=\"headerlink\" title=\"💻 实现细节\"></a>💻 实现细节</h2><h3 id=\"PyTorch实现的GAT层\"><a href=\"#PyTorch实现的GAT层\" class=\"headerlink\" title=\"PyTorch实现的GAT层\"></a>PyTorch实现的GAT层</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GATLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features, dropout, alpha, concat=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GATLayer, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.in_features = in_features</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_features = out_features</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.alpha = alpha</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.concat = concat</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 变换矩阵</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))</span><br><span class=\"line\">        nn.init.xavier_uniform_(<span class=\"variable language_\">self</span>.W.data, gain=<span class=\"number\">1.414</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 注意力向量</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.a = nn.Parameter(torch.zeros(size=(<span class=\"number\">2</span>*out_features, <span class=\"number\">1</span>)))</span><br><span class=\"line\">        nn.init.xavier_uniform_(<span class=\"variable language_\">self</span>.a.data, gain=<span class=\"number\">1.414</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.leakyrelu = nn.LeakyReLU(<span class=\"variable language_\">self</span>.alpha)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        <span class=\"comment\"># x: 节点特征矩阵 [N, in_features]</span></span><br><span class=\"line\">        <span class=\"comment\"># adj: 邻接矩阵 [N, N]</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 线性变换</span></span><br><span class=\"line\">        h = torch.mm(x, <span class=\"variable language_\">self</span>.W)  <span class=\"comment\"># [N, out_features]</span></span><br><span class=\"line\">        N = h.size()[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 计算注意力分数</span></span><br><span class=\"line\">        a_input = torch.cat([h.repeat(<span class=\"number\">1</span>, N).view(N * N, -<span class=\"number\">1</span>), h.repeat(N, <span class=\"number\">1</span>)], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        a_input = a_input.view(N, N, <span class=\"number\">2</span> * <span class=\"variable language_\">self</span>.out_features)</span><br><span class=\"line\">        e = <span class=\"variable language_\">self</span>.leakyrelu(torch.matmul(a_input, <span class=\"variable language_\">self</span>.a).squeeze(<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 掩码机制</span></span><br><span class=\"line\">        zero_vec = -<span class=\"number\">9e15</span> * torch.ones_like(e)</span><br><span class=\"line\">        attention = torch.where(adj &gt; <span class=\"number\">0</span>, e, zero_vec)</span><br><span class=\"line\">        attention = F.softmax(attention, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        attention = F.dropout(attention, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 聚合特征</span></span><br><span class=\"line\">        h_prime = torch.matmul(attention, h)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.concat:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> F.elu(h_prime)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> h_prime</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">GAT</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, nfeat, nhid, nclass, dropout, alpha, nheads</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(GAT, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 多头注意力层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attentions = nn.ModuleList([</span><br><span class=\"line\">            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=<span class=\"literal\">True</span>) </span><br><span class=\"line\">            <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(nheads)</span><br><span class=\"line\">        ])</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 输出层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.out_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, adj</span>):</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        <span class=\"comment\"># 多头注意力</span></span><br><span class=\"line\">        x = torch.cat([att(x, adj) <span class=\"keyword\">for</span> att <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.attentions], dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        x = F.dropout(x, <span class=\"variable language_\">self</span>.dropout, training=<span class=\"variable language_\">self</span>.training)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.out_att(x, adj)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> F.log_softmax(x, dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"实际应用示例\"><a href=\"#实际应用示例\" class=\"headerlink\" title=\"实际应用示例\"></a>实际应用示例</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 模型初始化</span></span><br><span class=\"line\">model = GAT(nfeat=input_dim,</span><br><span class=\"line\">           nhid=<span class=\"number\">8</span>,</span><br><span class=\"line\">           nclass=num_classes,</span><br><span class=\"line\">           dropout=<span class=\"number\">0.6</span>,</span><br><span class=\"line\">           alpha=<span class=\"number\">0.2</span>,</span><br><span class=\"line\">           nheads=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 优化器</span></span><br><span class=\"line\">optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.005</span>, weight_decay=<span class=\"number\">5e-4</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 训练循环</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>():</span><br><span class=\"line\">    model.train()</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    output = model(features, adj)</span><br><span class=\"line\">    loss = F.nll_loss(output[idx_train], labels[idx_train])</span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> loss.item()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"🔍-注意事项与最佳实践\"><a href=\"#🔍-注意事项与最佳实践\" class=\"headerlink\" title=\"🔍 注意事项与最佳实践\"></a>🔍 注意事项与最佳实践</h2><h2 id=\"📈-未来展望\"><a href=\"#📈-未来展望\" class=\"headerlink\" title=\"📈 未来展望\"></a>📈 未来展望</h2><h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Lee 等 - 2018 - Attention Models in Graphs A Survey.pdf\" target=\"_blank\">📄 Lee 等 - 2018 - Attention Models in Graphs A Survey</a><br><a href=\"https://github.com/xmu-xiaoma666/External-Attention-pytorch\" target=\"_blank\">github: External-Attention-pytorch</a> </p>"},{"title":"CDR Input Data Analysis","date":"2025-07-09T13:24:58.000Z","_content":"\n# CDR 数据源分析\n\n本文主要是介绍一下 **深度学习** 在 _药物反应预测_ 中运用到的数据源。~~但由于本人比较捞~~ 本文主要从 **深度学习** 角度来看待这些数据源，对其在医学方面的意义~~（主要是鼠鼠也不会捏）~~不会有太多的描述\n\n<!-- more -->\n\n## CDR = Cancer Drug Response\n\n我们的数据源有三种：\n\n- _Cancer Representations_（癌症特征的表示）\n- _Representations of Drug Compounds_（药物特征的表示）\n- _Representations of Treatment Response_（治疗响应的表示）\n\n接下来会按顺序进行说明\n\n---\n\n### Cancer Representations\n\n癌症的特征是多组学的 ~~这不是理所应当吗~~\n\n#### 多组学类型\n\n通常基于以下四类组学数据：\n\n- 基因组（Genomic）\n\n  - 突变（Mutation）：体细胞突变（如单核苷酸变异 SNVs）可能驱动癌症进展，并影响药物靶点。\n  - 拷贝数变异（CNV）：基因拷贝数的增加或缺失可能影响药物敏感性（如 HER2 扩增与曲妥珠单抗疗效相关）。\n\n- 转录组（Transcriptomic）\n\n  - 基因表达（Gene Expression）：通过微阵列或 RNA 测序（RNA-Seq）量化基因的 mRNA 水平。例如，高表达的耐药基因可能预示治疗失败。\n\n- 表观组（Epigenomic）\n\n  - DNA 甲基化（Methylation）：启动子区域的甲基化可能沉默抑癌基因，影响药物反应。\n\n- 蛋白质组（Proteomic）\n  - 蛋白质表达（RPPA 等）：直接测量蛋白质丰度（如激酶活性），更接近功能表型。\n\n对于同一种组学数据，他们被表示成一组 **维数相同的向量**\n\n#### 预处理与整合\n\n1. 数据预处理\n\n- 包括标准化（normalization）、批次效应校正（batch effect correction）和质量控制（QC）。例如，RNA-Seq 数据需通过 RPKM 或 TPM 标准化。\n\n2. 多组学整合方法 ：\n   - 早期整合（Early Integration）：直接拼接不同组学特征为单一向量，但可能因维度灾难（curse of dimensionality）导致过拟合。\n   - 晚期整合（Late Integration）：通过独立子网络处理每组学数据（如 CNN 处理突变，GNN 处理表达数据），再融合特征。例如，MOLI 模型通过三重损失函数整合多组学数据，显著提升跨癌症模型的泛化能力。\n\n#### 基因特征具有优势及新兴趋势\n\n> 2014 年 NCI-DREAM 挑战赛表明， 基因表达数据在预测乳腺癌细胞系药物敏感性时最具预测力（优于突变或 CNV）。因此，约 90%的 DRP 模型使用基因表达（单独或联合其他组学）\n> <img src=\"/img/CDR-data-analysis/gene.png\" alt=\"gene\" width=\"50%\">\n\n##### 新兴趋势\n\n1. **结构生物学整合**：如利用蛋白质-蛋白质相互作用（PPI）网络（STRING 数据库）或通路信息（GSEA）构建生物网络，增强模型可解释性。\n2. **图神经网络（GNN）**：将基因视为节点、相互作用为边，学习拓扑特征（如 GraOmicDRP 模型）。\n\n---\n\n### Representations of Drug Compounds\n\n对药物的表示主要分为三种，一般只选取其中的一种 ~~虽然也有选用几种的 **创新** 方式~~。值得一提的是，在选定药物的表示方式后，之后的特征工程的方式目前来看非常的统一。接下来一一说明每一种表示方式。\n\n#### SMILES（简化分子输入行条目系统）\n\n1. _定义_：SMILES 是一种**线性字符串**表示法，通过符号编码分子结构（如`CCO`表示乙醇）。\n2. _优势_：\n   - 易于存储和处理，广泛用于化学信息学工具（如 RDKit）。\n   - 可直接用于序列模型（如 RNN、Transformer）或通过预处理转换为其他表示（如图结构）。\n\n#### 分子指纹（Fingerprints, FPs）和描述符（Descriptors）\n\n1. 分子指纹\n\n   - _定义_：**二进制向量**，表示分子中是否存在特定子结构（如药效团或官能团）。\n   - _常用类型_：\n     - **Morgan 指纹（ECFP）**：基于原子邻域的圆形拓扑指纹，长度通常为 512 或 1024 位。\n     - **RDKit 指纹**：开源工具生成的二进制指纹。\n   - _优势_：固定长度，适合传统机器学习模型（如随机森林）。\n\n2. 分子描述符\n\n   - _定义_：**数值向量**，编码物理化学性质（如分子量、疏水性、极性表面积等）。\n   - _工具_：PaDEL、Mordred、Dragon 等软件可自动计算数百至数千个描述符。\n\n#### 图结构表示（Graph-based Representations）\n\n1. _定义_ ：将分子表示为**图**，其中原子为**节点**，化学键为**边**，节点和边可附加属性（如原子类型、键类型）。\n2. _优势_ ：\n   - 更自然地表征分子拓扑结构，适合图神经网络（GNN）。\n   - 可捕捉局部和全局分子特征（如官能团相互作用）。\n\n---\n\n### Representations of Treatment Response\n\n从构造模型的角度出发，这是 DRP 的核心数据源\n\n- 它决定了模型最后完成的**任务类型**：训练连续值的**回归任务**和训练离散值的**分类任务**\n- 他的数据质量很大程度上决定了模型的结果的优劣，即对该数据源对模型的好坏影响很大\n\n此外，很少有从数据分析的角度出发分析这个数据源的文献，于是在这里给出简要的说明\n\n#### 连续值表示（Continuous Measures）\n\n1. **IC50**\n\n   - 半数抑制浓度，即抑制 50%细胞活力所需的药物浓度。\n   - _优势_：直观反映药物效力，广泛用于回归模型（如预测 IC50 的数值）。\n   - _局限性_：仅反映单一浓度点的效果，可能忽略剂量-反应曲线的整体形状。\n\n2. **AUC/AAC**\n   - 剂量-反应曲线下面积（Area Under the Curve）或曲线上面积（Activity Area）。\n   - _优势_：全局度量，综合所有浓度点的效果，对噪声更鲁棒。\n   - _应用_：如 DeepCDR 等模型使用 AUC 作为回归目标，实证表明其泛化性优于 IC50。\n\n#### 分类表示（Categorical Measures）\n\n1. **二分类（敏感/耐药）**\n\n   - 通过阈值（如瀑布算法、LOBICO）将连续反应（如 IC50）转化为离散标签。\n   - _优势_：更贴近临床决策需求（如选择敏感药物）。\n   - _示例_：Sharifi-Noghabi et al. (2021) 使用二分类训练深度神经网络，预测患者肿瘤的敏感性。\n\n2. **多分类**\n   - 如低/中/高反应性，适用于更细粒度的临床分级。\n\n#### 排序表示（Ranking）\n\n1. _目标_\n\n   - 为个性化治疗推荐药物排序（如 Top-k 最有效药物）。\n\n2. _方法_\n\n   - Prasse et al. (2022)：将 IC50 转化为相关性分数，设计可微排序损失函数。\n   - PPORank：利用强化学习动态优化排序，适应新增数据。\n\n3. _优势_\n   - 直接支持临床优先级排序，优于传统回归或分类。\n\n#### 数据分析\n\n由于本人大概率会做个分类模型，所以会将主要分析的是**分类表示**的数据在**图神经网络**中比较重视的几个指标，这里分析 _CCLE_ 和 _GDSC_ 两个数据集在选用主流阈值选取方法之后的表示。\n\n直接先看结果捏（这里画了两个小图）\n\n- CCLE\n\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png\" alt=\"CCLE\" style=\"max-width: 100%; height: auto;\">\n\n- GDSC\n\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png\" alt=\"GDSC\" style=\"max-width: 100%; height: auto;\">\n\n<p>\n  👉 <a href=\"/code/data_analysis/visualize_graph_analysis.py\" target=\"_blank\">查看用于生成上述图表的本地 Python 脚本：visualize_graph_analysis.py</a>\n</p>\n\n##### 🔍 关键数据对比\n\n| 特征         | CCLE   | GDSC    | 倍数差异    |\n| ------------ | ------ | ------- | ----------- |\n| **数据规模** |\n| 总节点数     | 341    | 783     | 2.3×        |\n| 第一类节点   | 317    | 561     | 1.8×        |\n| 第二类节点   | 24     | 222     | 9.3×        |\n| 总边数       | 7,307  | 100,572 | 13.8×       |\n| **图结构**   |\n| 密度         | 0.9604 | 0.8075  | 0.84×       |\n| 稀疏性       | 0.0396 | 0.1925  | 4.9×        |\n| 平均度       | 42.86  | 256.89  | 6.0×        |\n| 图直径       | 3      | 4       | 1.3×        |\n| **边分布**   |\n| 正边数量     | 1,375  | 11,591  | 8.4×        |\n| 负边数量     | 5,932  | 88,981  | 15.0×       |\n| 正边比例     | 18.8%  | 11.5%   | 0.61×       |\n| 正负边比例   | 1:4.3  | 1:7.7   | 1.8× 不平衡 |\n\n##### 📊 GNN 训练挑战分析\n\n###### 过平滑风险评估\n\n- **CCLE**: ⚠️ 高风险 (平均度 42.86)\n- **GDSC**: 🚨 极高风险 (平均度 256.89)\n\n###### 样本不平衡程度\n\n- **CCLE**: 正负边比例 1:4.3 (中等不平衡)\n- **GDSC**: 正负边比例 1:7.7 (严重不平衡)\n\n###### 邻居相似度分析\n\n```python\n# 邻居重叠度对比\nCCLE_similarity = {\n    \"第一类节点\": 0.9374,  # 高度相似\n    \"第二类节点\": 0.9274   # 高度相似\n}\n\nGDSC_similarity = {\n    \"第一类节点\": 0.7659,  # 中等相似\n    \"第二类节点\": 0.7143   # 中等相似\n}\n```\n\n**结论**: CCLE 结构更均匀但多样性不足，GDSC 结构更复杂但多样性更好\n\n##### 🎯 GNN 架构建议对比\n\n###### 推荐架构优先级\n\n- CCLE 推荐架构\n\n  1. **Bipartite GNN** + Signed GCN\n  2. **简单异构图 GNN** (HetGNN)\n  3. **标准 GCN** + 强正则化\n\n- GDSC 推荐架构\n\n  1. **采样型 GNN** (GraphSAINT, FastGCN) + SGCN\n  2. **大规模异构图 GNN** (HGT, RGCN)\n  3. **图 Transformer** (处理复杂结构)\n\n###### 具体参数建议\n\n| 参数           | CCLE         | GDSC         | 原因                |\n| -------------- | ------------ | ------------ | ------------------- |\n| **网络深度**   | 2-3 层       | 严格 2 层    | GDSC 过平滑风险更高 |\n| **隐藏维度**   | 64-128       | 128-256      | GDSC 需要更大容量   |\n| **Dropout 率** | 0.3-0.5      | 0.5-0.7      | GDSC 需要更强正则化 |\n| **学习率**     | 0.001-0.01   | 0.0001-0.001 | GDSC 需要更保守训练 |\n| **批次大小**   | 32-64 个子图 | 16-32 个子图 | GDSC 内存限制       |\n| **采样策略**   | 可选         | 必须         | GDSC 无法全图训练   |\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf\" target=\"_blank\">📄 Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a>","source":"_posts/CDR-data-analysis.md","raw":"---\ntitle: CDR Input Data Analysis\ndate: 2025-07-09 21:24:58\ntags:\n  - CDR\n  - Data Analysis\n  - 可能有点用\n  - graph theory\ncategories:\n  - CDR\n  - Data Analysis\n---\n\n# CDR 数据源分析\n\n本文主要是介绍一下 **深度学习** 在 _药物反应预测_ 中运用到的数据源。~~但由于本人比较捞~~ 本文主要从 **深度学习** 角度来看待这些数据源，对其在医学方面的意义~~（主要是鼠鼠也不会捏）~~不会有太多的描述\n\n<!-- more -->\n\n## CDR = Cancer Drug Response\n\n我们的数据源有三种：\n\n- _Cancer Representations_（癌症特征的表示）\n- _Representations of Drug Compounds_（药物特征的表示）\n- _Representations of Treatment Response_（治疗响应的表示）\n\n接下来会按顺序进行说明\n\n---\n\n### Cancer Representations\n\n癌症的特征是多组学的 ~~这不是理所应当吗~~\n\n#### 多组学类型\n\n通常基于以下四类组学数据：\n\n- 基因组（Genomic）\n\n  - 突变（Mutation）：体细胞突变（如单核苷酸变异 SNVs）可能驱动癌症进展，并影响药物靶点。\n  - 拷贝数变异（CNV）：基因拷贝数的增加或缺失可能影响药物敏感性（如 HER2 扩增与曲妥珠单抗疗效相关）。\n\n- 转录组（Transcriptomic）\n\n  - 基因表达（Gene Expression）：通过微阵列或 RNA 测序（RNA-Seq）量化基因的 mRNA 水平。例如，高表达的耐药基因可能预示治疗失败。\n\n- 表观组（Epigenomic）\n\n  - DNA 甲基化（Methylation）：启动子区域的甲基化可能沉默抑癌基因，影响药物反应。\n\n- 蛋白质组（Proteomic）\n  - 蛋白质表达（RPPA 等）：直接测量蛋白质丰度（如激酶活性），更接近功能表型。\n\n对于同一种组学数据，他们被表示成一组 **维数相同的向量**\n\n#### 预处理与整合\n\n1. 数据预处理\n\n- 包括标准化（normalization）、批次效应校正（batch effect correction）和质量控制（QC）。例如，RNA-Seq 数据需通过 RPKM 或 TPM 标准化。\n\n2. 多组学整合方法 ：\n   - 早期整合（Early Integration）：直接拼接不同组学特征为单一向量，但可能因维度灾难（curse of dimensionality）导致过拟合。\n   - 晚期整合（Late Integration）：通过独立子网络处理每组学数据（如 CNN 处理突变，GNN 处理表达数据），再融合特征。例如，MOLI 模型通过三重损失函数整合多组学数据，显著提升跨癌症模型的泛化能力。\n\n#### 基因特征具有优势及新兴趋势\n\n> 2014 年 NCI-DREAM 挑战赛表明， 基因表达数据在预测乳腺癌细胞系药物敏感性时最具预测力（优于突变或 CNV）。因此，约 90%的 DRP 模型使用基因表达（单独或联合其他组学）\n> <img src=\"/img/CDR-data-analysis/gene.png\" alt=\"gene\" width=\"50%\">\n\n##### 新兴趋势\n\n1. **结构生物学整合**：如利用蛋白质-蛋白质相互作用（PPI）网络（STRING 数据库）或通路信息（GSEA）构建生物网络，增强模型可解释性。\n2. **图神经网络（GNN）**：将基因视为节点、相互作用为边，学习拓扑特征（如 GraOmicDRP 模型）。\n\n---\n\n### Representations of Drug Compounds\n\n对药物的表示主要分为三种，一般只选取其中的一种 ~~虽然也有选用几种的 **创新** 方式~~。值得一提的是，在选定药物的表示方式后，之后的特征工程的方式目前来看非常的统一。接下来一一说明每一种表示方式。\n\n#### SMILES（简化分子输入行条目系统）\n\n1. _定义_：SMILES 是一种**线性字符串**表示法，通过符号编码分子结构（如`CCO`表示乙醇）。\n2. _优势_：\n   - 易于存储和处理，广泛用于化学信息学工具（如 RDKit）。\n   - 可直接用于序列模型（如 RNN、Transformer）或通过预处理转换为其他表示（如图结构）。\n\n#### 分子指纹（Fingerprints, FPs）和描述符（Descriptors）\n\n1. 分子指纹\n\n   - _定义_：**二进制向量**，表示分子中是否存在特定子结构（如药效团或官能团）。\n   - _常用类型_：\n     - **Morgan 指纹（ECFP）**：基于原子邻域的圆形拓扑指纹，长度通常为 512 或 1024 位。\n     - **RDKit 指纹**：开源工具生成的二进制指纹。\n   - _优势_：固定长度，适合传统机器学习模型（如随机森林）。\n\n2. 分子描述符\n\n   - _定义_：**数值向量**，编码物理化学性质（如分子量、疏水性、极性表面积等）。\n   - _工具_：PaDEL、Mordred、Dragon 等软件可自动计算数百至数千个描述符。\n\n#### 图结构表示（Graph-based Representations）\n\n1. _定义_ ：将分子表示为**图**，其中原子为**节点**，化学键为**边**，节点和边可附加属性（如原子类型、键类型）。\n2. _优势_ ：\n   - 更自然地表征分子拓扑结构，适合图神经网络（GNN）。\n   - 可捕捉局部和全局分子特征（如官能团相互作用）。\n\n---\n\n### Representations of Treatment Response\n\n从构造模型的角度出发，这是 DRP 的核心数据源\n\n- 它决定了模型最后完成的**任务类型**：训练连续值的**回归任务**和训练离散值的**分类任务**\n- 他的数据质量很大程度上决定了模型的结果的优劣，即对该数据源对模型的好坏影响很大\n\n此外，很少有从数据分析的角度出发分析这个数据源的文献，于是在这里给出简要的说明\n\n#### 连续值表示（Continuous Measures）\n\n1. **IC50**\n\n   - 半数抑制浓度，即抑制 50%细胞活力所需的药物浓度。\n   - _优势_：直观反映药物效力，广泛用于回归模型（如预测 IC50 的数值）。\n   - _局限性_：仅反映单一浓度点的效果，可能忽略剂量-反应曲线的整体形状。\n\n2. **AUC/AAC**\n   - 剂量-反应曲线下面积（Area Under the Curve）或曲线上面积（Activity Area）。\n   - _优势_：全局度量，综合所有浓度点的效果，对噪声更鲁棒。\n   - _应用_：如 DeepCDR 等模型使用 AUC 作为回归目标，实证表明其泛化性优于 IC50。\n\n#### 分类表示（Categorical Measures）\n\n1. **二分类（敏感/耐药）**\n\n   - 通过阈值（如瀑布算法、LOBICO）将连续反应（如 IC50）转化为离散标签。\n   - _优势_：更贴近临床决策需求（如选择敏感药物）。\n   - _示例_：Sharifi-Noghabi et al. (2021) 使用二分类训练深度神经网络，预测患者肿瘤的敏感性。\n\n2. **多分类**\n   - 如低/中/高反应性，适用于更细粒度的临床分级。\n\n#### 排序表示（Ranking）\n\n1. _目标_\n\n   - 为个性化治疗推荐药物排序（如 Top-k 最有效药物）。\n\n2. _方法_\n\n   - Prasse et al. (2022)：将 IC50 转化为相关性分数，设计可微排序损失函数。\n   - PPORank：利用强化学习动态优化排序，适应新增数据。\n\n3. _优势_\n   - 直接支持临床优先级排序，优于传统回归或分类。\n\n#### 数据分析\n\n由于本人大概率会做个分类模型，所以会将主要分析的是**分类表示**的数据在**图神经网络**中比较重视的几个指标，这里分析 _CCLE_ 和 _GDSC_ 两个数据集在选用主流阈值选取方法之后的表示。\n\n直接先看结果捏（这里画了两个小图）\n\n- CCLE\n\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png\" alt=\"CCLE\" style=\"max-width: 100%; height: auto;\">\n\n- GDSC\n\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png\" alt=\"GDSC\" style=\"max-width: 100%; height: auto;\">\n\n<p>\n  👉 <a href=\"/code/data_analysis/visualize_graph_analysis.py\" target=\"_blank\">查看用于生成上述图表的本地 Python 脚本：visualize_graph_analysis.py</a>\n</p>\n\n##### 🔍 关键数据对比\n\n| 特征         | CCLE   | GDSC    | 倍数差异    |\n| ------------ | ------ | ------- | ----------- |\n| **数据规模** |\n| 总节点数     | 341    | 783     | 2.3×        |\n| 第一类节点   | 317    | 561     | 1.8×        |\n| 第二类节点   | 24     | 222     | 9.3×        |\n| 总边数       | 7,307  | 100,572 | 13.8×       |\n| **图结构**   |\n| 密度         | 0.9604 | 0.8075  | 0.84×       |\n| 稀疏性       | 0.0396 | 0.1925  | 4.9×        |\n| 平均度       | 42.86  | 256.89  | 6.0×        |\n| 图直径       | 3      | 4       | 1.3×        |\n| **边分布**   |\n| 正边数量     | 1,375  | 11,591  | 8.4×        |\n| 负边数量     | 5,932  | 88,981  | 15.0×       |\n| 正边比例     | 18.8%  | 11.5%   | 0.61×       |\n| 正负边比例   | 1:4.3  | 1:7.7   | 1.8× 不平衡 |\n\n##### 📊 GNN 训练挑战分析\n\n###### 过平滑风险评估\n\n- **CCLE**: ⚠️ 高风险 (平均度 42.86)\n- **GDSC**: 🚨 极高风险 (平均度 256.89)\n\n###### 样本不平衡程度\n\n- **CCLE**: 正负边比例 1:4.3 (中等不平衡)\n- **GDSC**: 正负边比例 1:7.7 (严重不平衡)\n\n###### 邻居相似度分析\n\n```python\n# 邻居重叠度对比\nCCLE_similarity = {\n    \"第一类节点\": 0.9374,  # 高度相似\n    \"第二类节点\": 0.9274   # 高度相似\n}\n\nGDSC_similarity = {\n    \"第一类节点\": 0.7659,  # 中等相似\n    \"第二类节点\": 0.7143   # 中等相似\n}\n```\n\n**结论**: CCLE 结构更均匀但多样性不足，GDSC 结构更复杂但多样性更好\n\n##### 🎯 GNN 架构建议对比\n\n###### 推荐架构优先级\n\n- CCLE 推荐架构\n\n  1. **Bipartite GNN** + Signed GCN\n  2. **简单异构图 GNN** (HetGNN)\n  3. **标准 GCN** + 强正则化\n\n- GDSC 推荐架构\n\n  1. **采样型 GNN** (GraphSAINT, FastGCN) + SGCN\n  2. **大规模异构图 GNN** (HGT, RGCN)\n  3. **图 Transformer** (处理复杂结构)\n\n###### 具体参数建议\n\n| 参数           | CCLE         | GDSC         | 原因                |\n| -------------- | ------------ | ------------ | ------------------- |\n| **网络深度**   | 2-3 层       | 严格 2 层    | GDSC 过平滑风险更高 |\n| **隐藏维度**   | 64-128       | 128-256      | GDSC 需要更大容量   |\n| **Dropout 率** | 0.3-0.5      | 0.5-0.7      | GDSC 需要更强正则化 |\n| **学习率**     | 0.001-0.01   | 0.0001-0.001 | GDSC 需要更保守训练 |\n| **批次大小**   | 32-64 个子图 | 16-32 个子图 | GDSC 内存限制       |\n| **采样策略**   | 可选         | 必须         | GDSC 无法全图训练   |\n\n# 📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\n\n<a href=\"/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf\" target=\"_blank\">📄 Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a>","slug":"CDR-data-analysis","published":1,"updated":"2025-07-11T03:07:36.876Z","comments":1,"layout":"post","photos":[],"_id":"cmd4rbxvz001tk8417bw4fd17","content":"<h1 id=\"CDR-数据源分析\"><a href=\"#CDR-数据源分析\" class=\"headerlink\" title=\"CDR 数据源分析\"></a>CDR 数据源分析</h1><p>本文主要是介绍一下 <strong>深度学习</strong> 在 <em>药物反应预测</em> 中运用到的数据源。<del>但由于本人比较捞</del> 本文主要从 <strong>深度学习</strong> 角度来看待这些数据源，对其在医学方面的意义<del>（主要是鼠鼠也不会捏）</del>不会有太多的描述</p>\n<span id=\"more\"></span>\n\n<h2 id=\"CDR-Cancer-Drug-Response\"><a href=\"#CDR-Cancer-Drug-Response\" class=\"headerlink\" title=\"CDR &#x3D; Cancer Drug Response\"></a>CDR &#x3D; Cancer Drug Response</h2><p>我们的数据源有三种：</p>\n<ul>\n<li><em>Cancer Representations</em>（癌症特征的表示）</li>\n<li><em>Representations of Drug Compounds</em>（药物特征的表示）</li>\n<li><em>Representations of Treatment Response</em>（治疗响应的表示）</li>\n</ul>\n<p>接下来会按顺序进行说明</p>\n<hr>\n<h3 id=\"Cancer-Representations\"><a href=\"#Cancer-Representations\" class=\"headerlink\" title=\"Cancer Representations\"></a>Cancer Representations</h3><p>癌症的特征是多组学的 <del>这不是理所应当吗</del></p>\n<h4 id=\"多组学类型\"><a href=\"#多组学类型\" class=\"headerlink\" title=\"多组学类型\"></a>多组学类型</h4><p>通常基于以下四类组学数据：</p>\n<ul>\n<li><p>基因组（Genomic）</p>\n<ul>\n<li>突变（Mutation）：体细胞突变（如单核苷酸变异 SNVs）可能驱动癌症进展，并影响药物靶点。</li>\n<li>拷贝数变异（CNV）：基因拷贝数的增加或缺失可能影响药物敏感性（如 HER2 扩增与曲妥珠单抗疗效相关）。</li>\n</ul>\n</li>\n<li><p>转录组（Transcriptomic）</p>\n<ul>\n<li>基因表达（Gene Expression）：通过微阵列或 RNA 测序（RNA-Seq）量化基因的 mRNA 水平。例如，高表达的耐药基因可能预示治疗失败。</li>\n</ul>\n</li>\n<li><p>表观组（Epigenomic）</p>\n<ul>\n<li>DNA 甲基化（Methylation）：启动子区域的甲基化可能沉默抑癌基因，影响药物反应。</li>\n</ul>\n</li>\n<li><p>蛋白质组（Proteomic）</p>\n<ul>\n<li>蛋白质表达（RPPA 等）：直接测量蛋白质丰度（如激酶活性），更接近功能表型。</li>\n</ul>\n</li>\n</ul>\n<p>对于同一种组学数据，他们被表示成一组 <strong>维数相同的向量</strong></p>\n<h4 id=\"预处理与整合\"><a href=\"#预处理与整合\" class=\"headerlink\" title=\"预处理与整合\"></a>预处理与整合</h4><ol>\n<li>数据预处理</li>\n</ol>\n<ul>\n<li>包括标准化（normalization）、批次效应校正（batch effect correction）和质量控制（QC）。例如，RNA-Seq 数据需通过 RPKM 或 TPM 标准化。</li>\n</ul>\n<ol start=\"2\">\n<li>多组学整合方法 ：<ul>\n<li>早期整合（Early Integration）：直接拼接不同组学特征为单一向量，但可能因维度灾难（curse of dimensionality）导致过拟合。</li>\n<li>晚期整合（Late Integration）：通过独立子网络处理每组学数据（如 CNN 处理突变，GNN 处理表达数据），再融合特征。例如，MOLI 模型通过三重损失函数整合多组学数据，显著提升跨癌症模型的泛化能力。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"基因特征具有优势及新兴趋势\"><a href=\"#基因特征具有优势及新兴趋势\" class=\"headerlink\" title=\"基因特征具有优势及新兴趋势\"></a>基因特征具有优势及新兴趋势</h4><blockquote>\n<p>2014 年 NCI-DREAM 挑战赛表明， 基因表达数据在预测乳腺癌细胞系药物敏感性时最具预测力（优于突变或 CNV）。因此，约 90%的 DRP 模型使用基因表达（单独或联合其他组学）<br><img src=\"/img/CDR-data-analysis/gene.png\" alt=\"gene\" width=\"50%\"></p>\n</blockquote>\n<h5 id=\"新兴趋势\"><a href=\"#新兴趋势\" class=\"headerlink\" title=\"新兴趋势\"></a>新兴趋势</h5><ol>\n<li><strong>结构生物学整合</strong>：如利用蛋白质-蛋白质相互作用（PPI）网络（STRING 数据库）或通路信息（GSEA）构建生物网络，增强模型可解释性。</li>\n<li><strong>图神经网络（GNN）</strong>：将基因视为节点、相互作用为边，学习拓扑特征（如 GraOmicDRP 模型）。</li>\n</ol>\n<hr>\n<h3 id=\"Representations-of-Drug-Compounds\"><a href=\"#Representations-of-Drug-Compounds\" class=\"headerlink\" title=\"Representations of Drug Compounds\"></a>Representations of Drug Compounds</h3><p>对药物的表示主要分为三种，一般只选取其中的一种 <del>虽然也有选用几种的 <strong>创新</strong> 方式</del>。值得一提的是，在选定药物的表示方式后，之后的特征工程的方式目前来看非常的统一。接下来一一说明每一种表示方式。</p>\n<h4 id=\"SMILES（简化分子输入行条目系统）\"><a href=\"#SMILES（简化分子输入行条目系统）\" class=\"headerlink\" title=\"SMILES（简化分子输入行条目系统）\"></a>SMILES（简化分子输入行条目系统）</h4><ol>\n<li><em>定义</em>：SMILES 是一种<strong>线性字符串</strong>表示法，通过符号编码分子结构（如<code>CCO</code>表示乙醇）。</li>\n<li><em>优势</em>：<ul>\n<li>易于存储和处理，广泛用于化学信息学工具（如 RDKit）。</li>\n<li>可直接用于序列模型（如 RNN、Transformer）或通过预处理转换为其他表示（如图结构）。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"分子指纹（Fingerprints-FPs）和描述符（Descriptors）\"><a href=\"#分子指纹（Fingerprints-FPs）和描述符（Descriptors）\" class=\"headerlink\" title=\"分子指纹（Fingerprints, FPs）和描述符（Descriptors）\"></a>分子指纹（Fingerprints, FPs）和描述符（Descriptors）</h4><ol>\n<li><p>分子指纹</p>\n<ul>\n<li><em>定义</em>：<strong>二进制向量</strong>，表示分子中是否存在特定子结构（如药效团或官能团）。</li>\n<li><em>常用类型</em>：<ul>\n<li><strong>Morgan 指纹（ECFP）</strong>：基于原子邻域的圆形拓扑指纹，长度通常为 512 或 1024 位。</li>\n<li><strong>RDKit 指纹</strong>：开源工具生成的二进制指纹。</li>\n</ul>\n</li>\n<li><em>优势</em>：固定长度，适合传统机器学习模型（如随机森林）。</li>\n</ul>\n</li>\n<li><p>分子描述符</p>\n<ul>\n<li><em>定义</em>：<strong>数值向量</strong>，编码物理化学性质（如分子量、疏水性、极性表面积等）。</li>\n<li><em>工具</em>：PaDEL、Mordred、Dragon 等软件可自动计算数百至数千个描述符。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"图结构表示（Graph-based-Representations）\"><a href=\"#图结构表示（Graph-based-Representations）\" class=\"headerlink\" title=\"图结构表示（Graph-based Representations）\"></a>图结构表示（Graph-based Representations）</h4><ol>\n<li><em>定义</em> ：将分子表示为<strong>图</strong>，其中原子为<strong>节点</strong>，化学键为<strong>边</strong>，节点和边可附加属性（如原子类型、键类型）。</li>\n<li><em>优势</em> ：<ul>\n<li>更自然地表征分子拓扑结构，适合图神经网络（GNN）。</li>\n<li>可捕捉局部和全局分子特征（如官能团相互作用）。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"Representations-of-Treatment-Response\"><a href=\"#Representations-of-Treatment-Response\" class=\"headerlink\" title=\"Representations of Treatment Response\"></a>Representations of Treatment Response</h3><p>从构造模型的角度出发，这是 DRP 的核心数据源</p>\n<ul>\n<li>它决定了模型最后完成的<strong>任务类型</strong>：训练连续值的<strong>回归任务</strong>和训练离散值的<strong>分类任务</strong></li>\n<li>他的数据质量很大程度上决定了模型的结果的优劣，即对该数据源对模型的好坏影响很大</li>\n</ul>\n<p>此外，很少有从数据分析的角度出发分析这个数据源的文献，于是在这里给出简要的说明</p>\n<h4 id=\"连续值表示（Continuous-Measures）\"><a href=\"#连续值表示（Continuous-Measures）\" class=\"headerlink\" title=\"连续值表示（Continuous Measures）\"></a>连续值表示（Continuous Measures）</h4><ol>\n<li><p><strong>IC50</strong></p>\n<ul>\n<li>半数抑制浓度，即抑制 50%细胞活力所需的药物浓度。</li>\n<li><em>优势</em>：直观反映药物效力，广泛用于回归模型（如预测 IC50 的数值）。</li>\n<li><em>局限性</em>：仅反映单一浓度点的效果，可能忽略剂量-反应曲线的整体形状。</li>\n</ul>\n</li>\n<li><p><strong>AUC&#x2F;AAC</strong></p>\n<ul>\n<li>剂量-反应曲线下面积（Area Under the Curve）或曲线上面积（Activity Area）。</li>\n<li><em>优势</em>：全局度量，综合所有浓度点的效果，对噪声更鲁棒。</li>\n<li><em>应用</em>：如 DeepCDR 等模型使用 AUC 作为回归目标，实证表明其泛化性优于 IC50。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"分类表示（Categorical-Measures）\"><a href=\"#分类表示（Categorical-Measures）\" class=\"headerlink\" title=\"分类表示（Categorical Measures）\"></a>分类表示（Categorical Measures）</h4><ol>\n<li><p><strong>二分类（敏感&#x2F;耐药）</strong></p>\n<ul>\n<li>通过阈值（如瀑布算法、LOBICO）将连续反应（如 IC50）转化为离散标签。</li>\n<li><em>优势</em>：更贴近临床决策需求（如选择敏感药物）。</li>\n<li><em>示例</em>：Sharifi-Noghabi et al. (2021) 使用二分类训练深度神经网络，预测患者肿瘤的敏感性。</li>\n</ul>\n</li>\n<li><p><strong>多分类</strong></p>\n<ul>\n<li>如低&#x2F;中&#x2F;高反应性，适用于更细粒度的临床分级。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"排序表示（Ranking）\"><a href=\"#排序表示（Ranking）\" class=\"headerlink\" title=\"排序表示（Ranking）\"></a>排序表示（Ranking）</h4><ol>\n<li><p><em>目标</em></p>\n<ul>\n<li>为个性化治疗推荐药物排序（如 Top-k 最有效药物）。</li>\n</ul>\n</li>\n<li><p><em>方法</em></p>\n<ul>\n<li>Prasse et al. (2022)：将 IC50 转化为相关性分数，设计可微排序损失函数。</li>\n<li>PPORank：利用强化学习动态优化排序，适应新增数据。</li>\n</ul>\n</li>\n<li><p><em>优势</em></p>\n<ul>\n<li>直接支持临床优先级排序，优于传统回归或分类。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"数据分析\"><a href=\"#数据分析\" class=\"headerlink\" title=\"数据分析\"></a>数据分析</h4><p>由于本人大概率会做个分类模型，所以会将主要分析的是<strong>分类表示</strong>的数据在<strong>图神经网络</strong>中比较重视的几个指标，这里分析 <em>CCLE</em> 和 <em>GDSC</em> 两个数据集在选用主流阈值选取方法之后的表示。</p>\n<p>直接先看结果捏（这里画了两个小图）</p>\n<ul>\n<li>CCLE</li>\n</ul>\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png\" alt=\"CCLE\" style=\"max-width: 100%; height: auto;\">\n\n<ul>\n<li>GDSC</li>\n</ul>\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png\" alt=\"GDSC\" style=\"max-width: 100%; height: auto;\">\n\n<p>\n  👉 <a href=\"/code/data_analysis/visualize_graph_analysis.py\" target=\"_blank\">查看用于生成上述图表的本地 Python 脚本：visualize_graph_analysis.py</a>\n</p>\n\n<h5 id=\"🔍-关键数据对比\"><a href=\"#🔍-关键数据对比\" class=\"headerlink\" title=\"🔍 关键数据对比\"></a>🔍 关键数据对比</h5><table>\n<thead>\n<tr>\n<th>特征</th>\n<th>CCLE</th>\n<th>GDSC</th>\n<th>倍数差异</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>数据规模</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>总节点数</td>\n<td>341</td>\n<td>783</td>\n<td>2.3×</td>\n</tr>\n<tr>\n<td>第一类节点</td>\n<td>317</td>\n<td>561</td>\n<td>1.8×</td>\n</tr>\n<tr>\n<td>第二类节点</td>\n<td>24</td>\n<td>222</td>\n<td>9.3×</td>\n</tr>\n<tr>\n<td>总边数</td>\n<td>7,307</td>\n<td>100,572</td>\n<td>13.8×</td>\n</tr>\n<tr>\n<td><strong>图结构</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>密度</td>\n<td>0.9604</td>\n<td>0.8075</td>\n<td>0.84×</td>\n</tr>\n<tr>\n<td>稀疏性</td>\n<td>0.0396</td>\n<td>0.1925</td>\n<td>4.9×</td>\n</tr>\n<tr>\n<td>平均度</td>\n<td>42.86</td>\n<td>256.89</td>\n<td>6.0×</td>\n</tr>\n<tr>\n<td>图直径</td>\n<td>3</td>\n<td>4</td>\n<td>1.3×</td>\n</tr>\n<tr>\n<td><strong>边分布</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>正边数量</td>\n<td>1,375</td>\n<td>11,591</td>\n<td>8.4×</td>\n</tr>\n<tr>\n<td>负边数量</td>\n<td>5,932</td>\n<td>88,981</td>\n<td>15.0×</td>\n</tr>\n<tr>\n<td>正边比例</td>\n<td>18.8%</td>\n<td>11.5%</td>\n<td>0.61×</td>\n</tr>\n<tr>\n<td>正负边比例</td>\n<td>1:4.3</td>\n<td>1:7.7</td>\n<td>1.8× 不平衡</td>\n</tr>\n</tbody></table>\n<h5 id=\"📊-GNN-训练挑战分析\"><a href=\"#📊-GNN-训练挑战分析\" class=\"headerlink\" title=\"📊 GNN 训练挑战分析\"></a>📊 GNN 训练挑战分析</h5><h6 id=\"过平滑风险评估\"><a href=\"#过平滑风险评估\" class=\"headerlink\" title=\"过平滑风险评估\"></a>过平滑风险评估</h6><ul>\n<li><strong>CCLE</strong>: ⚠️ 高风险 (平均度 42.86)</li>\n<li><strong>GDSC</strong>: 🚨 极高风险 (平均度 256.89)</li>\n</ul>\n<h6 id=\"样本不平衡程度\"><a href=\"#样本不平衡程度\" class=\"headerlink\" title=\"样本不平衡程度\"></a>样本不平衡程度</h6><ul>\n<li><strong>CCLE</strong>: 正负边比例 1:4.3 (中等不平衡)</li>\n<li><strong>GDSC</strong>: 正负边比例 1:7.7 (严重不平衡)</li>\n</ul>\n<h6 id=\"邻居相似度分析\"><a href=\"#邻居相似度分析\" class=\"headerlink\" title=\"邻居相似度分析\"></a>邻居相似度分析</h6><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 邻居重叠度对比</span></span><br><span class=\"line\">CCLE_similarity = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;第一类节点&quot;</span>: <span class=\"number\">0.9374</span>,  <span class=\"comment\"># 高度相似</span></span><br><span class=\"line\">    <span class=\"string\">&quot;第二类节点&quot;</span>: <span class=\"number\">0.9274</span>   <span class=\"comment\"># 高度相似</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">GDSC_similarity = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;第一类节点&quot;</span>: <span class=\"number\">0.7659</span>,  <span class=\"comment\"># 中等相似</span></span><br><span class=\"line\">    <span class=\"string\">&quot;第二类节点&quot;</span>: <span class=\"number\">0.7143</span>   <span class=\"comment\"># 中等相似</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>结论</strong>: CCLE 结构更均匀但多样性不足，GDSC 结构更复杂但多样性更好</p>\n<h5 id=\"🎯-GNN-架构建议对比\"><a href=\"#🎯-GNN-架构建议对比\" class=\"headerlink\" title=\"🎯 GNN 架构建议对比\"></a>🎯 GNN 架构建议对比</h5><h6 id=\"推荐架构优先级\"><a href=\"#推荐架构优先级\" class=\"headerlink\" title=\"推荐架构优先级\"></a>推荐架构优先级</h6><ul>\n<li><p>CCLE 推荐架构</p>\n<ol>\n<li><strong>Bipartite GNN</strong> + Signed GCN</li>\n<li><strong>简单异构图 GNN</strong> (HetGNN)</li>\n<li><strong>标准 GCN</strong> + 强正则化</li>\n</ol>\n</li>\n<li><p>GDSC 推荐架构</p>\n<ol>\n<li><strong>采样型 GNN</strong> (GraphSAINT, FastGCN) + SGCN</li>\n<li><strong>大规模异构图 GNN</strong> (HGT, RGCN)</li>\n<li><strong>图 Transformer</strong> (处理复杂结构)</li>\n</ol>\n</li>\n</ul>\n<h6 id=\"具体参数建议\"><a href=\"#具体参数建议\" class=\"headerlink\" title=\"具体参数建议\"></a>具体参数建议</h6><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>CCLE</th>\n<th>GDSC</th>\n<th>原因</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>网络深度</strong></td>\n<td>2-3 层</td>\n<td>严格 2 层</td>\n<td>GDSC 过平滑风险更高</td>\n</tr>\n<tr>\n<td><strong>隐藏维度</strong></td>\n<td>64-128</td>\n<td>128-256</td>\n<td>GDSC 需要更大容量</td>\n</tr>\n<tr>\n<td><strong>Dropout 率</strong></td>\n<td>0.3-0.5</td>\n<td>0.5-0.7</td>\n<td>GDSC 需要更强正则化</td>\n</tr>\n<tr>\n<td><strong>学习率</strong></td>\n<td>0.001-0.01</td>\n<td>0.0001-0.001</td>\n<td>GDSC 需要更保守训练</td>\n</tr>\n<tr>\n<td><strong>批次大小</strong></td>\n<td>32-64 个子图</td>\n<td>16-32 个子图</td>\n<td>GDSC 内存限制</td>\n</tr>\n<tr>\n<td><strong>采样策略</strong></td>\n<td>可选</td>\n<td>必须</td>\n<td>GDSC 无法全图训练</td>\n</tr>\n</tbody></table>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf\" target=\"_blank\">📄 Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a></p>\n","length":2290,"excerpt":"<h1 id=\"CDR-数据源分析\"><a href=\"#CDR-数据源分析\" class=\"headerlink\" title=\"CDR 数据源分析\"></a>CDR 数据源分析</h1><p>本文主要是介绍一下 <strong>深度学习</strong> 在 <em>药物反应预测</em> 中运用到的数据源。<del>但由于本人比较捞</del> 本文主要从 <strong>深度学习</strong> 角度来看待这些数据源，对其在医学方面的意义<del>（主要是鼠鼠也不会捏）</del>不会有太多的描述</p>","more":"<h2 id=\"CDR-Cancer-Drug-Response\"><a href=\"#CDR-Cancer-Drug-Response\" class=\"headerlink\" title=\"CDR &#x3D; Cancer Drug Response\"></a>CDR &#x3D; Cancer Drug Response</h2><p>我们的数据源有三种：</p>\n<ul>\n<li><em>Cancer Representations</em>（癌症特征的表示）</li>\n<li><em>Representations of Drug Compounds</em>（药物特征的表示）</li>\n<li><em>Representations of Treatment Response</em>（治疗响应的表示）</li>\n</ul>\n<p>接下来会按顺序进行说明</p>\n<hr>\n<h3 id=\"Cancer-Representations\"><a href=\"#Cancer-Representations\" class=\"headerlink\" title=\"Cancer Representations\"></a>Cancer Representations</h3><p>癌症的特征是多组学的 <del>这不是理所应当吗</del></p>\n<h4 id=\"多组学类型\"><a href=\"#多组学类型\" class=\"headerlink\" title=\"多组学类型\"></a>多组学类型</h4><p>通常基于以下四类组学数据：</p>\n<ul>\n<li><p>基因组（Genomic）</p>\n<ul>\n<li>突变（Mutation）：体细胞突变（如单核苷酸变异 SNVs）可能驱动癌症进展，并影响药物靶点。</li>\n<li>拷贝数变异（CNV）：基因拷贝数的增加或缺失可能影响药物敏感性（如 HER2 扩增与曲妥珠单抗疗效相关）。</li>\n</ul>\n</li>\n<li><p>转录组（Transcriptomic）</p>\n<ul>\n<li>基因表达（Gene Expression）：通过微阵列或 RNA 测序（RNA-Seq）量化基因的 mRNA 水平。例如，高表达的耐药基因可能预示治疗失败。</li>\n</ul>\n</li>\n<li><p>表观组（Epigenomic）</p>\n<ul>\n<li>DNA 甲基化（Methylation）：启动子区域的甲基化可能沉默抑癌基因，影响药物反应。</li>\n</ul>\n</li>\n<li><p>蛋白质组（Proteomic）</p>\n<ul>\n<li>蛋白质表达（RPPA 等）：直接测量蛋白质丰度（如激酶活性），更接近功能表型。</li>\n</ul>\n</li>\n</ul>\n<p>对于同一种组学数据，他们被表示成一组 <strong>维数相同的向量</strong></p>\n<h4 id=\"预处理与整合\"><a href=\"#预处理与整合\" class=\"headerlink\" title=\"预处理与整合\"></a>预处理与整合</h4><ol>\n<li>数据预处理</li>\n</ol>\n<ul>\n<li>包括标准化（normalization）、批次效应校正（batch effect correction）和质量控制（QC）。例如，RNA-Seq 数据需通过 RPKM 或 TPM 标准化。</li>\n</ul>\n<ol start=\"2\">\n<li>多组学整合方法 ：<ul>\n<li>早期整合（Early Integration）：直接拼接不同组学特征为单一向量，但可能因维度灾难（curse of dimensionality）导致过拟合。</li>\n<li>晚期整合（Late Integration）：通过独立子网络处理每组学数据（如 CNN 处理突变，GNN 处理表达数据），再融合特征。例如，MOLI 模型通过三重损失函数整合多组学数据，显著提升跨癌症模型的泛化能力。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"基因特征具有优势及新兴趋势\"><a href=\"#基因特征具有优势及新兴趋势\" class=\"headerlink\" title=\"基因特征具有优势及新兴趋势\"></a>基因特征具有优势及新兴趋势</h4><blockquote>\n<p>2014 年 NCI-DREAM 挑战赛表明， 基因表达数据在预测乳腺癌细胞系药物敏感性时最具预测力（优于突变或 CNV）。因此，约 90%的 DRP 模型使用基因表达（单独或联合其他组学）<br><img src=\"/img/CDR-data-analysis/gene.png\" alt=\"gene\" width=\"50%\"></p>\n</blockquote>\n<h5 id=\"新兴趋势\"><a href=\"#新兴趋势\" class=\"headerlink\" title=\"新兴趋势\"></a>新兴趋势</h5><ol>\n<li><strong>结构生物学整合</strong>：如利用蛋白质-蛋白质相互作用（PPI）网络（STRING 数据库）或通路信息（GSEA）构建生物网络，增强模型可解释性。</li>\n<li><strong>图神经网络（GNN）</strong>：将基因视为节点、相互作用为边，学习拓扑特征（如 GraOmicDRP 模型）。</li>\n</ol>\n<hr>\n<h3 id=\"Representations-of-Drug-Compounds\"><a href=\"#Representations-of-Drug-Compounds\" class=\"headerlink\" title=\"Representations of Drug Compounds\"></a>Representations of Drug Compounds</h3><p>对药物的表示主要分为三种，一般只选取其中的一种 <del>虽然也有选用几种的 <strong>创新</strong> 方式</del>。值得一提的是，在选定药物的表示方式后，之后的特征工程的方式目前来看非常的统一。接下来一一说明每一种表示方式。</p>\n<h4 id=\"SMILES（简化分子输入行条目系统）\"><a href=\"#SMILES（简化分子输入行条目系统）\" class=\"headerlink\" title=\"SMILES（简化分子输入行条目系统）\"></a>SMILES（简化分子输入行条目系统）</h4><ol>\n<li><em>定义</em>：SMILES 是一种<strong>线性字符串</strong>表示法，通过符号编码分子结构（如<code>CCO</code>表示乙醇）。</li>\n<li><em>优势</em>：<ul>\n<li>易于存储和处理，广泛用于化学信息学工具（如 RDKit）。</li>\n<li>可直接用于序列模型（如 RNN、Transformer）或通过预处理转换为其他表示（如图结构）。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"分子指纹（Fingerprints-FPs）和描述符（Descriptors）\"><a href=\"#分子指纹（Fingerprints-FPs）和描述符（Descriptors）\" class=\"headerlink\" title=\"分子指纹（Fingerprints, FPs）和描述符（Descriptors）\"></a>分子指纹（Fingerprints, FPs）和描述符（Descriptors）</h4><ol>\n<li><p>分子指纹</p>\n<ul>\n<li><em>定义</em>：<strong>二进制向量</strong>，表示分子中是否存在特定子结构（如药效团或官能团）。</li>\n<li><em>常用类型</em>：<ul>\n<li><strong>Morgan 指纹（ECFP）</strong>：基于原子邻域的圆形拓扑指纹，长度通常为 512 或 1024 位。</li>\n<li><strong>RDKit 指纹</strong>：开源工具生成的二进制指纹。</li>\n</ul>\n</li>\n<li><em>优势</em>：固定长度，适合传统机器学习模型（如随机森林）。</li>\n</ul>\n</li>\n<li><p>分子描述符</p>\n<ul>\n<li><em>定义</em>：<strong>数值向量</strong>，编码物理化学性质（如分子量、疏水性、极性表面积等）。</li>\n<li><em>工具</em>：PaDEL、Mordred、Dragon 等软件可自动计算数百至数千个描述符。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"图结构表示（Graph-based-Representations）\"><a href=\"#图结构表示（Graph-based-Representations）\" class=\"headerlink\" title=\"图结构表示（Graph-based Representations）\"></a>图结构表示（Graph-based Representations）</h4><ol>\n<li><em>定义</em> ：将分子表示为<strong>图</strong>，其中原子为<strong>节点</strong>，化学键为<strong>边</strong>，节点和边可附加属性（如原子类型、键类型）。</li>\n<li><em>优势</em> ：<ul>\n<li>更自然地表征分子拓扑结构，适合图神经网络（GNN）。</li>\n<li>可捕捉局部和全局分子特征（如官能团相互作用）。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"Representations-of-Treatment-Response\"><a href=\"#Representations-of-Treatment-Response\" class=\"headerlink\" title=\"Representations of Treatment Response\"></a>Representations of Treatment Response</h3><p>从构造模型的角度出发，这是 DRP 的核心数据源</p>\n<ul>\n<li>它决定了模型最后完成的<strong>任务类型</strong>：训练连续值的<strong>回归任务</strong>和训练离散值的<strong>分类任务</strong></li>\n<li>他的数据质量很大程度上决定了模型的结果的优劣，即对该数据源对模型的好坏影响很大</li>\n</ul>\n<p>此外，很少有从数据分析的角度出发分析这个数据源的文献，于是在这里给出简要的说明</p>\n<h4 id=\"连续值表示（Continuous-Measures）\"><a href=\"#连续值表示（Continuous-Measures）\" class=\"headerlink\" title=\"连续值表示（Continuous Measures）\"></a>连续值表示（Continuous Measures）</h4><ol>\n<li><p><strong>IC50</strong></p>\n<ul>\n<li>半数抑制浓度，即抑制 50%细胞活力所需的药物浓度。</li>\n<li><em>优势</em>：直观反映药物效力，广泛用于回归模型（如预测 IC50 的数值）。</li>\n<li><em>局限性</em>：仅反映单一浓度点的效果，可能忽略剂量-反应曲线的整体形状。</li>\n</ul>\n</li>\n<li><p><strong>AUC&#x2F;AAC</strong></p>\n<ul>\n<li>剂量-反应曲线下面积（Area Under the Curve）或曲线上面积（Activity Area）。</li>\n<li><em>优势</em>：全局度量，综合所有浓度点的效果，对噪声更鲁棒。</li>\n<li><em>应用</em>：如 DeepCDR 等模型使用 AUC 作为回归目标，实证表明其泛化性优于 IC50。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"分类表示（Categorical-Measures）\"><a href=\"#分类表示（Categorical-Measures）\" class=\"headerlink\" title=\"分类表示（Categorical Measures）\"></a>分类表示（Categorical Measures）</h4><ol>\n<li><p><strong>二分类（敏感&#x2F;耐药）</strong></p>\n<ul>\n<li>通过阈值（如瀑布算法、LOBICO）将连续反应（如 IC50）转化为离散标签。</li>\n<li><em>优势</em>：更贴近临床决策需求（如选择敏感药物）。</li>\n<li><em>示例</em>：Sharifi-Noghabi et al. (2021) 使用二分类训练深度神经网络，预测患者肿瘤的敏感性。</li>\n</ul>\n</li>\n<li><p><strong>多分类</strong></p>\n<ul>\n<li>如低&#x2F;中&#x2F;高反应性，适用于更细粒度的临床分级。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"排序表示（Ranking）\"><a href=\"#排序表示（Ranking）\" class=\"headerlink\" title=\"排序表示（Ranking）\"></a>排序表示（Ranking）</h4><ol>\n<li><p><em>目标</em></p>\n<ul>\n<li>为个性化治疗推荐药物排序（如 Top-k 最有效药物）。</li>\n</ul>\n</li>\n<li><p><em>方法</em></p>\n<ul>\n<li>Prasse et al. (2022)：将 IC50 转化为相关性分数，设计可微排序损失函数。</li>\n<li>PPORank：利用强化学习动态优化排序，适应新增数据。</li>\n</ul>\n</li>\n<li><p><em>优势</em></p>\n<ul>\n<li>直接支持临床优先级排序，优于传统回归或分类。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"数据分析\"><a href=\"#数据分析\" class=\"headerlink\" title=\"数据分析\"></a>数据分析</h4><p>由于本人大概率会做个分类模型，所以会将主要分析的是<strong>分类表示</strong>的数据在<strong>图神经网络</strong>中比较重视的几个指标，这里分析 <em>CCLE</em> 和 <em>GDSC</em> 两个数据集在选用主流阈值选取方法之后的表示。</p>\n<p>直接先看结果捏（这里画了两个小图）</p>\n<ul>\n<li>CCLE</li>\n</ul>\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png\" alt=\"CCLE\" style=\"max-width: 100%; height: auto;\">\n\n<ul>\n<li>GDSC</li>\n</ul>\n<img src=\"/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png\" alt=\"GDSC\" style=\"max-width: 100%; height: auto;\">\n\n<p>\n  👉 <a href=\"/code/data_analysis/visualize_graph_analysis.py\" target=\"_blank\">查看用于生成上述图表的本地 Python 脚本：visualize_graph_analysis.py</a>\n</p>\n\n<h5 id=\"🔍-关键数据对比\"><a href=\"#🔍-关键数据对比\" class=\"headerlink\" title=\"🔍 关键数据对比\"></a>🔍 关键数据对比</h5><table>\n<thead>\n<tr>\n<th>特征</th>\n<th>CCLE</th>\n<th>GDSC</th>\n<th>倍数差异</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>数据规模</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>总节点数</td>\n<td>341</td>\n<td>783</td>\n<td>2.3×</td>\n</tr>\n<tr>\n<td>第一类节点</td>\n<td>317</td>\n<td>561</td>\n<td>1.8×</td>\n</tr>\n<tr>\n<td>第二类节点</td>\n<td>24</td>\n<td>222</td>\n<td>9.3×</td>\n</tr>\n<tr>\n<td>总边数</td>\n<td>7,307</td>\n<td>100,572</td>\n<td>13.8×</td>\n</tr>\n<tr>\n<td><strong>图结构</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>密度</td>\n<td>0.9604</td>\n<td>0.8075</td>\n<td>0.84×</td>\n</tr>\n<tr>\n<td>稀疏性</td>\n<td>0.0396</td>\n<td>0.1925</td>\n<td>4.9×</td>\n</tr>\n<tr>\n<td>平均度</td>\n<td>42.86</td>\n<td>256.89</td>\n<td>6.0×</td>\n</tr>\n<tr>\n<td>图直径</td>\n<td>3</td>\n<td>4</td>\n<td>1.3×</td>\n</tr>\n<tr>\n<td><strong>边分布</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>正边数量</td>\n<td>1,375</td>\n<td>11,591</td>\n<td>8.4×</td>\n</tr>\n<tr>\n<td>负边数量</td>\n<td>5,932</td>\n<td>88,981</td>\n<td>15.0×</td>\n</tr>\n<tr>\n<td>正边比例</td>\n<td>18.8%</td>\n<td>11.5%</td>\n<td>0.61×</td>\n</tr>\n<tr>\n<td>正负边比例</td>\n<td>1:4.3</td>\n<td>1:7.7</td>\n<td>1.8× 不平衡</td>\n</tr>\n</tbody></table>\n<h5 id=\"📊-GNN-训练挑战分析\"><a href=\"#📊-GNN-训练挑战分析\" class=\"headerlink\" title=\"📊 GNN 训练挑战分析\"></a>📊 GNN 训练挑战分析</h5><h6 id=\"过平滑风险评估\"><a href=\"#过平滑风险评估\" class=\"headerlink\" title=\"过平滑风险评估\"></a>过平滑风险评估</h6><ul>\n<li><strong>CCLE</strong>: ⚠️ 高风险 (平均度 42.86)</li>\n<li><strong>GDSC</strong>: 🚨 极高风险 (平均度 256.89)</li>\n</ul>\n<h6 id=\"样本不平衡程度\"><a href=\"#样本不平衡程度\" class=\"headerlink\" title=\"样本不平衡程度\"></a>样本不平衡程度</h6><ul>\n<li><strong>CCLE</strong>: 正负边比例 1:4.3 (中等不平衡)</li>\n<li><strong>GDSC</strong>: 正负边比例 1:7.7 (严重不平衡)</li>\n</ul>\n<h6 id=\"邻居相似度分析\"><a href=\"#邻居相似度分析\" class=\"headerlink\" title=\"邻居相似度分析\"></a>邻居相似度分析</h6><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 邻居重叠度对比</span></span><br><span class=\"line\">CCLE_similarity = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;第一类节点&quot;</span>: <span class=\"number\">0.9374</span>,  <span class=\"comment\"># 高度相似</span></span><br><span class=\"line\">    <span class=\"string\">&quot;第二类节点&quot;</span>: <span class=\"number\">0.9274</span>   <span class=\"comment\"># 高度相似</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">GDSC_similarity = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;第一类节点&quot;</span>: <span class=\"number\">0.7659</span>,  <span class=\"comment\"># 中等相似</span></span><br><span class=\"line\">    <span class=\"string\">&quot;第二类节点&quot;</span>: <span class=\"number\">0.7143</span>   <span class=\"comment\"># 中等相似</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>结论</strong>: CCLE 结构更均匀但多样性不足，GDSC 结构更复杂但多样性更好</p>\n<h5 id=\"🎯-GNN-架构建议对比\"><a href=\"#🎯-GNN-架构建议对比\" class=\"headerlink\" title=\"🎯 GNN 架构建议对比\"></a>🎯 GNN 架构建议对比</h5><h6 id=\"推荐架构优先级\"><a href=\"#推荐架构优先级\" class=\"headerlink\" title=\"推荐架构优先级\"></a>推荐架构优先级</h6><ul>\n<li><p>CCLE 推荐架构</p>\n<ol>\n<li><strong>Bipartite GNN</strong> + Signed GCN</li>\n<li><strong>简单异构图 GNN</strong> (HetGNN)</li>\n<li><strong>标准 GCN</strong> + 强正则化</li>\n</ol>\n</li>\n<li><p>GDSC 推荐架构</p>\n<ol>\n<li><strong>采样型 GNN</strong> (GraphSAINT, FastGCN) + SGCN</li>\n<li><strong>大规模异构图 GNN</strong> (HGT, RGCN)</li>\n<li><strong>图 Transformer</strong> (处理复杂结构)</li>\n</ol>\n</li>\n</ul>\n<h6 id=\"具体参数建议\"><a href=\"#具体参数建议\" class=\"headerlink\" title=\"具体参数建议\"></a>具体参数建议</h6><table>\n<thead>\n<tr>\n<th>参数</th>\n<th>CCLE</th>\n<th>GDSC</th>\n<th>原因</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>网络深度</strong></td>\n<td>2-3 层</td>\n<td>严格 2 层</td>\n<td>GDSC 过平滑风险更高</td>\n</tr>\n<tr>\n<td><strong>隐藏维度</strong></td>\n<td>64-128</td>\n<td>128-256</td>\n<td>GDSC 需要更大容量</td>\n</tr>\n<tr>\n<td><strong>Dropout 率</strong></td>\n<td>0.3-0.5</td>\n<td>0.5-0.7</td>\n<td>GDSC 需要更强正则化</td>\n</tr>\n<tr>\n<td><strong>学习率</strong></td>\n<td>0.001-0.01</td>\n<td>0.0001-0.001</td>\n<td>GDSC 需要更保守训练</td>\n</tr>\n<tr>\n<td><strong>批次大小</strong></td>\n<td>32-64 个子图</td>\n<td>16-32 个子图</td>\n<td>GDSC 内存限制</td>\n</tr>\n<tr>\n<td><strong>采样策略</strong></td>\n<td>可选</td>\n<td>必须</td>\n<td>GDSC 无法全图训练</td>\n</tr>\n</tbody></table>\n<h1 id=\"📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"><a href=\"#📚-𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\" class=\"headerlink\" title=\"📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒\"></a>📚 𝒥𝑒𝒻𝑒𝓇𝑒𝓃𝒸𝑒</h1><p><a href=\"/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf\" target=\"_blank\">📄 Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cmd4rbxvm0003k84157b5gpja","category_id":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxvu000tk841cllr1858"},{"post_id":"cmd4rbxvm0003k84157b5gpja","category_id":"cmd4rbxvr000bk841ea5c4at0","_id":"cmd4rbxvu000vk841dro587hq"},{"post_id":"cmd4rbxvm0003k84157b5gpja","category_id":"cmd4rbxvt000mk841h6ko6e9n","_id":"cmd4rbxvu000wk84177as0x5k"},{"post_id":"cmd4rbxvp0006k841g5i01rie","category_id":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxvv000xk8411v5lhkyl"},{"post_id":"cmd4rbxvp0006k841g5i01rie","category_id":"cmd4rbxvr000bk841ea5c4at0","_id":"cmd4rbxvv000zk841hg934fa3"},{"post_id":"cmd4rbxvp0006k841g5i01rie","category_id":"cmd4rbxvt000ik841glsz2ph2","_id":"cmd4rbxvv0010k84143zw6l0k"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","category_id":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxvv0013k841c1da0own"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","category_id":"cmd4rbxvr000bk841ea5c4at0","_id":"cmd4rbxvv0015k841c9ypfx8c"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","category_id":"cmd4rbxvt000ik841glsz2ph2","_id":"cmd4rbxvv0018k8411wk0cdx8"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","category_id":"cmd4rbxvu000sk841fpgc720o","_id":"cmd4rbxvv001ak8415yrqh48x"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","category_id":"cmd4rbxvy001qk841f99m205s","_id":"cmd4rbxw0001wk841bdlheos9"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","category_id":"cmd4rbxvo0004k841gmbb2odl","_id":"cmd4rbxw0001zk8413vpnfhtg"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","category_id":"cmd4rbxw0001vk841cykw32ba","_id":"cmd4rbxw00020k8415i4x7kxn"}],"PostTag":[{"post_id":"cmd4rbxvk0001k8419og6gjhk","tag_id":"cmd4rbxvp0005k841h8q15pl5","_id":"cmd4rbxvt000hk841fx3j6gl8"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","tag_id":"cmd4rbxvq0008k841a18beydb","_id":"cmd4rbxvt000jk8417rro439e"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","tag_id":"cmd4rbxvr000ak841h7txgp0d","_id":"cmd4rbxvt000lk841edn893oq"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","tag_id":"cmd4rbxvs000ck841e7b589m7","_id":"cmd4rbxvt000nk841hgifefae"},{"post_id":"cmd4rbxvk0001k8419og6gjhk","tag_id":"cmd4rbxvs000ek841a265g2kz","_id":"cmd4rbxvu000pk841bpysh5z4"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvp0005k841h8q15pl5","_id":"cmd4rbxvv0012k841adzt141i"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvq0008k841a18beydb","_id":"cmd4rbxvv0014k8413rw0eyd5"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvt000ok8415ecgc0o8","_id":"cmd4rbxvv0017k841dps33vn2"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvu000rk8419r3ofg4j","_id":"cmd4rbxvv0019k841fqigcnlh"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvu000uk841e2cxguxx","_id":"cmd4rbxvv001ck841bl06gd9z"},{"post_id":"cmd4rbxvm0003k84157b5gpja","tag_id":"cmd4rbxvr000ak841h7txgp0d","_id":"cmd4rbxvv001dk841ftmm86oa"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvp0005k841h8q15pl5","_id":"cmd4rbxvw001hk8416xaw1ron"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvq0008k841a18beydb","_id":"cmd4rbxvw001ik841evet6juc"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvr000ak841h7txgp0d","_id":"cmd4rbxvw001jk8411pppb6ce"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvs000ek841a265g2kz","_id":"cmd4rbxvw001kk841el2ibpmr"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvs000ck841e7b589m7","_id":"cmd4rbxvw001lk841ge3c6vbr"},{"post_id":"cmd4rbxvp0006k841g5i01rie","tag_id":"cmd4rbxvu000rk8419r3ofg4j","_id":"cmd4rbxvw001mk84179500her"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","tag_id":"cmd4rbxvp0005k841h8q15pl5","_id":"cmd4rbxw10022k841048maycw"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","tag_id":"cmd4rbxvz001rk8416fgq01au","_id":"cmd4rbxw10023k841al2ocsdz"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","tag_id":"cmd4rbxw0001uk841czyoemn9","_id":"cmd4rbxw10025k841c95eb5pd"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","tag_id":"cmd4rbxw0001xk8417hj0a8wl","_id":"cmd4rbxw10026k841ebfu590y"},{"post_id":"cmd4rbxvx001nk8415kwo9s83","tag_id":"cmd4rbxw0001yk841hqei2shd","_id":"cmd4rbxw10027k841a74a946s"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","tag_id":"cmd4rbxvp0005k841h8q15pl5","_id":"cmd4rbxw10028k841f0qefnjb"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","tag_id":"cmd4rbxw10021k8416tztgz4i","_id":"cmd4rbxw10029k841fso95620"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","tag_id":"cmd4rbxw10024k8410pku9zme","_id":"cmd4rbxw1002ak8411m3x2bi1"},{"post_id":"cmd4rbxvz001tk8417bw4fd17","tag_id":"cmd4rbxvu000uk841e2cxguxx","_id":"cmd4rbxw1002bk841fne7hun8"}],"Tag":[{"name":"CDR","_id":"cmd4rbxvp0005k841h8q15pl5"},{"name":"model","_id":"cmd4rbxvq0008k841a18beydb"},{"name":"Basic","_id":"cmd4rbxvr000ak841h7txgp0d"},{"name":"deep learning","_id":"cmd4rbxvs000ck841e7b589m7"},{"name":"还没写完捏","_id":"cmd4rbxvs000ek841a265g2kz"},{"name":"embedding","_id":"cmd4rbxvt000ok8415ecgc0o8"},{"name":"PyTorch","_id":"cmd4rbxvu000rk8419r3ofg4j"},{"name":"graph theory","_id":"cmd4rbxvu000uk841e2cxguxx"},{"name":"Python","_id":"cmd4rbxvz001rk8416fgq01au"},{"name":"PEP","_id":"cmd4rbxw0001uk841czyoemn9"},{"name":"闲🉐无聊","_id":"cmd4rbxw0001xk8417hj0a8wl"},{"name":"大概率没用","_id":"cmd4rbxw0001yk841hqei2shd"},{"name":"Data Analysis","_id":"cmd4rbxw10021k8416tztgz4i"},{"name":"可能有点用","_id":"cmd4rbxw10024k8410pku9zme"}]}}