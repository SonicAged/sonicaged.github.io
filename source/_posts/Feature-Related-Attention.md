---
title: Feature-Related Attention
date: 2025-07-14 22:30:57
categories:
  - CDR
  - model
  - attention
  - feature related
tags:
  - CDR
  - model
  - Basic
  - deep learning
  - è¿˜æ²¡å†™å®Œæ
---

# åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention

æœ¬æ–‡å°†æ¥ç€è¯¦ç»†è¯´æ˜ä¸€ç§åŸºäºè¾“å…¥ç‰¹å¾åˆ†ç±» Attention çš„æ–¹å¼ï¼Œå¹¶ä»‹ç»åœ¨è¿™ç§åˆ†ç±»æ–¹å¼ä¸‹å…³æ³¨åˆ°çš„ä¸åŒçš„ Attention çš„æ¶æ„ã€‚

å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä¸»è¦æ¢è®¨äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚æœ¬èŠ‚æ ¹æ®è¾“å…¥ç‰¹å¾çš„ä¸åŒç‰¹æ€§ï¼Œå°†ç‰¹å¾ç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)ã€ç‰¹å¾å±‚çº§(Levels of Features)å’Œç‰¹å¾è¡¨ç¤º(Feature Representations)ã€‚

åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» {% post_link Attention %}

<!-- more -->

## ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)

è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å¤šä¸ªè¾“å…¥æºçš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€ç‰¹å¾æ³¨æ„åŠ›å’Œå¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚

### å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)

å¤§å¤šæ•°ä»»åŠ¡æ¨¡å‹åªå¤„ç†å•ä¸€è¾“å…¥(å¦‚å›¾åƒã€å¥å­æˆ–å£°éŸ³åºåˆ—)ï¼Œä½¿ç”¨å•ä¸€ç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ç›´æ¥å¯¹å•ä¸ªè¾“å…¥çš„ç‰¹å¾å‘é‡è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚

### å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶

å½“æ¨¡å‹éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æºæ—¶ï¼Œéœ€è¦ç‰¹æ®Šçš„å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ï¼š

**ååŒæ³¨æ„åŠ›(Co-attention)**

- åˆ†ä¸º **ç²—ç§‘ç²’åº¦(Coarse-grained)** å’Œ **ç»†é¢—ç²’åº¦(Fine-grained)** ä¸¤ç§
- **ç²—é¢—ç²’åº¦ååŒ**æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„*ç´§å‡‘è¡¨ç¤º*ä½œä¸ºæŸ¥è¯¢æ¥å…³æ³¨å¦ä¸€ä¸ªè¾“å…¥
- **ç»†é¢—ç²’åº¦ååŒ**æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„æ‰€æœ‰ç‰¹å¾å‘é‡ä½œä¸ºæŸ¥è¯¢

#### ç²—é¢—ç²’åº¦ååŒ

è®ºæ–‡ç»™å‡ºçš„ç²—é¢—ç²’åº¦ååŒçš„å®ä¾‹æ˜¯**alternating co-attention**

##### alternating co-attention

<img src="/img/Attention/AlternatingCo-Attention.png" alt="alternating co-attention" width="60%" height="auto">

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™æ˜¯ alternating co-attention çš„æ¶æ„å›¾ï¼Œè¯¥æœºåˆ¶äº¤æ›¿ä½¿ç”¨ä¸¤ä¸ªè¾“å…¥çš„ç‰¹å¾çŸ©é˜µï¼Œå…ˆè®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œå°†å…¶ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºæŸ¥è¯¢è®¡ç®—ç¬¬äºŒä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œç„¶åå†ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„ä¸Šä¸‹æ–‡å‘é‡é‡æ–°è®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ã€‚

è¿™é‡Œç°ç»™å‡ºä»–çš„ score å‡½æ•°

å¯¹äºæœ‰åºåˆ—è¾“å…¥çš„ Attentionï¼š

$$
\mathrm{score}(\underset{d\_{q}\times1}{\boldsymbol{q}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{l}})=\underset{1\times d\_{w}}{\boldsymbol{w}^{T}}\times\mathrm{act}(\underset{d\_{w}\times d\_{q}}{\boldsymbol{W}\_{1}}\times\underset{d\_{q}\times1}{\boldsymbol{q}}+\underset{d\_{w}\times d\_{k}}{\boldsymbol{W}\_{2}}\times\underset{d\_{k}\times1}{\boldsymbol{k}\_{l}}+\underset{d\_{w}\times1}{\boldsymbol{b}})
$$

å¯¹äºæ— åºåˆ—è¾“å…¥çš„ Attention ~~ï¼ˆè¿™æ˜¯ä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œåé¢ä¼šæåˆ°ï¼‰~~ ï¼š

$$
\underset{1\times1}{e\_{l}^{(0)}}=\underset{1\times d\_{w}}{\boldsymbol{w}^{(1)T}}\times\operatorname{act}(\underset{d\_{w}\times d\_{k}^{(1)}}{\boldsymbol{W}^{(1)}}\times\underset{d\_{k}^{(1)}\times1}{\boldsymbol{k}\_{l}^{(1)}}+\underset{d\_{w}\times1}{\boldsymbol{b}^{(1)}})
$$

å¯¹äºç¬¬äºŒå±‚ Attentionï¼š

$$
\underset{1\times1}{e\_{l}^{(2)}}=\mathrm{score}(\underset{d\_{v}^{(1)}\times 1}{\boldsymbol{c}^{(0)}},\underset{d\_{k}^{(2)}\times1}{\boldsymbol{k}\_{l}^{(2)}})
$$

å¯¹äºç¬¬ä¸‰å±‚ Attentionï¼š

$$
\underset{1\times1}{e\_{l}^{(1)}}=\mathrm{score}(\underset{d\_{v}^{(2)}\times 1}{\boldsymbol{c}^{(2)}},\underset{d\_{k}^{(1)}\times1}{\boldsymbol{k}\_{l}^{(1)}})
$$

ç”Ÿæˆçš„ä¸Šä¸‹æ–‡å‘é‡$\boldsymbol{c}^{(1)}$å’Œ$\boldsymbol{c}^{(2)}$è¢«è¿æ¥èµ·æ¥ï¼Œå¹¶åœ¨è¾“å‡ºæ¨¡å‹ä¸­ç”¨äºé¢„æµ‹ã€‚äº¤æ›¿ååŒæ³¨æ„åŠ›ç”±äºéœ€è¦ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è®¡ç®—ä¸Šä¸‹æ–‡å‘é‡ï¼Œå› æ­¤æœ¬è´¨ä¸ŠåŒ…å«äº†*ä¸€ç§é¡ºåºæ€§*ã€‚è¿™å¯èƒ½ä¼šå¸¦æ¥è®¡ç®—ä¸Šçš„åŠ£åŠ¿ï¼Œå› ä¸º*æ— æ³•å¹¶è¡Œ*åŒ–ã€‚

##### interactive co-attention

<img src="/img/Attention/InteractiveCo-Attention.png" alt="interactive co-attention" width="60%" height="auto">

- å¹¶è¡Œè®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›
- ä½¿ç”¨æœªåŠ æƒå¹³å‡çš„å…³é”®å‘é‡ä½œä¸ºæŸ¥è¯¢
- è®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†

$$
\underset{d\_k^{(i)}\times1}{\bar{\boldsymbol{k}}^{(i)}}=\frac{1}{n\_f^{(i)}}\sum\limits\_{l=1}^{n\_f^{(i)}}\underset{d\_k^{(i)}\times1}{\boldsymbol{k}\_l^{(i)}}, \quad \underset{1\times1}{e\_{l}^{(i)}}=\mathrm{score}(\underset{d\_{k}^{(3-i)}\times1}{\bar{\boldsymbol{k}}^{(3-i)}},\underset{d\_{k}^{(i)}\times1}{\boldsymbol{k}\_{l}^{(i)}}) , \qquad i=1,2
$$

#### ç»†é¢—ç²’åº¦ååŒ

è™½ç„¶ç²—ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„ç´§å‡‘è¡¨ç¤ºä½œä¸ºæŸ¥è¯¢ï¼Œä»¥è®¡ç®—å¦ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œä½†ç»†ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°æ—¶ä¼šå•ç‹¬è€ƒè™‘æ¯ä¸ªè¾“å…¥çš„æ¯ä¸ªå…ƒç´ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŸ¥è¯¢å˜æˆäº†ä¸€ä¸ªçŸ©é˜µã€‚

##### å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)

<img src="/img/Attention/ParallelCo-Attention.png" alt="parallel co-attention" width="60%" height="auto">

- åŒæ—¶è®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›
- ä½¿ç”¨äº²å’ŒçŸ©é˜µ(Affinity Matrix)è½¬æ¢å…³é”®å‘é‡ç©ºé—´
- é€šè¿‡èšåˆå½¢å¼è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°

æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼ç”ŸæˆçŸ©é˜µ $\mathbf{A}$

$$
\underset{n\_{f}^{(1)}\times n\_{f}^{(2)}}{\mathbf{A}}=\operatorname{act}(\underset{n\_{f}^{(1)}\times d\_{k}^{(1)}}{\begin{array}{c}K^{(1)^{T}}\end{array}}\times\underset{d\_{k}^{(1)}\times d\_{k}^{(2)}}{\begin{array}{c}W\_{A}\end{array}}\times\underset{d\_{k}^{(2)}\times n\_{f}^{(2)}}{\begin{array}{c}K^{(2)}\end{array}})
$$

$$
\underset{1\times1}{A\_{i,j}}=\underset{1\times3d\_{k}}{\boldsymbol{w}\_{A}^{T}}\times\mathrm{concat}(\underset{d\_{k}\times1}{\boldsymbol{k}\_{i}^{(1)}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{j}^{(2)}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{i}^{(1)}}\circ\underset{d\_{k}\times1}{\boldsymbol{k}\_{j}^{(2)}})
$$

å…¶ä¸­ï¼Œ$\circ$è¡¨ç¤ºå“ˆå¾·æ›¼ç§¯

Affinity Matrix å¯ä»¥è§£é‡Šä¸ºä¸¤ä¸ªé”®çŸ©é˜µåˆ—çš„ç›¸ä¼¼æ€§çŸ©é˜µï¼Œå¹¶æœ‰åŠ©äºå°†å›¾åƒé”®è½¬æ¢åˆ°ä¸å¥å­ä¸­å•è¯çš„é”®ç›¸åŒçš„ç©ºé—´ï¼Œåä¹‹äº¦ç„¶ã€‚

ç”±äºç°åœ¨æŸ¥è¯¢ç”±å‘é‡å˜æˆäº†çŸ©é˜µï¼Œå› æ­¤ score å‡½æ•°ä¹Ÿå‘ç”Ÿäº†å˜åŒ–

$$
e^{(1)} =\boldsymbol{w}\_{1}\times\mathrm{act}(\boldsymbol{W}\_{2}\times\boldsymbol{K}^{(2)}\times\boldsymbol{A}^{T}+\boldsymbol{W}\_{1}\times\boldsymbol{K}^{(1)})
$$

$$
e^{(2)} =\boldsymbol{w}\_{2}\times\mathrm{act}(\boldsymbol{W}\_{1}\times\boldsymbol{K}^{(1)}\times\boldsymbol{A}^{\:\:}+\boldsymbol{W}\_{2}\times\boldsymbol{K}^{(2)})
$$

å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä¹‹å‰çš„ score å‡½æ•°å®é™…æ˜¯ç°åœ¨è¿™ä¸€å½¢å¼çš„ç‰¹æ®Šè¡¨è¾¾ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªè¡¨è¾¾æ›´å…·ä¸€èˆ¬æ€§

å¦‚å‰æ‰€è¿°ï¼Œäº²å’ŒçŸ©é˜µæœ¬è´¨ä¸Šæ˜¯ä¸¤ä¸ªæ³¨æ„åŠ›æ¨¡å— 1 å’Œ 2 çš„å…³é”®å‘é‡çš„ç›¸ä¼¼æ€§çŸ©é˜µã€‚è¿™ä¸ªæ„å‘³ç€ä¸€ç§ä¸åŒçš„ç¡®å®šæ³¨æ„åŠ›åˆ†æ•°çš„æ–¹æ³•ã€‚å³ï¼Œå¯ä»¥å°†ä¸€è¡Œæˆ–ä¸€åˆ—ä¸­çš„æœ€å¤§ç›¸ä¼¼åº¦å€¼ä½œä¸ºæ³¨æ„åŠ›åˆ†æ•°ã€‚

$$
e\_{i}^{(1)}=\max\_{j=1,\ldots,n\_{f}^{(2)}}A\_{i,j},\quad e\_{j}^{(2)}=\max\_{i=1,\ldots,n\_{f}^{(1)}}A\_{i,j}.
$$

##### æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)

Rotatory Attention æ˜¯ä¸€ç§ç”¨äºå¤„ç†å¤šè¾“å…¥æ•°æ®çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹åˆ«é€‚ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­åŒæ—¶è€ƒè™‘ç›®æ ‡çŸ­è¯­ã€å·¦ä¸Šä¸‹æ–‡å’Œå³ä¸Šä¸‹æ–‡çš„åœºæ™¯ã€‚è¯¥æœºåˆ¶é€šè¿‡äº¤æ›¿å…³æ³¨ä¸åŒè¾“å…¥æ¥æ„å»ºæ›´ä¸°å¯Œçš„è¡¨ç¤ºã€‚

- ä¸»è¦ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡
- å¤„ç†ä¸‰ä¸ªè¾“å…¥ï¼šç›®æ ‡çŸ­è¯­ $\boldsymbol{F}^{t} = [ \boldsymbol{f}\_{1}^{t}, \ldots , \boldsymbol{f}\_{n\_{f}^{t}}^{t}] \in \mathbb{R} ^{d\_{f}^{t}\times n\_{f}^{t}}$ ã€å·¦ä¸Šä¸‹æ–‡ $F^{l} = [ f\_{1}^{l}, \ldots , f\_{n\_{f}^{l}}^{l}]\in\mathbb{R} ^{d\_{f}^{l}\times n\_{f}^{l}}$ å’Œå³ä¸Šä¸‹æ–‡ $F^{r} = [ f\_{1}^{r}, \ldots , f\_{n\_{f}^{r}}^{r}]\in\mathbb{R}^{d\_f^r\times n\_f^r}$
- é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿­ä»£æ”¹è¿›è¡¨ç¤º

å…¶å¤§è‡´çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. **åˆå§‹ç‰¹å¾æå–**

   é¦–å…ˆï¼Œæ¨¡å‹ä»ä¸‰ä¸ªè¾“å…¥ä¸­æå–ç‰¹å¾å‘é‡ï¼š

   - ç›®æ ‡çŸ­è¯­ç‰¹å¾çŸ©é˜µï¼š$F^{t}=[f\_{1}^{t},\ldots,f\_{n\_{f}^{t}}^{t}]\in R^{d\_{f}^{t}\times n\_{f}^{t}}$
   - å·¦ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µï¼š$F^{l}=[f\_{1}^{l},\ldots,f\_{n\_{f}^{l}}^{l}]\in R^{d\_{f}^{l}\times n\_{f}^{l}}$
   - å³ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µï¼š$F^{r}=[f\_{1}^{r},\ldots,f\_{n\_{f}^{r}}^{r}]\in R^{d\_{f}^{r}\times n\_{f}^{r}}$

2. **ç›®æ ‡çŸ­è¯­åˆå§‹è¡¨ç¤º**

   è®¡ç®—ç›®æ ‡çŸ­è¯­çš„åˆå§‹è¡¨ç¤ºå‘é‡$r^{t}$ï¼Œé€šè¿‡å¯¹ç‰¹å¾å‘é‡å–å¹³å‡ï¼š

   $$
   r^{t}=\frac{1}{n\_{f}^{t}}\sum\_{i=1}^{n\_{f}^{t}} f\_{i}^{t}
   $$

3. **å·¦ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—**

   ä½¿ç”¨$r^{t}$ä½œä¸ºæŸ¥è¯¢ï¼Œè®¡ç®—å·¦ä¸Šä¸‹æ–‡çš„æ³¨æ„åŠ›ï¼š

   1. æå–é”®å‘é‡ $k\_{1}^{l},\ldots,k\_{n\_{f}^{l}}^{l}\in R^{d\_{k}^{l}}$ å’Œå€¼å‘é‡ $v\_{1}^{l},\ldots,v\_{n\_{f}^{l}}^{l}\in R^{d\_{v}^{l}}$

   2. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e\_{i}^{l}=\operatorname{score}\left(r^{t}, k\_{i}^{l}\right)$

   3. ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{l}$

   4. è®¡ç®—å·¦ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{l}=\sum\_{i=1}^{n\_{f}^{l}} a\_{i}^{l}v\_{i}^{l}$

4. **å³ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—**

   ç±»ä¼¼åœ°ï¼Œè®¡ç®—å³ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºå‘é‡$r^{r}$ï¼š

   1. æå–é”®å‘é‡ $k\_{1}^{r},\ldots,k\_{n\_{f}^{r}}^{r}\in R^{d\_{k}^{r}}$ å’Œå€¼å‘é‡ $v\_{1}^{r},\ldots,v\_{n\_{f}^{r}}^{r}\in R^{d\_{v}^{r}}$

   2. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e\_{i}^{r}=\operatorname{score}\left(r^{t}, k\_{i}^{r}\right)$

   3. ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{r}$

   4. è®¡ç®—å³ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{r}=\sum\_{i=1}^{n\_{f}^{r}} a\_{i}^{r}v\_{i}^{r}$

5. **ç›®æ ‡çŸ­è¯­æ›´æ–°è¡¨ç¤º**

   ä½¿ç”¨å·¦ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{l}$å’Œå³ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{r}$æ¥æ›´æ–°ç›®æ ‡çŸ­è¯­çš„è¡¨ç¤ºï¼š

   1. æå–ç›®æ ‡çŸ­è¯­çš„é”®å‘é‡ $k\_{1}^{t},\ldots,k\_{n\_{f}^{t}}^{t}\in R^{d\_{k}^{t}}$ å’Œå€¼å‘é‡ $v\_{1}^{t},\ldots,v\_{n\_{f}^{t}}^{t}\in R^{d\_{v}^{t}}$

   2. è®¡ç®—å·¦æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º$r^{l\_{t}}$ï¼š

      - æ³¨æ„åŠ›åˆ†æ•°ï¼š$e\_{i}^{l\_{t}}=\operatorname{score}\left(r^{l}, k\_{i}^{t}\right)$
      - ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{l\_{t}}$
      - è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{l\_{t}}=\sum\_{i=1}^{n\_{f}^{t}} a\_{i}^{l\_{t}}v\_{i}^{t}$

   3. è®¡ç®—å³æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º$r^{r\_{t}}$ï¼š

      - æ³¨æ„åŠ›åˆ†æ•°ï¼š$e\_{i}^{r\_{t}}=\operatorname{score}\left(r^{r}, k\_{i}^{t}\right)$
      - ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{r\_{t}}$
      - è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{r\_{t}}=\sum\_{i=1}^{n\_{f}^{t}} a\_{i}^{r\_{t}}v\_{i}^{t}$

6. æœ€ç»ˆè¡¨ç¤ºä¸º $r=\operatorname{concat}\left(r^{l},r^{r},r^{l\_{t}},r^{r\_{t}}\right)$

Rotatory Attention å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1. **åŒå‘ä¿¡æ¯æµåŠ¨**ï¼šé€šè¿‡ä»ç›®æ ‡çŸ­è¯­åˆ°ä¸Šä¸‹æ–‡ï¼Œå†ä»ä¸Šä¸‹æ–‡å›åˆ°ç›®æ ‡çŸ­è¯­çš„ä¿¡æ¯æµåŠ¨ï¼Œå®ç°äº†åŒå‘çš„ä¿¡æ¯äº¤äº’ã€‚

2. **å±‚æ¬¡åŒ–è¡¨ç¤º**ï¼šæ„å»ºäº†å¤šå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»åŸå§‹ç‰¹å¾åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾ã€‚

3. **ç‰¹å®šä»»åŠ¡ä¼˜åŒ–**ï¼šç‰¹åˆ«é€‚åˆæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œèƒ½å¤Ÿæ•æ‰ç›®æ ‡çŸ­è¯­ä¸ä¸Šä¸‹æ–‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚

Rotatory Attention é€šè¿‡è¿™ç§äº¤æ›¿å…³æ³¨çš„æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç›®æ ‡çŸ­è¯­åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼Œä»è€Œæé«˜äº†æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

## ç‰¹å¾å±‚çº§(Levels of Features)

è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å…·æœ‰å±‚çº§ç»“æ„çš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•å±‚çº§æ³¨æ„åŠ›å’Œå¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶ã€‚

### å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)

ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶é€šå¸¸åœ¨å•ä¸€å±‚çº§ä¸Šå¤„ç†ç‰¹å¾ï¼Œå¦‚åªå…³æ³¨å•è¯çº§åˆ«æˆ–å¥å­çº§åˆ«ã€‚

### å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶

1. **æ³¨æ„åŠ›å åŠ (Attention-via-Attention)**

<img src="img/Attention/AttentionViaAttention.png" alt="attention-via-attention" width="60%" height="auto">

- åŒæ—¶å¤„ç†å­—ç¬¦çº§å’Œè¯çº§ç‰¹å¾
- å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”¨å…¶ä¸Šä¸‹æ–‡å‘é‡è¾…åŠ©è®¡ç®—å­—ç¬¦çº§æ³¨æ„åŠ›
- æœ€ç»ˆæ‹¼æ¥ä¸¤ä¸ªå±‚çº§çš„ä¸Šä¸‹æ–‡å‘é‡

2. **å±‚çº§æ³¨æ„åŠ›(Hierarchical Attention)**

<img src="img/Attention/HierarchicalAttention.png" alt="hierarchical attention" width="60%" height="auto">

- ä»æœ€ä½å±‚çº§å¼€å§‹ï¼Œé€æ­¥æ„å»ºé«˜å±‚çº§è¡¨ç¤º
- å¸¸ç”¨äºæ–‡æ¡£åˆ†ç±»ï¼šè¯ â†’ å¥ â†’ æ–‡æ¡£
- æ¯ä¸ªå±‚çº§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç”Ÿæˆæ‘˜è¦è¡¨ç¤º

## ç‰¹å¾è¡¨ç¤º(Feature Representations)

è¿™éƒ¨åˆ†è®¨è®ºäº†ç‰¹å¾è¡¨ç¤ºæ–¹å¼çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›å’Œå¤šè¡¨ç¤ºæ³¨æ„åŠ›ã€‚

### å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)

ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨å•ä¸€åµŒå…¥æˆ–è¡¨ç¤ºæ¨¡å‹ç”Ÿæˆç‰¹å¾è¡¨ç¤ºã€‚

### å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)

1. **å…ƒåµŒå…¥(Meta-embeddings)**

   - æ•´åˆå¤šä¸ªåµŒå…¥è¡¨ç¤º
   - é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ æƒå¹³å‡ä¸åŒè¡¨ç¤º
   - ç”Ÿæˆæ›´é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤º

2. **è‡ªæ³¨æ„åŠ›æœºåˆ¶**
   - å­¦ä¹ ç‰¹å¾å‘é‡ä¹‹é—´çš„å…³ç³»
   - é€šè¿‡æ³¨æ„åŠ›æ”¹è¿›ç‰¹å¾è¡¨ç¤º
   - å¸¸ç”¨äº Transformer æ¶æ„ä¸­

## åº”ç”¨é¢†åŸŸ

3.1 èŠ‚è®¨è®ºçš„ç‰¹å¾ç›¸å…³æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ï¼š

- åŒ»å­¦æ•°æ®åˆ†æ(å¤šç‰¹å¾ååŒæ³¨æ„åŠ›)
- æ¨èç³»ç»Ÿ(å¤šå±‚çº§æ³¨æ„åŠ›)
- æƒ…æ„Ÿåˆ†æ(æ—‹è½¬æ³¨æ„åŠ›)
- æ–‡æ¡£åˆ†ç±»(å±‚çº§æ³¨æ„åŠ›)
- å¤šè¯­è¨€å¤„ç†(å¤šè¡¨ç¤ºæ³¨æ„åŠ›)

## æ€»ç»“

3.1 èŠ‚ç³»ç»Ÿæ€§åœ°åˆ†ç±»äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ï¼Œä¸ºç ”ç©¶è€…æä¾›äº†æ¸…æ™°çš„æ¡†æ¶æ¥é€‰æ‹©é€‚åˆç‰¹å®šä»»åŠ¡å’Œæ•°æ®ç±»å‹çš„æœ€ä½³æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™äº›æœºåˆ¶é€šè¿‡å……åˆ†åˆ©ç”¨è¾“å…¥ç‰¹å¾çš„å¤šé‡æ€§ã€å±‚çº§ç»“æ„å’Œè¡¨ç¤ºå¤šæ ·æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

å›¾ 3 å±•ç¤ºäº†å®Œæ•´çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ç±»ä½“ç³»ï¼Œå…¶ä¸­ 3.1 èŠ‚è®¨è®ºçš„ç‰¹å¾ç›¸å…³æ³¨æ„åŠ›æœºåˆ¶æ˜¯è¯¥ä½“ç³»çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

# ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’

<a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>

{% post_link Attention %}
