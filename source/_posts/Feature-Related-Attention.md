---
title: Fufufu Relashinala
date: 2025-07-14 22:30:57
categories:
  - model
  - attention
  - category
tags:
  - CDR
  - model
  - Basic
  - deep learning
---

# åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention

æœ¬æ–‡å°†æ¥ç€è¯¦ç»†è¯´æ˜ä¸€ç§åŸºäºè¾“å…¥ç‰¹å¾åˆ†ç±» Attention çš„æ–¹å¼ï¼Œå¹¶ä»‹ç»åœ¨è¿™ç§åˆ†ç±»æ–¹å¼ä¸‹å…³æ³¨åˆ°çš„ä¸åŒçš„ Attention çš„æ¶æ„ã€‚

<div style="display: flex; align-items: center;">
  <img src="\img\Attention\Fufufu Relashinala.png" style="width: 200px; margin-right: 20px;">
  <p>
  å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä¸»è¦æ¢è®¨äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚æœ¬èŠ‚æ ¹æ®è¾“å…¥ç‰¹å¾çš„ä¸åŒç‰¹æ€§ï¼Œå°†ç‰¹å¾ç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)ã€ç‰¹å¾å±‚çº§(Levels of Features)å’Œç‰¹å¾è¡¨ç¤º(Feature Representations)ã€‚
  </p>
</div>



åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» {% post_link Attention %}

<!-- more -->

## ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)

è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å¤šä¸ªè¾“å…¥æºçš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€ç‰¹å¾æ³¨æ„åŠ›å’Œå¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚

### å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)

å¤§å¤šæ•°ä»»åŠ¡æ¨¡å‹åªå¤„ç†å•ä¸€è¾“å…¥(å¦‚å›¾åƒã€å¥å­æˆ–å£°éŸ³åºåˆ—)ï¼Œä½¿ç”¨å•ä¸€ç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ç›´æ¥å¯¹å•ä¸ªè¾“å…¥çš„ç‰¹å¾å‘é‡è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚

### å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶

å½“æ¨¡å‹éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æºæ—¶ï¼Œéœ€è¦ç‰¹æ®Šçš„å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ï¼š

**ååŒæ³¨æ„åŠ›(Co-attention)**

- åˆ†ä¸º **ç²—ç§‘ç²’åº¦(Coarse-grained)** å’Œ **ç»†é¢—ç²’åº¦(Fine-grained)** ä¸¤ç§
- **ç²—é¢—ç²’åº¦ååŒ**æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„*ç´§å‡‘è¡¨ç¤º*ä½œä¸ºæŸ¥è¯¢æ¥å…³æ³¨å¦ä¸€ä¸ªè¾“å…¥
- **ç»†é¢—ç²’åº¦ååŒ**æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„æ‰€æœ‰ç‰¹å¾å‘é‡ä½œä¸ºæŸ¥è¯¢

#### ç²—é¢—ç²’åº¦ååŒ

è®ºæ–‡ç»™å‡ºçš„ç²—é¢—ç²’åº¦ååŒçš„å®ä¾‹æ˜¯**alternating co-attention**

##### alternating co-attention

<img src="/img/Attention/AlternatingCo-Attention.png" alt="alternating co-attention" width="60%" height="auto">

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™æ˜¯ alternating co-attention çš„æ¶æ„å›¾ï¼Œè¯¥æœºåˆ¶äº¤æ›¿ä½¿ç”¨ä¸¤ä¸ªè¾“å…¥çš„ç‰¹å¾çŸ©é˜µï¼Œå…ˆè®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œå°†å…¶ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºæŸ¥è¯¢è®¡ç®—ç¬¬äºŒä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œç„¶åå†ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„ä¸Šä¸‹æ–‡å‘é‡é‡æ–°è®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ã€‚

è¿™é‡Œç°ç»™å‡ºä»–çš„ score å‡½æ•°

å¯¹äºæœ‰åºåˆ—è¾“å…¥çš„ Attentionï¼š

$$
\mathrm{score}(\underset{d\_{q}\times1}{\boldsymbol{q}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{l}})=\underset{1\times d\_{w}}{\boldsymbol{w}^{T}}\times\mathrm{act}(\underset{d\_{w}\times d\_{q}}{\boldsymbol{W}\_{1}}\times\underset{d\_{q}\times1}{\boldsymbol{q}}+\underset{d\_{w}\times d\_{k}}{\boldsymbol{W}\_{2}}\times\underset{d\_{k}\times1}{\boldsymbol{k}\_{l}}+\underset{d\_{w}\times1}{\boldsymbol{b}})
$$

å¯¹äºæ— åºåˆ—è¾“å…¥çš„ Attention ~~ï¼ˆè¿™æ˜¯ä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œåé¢ä¼šæåˆ°ï¼‰~~ ï¼š

$$
\underset{1\times1}{e\_{l}^{(0)}}=\underset{1\times d\_{w}}{\boldsymbol{w}^{(1)T}}\times\operatorname{act}(\underset{d\_{w}\times d\_{k}^{(1)}}{\boldsymbol{W}^{(1)}}\times\underset{d\_{k}^{(1)}\times1}{\boldsymbol{k}\_{l}^{(1)}}+\underset{d\_{w}\times1}{\boldsymbol{b}^{(1)}})
$$

å¯¹äºç¬¬äºŒå±‚ Attentionï¼š

$$
\underset{1\times1}{e\_{l}^{(2)}}=\mathrm{score}(\underset{d\_{v}^{(1)}\times 1}{\boldsymbol{c}^{(0)}},\underset{d\_{k}^{(2)}\times1}{\boldsymbol{k}\_{l}^{(2)}})
$$

å¯¹äºç¬¬ä¸‰å±‚ Attentionï¼š

$$
\underset{1\times1}{e\_{l}^{(1)}}=\mathrm{score}(\underset{d\_{v}^{(2)}\times 1}{\boldsymbol{c}^{(2)}},\underset{d\_{k}^{(1)}\times1}{\boldsymbol{k}\_{l}^{(1)}})
$$

ç”Ÿæˆçš„ä¸Šä¸‹æ–‡å‘é‡$\boldsymbol{c}^{(1)}$å’Œ$\boldsymbol{c}^{(2)}$è¢«è¿æ¥èµ·æ¥ï¼Œå¹¶åœ¨è¾“å‡ºæ¨¡å‹ä¸­ç”¨äºé¢„æµ‹ã€‚äº¤æ›¿ååŒæ³¨æ„åŠ›ç”±äºéœ€è¦ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è®¡ç®—ä¸Šä¸‹æ–‡å‘é‡ï¼Œå› æ­¤æœ¬è´¨ä¸ŠåŒ…å«äº†*ä¸€ç§é¡ºåºæ€§*ã€‚è¿™å¯èƒ½ä¼šå¸¦æ¥è®¡ç®—ä¸Šçš„åŠ£åŠ¿ï¼Œå› ä¸º*æ— æ³•å¹¶è¡Œ*åŒ–ã€‚

##### interactive co-attention

<img src="/img/Attention/InteractiveCo-Attention.png" alt="interactive co-attention" width="60%" height="auto">

- å¹¶è¡Œè®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›
- ä½¿ç”¨æœªåŠ æƒå¹³å‡çš„å…³é”®å‘é‡ä½œä¸ºæŸ¥è¯¢
- è®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†

$$
\underset{d\_k^{(i)}\times1}{\bar{\boldsymbol{k}}^{(i)}}=\frac{1}{n\_f^{(i)}}\sum\limits\_{l=1}^{n\_f^{(i)}}\underset{d\_k^{(i)}\times1}{\boldsymbol{k}\_l^{(i)}}, \quad \underset{1\times1}{e\_{l}^{(i)}}=\mathrm{score}(\underset{d\_{k}^{(3-i)}\times1}{\bar{\boldsymbol{k}}^{(3-i)}},\underset{d\_{k}^{(i)}\times1}{\boldsymbol{k}\_{l}^{(i)}}) , \qquad i=1,2
$$

#### ç»†é¢—ç²’åº¦ååŒ

è™½ç„¶ç²—ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„ç´§å‡‘è¡¨ç¤ºä½œä¸ºæŸ¥è¯¢ï¼Œä»¥è®¡ç®—å¦ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œä½†ç»†ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°æ—¶ä¼šå•ç‹¬è€ƒè™‘æ¯ä¸ªè¾“å…¥çš„æ¯ä¸ªå…ƒç´ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŸ¥è¯¢å˜æˆäº†ä¸€ä¸ªçŸ©é˜µã€‚

##### å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)

<img src="/img/Attention/ParallelCo-Attention.png" alt="parallel co-attention" width="60%" height="auto">

- åŒæ—¶è®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›
- ä½¿ç”¨äº²å’ŒçŸ©é˜µ(Affinity Matrix)è½¬æ¢å…³é”®å‘é‡ç©ºé—´
- é€šè¿‡èšåˆå½¢å¼è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°

æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼ç”ŸæˆçŸ©é˜µ $\mathbf{A}$

$$
\underset{n\_{f}^{(1)}\times n\_{f}^{(2)}}{\mathbf{A}}=\operatorname{act}(\underset{n\_{f}^{(1)}\times d\_{k}^{(1)}}{\begin{array}{c}K^{(1)^{T}}\end{array}}\times\underset{d\_{k}^{(1)}\times d\_{k}^{(2)}}{\begin{array}{c}W\_{A}\end{array}}\times\underset{d\_{k}^{(2)}\times n\_{f}^{(2)}}{\begin{array}{c}K^{(2)}\end{array}})
$$

$$
\underset{1\times1}{A\_{i,j}}=\underset{1\times3d\_{k}}{\boldsymbol{w}\_{A}^{T}}\times\mathrm{concat}(\underset{d\_{k}\times1}{\boldsymbol{k}\_{i}^{(1)}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{j}^{(2)}},\underset{d\_{k}\times1}{\boldsymbol{k}\_{i}^{(1)}}\circ\underset{d\_{k}\times1}{\boldsymbol{k}\_{j}^{(2)}})
$$

å…¶ä¸­ï¼Œ$\circ$è¡¨ç¤ºå“ˆå¾·æ›¼ç§¯

Affinity Matrix å¯ä»¥è§£é‡Šä¸ºä¸¤ä¸ªé”®çŸ©é˜µåˆ—çš„ç›¸ä¼¼æ€§çŸ©é˜µï¼Œå¹¶æœ‰åŠ©äºå°†å›¾åƒé”®è½¬æ¢åˆ°ä¸å¥å­ä¸­å•è¯çš„é”®ç›¸åŒçš„ç©ºé—´ï¼Œåä¹‹äº¦ç„¶ã€‚

ç”±äºç°åœ¨æŸ¥è¯¢ç”±å‘é‡å˜æˆäº†çŸ©é˜µï¼Œå› æ­¤ score å‡½æ•°ä¹Ÿå‘ç”Ÿäº†å˜åŒ–

$$
e^{(1)} =\boldsymbol{w}\_{1}\times\mathrm{act}(\boldsymbol{W}\_{2}\times\boldsymbol{K}^{(2)}\times\boldsymbol{A}^{T}+\boldsymbol{W}\_{1}\times\boldsymbol{K}^{(1)})
$$

$$
e^{(2)} =\boldsymbol{w}\_{2}\times\mathrm{act}(\boldsymbol{W}\_{1}\times\boldsymbol{K}^{(1)}\times\boldsymbol{A}^{\:\:}+\boldsymbol{W}\_{2}\times\boldsymbol{K}^{(2)})
$$

å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä¹‹å‰çš„ score å‡½æ•°å®é™…æ˜¯ç°åœ¨è¿™ä¸€å½¢å¼çš„ç‰¹æ®Šè¡¨è¾¾ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªè¡¨è¾¾æ›´å…·ä¸€èˆ¬æ€§

å¦‚å‰æ‰€è¿°ï¼Œäº²å’ŒçŸ©é˜µæœ¬è´¨ä¸Šæ˜¯ä¸¤ä¸ªæ³¨æ„åŠ›æ¨¡å— 1 å’Œ 2 çš„å…³é”®å‘é‡çš„ç›¸ä¼¼æ€§çŸ©é˜µã€‚è¿™ä¸ªæ„å‘³ç€ä¸€ç§ä¸åŒçš„ç¡®å®šæ³¨æ„åŠ›åˆ†æ•°çš„æ–¹æ³•ã€‚å³ï¼Œå¯ä»¥å°†ä¸€è¡Œæˆ–ä¸€åˆ—ä¸­çš„æœ€å¤§ç›¸ä¼¼åº¦å€¼ä½œä¸ºæ³¨æ„åŠ›åˆ†æ•°ã€‚

$$
e\_{i}^{(1)}=\max\_{j=1,\ldots,n\_{f}^{(2)}}A\_{i,j},\quad e\_{j}^{(2)}=\max\_{i=1,\ldots,n\_{f}^{(1)}}A\_{i,j}.
$$

##### æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)

Rotatory Attention æ˜¯ä¸€ç§ç”¨äºå¤„ç†å¤šè¾“å…¥æ•°æ®çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹åˆ«é€‚ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­åŒæ—¶è€ƒè™‘ç›®æ ‡çŸ­è¯­ã€å·¦ä¸Šä¸‹æ–‡å’Œå³ä¸Šä¸‹æ–‡çš„åœºæ™¯ã€‚è¯¥æœºåˆ¶é€šè¿‡äº¤æ›¿å…³æ³¨ä¸åŒè¾“å…¥æ¥æ„å»ºæ›´ä¸°å¯Œçš„è¡¨ç¤ºã€‚

- ä¸»è¦ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡
- å¤„ç†ä¸‰ä¸ªè¾“å…¥ï¼šç›®æ ‡çŸ­è¯­ $\boldsymbol{F}^{t} = [ \boldsymbol{f}\_{1}^{t}, \ldots , \boldsymbol{f}\_{n\_{f}^{t}}^{t}] \in \mathbb{R} ^{d\_{f}^{t}\times n\_{f}^{t}}$ ã€å·¦ä¸Šä¸‹æ–‡ $\boldsymbol{F^{l}} = [ \boldsymbol{f\_{1}^{l}}, \ldots , \boldsymbol{f\_{n\_{f}^{l}}^{l}}]\in\mathbb{R} ^{d\_{f}^{l}\times n\_{f}^{l}}$ å’Œå³ä¸Šä¸‹æ–‡ $\boldsymbol{F^{r}} = [ \boldsymbol{f\_{1}^{r}}, \ldots , \boldsymbol{f\_{n\_{f}^{r}}^{r}}]\in\mathbb{R}^{d\_f^r\times n\_f^r}$
- é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿­ä»£æ”¹è¿›è¡¨ç¤º

å…¶å¤§è‡´çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. **åˆå§‹ç‰¹å¾æå–**

   é¦–å…ˆï¼Œæ¨¡å‹ä»ä¸‰ä¸ªè¾“å…¥ä¸­æå–ç‰¹å¾å‘é‡ç›®æ ‡çŸ­è¯­ç‰¹å¾çŸ©é˜µ $\boldsymbol{F}^{t}$ å·¦ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µ $\boldsymbol{F^{l}}$ å³ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µ $\boldsymbol{F^{r}}$ 

2. **ç›®æ ‡çŸ­è¯­åˆå§‹è¡¨ç¤º**

   è®¡ç®—ç›®æ ‡çŸ­è¯­çš„åˆå§‹è¡¨ç¤ºå‘é‡$r^{t}$ï¼Œé€šè¿‡å¯¹ç‰¹å¾å‘é‡å–å¹³å‡ï¼š

   $$
   r^{t}=\frac{1}{n\_{f}^{t}}\sum\_{i=1}^{n\_{f}^{t}} f\_{i}^{t}
   $$

3. **å·¦ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—**

   ä½¿ç”¨$r^{t}$ä½œä¸ºæŸ¥è¯¢ï¼Œè®¡ç®—å·¦ä¸Šä¸‹æ–‡çš„æ³¨æ„åŠ›ï¼š

   1. æå–é”®å‘é‡ $k\_{1}^{l},\ldots,k\_{n\_{f}^{l}}^{l}\in \mathbb{R}^{d\_{k}^{l}}$ å’Œå€¼å‘é‡ $v\_{1}^{l},\ldots,v\_{n\_{f}^{l}}^{l}\in \mathbb{R}^{d\_{v}^{l}}$

   2. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e\_{i}^{l}=\operatorname{score}\left(r^{t}, k\_{i}^{l}\right)$

   3. ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{l}$

   4. è®¡ç®—å·¦ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{l}=\sum\_{i=1}^{n\_{f}^{l}} a\_{i}^{l}v\_{i}^{l}$

4. **å³ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—**

   ç±»ä¼¼åœ°ï¼Œè®¡ç®—å³ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºå‘é‡$r^{r}$ï¼š

   1. æå–é”®å‘é‡ $k\_{1}^{r},\ldots,k\_{n\_{f}^{r}}^{r}\in \mathbb{R}^{d\_{k}^{r}}$ å’Œå€¼å‘é‡ $v\_{1}^{r},\ldots,v\_{n\_{f}^{r}}^{r}\in \mathbb{R}^{d\_{v}^{r}}$

   2. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e\_{i}^{r}=\operatorname{score}\left(r^{t}, k\_{i}^{r}\right)$

   3. ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a\_{i}^{r}$

   4. è®¡ç®—å³ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{r}=\sum\_{i=1}^{n\_{f}^{r}} a\_{i}^{r}v\_{i}^{r}$

5. **ç›®æ ‡çŸ­è¯­æ›´æ–°è¡¨ç¤º**

   ä½¿ç”¨å·¦ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{l}$å’Œå³ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{r}$æ¥æ›´æ–°ç›®æ ‡çŸ­è¯­çš„è¡¨ç¤ºï¼š

   1. æå–ç›®æ ‡çŸ­è¯­çš„é”®å‘é‡ $k\_{1}^{t},\ldots,k\_{n\_{f}^{t}}^{t}\in \mathbb{R}^{d\_{k}^{t}}$ å’Œå€¼å‘é‡ $v\_{1}^{t},\ldots,v\_{n\_{f}^{t}}^{t}\in \mathbb{R}^{d\_{v}^{t}}$

   2. è®¡ç®—å·¦æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º $r^{l\_{t}}$ï¼š

      - æ³¨æ„åŠ›åˆ†æ•°ï¼š$e\_{i}^{l\_{t}}=\operatorname{score}\left(r^{l}, k\_{i}^{t}\right)$
      - ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡ $a\_{i}^{l\_{t}}$
      - è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{l\_{t}}=\sum\_{i=1}^{n\_{f}^{t}} a\_{i}^{l\_{t}}v\_{i}^{t}$

   3. è®¡ç®—å³æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º $r^{r\_{t}}$ï¼š

      - æ³¨æ„åŠ›åˆ†æ•°ï¼š$e\_{i}^{r\_{t}}=\operatorname{score}\left(r^{r}, k\_{i}^{t}\right)$
      - ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡ $a\_{i}^{r\_{t}}$
      - è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{r\_{t}}=\sum\_{i=1}^{n\_{f}^{t}} a\_{i}^{r\_{t}}v\_{i}^{t}$

6. æœ€ç»ˆè¡¨ç¤ºä¸º $r=\operatorname{concat}\left(r^{l},r^{r},r^{l\_{t}},r^{r\_{t}}\right)$

Rotatory Attention å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1. **åŒå‘ä¿¡æ¯æµåŠ¨**ï¼šé€šè¿‡ä»ç›®æ ‡çŸ­è¯­åˆ°ä¸Šä¸‹æ–‡ï¼Œå†ä»ä¸Šä¸‹æ–‡å›åˆ°ç›®æ ‡çŸ­è¯­çš„ä¿¡æ¯æµåŠ¨ï¼Œå®ç°äº†åŒå‘çš„ä¿¡æ¯äº¤äº’ã€‚

2. **å±‚æ¬¡åŒ–è¡¨ç¤º**ï¼šæ„å»ºäº†å¤šå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»åŸå§‹ç‰¹å¾åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾ã€‚

3. **ç‰¹å®šä»»åŠ¡ä¼˜åŒ–**ï¼šç‰¹åˆ«é€‚åˆæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œèƒ½å¤Ÿæ•æ‰ç›®æ ‡çŸ­è¯­ä¸ä¸Šä¸‹æ–‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚

Rotatory Attention é€šè¿‡è¿™ç§äº¤æ›¿å…³æ³¨çš„æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç›®æ ‡çŸ­è¯­åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼Œä»è€Œæé«˜äº†æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

## ç‰¹å¾å±‚çº§(Levels of Features)

è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å…·æœ‰å±‚çº§ç»“æ„çš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•å±‚çº§æ³¨æ„åŠ›å’Œå¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶ã€‚å¤šå±‚çº§æ³¨æ„åŠ›èƒ½å¤Ÿæ•æ‰**ä¸åŒç²’åº¦**ä¸Šçš„é‡è¦ä¿¡æ¯ã€‚

### å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)

ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶é€šå¸¸åœ¨å•ä¸€å±‚çº§ä¸Šå¤„ç†ç‰¹å¾ï¼Œå¦‚åªå…³æ³¨å•è¯çº§åˆ«æˆ–å¥å­çº§åˆ«ã€‚

### å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶

1. **æ³¨æ„åŠ›å åŠ (Attention-via-Attention)**

<img src="/img/Attention/AttentionViaAttention.png" alt="attention-via-attention" width="60%" height="auto">

- åŒæ—¶å¤„ç†å­—ç¬¦çº§å’Œè¯çº§ç‰¹å¾
- å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”¨å…¶ä¸Šä¸‹æ–‡å‘é‡è¾…åŠ©è®¡ç®—å­—ç¬¦çº§æ³¨æ„åŠ›
- æœ€ç»ˆæ‹¼æ¥ä¸¤ä¸ªå±‚çº§çš„ä¸Šä¸‹æ–‡å‘é‡



ç”¨äºæœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼ŒåŒæ—¶åˆ©ç”¨å­—ç¬¦çº§å’Œè¯çº§ä¿¡æ¯ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨é¢„æµ‹å­—ç¬¦æ—¶ï¼Œå…ˆé€šè¿‡è¯çº§æ³¨æ„åŠ›ç¡®å®šé‡è¦è¯è¯­ï¼Œå†åœ¨è¿™äº›è¯è¯­å¯¹åº”çš„å­—ç¬¦ä¸Šæ–½åŠ æ³¨æ„åŠ›ã€‚



å…¶å¤§è‡´è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. è¾“å…¥å¥å­è¢«ç¼–ç ä¸ºå­—ç¬¦çº§ç‰¹å¾çŸ©é˜µ $F^{(c)}\in \mathbb{R}^{d\_{f}^{(c)}\times n\_{f}^{(c)}}$ å’Œè¯çº§ç‰¹å¾çŸ©é˜µ $F^{(w)}\in \mathbb{R}^{d\_{f}^{(w)}\times n\_{f}^{(w)}}$

2. å­—ç¬¦çº§æŸ¥è¯¢ $q^{(c)}\in \mathbb{R}^{d\_{q}}$ é€šè¿‡æŸ¥è¯¢æ¨¡å‹ç”Ÿæˆ

3. å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”Ÿæˆè¯çº§ä¸Šä¸‹æ–‡å‘é‡ $c^{(w)}\in \mathbb{R}^{d\_{v}^{(w)}}$

4. å°† $q^{(c)}$ å’Œ $c^{(w)}$ æ‹¼æ¥ä½œä¸ºå­—ç¬¦çº§æ³¨æ„åŠ›çš„æŸ¥è¯¢

5. æœ€ç»ˆè¾“å‡ºæ˜¯å­—ç¬¦çº§å’Œè¯çº§ä¸Šä¸‹æ–‡å‘é‡çš„æ‹¼æ¥


1. **å±‚çº§æ³¨æ„åŠ›(Hierarchical Attention)**

<img src="/img/Attention/HierarchicalAttention.png" alt="hierarchical attention" width="60%" height="auto">

- ä»æœ€ä½å±‚çº§å¼€å§‹ï¼Œé€æ­¥æ„å»ºé«˜å±‚çº§è¡¨ç¤º
- å¸¸ç”¨äºæ–‡æ¡£åˆ†ç±»ï¼šè¯ â†’ å¥ â†’ æ–‡æ¡£
- æ¯ä¸ªå±‚çº§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç”Ÿæˆæ‘˜è¦è¡¨ç¤º

ç”¨äºæ–‡æ¡£åˆ†ç±»ã€‚è¯¥æ–¹æ³•è‡ªåº•å‘ä¸Šæ„å»ºå±‚çº§è¡¨ç¤ºï¼šä»è¯çº§è¡¨ç¤ºæ„å»ºå¥çº§è¡¨ç¤ºï¼Œå†ä»å¥çº§è¡¨ç¤ºæ„å»ºæ–‡æ¡£çº§è¡¨ç¤ºã€‚



å…¶å¤§è‡´è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. æ–‡æ¡£åŒ…å« $n\_S$ ä¸ªå¥å­ï¼Œç¬¬ $s$ ä¸ªå¥å­åŒ…å« $n\_s$ ä¸ªè¯

2. å¯¹æ¯ä¸ªå¥å­è®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”Ÿæˆå¥è¡¨ç¤º $c^{(s)}\in \mathbb{R}^{d\_{v}^{(S)}}$

3. å°†æ‰€æœ‰å¥è¡¨ç¤º $C=[c^{(1)},\ldots,c^{(n\_{S})}]\in \mathbb{R}^{d\_{v}^{(S)} \times n\_{S}}$ ä½œä¸ºæ–‡æ¡£çº§æ³¨æ„åŠ›çš„è¾“å…¥

4. æ–‡æ¡£çº§æ³¨æ„åŠ›è¾“å‡º $c^{(D)}\in \mathbb{R}^{d\_{v}^{(D)}}$ ç”¨äºåˆ†ç±»

#### åº”ç”¨é¢†åŸŸ

å¤šå±‚çº§æ³¨æ„åŠ›å·²æˆåŠŸåº”ç”¨äº ~~æ‡’å¾—åšé“¾æ¥äº†æï¼Œå¯ä»¥å»åŸæ–‡æ‰¾æ~~ ï¼š
- æ¨èç³»ç»Ÿï¼šå»ºæ¨¡ç”¨æˆ·é•¿çŸ­æœŸåå¥½(Ying et al., 2018)
- è§†é¢‘åŠ¨ä½œè¯†åˆ«ï¼šæ•æ‰ä¸åŒæ—¶é—´å°ºåº¦çš„è¿åŠ¨ä¿¡æ¯(Wang et al., 2016)
- è·¨é¢†åŸŸæƒ…æ„Ÿåˆ†ç±»ï¼šå­¦ä¹ é¢†åŸŸå…±äº«å’Œç‰¹å®šç‰¹å¾(Li et al., 2018)
- èŠå¤©æœºå™¨äººï¼šç”Ÿæˆæ›´è¿è´¯çš„å“åº”(Xing et al., 2018)
- äººç¾¤è®¡æ•°ï¼šå¤„ç†ä¸åŒå°ºåº¦çš„äººç¾¤å¯†åº¦(Sindagi & Patel, 2019)

## ç‰¹å¾è¡¨ç¤º(Feature Representations)

è¿™éƒ¨åˆ†è®¨è®ºäº†ç‰¹å¾è¡¨ç¤ºç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆFeature Representationsï¼‰ï¼Œä¸»è¦å…³æ³¨å¦‚ä½•åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥å¤„ç†å’Œç»„åˆä¸åŒçš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™éƒ¨åˆ†å†…å®¹å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šå•è¡¨ç¤ºæ³¨æ„åŠ›ï¼ˆSingle-representational attentionï¼‰å’Œå¤šè¡¨ç¤ºæ³¨æ„åŠ›ï¼ˆMulti-representational attentionï¼‰ã€‚

### å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)

å•è¡¨ç¤ºæ³¨æ„åŠ›æ˜¯æœ€åŸºç¡€çš„æ³¨æ„åŠ›å½¢å¼ï¼Œå®ƒä½¿ç”¨å•ä¸€çš„ç‰¹å¾è¡¨ç¤ºæ¨¡å‹ï¼ˆå¦‚è¯åµŒå…¥ã€CNNç‰¹å¾æå–å™¨ç­‰ï¼‰æ¥ç”Ÿæˆç‰¹å¾å‘é‡ã€‚è¿™äº›ç‰¹å¾å‘é‡éšåè¢«é€å…¥æ³¨æ„åŠ›æ¨¡å—è¿›è¡Œå¤„ç†ã€‚

### å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)

å¤šè¡¨ç¤ºæ³¨æ„åŠ›æ˜¯ä¸€ç§æ›´é«˜çº§çš„æŠ€æœ¯ï¼Œå®ƒå…è®¸æ¨¡å‹åŒæ—¶è€ƒè™‘å¤šç§ä¸åŒçš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æ¥å­¦ä¹ å¦‚ä½•æœ€ä¼˜åœ°ç»„åˆè¿™äº›è¡¨ç¤ºã€‚

#### å…ƒåµŒå…¥(Meta-embeddings)

è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºæ‰€è°“çš„"å…ƒåµŒå…¥"ï¼ˆmeta-embeddingsï¼‰ã€‚

   - æ•´åˆå¤šä¸ªåµŒå…¥è¡¨ç¤º
   - é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ æƒå¹³å‡ä¸åŒè¡¨ç¤º
   - ç”Ÿæˆæ›´é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤º


å…ƒåµŒå…¥çš„åˆ›å»ºè¿‡ç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

1. **è¾“å…¥è¡¨ç¤º**ï¼šå¯¹äºä¸€ä¸ªè¾“å…¥ $x$ ï¼ˆå¦‚ä¸€ä¸ªè¯ï¼‰ï¼Œæˆ‘ä»¬æœ‰ $E$ ç§ä¸åŒçš„åµŒå…¥è¡¨ç¤ºï¼š $x^{(e\_1)}, \ldots, x^{(e\_E)}$ , å…¶ä¸­æ¯ç§åµŒå…¥ $x^{(e\_i)}$ çš„ç»´åº¦ä¸º $d\_{e\_i}$ï¼ˆ$i=1,\ldots,E$ ï¼‰ã€‚

2. **ç»´åº¦æ ‡å‡†åŒ–**ï¼šç”±äºä¸åŒåµŒå…¥å¯èƒ½æœ‰ä¸åŒç»´åº¦ï¼Œé¦–å…ˆé€šè¿‡çº¿æ€§å˜æ¢å°†å®ƒä»¬æ˜ å°„åˆ°ç»Ÿä¸€ç»´åº¦ $d\_t$ ï¼š $x^{(t\_i)} = W\_{e\_i} \times x^{(e\_i)} + b\_{e\_i}$ ï¼Œ å…¶ä¸­ $W\_{e\_i} \in \mathbb{R}^{d\_t \times d\_{e\_i}}$ å’Œ $b\_{e\_i} \in \mathbb{R}^{d\_t}$ æ˜¯å¯è®­ç»ƒçš„å‚æ•°ã€‚

3. **æ³¨æ„åŠ›åŠ æƒç»„åˆ**ï¼šæœ€ç»ˆçš„å…ƒåµŒå…¥æ˜¯è¿™äº›æ ‡å‡†åŒ–è¡¨ç¤ºçš„åŠ æƒå’Œï¼š $x^{(e)} = \sum\_{i=1}^E a\_i \times x^{(t\_i)}$ å…¶ä¸­æƒé‡ $a\_i$ é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—å¾—åˆ°ã€‚

##### æ³¨æ„åŠ›è®¡ç®—

åœ¨å¤šè¡¨ç¤ºæ³¨æ„åŠ›ä¸­ï¼Œæ³¨æ„åŠ›æƒé‡çš„è®¡ç®—å¯ä»¥è§†ä¸ºä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶æŸ¥è¯¢å¯ä»¥ç†è§£ä¸º"å“ªäº›è¡¨ç¤ºå¯¹å½“å‰ä»»åŠ¡æœ€é‡è¦"ã€‚å…·ä½“è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š

1. å°†æ ‡å‡†åŒ–åçš„è¡¨ç¤º $x^{(t\_1)}, \ldots, x^{(t\_E)}$ ä½œä¸ºç‰¹å¾çŸ©é˜µFçš„åˆ—å‘é‡
2. ç”±äºæ²¡æœ‰æ˜¾å¼æŸ¥è¯¢ï¼Œè¿™ç›¸å½“äºè‡ªæ³¨æ„åŠ›æœºåˆ¶
3. ä½¿ç”¨é€‚å½“çš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°è®¡ç®—æƒé‡
4. é€šè¿‡å¯¹é½å‡½æ•°ï¼ˆå¦‚softmaxï¼‰å¾—åˆ°å½’ä¸€åŒ–çš„æ³¨æ„åŠ›æƒé‡

### æŠ€æœ¯ä¼˜åŠ¿

1. **çµæ´»æ€§**ï¼šå¯ä»¥æ•´åˆæ¥è‡ªä¸åŒæ¥æºæˆ–ä¸åŒç²’åº¦çš„ç‰¹å¾è¡¨ç¤º
2. **é€‚åº”æ€§**ï¼šé€šè¿‡æ³¨æ„åŠ›æƒé‡è‡ªåŠ¨å­¦ä¹ ä¸åŒè¡¨ç¤ºçš„é‡è¦æ€§
3. **å¯è§£é‡Šæ€§**ï¼šæ³¨æ„åŠ›æƒé‡å¯ä»¥æä¾›å…³äºå“ªäº›ç‰¹å¾è¡¨ç¤ºå¯¹ä»»åŠ¡æ›´é‡è¦çš„è§è§£


# ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’

<a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>

{% post_link Attention %}
