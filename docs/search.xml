<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Attention Overview</title>
    <url>/2025/07/10/Attention/</url>
    <content><![CDATA[<h1 id="Is-Attention-All-My-Need"><a href="#Is-Attention-All-My-Need" class="headerlink" title="Is Attention All My Need ?"></a>Is Attention All My Need ?</h1><blockquote>
<p>æ³¨æ„åŠ›æœºåˆ¶åœ¨å›¾ç¥ç»ç½‘ç»œä¸­æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ã€‚<del>ä½†é¼ é¼ ç°åœ¨è¿æ­£å¸¸çš„ Attention æœ‰å“ªäº›éƒ½ä¸æ¸…æ¥šæ</del>æœ¬æ–‡é¼ é¼ å°†ä»ä¸€èˆ¬çš„ Attention å‡ºå‘ï¼Œç»™å‡º Attention çš„æ€»ä½“ç»“æ„ï¼Œç„¶åæŒ‰åˆ†ç±»ä»‹ç»ç°æœ‰çš„ä¸»è¦çš„ Attention</p>
</blockquote>
<p>æœ¬æ–‡ä¸»è¦æ¥è‡ªäºä¸€ç¯‡è®ºæ–‡ï¼ŒåŸºæœ¬å¯ä»¥çœ‹ä½œ<a href="/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf">é‚£ç¯‡è®ºæ–‡</a>çš„é˜…è¯»ç¬”è®°</p>
<span id="more"></span>

<h2 id="ğŸ¯-å¼•è¨€"><a href="#ğŸ¯-å¼•è¨€" class="headerlink" title="ğŸ¯ å¼•è¨€"></a>ğŸ¯ å¼•è¨€</h2><p>åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œæ³¨æ„åŠ›æœºåˆ¶å·²ç»æˆä¸ºä¸€ä¸ªé©å‘½æ€§çš„åˆ›æ–°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†åºåˆ—æ•°æ®å’Œå›¾åƒæ•°æ®æ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚è€Œåœ¨å›¾ç¥ç»ç½‘ç»œä¸­ï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥ä¸ä»…æé«˜äº†æ¨¡å‹çš„è¡¨ç°åŠ›ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚</p>
<p>åœ¨å›¾ç»“æ„æ•°æ®ä¸­åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¸»è¦æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š</p>
<ol>
<li>è‡ªé€‚åº”æ€§ï¼šèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡åŠ¨æ€è°ƒæ•´ä¸åŒé‚»å±…èŠ‚ç‚¹çš„é‡è¦æ€§</li>
<li>å¯è§£é‡Šæ€§ï¼šé€šè¿‡æ³¨æ„åŠ›æƒé‡å¯ä»¥ç›´è§‚ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹</li>
<li>é•¿ç¨‹ä¾èµ–ï¼šæœ‰æ•ˆç¼“è§£äº†ä¼ ç»Ÿ GNN ä¸­çš„è¿‡å¹³æ»‘é—®é¢˜</li>
<li>å¼‚è´¨æ€§å¤„ç†ï¼šæ›´å¥½åœ°å¤„ç†å¼‚è´¨å›¾ä¸­çš„ä¸åŒç±»å‹èŠ‚ç‚¹å’Œè¾¹</li>
</ol>
<h2 id="ğŸ“š-æ€»è§ˆ-Attention"><a href="#ğŸ“š-æ€»è§ˆ-Attention" class="headerlink" title="ğŸ“š æ€»è§ˆ Attention"></a>ğŸ“š æ€»è§ˆ Attention</h2><p>æœ¬ç« èŠ‚ä¸»è¦å‚è€ƒäº†è®ºæ–‡<a href="/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>æœ‰å…´è¶£çš„è¯å¯ä»¥çœ‹çœ‹åŸæ–‡æ</p>
<embed src="/paper/Brauwerså’ŒFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf" width="45%" height="400" type="application/pdf">

<h3 id="Attention-çš„ä¸€èˆ¬ç»“æ„"><a href="#Attention-çš„ä¸€èˆ¬ç»“æ„" class="headerlink" title="Attention çš„ä¸€èˆ¬ç»“æ„"></a>Attention çš„ä¸€èˆ¬ç»“æ„</h3><img src="/img/Attention/TotalModel.png" alt="TotalModel" width="60%" height="auto">

<p>ä¸Šå›¾æ˜¯ä»æ€»ä½“ä¸Šçœ‹ Attention åœ¨æ•´ä¸ªä»»åŠ¡æ¨¡å‹æ¡†æ¶ä¸­çš„ä½ç½®</p>
<p>æ¡†æ¶åŒ…å«å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š</p>
<ol>
<li><strong>ç‰¹å¾æ¨¡å‹</strong>ï¼šè´Ÿè´£è¾“å…¥æ•°æ®çš„ç‰¹å¾æå–</li>
<li><strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼šç”Ÿæˆæ³¨æ„åŠ›æŸ¥è¯¢å‘é‡</li>
<li><strong>æ³¨æ„åŠ›æ¨¡å‹</strong>ï¼šè®¡ç®—æ³¨æ„åŠ›æƒé‡</li>
<li><strong>è¾“å‡ºæ¨¡å‹</strong>ï¼šç”Ÿæˆæœ€ç»ˆé¢„æµ‹ç»“æœ</li>
</ol>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¼šä» <em>è¾“å…¥</em> çš„è§’åº¦æ¥çœ‹<strong>ç‰¹å¾æ¨¡å‹</strong>å’Œ<strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼Œä» <em>è¾“å‡º</em> çš„è§’åº¦æ¥çœ‹<strong>æ³¨æ„åŠ›æ¨¡å‹</strong>å’Œ<strong>è¾“å‡ºæ¨¡å‹</strong></p>
<h4 id="è¾“å…¥å¤„ç†æœºåˆ¶"><a href="#è¾“å…¥å¤„ç†æœºåˆ¶" class="headerlink" title="è¾“å…¥å¤„ç†æœºåˆ¶"></a>è¾“å…¥å¤„ç†æœºåˆ¶</h4><ol>
<li><p><strong>ç‰¹å¾æ¨¡å‹</strong>ï¼Œå³å°†ä»»åŠ¡çš„è¾“å…¥è¿›è¡Œ embedding</p>
<p>å¯¹äºè¾“å…¥çŸ©é˜µ $ X \in \mathbb{R}^{d_x \times n_x} $ ï¼Œç‰¹å¾æ¨¡å‹æå–ç‰¹å¾å‘é‡ï¼š $\boldsymbol{F} &#x3D; [f_1, \ldots, f_{n_f}] \in \mathbb{R}^{d_f \times n_f}$</p>
</li>
<li><p><strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼ŒæŸ¥è¯¢æ¨¡å‹äº§ç”ŸæŸ¥è¯¢å‘é‡$ \boldsymbol{q} \in \mathbb{R}^{d_q} $ï¼Œç”¨ä»¥å‘Šè¯‰æ³¨æ„åŠ›æ¨¡å‹å“ªä¸€ä¸ªç‰¹å¾æ˜¯é‡è¦çš„</p>
</li>
</ol>
<p>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹å¯ä»¥ç”¨ CNN æˆ– RNN</p>
<h4 id="è¾“å‡ºè®¡ç®—æœºåˆ¶"><a href="#è¾“å‡ºè®¡ç®—æœºåˆ¶" class="headerlink" title="è¾“å‡ºè®¡ç®—æœºåˆ¶"></a>è¾“å‡ºè®¡ç®—æœºåˆ¶</h4><img src="/img/Attention/GeneralAttentionModule.png" alt="GeneralAttentionModule" width="50%" height="auto">

<p>ä¸Šå›¾æ˜¯ Attention æ¨¡å‹æ€»ä½“ç»“æ„çš„è¯´æ˜ï¼Œä¸‹é¢å¯¹è¿™å¼ å›¾è¿›è¡Œè¯¦ç»†çš„è¯´æ˜</p>
<ol>
<li>ç‰¹å¾çŸ©é˜µ$\boldsymbol{F} &#x3D; [\boldsymbol{f}_1, \ldots, \boldsymbol{f}_{n_f}] \in \mathbb{R}^{d_f \times n_f}$ï¼Œé€šè¿‡<em>æŸäº›æ–¹æ³•</em>å°†å…¶åˆ†ä¸º Keys çŸ©é˜µ$\boldsymbol{K} &#x3D; [\boldsymbol{k}_1, \ldots, \boldsymbol{k}_{n_f}] \in \mathbb{R}^{d_k \times n_f}$å’Œ Values çŸ©é˜µ$\boldsymbol{V} &#x3D; [\boldsymbol{v}_1, \ldots, \boldsymbol{v}_{n_f}] \in \mathbb{R}^{d_v \times n_f}$ï¼Œè¿™é‡Œçš„<em>æŸäº›æ–¹æ³•</em>ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒæŒ‰ä»¥ä¸‹çš„æ–¹å¼é€šè¿‡<strong>çº¿æ€§å˜æ¢</strong>å¾—åˆ°ï¼š</li>
</ol>
<p>$$<br>\underset{d_{k} \times n_{f}}{\boldsymbol{K}}&#x3D;\underset{d_{k} \times d_{f}}{\boldsymbol{W}_{K}} \times \underset{d_{f} \times n_{f}}{\boldsymbol{F}}, \quad \underset{d_{v} \times n_{f}}{\boldsymbol{V}}&#x3D;\underset{d_{v} \times d_{f}}{\boldsymbol{W}_{V}} \times \underset{d_{f} \times n_{f}}{\boldsymbol{F}} .<br>$$</p>
<ol start="2">
<li><p><code>Attention Scores</code>æ¨¡å—æ ¹æ® $\boldsymbol{q}$ è®¡ç®—æ¯ä¸€ä¸ª key å‘é‡å¯¹åº”çš„åˆ†æ•°$\boldsymbol{e} &#x3D; [e_1, \ldots, e_{n_f}] \in \mathbb{R}^{n_f}$ï¼š</p>
<p>$$<br>\underset{1\times 1}{e_l} &#x3D; \text{score}(\underset{d_q \times 1}{\boldsymbol{q}}, \underset{d_k \times 1}{\boldsymbol{k}_l})<br>$$</p>
<p>å¦‚å‰æ‰€è¿°ï¼ŒæŸ¥è¯¢è±¡å¾ç€å¯¹ä¿¡æ¯çš„è¯·æ±‚ã€‚æ³¨æ„åŠ›åˆ†æ•°$e_l$è¡¨ç¤ºæ ¹æ®æŸ¥è¯¢ï¼Œå…³é”®å‘é‡$\boldsymbol{k}_l$ä¸­åŒ…å«çš„ä¿¡æ¯çš„é‡è¦æ€§ã€‚å¦‚æœæŸ¥è¯¢å’Œå…³é”®å‘é‡çš„ç»´åº¦ç›¸åŒï¼Œåˆ™å¾—åˆ†å‡½æ•°çš„ä¸€ä¸ªä¾‹å­æ˜¯å–å‘é‡çš„ç‚¹ç§¯ã€‚</p>
</li>
<li><p>ç”±äºç»è¿‡è¿™ä¹ˆä¸€å †æ“ä½œä¹‹åï¼Œåˆ†æ•°æœ‰å¾ˆå¤§çš„å¯èƒ½å·²ç»é£èµ·æ¥äº†æï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦<code>Attention Alignment</code>æ¨¡å—å¯¹å…¶è¿›è¡Œ<strong>å½’ä¸€åŒ–</strong>ä¹‹ç±»çš„æ“ä½œäº†æ</p>
<p>$$<br>\underset{1\times 1}{a_l} &#x3D; \text{align}(\underset{d_q \times 1}{\boldsymbol{e_l}}, \underset{n_f \times 1}{\boldsymbol{e}})<br>$$</p>
</li>
</ol>
<p>æ³¨æ„åŠ›æƒé‡$\boldsymbol{a} &#x3D; [a_1, \ldots, a_{n_f}] \in \mathbb{R}^{n_f}$ä¸ºæ³¨æ„åŠ›æ¨¡å—æä¾›äº†ä¸€ä¸ªç›¸å½“ç›´è§‚çš„è§£é‡Šã€‚æ¯ä¸ªæƒé‡ç›´æ¥è¡¨æ˜äº†æ¯ä¸ªç‰¹å¾å‘é‡ç›¸å¯¹äºå…¶ä»–ç‰¹å¾å‘é‡å¯¹äºè¿™ä¸ªé—®é¢˜çš„é‡è¦æ€§ã€‚</p>
<ol start="4">
<li><p>åœ¨<code>Weight Average</code>æ¨¡å—å®Œæˆ<strong>ä¸Šä¸‹æ–‡ç”Ÿæˆ</strong>ï¼š</p>
<p>$$<br>\underset{d_v \times 1}{\boldsymbol{c}} &#x3D; \sum_{l &#x3D; 1}^{n_f} \underset{1 \times 1}{a_l}\times \underset{d_v \times 1}{\boldsymbol{v}_l}<br>$$</p>
</li>
<li><p>è¾“å‡ºå¤„ç†å°±æƒ³æ€ä¹ˆæå°±æ€ä¹ˆæäº†æï¼Œä¾‹å¦‚ ç”¨äºåˆ†ç±»</p>
<p>$$<br>\underset{d_y \times 1}{\hat{\boldsymbol{y}}} &#x3D; \text{softmax}( \underset{d_y \times d_v}{\boldsymbol{W}_c}\times \underset{d_v \times 1}{\boldsymbol{c}} + \underset{d_y \times 1}{\boldsymbol{b}_c})<br>$$</p>
</li>
</ol>
<h3 id="Attention-åˆ†ç±»"><a href="#Attention-åˆ†ç±»" class="headerlink" title="Attention åˆ†ç±»"></a>Attention åˆ†ç±»</h3><img src="/img/Attention/Taxonomy.png" style="max-width: 100%; height: auto;">

<p>è®ºæ–‡æŒ‰ç…§ä¸Šå›¾çš„æ–¹å¼ç»™ Attention è¿›è¡Œäº†åˆ†ç±»</p>
<p>ç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¿™é‡Œå†³å®šé‡å¼€å‡ ä¸ªåšæ–‡æ¥åˆ†åˆ«ä»‹ç»è¿™äº› Attentionï¼Œé“¾æ¥å¦‚ä¸‹ï¼š</p>
<a href="/2025/07/14/Feature-Related-Attention/" title="Fufufu Relashinala">Fufufu Relashinala</a>
<br/>
<a href="/2025/07/16/General-Attention/" title="Gugugu Neralashun">Gugugu Neralashun</a>
<br/>
<a href="/2025/07/17/Query-Related-Attention/" title="Quaqua Rishinala">Quaqua Rishinala</a>

<h3 id="æ€æ ·è¯„ä»·-Attention"><a href="#æ€æ ·è¯„ä»·-Attention" class="headerlink" title="æ€æ ·è¯„ä»· Attention"></a>æ€æ ·è¯„ä»· Attention</h3><h4 id="å¤–åœ¨æ€§èƒ½è¯„ä¼°"><a href="#å¤–åœ¨æ€§èƒ½è¯„ä¼°" class="headerlink" title="å¤–åœ¨æ€§èƒ½è¯„ä¼°"></a>å¤–åœ¨æ€§èƒ½è¯„ä¼°</h4><ol>
<li><strong>é¢†åŸŸç‰¹å®šçš„è¯„ä¼°æŒ‡æ ‡</strong></li>
</ol>
<p>ä¸åŒé¢†åŸŸç”¨äºè¯„ä¼°æ³¨æ„åŠ›æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ï¼š</p>
<table>
<thead>
<tr>
<th>é¢†åŸŸ</th>
<th>å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡</th>
<th>å…¸å‹åº”ç”¨</th>
</tr>
</thead>
<tbody><tr>
<td>è‡ªç„¶è¯­è¨€å¤„ç†</td>
<td>BLEU, METEOR, Perplexity</td>
<td>æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆ</td>
</tr>
<tr>
<td>è¯­éŸ³å¤„ç†</td>
<td>è¯é”™è¯¯ç‡(WER)ã€éŸ³ç´ é”™è¯¯ç‡(PER)</td>
<td>è¯­éŸ³è¯†åˆ«</td>
</tr>
<tr>
<td>è®¡ç®—æœºè§†è§‰</td>
<td>PSNR, SSIM, IoU</td>
<td>å›¾åƒç”Ÿæˆã€åˆ†å‰²</td>
</tr>
<tr>
<td>é€šç”¨åˆ†ç±»</td>
<td>å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1</td>
<td>æƒ…æ„Ÿåˆ†æã€æ–‡æ¡£åˆ†ç±»</td>
</tr>
</tbody></table>
<ol start="2">
<li><p><strong>æ¶ˆèç ”ç©¶</strong></p>
<p> è®ºæ–‡å¼ºè°ƒäº†æ¶ˆèç ”ç©¶(ablation study)åœ¨è¯„ä¼°æ³¨æ„åŠ›æœºåˆ¶é‡è¦æ€§æ–¹é¢çš„ä»·å€¼ã€‚å…¸å‹åšæ³•åŒ…æ‹¬ï¼š</p>
<ol>
<li>ç§»é™¤æˆ–æ›¿æ¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚ç”¨å¹³å‡æ± åŒ–ä»£æ›¿æ³¨æ„åŠ›æ± åŒ–ï¼‰</li>
<li>æ¯”è¾ƒæ¨¡å‹åœ¨æœ‰æ— æ³¨æ„åŠ›æœºåˆ¶æ—¶çš„æ€§èƒ½å·®å¼‚</li>
<li>åˆ†æä¸åŒæ³¨æ„åŠ›å˜ä½“å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“</li>
</ol>
<p> è¿™ç§è¯„ä¼°æ–¹æ³•å¯ä»¥æ˜ç¡®æ³¨æ„åŠ›æœºåˆ¶å¯¹æ¨¡å‹æ€§èƒ½çš„å®é™…è´¡çŒ®ï¼Œè€Œä¸ä»…ä»…æ˜¯å±•ç¤ºæœ€ç»ˆç»“æœã€‚</p>
</li>
</ol>
<h4 id="å†…åœ¨ç‰¹æ€§è¯„ä¼°"><a href="#å†…åœ¨ç‰¹æ€§è¯„ä¼°" class="headerlink" title="å†…åœ¨ç‰¹æ€§è¯„ä¼°"></a>å†…åœ¨ç‰¹æ€§è¯„ä¼°</h4><ol>
<li><p><strong>æ³¨æ„åŠ›æƒé‡åˆ†æ</strong></p>
<ol>
<li><strong>å¯¹é½é”™è¯¯ç‡(AER)</strong>ï¼šæ¯”è¾ƒæ¨¡å‹ç”Ÿæˆçš„æ³¨æ„åŠ›æƒé‡ä¸äººå·¥æ ‡æ³¨çš„â€é»„é‡‘â€æ³¨æ„åŠ›æƒé‡ä¹‹é—´çš„å·®å¼‚</li>
<li><strong>ç›‘ç£æ³¨æ„åŠ›è®­ç»ƒ</strong>ï¼šå°†äººå·¥æ ‡æ³¨çš„æ³¨æ„åŠ›æƒé‡ä½œä¸ºé¢å¤–ç›‘ç£ä¿¡å·ï¼Œä¸ä»»åŠ¡æŸå¤±è”åˆè®­ç»ƒ</li>
<li><strong>æ³¨æ„åŠ›å¯è§†åŒ–</strong>ï¼šé€šè¿‡çƒ­å›¾ç­‰æ–¹å¼ç›´è§‚å±•ç¤ºæ¨¡å‹å…³æ³¨åŒºåŸŸ</li>
</ol>
<p>è¿™äº›æ–¹æ³•å¯ä»¥è¯„ä¼°æ³¨æ„åŠ›æƒé‡æ˜¯å¦ç¬¦åˆäººç±»ç›´è§‰æˆ–é¢†åŸŸçŸ¥è¯†ã€‚</p>
</li>
<li><p><strong>åŸºäºäººç±»æ³¨æ„åŠ›çš„è¯„ä¼°</strong></p>
<p> è®ºæ–‡æå‡ºäº†â€æ³¨æ„åŠ›æ­£ç¡®æ€§â€(Attention Correctness)çš„æ¦‚å¿µï¼Œå°†æ¨¡å‹çš„æ³¨æ„åŠ›æ¨¡å¼ä¸çœŸå®äººç±»æ³¨æ„åŠ›è¡Œä¸ºè¿›è¡Œæ¯”è¾ƒï¼š</p>
<ol>
<li><strong>æ•°æ®æ”¶é›†</strong>ï¼šè®°å½•äººç±»åœ¨æ‰§è¡Œç›¸åŒä»»åŠ¡æ—¶çš„æ³¨æ„åŠ›æ¨¡å¼ï¼ˆå¦‚çœ¼åŠ¨è¿½è¸ªï¼‰</li>
<li><strong>åº¦é‡è®¡ç®—</strong>ï¼šå®šä¹‰æ¨¡å‹æ³¨æ„åŠ›ä¸äººç±»æ³¨æ„åŠ›çš„ç›¸ä¼¼åº¦æŒ‡æ ‡</li>
<li><strong>è”åˆè®­ç»ƒ</strong>ï¼šå°†äººç±»æ³¨æ„åŠ›æ•°æ®ä½œä¸ºç›‘ç£ä¿¡å·</li>
</ol>
<p> è¿™ç§è¯„ä¼°æ–¹æ³•åŸºäºè®¤çŸ¥ç§‘å­¦åŸç†ï¼Œè®¤ä¸ºå¥½çš„æ³¨æ„åŠ›æ¨¡å‹åº”è¯¥æ¨¡æ‹Ÿäººç±»çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
</li>
</ol>
<h4 id="æ³¨æ„åŠ›è§£é‡Šæ€§è¯„ä¼°ã€"><a href="#æ³¨æ„åŠ›è§£é‡Šæ€§è¯„ä¼°ã€" class="headerlink" title="æ³¨æ„åŠ›è§£é‡Šæ€§è¯„ä¼°ã€"></a>æ³¨æ„åŠ›è§£é‡Šæ€§è¯„ä¼°ã€</h4><p>è®ºæ–‡è®¨è®ºäº†å­¦æœ¯ç•Œå…³äºâ€æ³¨æ„åŠ›æ˜¯å¦æä¾›è§£é‡Šâ€çš„äº‰è®ºï¼š</p>
<ol>
<li><p><strong>â€œAttention is not Explanationâ€è§‚ç‚¹</strong></p>
<ul>
<li>æ³¨æ„åŠ›æƒé‡ä¸æ¨¡å‹å†³ç­–ä¹‹é—´ç¼ºä¹ç¨³å®šå…³è”</li>
<li>å¯ä»¥æ„é€ å¯¹æŠ—æ€§æ³¨æ„åŠ›åˆ†å¸ƒè€Œä¸æ”¹å˜æ¨¡å‹è¾“å‡º</li>
<li>æ³¨æ„åŠ›æƒé‡å¯èƒ½åæ˜ ç›¸å…³æ€§è€Œéå› æœæ€§</li>
</ul>
</li>
<li><p><strong>â€œAttention is not not Explanationâ€åé©³</strong></p>
<ul>
<li>å¯¹æŠ—æ€§æ³¨æ„åŠ›åˆ†å¸ƒé€šå¸¸æ€§èƒ½æ›´å·®</li>
<li>æ³¨æ„åŠ›æƒé‡ç¡®å®åæ˜ äº†è¾“å…¥çš„ç›¸å¯¹é‡è¦æ€§</li>
<li>åœ¨ç‰¹å®šæ¶æ„ä¸‹æ³¨æ„åŠ›å¯ä»¥æä¾›æœ‰æ„ä¹‰çš„è§£é‡Š</li>
</ul>
</li>
</ol>
<p><del>è¿™æ®µæ¯”è¾ƒéš¾ç»·ï¼Œå› æ­¤æŠŠ</del>åŸæ–‡è´´åœ¨ä¸‹é¢äº†æ</p>
<blockquote>
<p>However, rather than checking if the model focuses on the most important parts of the data, some use the attention weights to determine which parts of the data are most important. This would imply that attention models provide a type of explanation, which is a subject of contention among researchers. Particularly, in [120], extensive experiments are conducted for various natural language processing tasks to investigate the relation between attention weights and important information to determine whether attention can actually provide meaningful explanations. In this paper titled â€œAttention is not Explanationâ€, it is found that attention weights do not tend to correlate with important features. Additionally, the authors are able to replace the produced attention weights with completely different values while keeping the model output the same. These so-called â€œadversarialâ€ attention distributions show that an attention model may focus on completely different information and still come to the same conclusions, which makes interpretation difficult. Yet, in another paper titled â€œAttention is not not Explanationâ€ [121], the claim that attention is not explanation is questioned by challenging the assumptions of the previous work. It is found that the adversarial attention distributions do not perform as reliably well as the learned attention weights, indicating that it was not proved that attention is not viable for explanation. In general, the conclusion regarding the interpretability of attention models is that researchers must be extremely careful when drawing conclusions based on attention patterns. For example, problems with an attention model can be diagnosed via the attention weights if the model is found to focus on the incorrect parts of the data, if such information is available. Yet, conversely, attention weights may only be used to obtain plausible explanations for why certain parts of the data are focused on, rather than concluding that those parts are significant to the problem [121]. However, one should still be cautious as the viability of such approaches can depend on the model architecture [122].</p>
</blockquote>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>What Is GNN and GCN ?</title>
    <url>/2025/07/10/GNN-and-GCN/</url>
    <content><![CDATA[<h1 id="GNN-ä¸-GCN"><a href="#GNN-ä¸-GCN" class="headerlink" title="GNN ä¸ GCN"></a>GNN ä¸ GCN</h1><blockquote>
<p>å›¾ç¥ç»ç½‘ç»œï¼ˆGraph Neural Networks, GNNï¼‰å’Œå›¾å·ç§¯ç½‘ç»œï¼ˆGraph Convolutional Networks, GCNï¼‰æ˜¯å¤„ç†å›¾æ•°æ®çš„å¼ºå¤§å·¥å…·ã€‚æœ¬æ–‡å°†ä»ç†è®ºåˆ°å®è·µï¼Œå…¨é¢ä»‹ç»è¿™ä¸¤ç§é‡è¦çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</p>
</blockquote>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†<em>GNN å’Œ GCN çš„å¤§è‡´åŸç†</em>ï¼Œ<em>GCN åœ¨ PyG å’Œ PyTorch çš„å®ç°</em> ä»¥åŠå®ƒä»¬åœ¨<em>DRP ä¸­çš„åº”ç”¨</em></p>
<span id="more"></span>

<h2 id="ğŸ¯-Intro"><a href="#ğŸ¯-Intro" class="headerlink" title="ğŸ¯ Intro"></a>ğŸ¯ Intro</h2><p>åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œå¤„ç†å›¾ç»“æ„æ•°æ®ä¸€ç›´æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ CNNã€RNNï¼‰åœ¨å¤„ç†æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æ•°æ®è¡¨ç°å‡ºè‰²ï¼Œä½†å¯¹äºå›¾è¿™ç§éæ¬§å‡ é‡Œå¾—ç»“æ„çš„æ•°æ®å´æ˜¾å¾—åŠ›ä¸ä»å¿ƒã€‚GNN å’Œ GCN çš„å‡ºç°ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†å¤„ç†å›¾æ•°æ®çš„æœ‰åŠ›å·¥å…·ã€‚</p>
<p>è€Œåœ¨ DRP é¢†åŸŸï¼Œç”±äºæ¶‰åŠåˆ°å¤§é‡çš„ Embeddingï¼ŒGCN ç°åœ¨å‡ ä¹å·²ç»æˆä¸ºäº†å¿…ä¸å¯å°‘çš„æ¨¡å—ã€‚</p>
<p>ä½†åœ¨å¼€å§‹å„ç§å„æ ·çš„å¥‡å½¢æ€ªçŠ¶çš„ GCN ä¹‹å‰ï¼Œäº†è§£ GNN å’Œ GCN æœ¬èº«çš„å®ç°ä»ç„¶æ˜¯éå¸¸å¿…è¦çš„ã€‚<del>äºé¼ é¼ è€Œè¨€</del>å¤§è‡´æœ‰ä»¥ä¸‹ç†ç”±ï¼š</p>
<ol>
<li>éƒ¨åˆ†æŠ½è±¡çš„åŸºäº GCN çš„æ¨¡å—ç¬¬ä¸‰æ–¹åº“ä¸ä¸€å®šæ”¯æŒ</li>
<li>ç”±äºååº”è¡¨ç¤ºæ•°æ®çš„ä¸å¹³è¡¡ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºçš„æ¨¡å‹çš„å±‚æ•°æ˜¯éå¸¸æœ‰é™çš„ï¼ˆå› ä¸ºä¼šè¿‡å¹³æ»‘ï¼‰ã€‚å› æ­¤å¯¹å±‚å†…çš„æ”¹é€ å°±æ˜¾å¾—éå¸¸å¿…è¦äº†ã€‚è€Œè¿™ä¸€åˆ‡çš„å‰æä¾¿æ˜¯ç†è§£åŸç†æ</li>
</ol>
<p>åœ¨è¿™é‡Œå¼ºçƒˆå»ºè®®å»çœ‹ä¸€ä¸‹<a href="https://distill.pub/">Distill</a>çš„ä¸¤ç¯‡æœ‰å…³å›¾ç¥ç»ç½‘ç»œçš„åšå®¢ï¼Œéå¸¸æ˜“æ‡‚ã€‚</p>
<hr>
<h2 id="ğŸ“š-ç†è®ºåŸºç¡€"><a href="#ğŸ“š-ç†è®ºåŸºç¡€" class="headerlink" title="ğŸ“š ç†è®ºåŸºç¡€"></a>ğŸ“š ç†è®ºåŸºç¡€</h2><h3 id="å›¾çš„åŸºæœ¬æ¦‚å¿µ"><a href="#å›¾çš„åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="å›¾çš„åŸºæœ¬æ¦‚å¿µ"></a>å›¾çš„åŸºæœ¬æ¦‚å¿µ</h3><p>åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£å›¾çš„åŸºæœ¬è¡¨ç¤ºï¼š</p>
<ul>
<li>å›¾ $G &#x3D; (V, E)$ï¼Œå…¶ä¸­ $V$ æ˜¯èŠ‚ç‚¹é›†åˆï¼Œ$E$ æ˜¯è¾¹é›†åˆ</li>
<li>é‚»æ¥çŸ©é˜µ $A \in \mathbb{R}^{n \times n}$</li>
<li>åº¦çŸ©é˜µ $D &#x3D; diag(d_1,â€¦,d_n)$ï¼Œå…¶ä¸­ $d_i &#x3D; \sum_j A_{ij}$</li>
<li>èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ $X \in \mathbb{R}^{n \times d}$</li>
</ul>
<h3 id="GNN-æ¡†æ¶"><a href="#GNN-æ¡†æ¶" class="headerlink" title="GNN æ¡†æ¶"></a>GNN æ¡†æ¶</h3><p>GNN çš„åŸºæœ¬æ¡†æ¶éµå¾ªæ¶ˆæ¯ä¼ é€’èŒƒå¼ï¼ˆMessage Passing Neural Network, MPNNï¼‰ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹æ•°å­¦å…¬å¼è¡¨ç¤ºï¼š</p>
<ol>
<li><p><strong>æ¶ˆæ¯ä¼ é€’é˜¶æ®µ</strong>ï¼ˆMessage Passingï¼‰ï¼š</p>
<p>å¯¹äºèŠ‚ç‚¹ $v$ï¼Œä»å…¶é‚»å±…èŠ‚ç‚¹ $u \in \mathcal{N}(v)$ æ”¶é›†ä¿¡æ¯ï¼š</p>
<p>$$m_v^{(l)} &#x3D; \sum_{u \in \mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$h_v^{(l-1)}$ æ˜¯èŠ‚ç‚¹ $v$ åœ¨ç¬¬ $l-1$ å±‚çš„ç‰¹å¾</li>
<li>$e_{uv}$ æ˜¯è¾¹ $(u,v)$ çš„ç‰¹å¾</li>
<li>$M_l$ æ˜¯å¯å­¦ä¹ çš„æ¶ˆæ¯å‡½æ•°</li>
</ul>
</li>
<li><p><strong>æ¶ˆæ¯èšåˆé˜¶æ®µ</strong>ï¼ˆAggregationï¼‰ï¼š</p>
<p>å°†æ”¶é›†åˆ°çš„æ¶ˆæ¯è¿›è¡Œèšåˆï¼š</p>
<p>$$a_v^{(l)} &#x3D; AGG({m_v^{(l)} | u \in \mathcal{N}(v)})$$</p>
<p>å¸¸è§çš„èšåˆå‡½æ•°åŒ…æ‹¬ï¼š</p>
<ul>
<li>æ±‚å’Œï¼š$AGG_{sum} &#x3D; \sum_{u \in \mathcal{N}(v)} m_u$</li>
<li>å¹³å‡ï¼š$AGG_{mean} &#x3D; \frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} m_u$</li>
<li>æœ€å¤§ï¼š$AGG_{max} &#x3D; max_{u \in \mathcal{N}(v)} m_u$</li>
</ul>
</li>
<li><p><strong>èŠ‚ç‚¹æ›´æ–°é˜¶æ®µ</strong>ï¼ˆUpdateï¼‰ï¼š</p>
<p>æ›´æ–°èŠ‚ç‚¹çš„è¡¨ç¤ºï¼š</p>
<p>$$h_v^{(l)} &#x3D; U_l(h_v^{(l-1)}, a_v^{(l)})$$</p>
<p>å…¶ä¸­ $U_l$ æ˜¯å¯å­¦ä¹ çš„æ›´æ–°å‡½æ•°ï¼Œé€šå¸¸æ˜¯ MLP æˆ–å…¶ä»–ç¥ç»ç½‘ç»œã€‚</p>
</li>
</ol>
<h3 id="GCN-å®ç°"><a href="#GCN-å®ç°" class="headerlink" title="GCN å®ç°"></a>GCN å®ç°</h3><h4 id="æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ-ğŸ”"><a href="#æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ-ğŸ”" class="headerlink" title="æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ ğŸ”"></a>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ ğŸ”</h4><p>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µæ˜¯å›¾ä¿¡å·å¤„ç†ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œæœ‰å¤šç§å½¢å¼ï¼š</p>
<ol>
<li><p><strong>ç»„åˆæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L &#x3D; D - A$</p>
</li>
<li><p><strong>æ ‡å‡†åŒ–æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L_{sym} &#x3D; D^{-\frac{1}{2}}LD^{-\frac{1}{2}} &#x3D; I - D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$</p>
</li>
<li><p><strong>éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L_{rw} &#x3D; D^{-1}L &#x3D; I - D^{-1}A$</p>
</li>
</ol>
<p>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹æ€§ï¼š</p>
<ul>
<li>å¯¹ç§°æ€§ï¼š$L &#x3D; L^T$</li>
<li>åŠæ­£å®šæ€§ï¼šæ‰€æœ‰ç‰¹å¾å€¼éè´Ÿ</li>
<li>æœ€å°ç‰¹å¾å€¼ä¸º 0ï¼Œå¯¹åº”çš„ç‰¹å¾å‘é‡æ˜¯å¸¸æ•°å‘é‡</li>
<li>ç‰¹å¾å€¼çš„é‡æ•°å¯¹åº”å›¾çš„è¿é€šåˆ†é‡æ•°</li>
</ul>
<h4 id="ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯-ğŸ”„"><a href="#ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯-ğŸ”„" class="headerlink" title="ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯ ğŸ”„"></a>ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯ ğŸ”„</h4><h5 id="ä¼ ç»Ÿå·ç§¯å›é¡¾"><a href="#ä¼ ç»Ÿå·ç§¯å›é¡¾" class="headerlink" title="ä¼ ç»Ÿå·ç§¯å›é¡¾"></a>ä¼ ç»Ÿå·ç§¯å›é¡¾</h5><p>åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ï¼Œå·ç§¯æ“ä½œå®šä¹‰ä¸ºï¼š</p>
<p>$$(f * g)(p) &#x3D; \sum_{q \in \mathcal{N}(p)} f(q) \cdot g(p-q)$$</p>
<p>è¿™é‡Œçš„å…³é”®ç‰¹ç‚¹æ˜¯ï¼š</p>
<ul>
<li>å¹³ç§»ä¸å˜æ€§</li>
<li>å±€éƒ¨æ€§</li>
<li>å‚æ•°å…±äº«</li>
</ul>
<h5 id="å›¾ä¸Šçš„å·ç§¯å®šä¹‰"><a href="#å›¾ä¸Šçš„å·ç§¯å®šä¹‰" class="headerlink" title="å›¾ä¸Šçš„å·ç§¯å®šä¹‰"></a>å›¾ä¸Šçš„å·ç§¯å®šä¹‰</h5><p>åœ¨å›¾åŸŸä¸­ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®šä¹‰è¿™äº›ç‰¹æ€§ï¼š</p>
<ol>
<li><p><strong>ç©ºé—´åŸŸå·ç§¯</strong>ï¼š<br>$$h_v &#x3D; \sum_{u \in \mathcal{N}(v)} W(e_{u,v})h_u$$<br>å…¶ä¸­ $W(e_{u,v})$ æ˜¯è¾¹çš„æƒé‡å‡½æ•°</p>
</li>
<li><p><strong>è°±åŸŸå·ç§¯</strong>ï¼š<br>$$g_\theta * x &#x3D; Ug_\theta U^T x$$<br>å…¶ä¸­ $U$ æ˜¯æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹å¾å‘é‡çŸ©é˜µ</p>
</li>
</ol>
<h4 id="GCN-çš„æ•°å­¦æ¨å¯¼-âš™ï¸"><a href="#GCN-çš„æ•°å­¦æ¨å¯¼-âš™ï¸" class="headerlink" title="GCN çš„æ•°å­¦æ¨å¯¼ âš™ï¸"></a>GCN çš„æ•°å­¦æ¨å¯¼ âš™ï¸</h4><p>Kipf &amp; Welling æå‡ºçš„ GCN æ¨¡å‹ä¸­ï¼Œå•å±‚ä¼ æ’­è§„åˆ™ä¸ºï¼š</p>
<p>$$H^{(l+1)} &#x3D; \sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$\tilde{A} &#x3D; A + I_N$ æ˜¯æ·»åŠ äº†è‡ªç¯çš„é‚»æ¥çŸ©é˜µ</li>
<li>$\tilde{D}_{ii} &#x3D; \sum_{j} \tilde{A}_{ij}$ æ˜¯å¯¹åº”çš„åº¦çŸ©é˜µ</li>
<li>$H^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„æ¿€æ´»å€¼</li>
<li>$W^{(l)}$ æ˜¯å¯å­¦ä¹ çš„æƒé‡çŸ©é˜µ</li>
<li>$\sigma$ æ˜¯éçº¿æ€§æ¿€æ´»å‡½æ•°</li>
</ul>
<p><del>ä¸€äº›è‡ªå·±çš„ç†è§£</del></p>
<ol>
<li>å¼•å…¥$L_{sym} &#x3D; \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ä½œä¸ºèšåˆï¼ˆAGGï¼‰éƒ¨åˆ†<ul>
<li>æ·»åŠ è‡ªç¯ï¼š$\tilde{A} &#x3D; A + I_N$</li>
<li>è®¡ç®—å½’ä¸€åŒ–ç³»æ•°ï¼š$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$</li>
</ul>
</li>
<li>ç‰¹å¾å˜æ¢ï¼š$H^{(l)}W^{(l)}$</li>
<li>é‚»åŸŸèšåˆï¼š$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}$</li>
<li>éçº¿æ€§å˜æ¢ï¼š$\sigma(\cdot)$</li>
</ol>
<hr>
<h2 id="ğŸ’»-å®ç°ç»†èŠ‚"><a href="#ğŸ’»-å®ç°ç»†èŠ‚" class="headerlink" title="ğŸ’» å®ç°ç»†èŠ‚"></a>ğŸ’» å®ç°ç»†èŠ‚</h2><p>åŸºäºè¿™ä¸ªç†è®ºæ¡†æ¶çš„ç®€å•å®ç°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">message_passing</span>(<span class="params">nodes, edges</span>):</span><br><span class="line">    messages = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">        src, dst = edge</span><br><span class="line">        msg = compute_message(nodes[src], nodes[dst])</span><br><span class="line">        messages.setdefault(dst, []).append(msg)</span><br><span class="line">    <span class="keyword">return</span> messages</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">aggregate_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    aggregated = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> node, msgs <span class="keyword">in</span> messages.items():</span><br><span class="line">        aggregated[node] = <span class="built_in">sum</span>(msgs) / <span class="built_in">len</span>(msgs)  <span class="comment"># å¹³å‡èšåˆ</span></span><br><span class="line">    <span class="keyword">return</span> aggregated</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_nodes</span>(<span class="params">nodes, aggregated</span>):</span><br><span class="line">    updated = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> node, agg_msg <span class="keyword">in</span> aggregated.items():</span><br><span class="line">        updated[node] = nodes[node] + agg_msg  <span class="comment"># æ®‹å·®è¿æ¥</span></span><br><span class="line">    <span class="keyword">return</span> updated</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Geometric-å®ç°-ğŸš€"><a href="#PyTorch-Geometric-å®ç°-ğŸš€" class="headerlink" title="PyTorch Geometric å®ç° ğŸš€"></a>PyTorch Geometric å®ç° ğŸš€</h3><blockquote>
<p>æœ¬èŠ‚ä»£ç åŸºäº PyTorch 2.1.0 å’Œ PyTorch Geometric 2.4.0 ç‰ˆæœ¬</p>
</blockquote>
<p>ä½¿ç”¨ PyTorch Geometric åº“çš„ GCN å®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = GCNConv(num_features, <span class="number">16</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = GCNConv(<span class="number">16</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x, edge_index)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.dropout(x, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="åŸç”Ÿ-PyTorch-å®ç°-ğŸ”§"><a href="#åŸç”Ÿ-PyTorch-å®ç°-ğŸ”§" class="headerlink" title="åŸç”Ÿ PyTorch å®ç° ğŸ”§"></a>åŸç”Ÿ PyTorch å®ç° ğŸ”§</h3><blockquote>
<p>æœ¬èŠ‚ä»£ç åŸºäº PyTorch 2.1.0ã€NumPy 1.24.0 å’Œ SciPy 1.11.0 ç‰ˆæœ¬</p>
</blockquote>
<p>ä¸ä½¿ç”¨ PyGï¼Œæ‰‹åŠ¨å®ç° GCN<del>ä¸»è¦æ˜¯ç›®å‰ä¸å¤ªæ¸…æ¥šä¸»æµçš„ HGCN çš„å®ç°æ–¹å¼æ</del>ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, out_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCNLayer, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.W = nn.Parameter(torch.FloatTensor(in_features, out_features))</span><br><span class="line">        <span class="variable language_">self</span>.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        nn.init.kaiming_uniform_(<span class="variable language_">self</span>.W)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        <span class="comment"># adj: å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µ</span></span><br><span class="line">        support = torch.mm(x, <span class="variable language_">self</span>.W)</span><br><span class="line">        output = torch.sparse.mm(adj, support)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nfeat, nhid, nclass, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gc1 = GCNLayer(nfeat, nhid)</span><br><span class="line">        <span class="variable language_">self</span>.gc2 = GCNLayer(nhid, nclass)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.gc1(x, adj))</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.gc2(x, adj)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_adj</span>(<span class="params">adj</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ&quot;&quot;&quot;</span></span><br><span class="line">    adj = sp.coo_matrix(adj)</span><br><span class="line">    rowsum = np.array(adj.<span class="built_in">sum</span>(<span class="number">1</span>))</span><br><span class="line">    d_inv_sqrt = np.power(rowsum, -<span class="number">0.5</span>).flatten()</span><br><span class="line">    d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class="number">0.</span></span><br><span class="line">    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class="line">    <span class="keyword">return</span> adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="ğŸ®-åº”ç”¨åœºæ™¯"><a href="#ğŸ®-åº”ç”¨åœºæ™¯" class="headerlink" title="ğŸ® åº”ç”¨åœºæ™¯"></a>ğŸ® åº”ç”¨åœºæ™¯</h2><p><del>ç”±äºé¼ é¼ å°±æ˜¯ä¸ªè‡­å†™ DRP çš„æ</del> è¿™é‡Œåªç»™å‡º GNN åœ¨ DRP ä¸­çš„åº”ç”¨</p>
<ol>
<li><p><strong>è¯ç‰©è¡¨ç¤º</strong></p>
<ul>
<li><em>åˆ†å­å›¾æ„å»º</em>ï¼šå°†è¯ç‰© SMILES å­—ç¬¦ä¸²è½¬æ¢ä¸ºå›¾ç»“æ„ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºåŸå­ï¼ˆå«åŸå­ç±»å‹ã€ç”µè·ç­‰ç‰¹å¾ï¼‰ï¼Œè¾¹è¡¨ç¤ºåŒ–å­¦é”®ï¼ˆå¦‚é”®ç±»å‹ã€è·ç¦»ï¼‰ã€‚</li>
<li><em>GNN ç¼–ç </em>ï¼šä½¿ç”¨å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ã€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰æˆ–å›¾åŒæ„ç½‘ç»œï¼ˆGINï¼‰ç­‰å±‚è¿­ä»£èšåˆé‚»åŸŸä¿¡æ¯ï¼Œç”Ÿæˆè¯ç‰©åµŒå…¥ï¼ˆembeddingï¼‰ã€‚ä¾‹å¦‚ï¼ŒGraTransDRPï¼ˆ2022ï¼‰ç»“åˆ GAT å’Œ Transformer æå‡è¯ç‰©è¡¨å¾èƒ½åŠ›ã€‚</li>
</ul>
</li>
<li><p><strong>ç™Œç—‡è¡¨ç¤º</strong></p>
<ul>
<li><em>ç”Ÿç‰©ç½‘ç»œæ„å»º</em>ï¼šåŸºäºåŸºå› äº’ä½œï¼ˆå¦‚ STRING æ•°æ®åº“çš„è›‹ç™½-è›‹ç™½äº’ä½œï¼‰ã€åŸºå› å…±è¡¨è¾¾æˆ–é€šè·¯ä¿¡æ¯æ„å»ºå¼‚è´¨å›¾ã€‚ä¾‹å¦‚ï¼ŒAGMIï¼ˆ2021ï¼‰æ•´åˆå¤šç»„å­¦æ•°æ®å’Œ PPI ç½‘ç»œï¼Œé€šè¿‡ GNN å­¦ä¹ ç™Œç—‡æ ·æœ¬çš„è”åˆè¡¨å¾ã€‚</li>
<li><em>å¤šç»„å­¦èåˆ</em>ï¼šéƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ TGSAï¼‰åˆ©ç”¨ GNN æ•´åˆåŸºå› ç»„ã€è½¬å½•ç»„ç­‰æ•°æ®ï¼Œé€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç‰¹å¾äº¤äº’ã€‚</li>
</ul>
</li>
<li><p><strong>å¼‚æ„å›¾ä¸è”åˆå»ºæ¨¡</strong></p>
<ul>
<li><em>ç»†èƒç³»-è¯ç‰©å¼‚æ„å›¾</em>ï¼šå¦‚ GraphCDRï¼ˆ2021ï¼‰å°†ç»†èƒç³»å’Œè¯ç‰©ä½œä¸ºä¸¤ç±»èŠ‚ç‚¹ï¼Œé€šè¿‡è¾¹è¿æ¥å·²çŸ¥å“åº”å¯¹ï¼Œç›´æ¥å­¦ä¹ è·¨å®ä½“å…³ç³»ã€‚</li>
<li><em>çŸ¥è¯†å¢å¼º</em>ï¼šé¢„è®­ç»ƒ GNN äºå¤§è§„æ¨¡ç”Ÿç‰©åŒ–å­¦å±æ€§é¢„æµ‹ï¼ˆå¦‚ Zhu et al., 2021ï¼‰ï¼Œå†è¿ç§»è‡³ DRP ä»»åŠ¡ï¼Œæå‡æ³›åŒ–æ€§ã€‚</li>
</ul>
</li>
</ol>
<h2 id="ğŸ¯-æ€»ç»“ä¸å±•æœ›"><a href="#ğŸ¯-æ€»ç»“ä¸å±•æœ›" class="headerlink" title="ğŸ¯ æ€»ç»“ä¸å±•æœ›"></a>ğŸ¯ æ€»ç»“ä¸å±•æœ›</h2><ul>
<li><strong>åŠ¨æ€å›¾å»ºæ¨¡</strong>ï¼šæ•æ‰æ²»ç–—è¿‡ç¨‹ä¸­åŠ¨æ€å˜åŒ–çš„ç”Ÿç‰©ç½‘ç»œã€‚</li>
<li><strong>ä¸‰ç»´åˆ†å­å›¾</strong>ï¼šç»“åˆå‡ ä½•æ·±åº¦å­¦ä¹ ï¼ˆå¦‚ SchNetï¼‰æå‡ç«‹ä½“åŒ–å­¦æ„ŸçŸ¥ã€‚</li>
<li><strong>åŸºå‡†æµ‹è¯•</strong>ï¼šéœ€ç»Ÿä¸€è¯„ä¼°åè®®ï¼ˆå¦‚å›ºå®šæ•°æ®é›†å’ŒæŒ‡æ ‡ï¼‰ä»¥å…¬å¹³æ¯”è¾ƒ GNN ä¸å…¶ä»–æ–¹æ³•ã€‚</li>
</ul>
<p><del>ä¹‹ååº”è¯¥ä¼šå†™ä¸€äº›å…·ä½“æ¨¡å‹çš„åšå®¢ï¼Œæœ‰ç›¸å…³çš„ä¼šç›´æ¥ä¸Šé“¾æ¥çš„æ jrm</del></p>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><a href="https://pytorch-geometric.readthedocs.io/" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/pyg.svg" alt="pyg" style="height: 1.5em; vertical-align: text-bottom; margin-top: 16px;">
  </span>
  PyTorch Geometric å®˜æ–¹æ–‡æ¡£</a>

<p><a href="/paper/1609.02907v4.pdf" target="_blank">ğŸ“„ Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a></p>
<a href="https://distill.pub/2021/gnn-intro/" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/google.svg" alt="google" style="height: 1.3em; vertical-align: text-bottom; margin-top: 16px;">
  </span>
  Distill: A Gentle Introduction to Graph Neural Networks
</a>

<p><a href="/paper/Feng ç­‰ - 2024 - A Comprehensive Survey of Dynamic Graph Neural Networks Models, Frameworks, Benchmarks, Experiments.pdf" target="_blank">ğŸ“„ Feng ç­‰ - 2024 - A Comprehensive Survey of Dynamic Graph Neural Networks Models, Frameworks, Benchmarks, Experiments</a></p>
<a href="https://distill.pub/2021/understanding-gnns/" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/google.svg" alt="google" style="height: 1.3em; vertical-align: text-bottom; margin-top: 16px;">
  </span>
  Distill: Understanding Convolutions on Graphs
</a>

<p><a href="https://arxiv.org/abs/2401.11768" target="_blank">ğŸ“„ ADA-GNN: Atom-Distance-Angle Graph Neural Network for Crystal Material Property Prediction</a></p>
<a href="https://www.zhihu.com/tardis/zm/art/107162772" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/zhihu.svg" alt="zhihu" style="height: 1.3em; vertical-align: text-bottom; margin-top: 16px;">
  </span>
  çŸ¥ä¹ï¼šå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å…¥é—¨è¯¦è§£
</a>

<p><a href="/paper/å´å‡Œé£[ç­‰]ç¼–. - 2022 - å›¾ç¥ç»ç½‘ç»œ åŸºç¡€,å‰æ²¿ä¸åº”ç”¨.pdf" target="_blank">ğŸ“„ å´å‡Œé£[ç­‰]ç¼–. - 2022 - å›¾ç¥ç»ç½‘ç»œ åŸºç¡€,å‰æ²¿ä¸åº”ç”¨</a></p>
<a href="https://github.com/tkipf/gcn" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/github.svg" alt="github" style="height: 1.3em; vertical-align: text-bottom; margin-top: 16px;">
  </span>
  GCN è®ºæ–‡å®˜æ–¹ä»£ç 
</a>
]]></content>
      <categories>
        <category>model</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>PyTorch</tag>
        <tag>embedding</tag>
        <tag>graph theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Woc?! GAT? We&#39;re Saved!</title>
    <url>/2025/07/18/GAT/</url>
    <content><![CDATA[<h1 id="GATï¼ˆGraph-Attention-Networksï¼‰"><a href="#GATï¼ˆGraph-Attention-Networksï¼‰" class="headerlink" title="GATï¼ˆGraph Attention Networksï¼‰"></a>GATï¼ˆGraph Attention Networksï¼‰</h1><p>å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰æ—¨åœ¨ä¸ºä¸‹æ¸¸ä»»åŠ¡å­¦ä¹ åœ¨ä½ç»´ç©ºé—´ä¸­è®­ç»ƒè‰¯å¥½çš„è¡¨ç¤ºï¼ŒåŒæ—¶ä¿ç•™æ‹“æ‰‘ç»“æ„ã€‚è¿‘å¹´æ¥ï¼Œæ³¨æ„åŠ›æœºåˆ¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œè¢«å¼•å…¥åˆ°GNNsä¸­ï¼Œä»¥è‡ªé€‚åº”åœ°é€‰æ‹©åˆ¤åˆ«ç‰¹å¾å¹¶è‡ªåŠ¨è¿‡æ»¤å™ªå£°ä¿¡æ¯ã€‚æœ¬åšå®¢å°†é‡ç‚¹ä»‹ç»GAT </p>
<span id="more"></span>

<h2 id="å±‚å†…-GAT-Intra-Layer-GAT"><a href="#å±‚å†…-GAT-Intra-Layer-GAT" class="headerlink" title="å±‚å†… GAT (Intra-Layer GAT)"></a>å±‚å†… GAT (Intra-Layer GAT)</h2><p>å±‚å†…GATsæ˜¯æŒ‡åœ¨å•ä¸ªç¥ç»ç½‘ç»œå±‚å†…åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„å›¾ç¥ç»ç½‘ç»œï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯ï¼š</p>
<ul>
<li>æ³¨æ„åŠ›æœºåˆ¶ä½œç”¨äºå±€éƒ¨é‚»å±…èŠ‚ç‚¹</li>
<li>åœ¨ç‰¹å¾èšåˆæ­¥éª¤ä¸­ä¸ºä¸åŒèŠ‚ç‚¹åˆ†é…ä¸åŒæƒé‡</li>
<li>èƒ½å¤Ÿè‡ªé€‚åº”åœ°å…³æ³¨å›¾ä¸­æœ€ç›¸å…³çš„éƒ¨åˆ†</li>
</ul>
<p>è€ƒè™‘åˆ°ä¸åŒçš„å±€éƒ¨é‚»åŸŸå’Œä¸åŒçš„åŠŸèƒ½ï¼Œå±‚å†…GATså¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºå…­ä¸ªå­ç±»ï¼ŒåŒ…æ‹¬é‚»å±…æ³¨æ„åŠ›ã€é«˜é˜¶æ³¨æ„åŠ›ã€å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ›ã€å±‚æ¬¡æ³¨æ„åŠ›ã€æ³¨æ„åŠ›é‡‡æ ·&#x2F;æ± åŒ–å’Œè¶…æ³¨æ„åŠ›ã€‚</p>
<h3 id="é‚»å±…æ³¨æ„åŠ›-Neighbor-Attention"><a href="#é‚»å±…æ³¨æ„åŠ›-Neighbor-Attention" class="headerlink" title="é‚»å±…æ³¨æ„åŠ› (Neighbor Attention)"></a>é‚»å±…æ³¨æ„åŠ› (Neighbor Attention)</h3><h4 id="é‚»å±…æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³"><a href="#é‚»å±…æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³" class="headerlink" title="é‚»å±…æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³"></a>é‚»å±…æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³</h4><p>é‚»å±…æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒæ˜¯é€šè¿‡å­¦ä¹ çš„æ–¹å¼åŠ¨æ€ç¡®å®šå›¾ä¸­æ¯ä¸ªèŠ‚ç‚¹å¯¹å…¶é‚»å±…çš„é‡è¦æ€§æƒé‡ï¼Œè€Œéä¼ ç»ŸGNNä¸­é‡‡ç”¨çš„å›ºå®šæƒé‡ç­–ç•¥ã€‚å…¶å…³é”®åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>åŠ¨æ€æƒé‡åˆ†é…</strong>ï¼šæ ¹æ®èŠ‚ç‚¹ç‰¹å¾ç›¸ä¼¼æ€§åŠ¨æ€è®¡ç®—æ³¨æ„åŠ›æƒé‡</li>
<li><strong>å±€éƒ¨èšç„¦</strong>ï¼šä»…è€ƒè™‘ä¸€é˜¶é‚»å±…èŠ‚ç‚¹çš„æ³¨æ„åŠ›è®¡ç®—</li>
<li><strong>ç«¯åˆ°ç«¯è®­ç»ƒ</strong>ï¼šæ³¨æ„åŠ›æƒé‡ä¸ç½‘ç»œå‚æ•°å…±åŒä¼˜åŒ–</li>
</ol>
<h4 id="åŸºç¡€GATæ¨¡å‹"><a href="#åŸºç¡€GATæ¨¡å‹" class="headerlink" title="åŸºç¡€GATæ¨¡å‹"></a>åŸºç¡€GATæ¨¡å‹</h4><p>GAT å¯ä»¥ç®€å•æ¦‚æ‹¬ä¸ºä¸€ç§å°† Attention æœºåˆ¶å¼•å…¥ GCNï¼ˆå›¾å·ç§¯ç½‘ç»œï¼‰çš„æ–¹æ³•ï¼Œè€Œ GCN æ˜¯ä¸€ç§èƒ½å¤Ÿåœ¨æ·±åº¦å­¦ä¹ ä¸­è¿›è¡Œå›¾ç»“æ„åˆ†ç±»ç­‰ä»»åŠ¡çš„æ–¹æ³•ã€‚Attention æœºåˆ¶æ˜¯æŒ‡ä¸€ç§æ ¹æ®è¾“å…¥æ•°æ®åŠ¨æ€å†³å®šå…³æ³¨ç„¦ç‚¹çš„æœºåˆ¶ï¼Œé€šè¿‡å°†è¿™ç§ Attention æœºåˆ¶å¼•å…¥ GCNï¼ˆå›¾å·ç§¯ç½‘ç»œï¼‰ï¼Œå¯ä»¥æé«˜åˆ†ç±»ã€è¯†åˆ«å’Œé¢„æµ‹çš„ç²¾åº¦ã€‚å› æ­¤ï¼Œå¦‚æœå¯¹ GCN çš„ç†è§£ä¸å¤Ÿæ·±å…¥ï¼Œå¯èƒ½ä¼šéš¾ä»¥å®Œå…¨ç†è§£ GATã€‚</p>
<p>GCN ä¸ GAT çš„ä¸»è¦åŒºåˆ«åœ¨äºèŠ‚ç‚¹å·ç§¯æ—¶çš„ç³»æ•°ï¼ˆè¿™å°±æ˜¯æ‰€è°“çš„ Attention ç³»æ•°ï¼‰å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</p>
<p>åœ¨å¸¸è§„ GCN ä¸­ï¼Œå½“è®¡ç®—æŸèŠ‚ç‚¹çš„ä¸‹ä¸€å±‚ç‰¹å¾ï¼ˆæ½œåœ¨å˜é‡ï¼‰æ—¶ï¼Œä¼šé€šè¿‡å°†ç›¸é‚»èŠ‚ç‚¹çš„ç‰¹å¾ä¸çº¿æ€§æƒé‡ç›¸ä¹˜åçš„å’Œï¼Œå†é€šè¿‡æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLU ç­‰ï¼‰ä¼ é€’è‡³ä¸‹ä¸€å±‚ã€‚åœ¨è®¡ç®—ç›¸é‚»èŠ‚ç‚¹çš„ç‰¹å¾é‡çš„çº¿æ€§ç»„åˆæ—¶ï¼Œä¼ ç»Ÿæ–¹æ³•å°†æ‰€æœ‰ç›¸é‚»èŠ‚ç‚¹å¹³ç­‰å¯¹å¾…ï¼Œè€Œ GAT åˆ™å¼•å…¥äº†é‡è¦æ€§ï¼ˆAttention ç³»æ•°ï¼‰çš„æ¦‚å¿µï¼Œä¸å†å°†ç›¸é‚»èŠ‚ç‚¹è§†ä¸ºåŒç­‰ã€‚</p>
<p>å…¶æ¦‚å¿µå¯ä»¥å½¢è±¡åœ°ç†è§£ä¸ºå¦‚ä¸‹ï¼š</p>
<img src="/img/GAT/AttentionInGraphVisualize.png" alt="AttentionInGraphVisualize" width="60%" height="auto">

<blockquote>
<p>ä¸Šå›¾å±•ç¤ºäº†èŠ‚ç‚¹ 1 ä¸å…¶ç›¸é‚»çš„èŠ‚ç‚¹ 2ã€3ã€4 ä¹‹é—´ï¼Œé€šè¿‡ç²—çº¿è¡¨ç¤ºçš„è¾¹ï¼ŒèŠ‚ç‚¹ 3 æœ€ä¸ºé‡è¦ï¼Œå…¶æ¬¡ä¸ºèŠ‚ç‚¹ 4ï¼Œç„¶åæ˜¯èŠ‚ç‚¹ 2ï¼ŒæŒ‰é‡è¦æ€§é¡ºåºæ’åˆ—çš„ç¤ºæ„å›¾ã€‚</p>
</blockquote>
<p>GAT æ­£æ˜¯é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå°†è¿™ç§æ¦‚å¿µåº”ç”¨äºç›¸é‚»èŠ‚ç‚¹ã€‚</p>
<p>GATé€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ æƒé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾ã€‚å¯¹äºèŠ‚ç‚¹iï¼Œå…¶æ›´æ–°å…¬å¼ä¸ºï¼š</p>
<p>$$h_i^{(l+1)} &#x3D; \sigma(\sum_{j \in \mathcal{N}_i} \alpha_{ij}W^{(l)}h_j^{(l)})$$</p>
<p>å…¶ä¸­æ³¨æ„åŠ›ç³»æ•°$\alpha_{ij}$çš„è®¡ç®—ï¼š</p>
<p>$$\alpha_{ij} &#x3D; \frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\sum_{k \in \mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$</p>
<h5 id="æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹"><a href="#æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹" class="headerlink" title="æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹"></a>æ³¨æ„åŠ›è®¡ç®—è¿‡ç¨‹</h5><p>åŸºç¡€GATæ¨¡å‹(Velickovic et al. 2018)çš„æ³¨æ„åŠ›è®¡ç®—åŒ…å«ä¸‰ä¸ªå…³é”®æ­¥éª¤ï¼š</p>
<ol>
<li><strong>çº¿æ€§å˜æ¢</strong>ï¼šå¯¹èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œå…±äº«çº¿æ€§å˜æ¢ $h_iâ€™ &#x3D; W h_i$</li>
<li><strong>æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—</strong>ï¼šä½¿ç”¨å•å±‚å‰é¦ˆç½‘ç»œè®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{ij} &#x3D; a^T[Wh_i||Wh_j]$</li>
<li><strong>å½’ä¸€åŒ–å¤„ç†</strong>ï¼šé€šè¿‡softmaxè¿›è¡Œå½’ä¸€åŒ– $\alpha_{ij} &#x3D; \text{softmax}(e_{ij})$</li>
</ol>
<h5 id="å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"><a href="#å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶"></a>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶</h5><p>GATå¼•å…¥å¤šå¤´æ³¨æ„åŠ›ä»¥ç¨³å®šå­¦ä¹ è¿‡ç¨‹ï¼š</p>
<ul>
<li><strong>è¿æ¥å¼å¤šå¤´</strong>ï¼šå„å¤´è¾“å‡ºç›´æ¥æ‹¼æ¥ $h_iâ€™ &#x3D; |_{k&#x3D;1}^K \sigma(\sum_{j\in N_i} \alpha_{ij}^k W^k h_j)$</li>
<li><strong>å¹³å‡å¼å¤šå¤´</strong>ï¼šå„å¤´è¾“å‡ºå–å¹³å‡ $h_iâ€™ &#x3D; \sigma(\frac{1}{K}\sum_{k&#x3D;1}^K \sum_{j\in N_i} \alpha_{ij}^k W^k h_j)$</li>
</ul>
<h4 id="å…³é”®æ”¹è¿›æ¨¡å‹"><a href="#å…³é”®æ”¹è¿›æ¨¡å‹" class="headerlink" title="å…³é”®æ”¹è¿›æ¨¡å‹"></a>å…³é”®æ”¹è¿›æ¨¡å‹</h4><h5 id="GATv2"><a href="#GATv2" class="headerlink" title="GATv2"></a>GATv2</h5><p>GATv2(Brody et al. 2021)è§£å†³äº†åŸå§‹GATçš„é™æ€æ³¨æ„åŠ›é—®é¢˜ï¼š</p>
<ul>
<li>è°ƒæ•´è®¡ç®—é¡ºåºï¼šå…ˆéçº¿æ€§å˜æ¢å†çº¿æ€§æŠ•å½±<br>$e_{ij} &#x3D; a^T \text{LeakyReLU}(W[h_i||h_j])$</li>
<li>è¯æ˜åŸå§‹GATçš„æ³¨æ„åŠ›æ’åä¸æŸ¥è¯¢æ— å…³</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜äºGAT</li>
</ul>
<h5 id="PPRGAT"><a href="#PPRGAT" class="headerlink" title="PPRGAT"></a>PPRGAT</h5><p>PPRGAT(Choi 2022)æ•´åˆä¸ªæ€§åŒ–PageRankä¿¡æ¯ï¼š</p>
<ul>
<li>åœ¨æ³¨æ„åŠ›è®¡ç®—ä¸­åŠ å…¥PPRåˆ†æ•°<br>$e_{ij} &#x3D; \text{LeakyReLU}(a^T[Wh_i||Wh_j||\pi_{ij}])$</li>
<li>ä¿ç•™åŸå§‹GATç»“æ„çš„åŒæ—¶åˆ©ç”¨å…¨å±€å›¾ä¿¡æ¯</li>
<li>åœ¨èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚</li>
</ul>
<h5 id="SuperGAT"><a href="#SuperGAT" class="headerlink" title="SuperGAT"></a>SuperGAT</h5><p>SuperGAT(Kim and Oh 2021)æå‡ºä¸¤ç§è‡ªç›‘ç£å˜ä½“ï¼š</p>
<ol>
<li>è¾¹é¢„æµ‹ä»»åŠ¡ï¼šåˆ©ç”¨æ³¨æ„åŠ›åˆ†æ•°é¢„æµ‹è¾¹å­˜åœ¨æ€§</li>
<li>æ ‡ç­¾ä¸€è‡´æ€§ä»»åŠ¡ï¼šåˆ©ç”¨æ³¨æ„åŠ›åˆ†æ•°é¢„æµ‹èŠ‚ç‚¹æ ‡ç­¾ä¸€è‡´æ€§</li>
<li>åœ¨å™ªå£°å›¾ä¸Šè¡¨ç°æ›´é²æ£’</li>
</ol>
<h4 id="ğŸ’»-å®ç°ç»†èŠ‚"><a href="#ğŸ’»-å®ç°ç»†èŠ‚" class="headerlink" title="ğŸ’» å®ç°ç»†èŠ‚"></a>ğŸ’» å®ç°ç»†èŠ‚</h4><h5 id="PyTorchå®ç°çš„GATå±‚"><a href="#PyTorchå®ç°çš„GATå±‚" class="headerlink" title="PyTorchå®ç°çš„GATå±‚"></a>PyTorchå®ç°çš„GATå±‚</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GATLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> \_\_init\_\_(<span class="variable language_">self</span>, <span class="keyword">in</span>\_features, out\_features, dropout, alpha, concat=<span class="literal">True</span>):</span><br><span class="line">        <span class="built_in">super</span>(GATLayer, <span class="variable language_">self</span>).\_\_init\_\_()</span><br><span class="line">        <span class="variable language_">self</span>.<span class="keyword">in</span>\_features = <span class="keyword">in</span>\_features</span><br><span class="line">        <span class="variable language_">self</span>.out\_features = out\_features</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line">        <span class="variable language_">self</span>.alpha = alpha</span><br><span class="line">        <span class="variable language_">self</span>.concat = concat</span><br><span class="line"></span><br><span class="line">        <span class="comment">### å˜æ¢çŸ©é˜µ</span></span><br><span class="line">        <span class="variable language_">self</span>.W = nn.Parameter(torch.zeros(size=(<span class="keyword">in</span>\_features, out\_features)))</span><br><span class="line">        nn.init.xavier\_uniform\_(<span class="variable language_">self</span>.W.data, gain=<span class="number">1.414</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### æ³¨æ„åŠ›å‘é‡</span></span><br><span class="line">        <span class="variable language_">self</span>.a = nn.Parameter(torch.zeros(size=(<span class="number">2</span>*out\_features, <span class="number">1</span>)))</span><br><span class="line">        nn.init.xavier\_uniform\_(<span class="variable language_">self</span>.a.data, gain=<span class="number">1.414</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.leakyrelu = nn.LeakyReLU(<span class="variable language_">self</span>.alpha)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        <span class="comment">### x: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ [N, in\_features]</span></span><br><span class="line">        <span class="comment">### adj: é‚»æ¥çŸ©é˜µ [N, N]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">### çº¿æ€§å˜æ¢</span></span><br><span class="line">        h = torch.mm(x, <span class="variable language_">self</span>.W)  <span class="comment">### [N, out\_features]</span></span><br><span class="line">        N = h.size()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">### è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°</span></span><br><span class="line">        a\_<span class="built_in">input</span> = torch.cat([h.repeat(<span class="number">1</span>, N).view(N * N, -<span class="number">1</span>), h.repeat(N, <span class="number">1</span>)], dim=<span class="number">1</span>)</span><br><span class="line">        a\_<span class="built_in">input</span> = a\_<span class="built_in">input</span>.view(N, N, <span class="number">2</span> * <span class="variable language_">self</span>.out\_features)</span><br><span class="line">        e = <span class="variable language_">self</span>.leakyrelu(torch.matmul(a\_<span class="built_in">input</span>, <span class="variable language_">self</span>.a).squeeze(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">### æ©ç æœºåˆ¶</span></span><br><span class="line">        zero\_vec = -<span class="number">9e15</span> * torch.ones\_like(e)</span><br><span class="line">        attention = torch.where(adj &gt; <span class="number">0</span>, e, zero\_vec)</span><br><span class="line">        attention = F.softmax(attention, dim=<span class="number">1</span>)</span><br><span class="line">        attention = F.dropout(attention, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line"></span><br><span class="line">        <span class="comment">### èšåˆç‰¹å¾</span></span><br><span class="line">        h\_prime = torch.matmul(attention, h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.concat:</span><br><span class="line">            <span class="keyword">return</span> F.elu(h\_prime)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> h\_prime</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GAT</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> \_\_init\_\_(<span class="variable language_">self</span>, nfeat, nhid, nclass, dropout, alpha, nheads):</span><br><span class="line">        <span class="built_in">super</span>(GAT, <span class="variable language_">self</span>).\_\_init\_\_()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### å¤šå¤´æ³¨æ„åŠ›å±‚</span></span><br><span class="line">        <span class="variable language_">self</span>.attentions = nn.ModuleList([</span><br><span class="line">            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=<span class="literal">True</span>) </span><br><span class="line">            <span class="keyword">for</span> \_ <span class="keyword">in</span> <span class="built_in">range</span>(nheads)</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### è¾“å‡ºå±‚</span></span><br><span class="line">        <span class="variable language_">self</span>.out\_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="comment">### å¤šå¤´æ³¨æ„åŠ›</span></span><br><span class="line">        x = torch.cat([att(x, adj) <span class="keyword">for</span> att <span class="keyword">in</span> <span class="variable language_">self</span>.attentions], dim=<span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.out\_att(x, adj)</span><br><span class="line">        <span class="keyword">return</span> F.log\_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h5 id="å®é™…åº”ç”¨ç¤ºä¾‹"><a href="#å®é™…åº”ç”¨ç¤ºä¾‹" class="headerlink" title="å®é™…åº”ç”¨ç¤ºä¾‹"></a>å®é™…åº”ç”¨ç¤ºä¾‹</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">### æ¨¡å‹åˆå§‹åŒ–</span></span><br><span class="line">model = GAT(nfeat=<span class="built_in">input</span>\_dim,</span><br><span class="line">           nhid=<span class="number">8</span>,</span><br><span class="line">           nclass=num\_classes,</span><br><span class="line">           dropout=<span class="number">0.6</span>,</span><br><span class="line">           alpha=<span class="number">0.2</span>,</span><br><span class="line">           nheads=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">### ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.005</span>, weight\_decay=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">### è®­ç»ƒå¾ªç¯</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    model.train()</span><br><span class="line">    optimizer.zero\_grad()</span><br><span class="line">    output = model(features, adj)</span><br><span class="line">    loss = F.nll\_loss(output[idx\_train], labels[idx\_train])</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> loss.item()</span><br></pre></td></tr></table></figure>

<h3 id="é«˜é˜¶æ³¨æ„åŠ›-High-Order-Attention"><a href="#é«˜é˜¶æ³¨æ„åŠ›-High-Order-Attention" class="headerlink" title="é«˜é˜¶æ³¨æ„åŠ› (High-Order Attention)"></a>é«˜é˜¶æ³¨æ„åŠ› (High-Order Attention)</h3><h4 id="é«˜é˜¶æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³"><a href="#é«˜é˜¶æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³" class="headerlink" title="é«˜é˜¶æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³"></a>é«˜é˜¶æ³¨æ„åŠ›æ ¸å¿ƒæ€æƒ³</h4><p>é«˜é˜¶æ³¨æ„åŠ›æœºåˆ¶çªç ´äº†ä¼ ç»ŸGATä»…å…³æ³¨ç›´æ¥é‚»å±…çš„é™åˆ¶ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼æ‰©å±•äº†æ³¨æ„åŠ›èŒƒå›´ï¼š</p>
<ol>
<li>å¤šè·³é‚»å±…èšåˆï¼šè€ƒè™‘k-hopèŒƒå›´å†…çš„èŠ‚ç‚¹ï¼ˆk&gt;1ï¼‰</li>
<li>è·¯å¾„æ„ŸçŸ¥ï¼šå…³æ³¨èŠ‚ç‚¹é—´çš„è·¯å¾„ä¿¡æ¯è€Œä¸ä»…æ˜¯ç›´æ¥è¿æ¥</li>
<li>å…¨å±€æ„Ÿå—é‡ï¼šéƒ¨åˆ†æ¨¡å‹å®ç°è¿‘ä¼¼å…¨å±€æ³¨æ„åŠ›</li>
</ol>
<img src="\img\GAT\HighOrderAttention.png" alt="HighOrderAttention" width="60%" height="auto">

<h4 id="å…³é”®æŠ€æœ¯è·¯çº¿"><a href="#å…³é”®æŠ€æœ¯è·¯çº¿" class="headerlink" title="å…³é”®æŠ€æœ¯è·¯çº¿"></a>å…³é”®æŠ€æœ¯è·¯çº¿</h4><h5 id="åŸºäºè·¯å¾„çš„æ³¨æ„åŠ›"><a href="#åŸºäºè·¯å¾„çš„æ³¨æ„åŠ›" class="headerlink" title="åŸºäºè·¯å¾„çš„æ³¨æ„åŠ›"></a>åŸºäºè·¯å¾„çš„æ³¨æ„åŠ›</h5><p>SPAGAN(Yang et al. 2019)å¼€åˆ›æ€§åœ°æå‡ºè·¯å¾„æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
<ul>
<li>è®¡ç®—èŠ‚ç‚¹é—´æœ€çŸ­è·¯å¾„ä½œä¸ºæ³¨æ„åŠ›ä¼ æ’­è·¯å¾„</li>
<li>è·¯å¾„ç‰¹å¾é€šè¿‡LSTMç¼–ç  $p_{ij} &#x3D; \text{LSTM}([h_i, h_{i1}, â€¦, h_{j}])$</li>
<li>æ³¨æ„åŠ›åˆ†æ•°è®¡ç®— $\alpha_{ij} &#x3D; \text{softmax}(W_p p_{ij})$</li>
</ul>
<h5 id="åŸºäºéšæœºæ¸¸èµ°çš„æ³¨æ„åŠ›"><a href="#åŸºäºéšæœºæ¸¸èµ°çš„æ³¨æ„åŠ›" class="headerlink" title="åŸºäºéšæœºæ¸¸èµ°çš„æ³¨æ„åŠ›"></a>åŸºäºéšæœºæ¸¸èµ°çš„æ³¨æ„åŠ›</h5><p>PaGNN(Yang et al. 2021d)é‡‡ç”¨ä¸ªæ€§åŒ–PageRankï¼š</p>
<ul>
<li>å®šä¹‰è½¬ç§»çŸ©é˜µP&#x3D;ADâ»Â¹</li>
<li>è®¡ç®—PPRåˆ†æ•°çŸ©é˜µ $\Pi &#x3D; \alpha(I - (1-\alpha)P)^{-1}$</li>
<li>å°†PPRåˆ†æ•°èå…¥æ³¨æ„åŠ›è®¡ç®—</li>
</ul>
<h5 id="è°±åŸŸæ³¨æ„åŠ›"><a href="#è°±åŸŸæ³¨æ„åŠ›" class="headerlink" title="è°±åŸŸæ³¨æ„åŠ›"></a>è°±åŸŸæ³¨æ„åŠ›</h5><p>MAGNA(Wang et al. 2021)ç»“åˆè°±ç†è®ºï¼š</p>
<ul>
<li>ä½¿ç”¨ä½é€šæ»¤æ³¢å™¨å¹³æ»‘é«˜é¢‘å™ªå£°</li>
<li>æ³¨æ„åŠ›ä¼ æ’­å…¬å¼ $H^{(l+1)} &#x3D; \sigma(\sum_{k&#x3D;0}^K \beta_k T_k(\tilde{L})H^{(l)}W_k)$ ï¼Œå…¶ä¸­$T_k$ä¸ºåˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼</li>
</ul>
<h3 id="å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ›-Relation-Aware-Attention"><a href="#å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ›-Relation-Aware-Attention" class="headerlink" title="å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ› (Relation-Aware Attention)"></a>å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ› (Relation-Aware Attention)</h3><p>å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ä¸»è¦è§£å†³å›¾ä¸­ä¸åŒç±»å‹å…³ç³»çš„å·®å¼‚åŒ–å¤„ç†é—®é¢˜ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>å…³ç³»ç±»å‹åŒºåˆ†</strong>ï¼šè¯†åˆ«å¹¶åˆ©ç”¨å›¾ä¸­ä¸åŒç±»å‹çš„å…³ç³»ï¼ˆè¾¹ï¼‰</li>
<li><strong>å…³ç³»ç‰¹å®šå‚æ•°</strong>ï¼šä¸ºæ¯ç§å…³ç³»ç±»å‹å­¦ä¹ ç‹¬ç«‹çš„æ³¨æ„åŠ›å‚æ•°</li>
<li><strong>å…³ç³»ç‰¹å¾èåˆ</strong>ï¼šç»“åˆå…³ç³»ç‰¹å¾ä¸èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—</li>
</ol>
<img src="\img\GAT\RelationAwareAttention.png" alt="RelationAwareAttention" width="60%" height="auto">

<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="å¸¦ç¬¦å·å›¾æ³¨æ„åŠ›"><a href="#å¸¦ç¬¦å·å›¾æ³¨æ„åŠ›" class="headerlink" title="å¸¦ç¬¦å·å›¾æ³¨æ„åŠ›"></a>å¸¦ç¬¦å·å›¾æ³¨æ„åŠ›</h5><p>SiGAT(Huang et al. 2019b)é’ˆå¯¹å¸¦ç¬¦å·å›¾æå‡ºï¼š</p>
<ul>
<li>å¹³è¡¡ç†è®ºå»ºæ¨¡ï¼šæœ‹å‹çš„æœ‹å‹æ˜¯æœ‹å‹</li>
<li>çŠ¶æ€ç†è®ºå»ºæ¨¡ï¼šæ•Œäººçš„æœ‹å‹æ˜¯æ•Œäºº</li>
<li>æ³¨æ„åŠ›åˆ†æ•°è®¡ç®— $Î±_{ij} &#x3D; \text{softmax}(\text{MLP}([h_iâ€–h_jâ€–r_{ij}]))$, å…¶ä¸­$r_{ij}$è¡¨ç¤ºè¾¹ç±»å‹ï¼ˆæ­£&#x2F;è´Ÿï¼‰</li>
</ul>
<h5 id="å¼‚æ„å›¾æ³¨æ„åŠ›"><a href="#å¼‚æ„å›¾æ³¨æ„åŠ›" class="headerlink" title="å¼‚æ„å›¾æ³¨æ„åŠ›"></a>å¼‚æ„å›¾æ³¨æ„åŠ›</h5><p>RGAT(Busbridge et al. 2019)å¤„ç†å¼‚æ„å›¾ï¼š</p>
<ul>
<li>å…³ç³»ç‰¹å®šå˜æ¢çŸ©é˜µ $h_i^r &#x3D; W_r h_i$</li>
<li>å…³ç³»æ„ŸçŸ¥æ³¨æ„åŠ› $e_{ij}^r &#x3D; a_r^T[h_i^râ€–h_j^r]$</li>
</ul>
<h3 id="å±‚æ¬¡æ³¨æ„åŠ›-Hierarchical-Attention"><a href="#å±‚æ¬¡æ³¨æ„åŠ›-Hierarchical-Attention" class="headerlink" title="å±‚æ¬¡æ³¨æ„åŠ› (Hierarchical Attention)"></a>å±‚æ¬¡æ³¨æ„åŠ› (Hierarchical Attention)</h3><p>å±‚æ¬¡æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ„å»ºå¤šçº§æ³¨æ„åŠ›ç»“æ„æ¥å¤„ç†å›¾æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>å¤šå±‚æ¬¡ä¿¡æ¯æ•´åˆ</strong>ï¼šåŒæ—¶è€ƒè™‘èŠ‚ç‚¹çº§ã€è·¯å¾„çº§å’Œå›¾çº§ä¿¡æ¯</li>
<li><strong>åˆ†å±‚æ³¨æ„åŠ›è®¡ç®—</strong>ï¼šåœ¨ä¸åŒå±‚æ¬¡åº”ç”¨ä¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶</li>
<li><strong>ä¿¡æ¯æµåŠ¨æ§åˆ¶</strong>ï¼šè®¾è®¡ä¿¡æ¯ä»ä½å±‚å‘é«˜å±‚çš„ä¼ é€’æ–¹å¼</li>
</ol>
<img src="\img\GAT\HierachicalAttention.png" alt="HierachicalAttention" width="60%" height="auto">

<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•-1"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•-1" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="èŠ‚ç‚¹-è¯­ä¹‰åŒå±‚æ¬¡æ³¨æ„åŠ›"><a href="#èŠ‚ç‚¹-è¯­ä¹‰åŒå±‚æ¬¡æ³¨æ„åŠ›" class="headerlink" title="èŠ‚ç‚¹-è¯­ä¹‰åŒå±‚æ¬¡æ³¨æ„åŠ›"></a>èŠ‚ç‚¹-è¯­ä¹‰åŒå±‚æ¬¡æ³¨æ„åŠ›</h5><p>HAN(Wang et al. 2019d)æå‡ºï¼š</p>
<ul>
<li><strong>èŠ‚ç‚¹çº§æ³¨æ„åŠ›</strong>ï¼šå­¦ä¹ åŒä¸€å…ƒè·¯å¾„ä¸‹èŠ‚ç‚¹çš„é‡è¦æ€§ $h_iâ€™ &#x3D; \sum_{j\in N_i} \alpha_{ij}h_j$</li>
<li><strong>è¯­ä¹‰çº§æ³¨æ„åŠ›</strong>ï¼šå­¦ä¹ ä¸åŒå…ƒè·¯å¾„çš„é‡è¦æ€§ $Z &#x3D; \sum_{m&#x3D;1}^M \beta_m \cdot Z_m$</li>
</ul>
<h5 id="å¤šç²’åº¦å±‚æ¬¡æ³¨æ„åŠ›"><a href="#å¤šç²’åº¦å±‚æ¬¡æ³¨æ„åŠ›" class="headerlink" title="å¤šç²’åº¦å±‚æ¬¡æ³¨æ„åŠ›"></a>å¤šç²’åº¦å±‚æ¬¡æ³¨æ„åŠ›</h5><p>GraphHAM(Lin et al. 2022)è®¾è®¡ï¼š</p>
<ul>
<li>å±€éƒ¨ç²’åº¦æ³¨æ„åŠ›ï¼šæ•æ‰èŠ‚ç‚¹é‚»åŸŸç‰¹å¾</li>
<li>å…¨å±€ç²’åº¦æ³¨æ„åŠ›ï¼šæ•æ‰å›¾ç»“æ„ç‰¹å¾</li>
<li>è·¨ç²’åº¦æ³¨æ„åŠ›ï¼šåè°ƒä¸åŒç²’åº¦ä¿¡æ¯</li>
</ul>
<h5 id="åŠ¨æ€å±‚æ¬¡æ³¨æ„åŠ›"><a href="#åŠ¨æ€å±‚æ¬¡æ³¨æ„åŠ›" class="headerlink" title="åŠ¨æ€å±‚æ¬¡æ³¨æ„åŠ›"></a>åŠ¨æ€å±‚æ¬¡æ³¨æ„åŠ›</h5><p>RGHAT(Zhang et al. 2020c)å®ç°ï¼š</p>
<ul>
<li><strong>åº•å±‚å®ä½“æ³¨æ„åŠ›</strong>ï¼šå¤„ç†èŠ‚ç‚¹ç‰¹å¾ $e_{ij} &#x3D; a(h_i,h_j)$</li>
<li><strong>é«˜å±‚å…³ç³»æ³¨æ„åŠ›</strong>ï¼šå¤„ç†è¾¹ç±»å‹ç‰¹å¾ $r_k &#x3D; \sum_{i,j} \beta_{ij}^k e_{ij}$</li>
</ul>
<h2 id="å±‚é—´æ³¨æ„åŠ›-Inter-Layer-GAT"><a href="#å±‚é—´æ³¨æ„åŠ›-Inter-Layer-GAT" class="headerlink" title="å±‚é—´æ³¨æ„åŠ› (Inter-Layer GAT)"></a>å±‚é—´æ³¨æ„åŠ› (Inter-Layer GAT)</h2><p>åœ¨ç¥ç»ç½‘ç»œå±‚ä¹‹é—´ï¼Œè·¨å±‚GATé€šè¿‡ç‰¹å¾èåˆæ–¹æ³•å°†ä¸åŒç‰¹å¾ç©ºé—´çš„è¡¨ç¤ºç»“åˆèµ·æ¥ã€‚æ ¹æ®ä¸åŒçš„èåˆæ–¹æ³•ï¼Œæˆ‘ä»¬å°†è¿™äº›åŸºäºæ³¨æ„åŠ›çš„GNNåˆ†ä¸ºäº”ä¸ªå­ç±»åˆ«ï¼ŒåŒ…æ‹¬å¤šçº§æ³¨æ„åŠ›ã€å¤šé€šé“æ³¨æ„åŠ›ã€å¤šè§†å›¾æ³¨æ„åŠ›å’Œæ—¶ç©ºæ³¨æ„åŠ›ã€‚</p>
<h3 id="å¤šçº§æ³¨æ„åŠ›-Multi-Level-Attention"><a href="#å¤šçº§æ³¨æ„åŠ›-Multi-Level-Attention" class="headerlink" title="å¤šçº§æ³¨æ„åŠ› (Multi-Level Attention)"></a>å¤šçº§æ³¨æ„åŠ› (Multi-Level Attention)</h3><p>å¤šçº§æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ„å»ºå¤šçº§æ³¨æ„åŠ›ç»“æ„æ¥å¤„ç†å›¾æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>å±‚æ¬¡åŒ–ä¿¡æ¯å¤„ç†</strong>ï¼šå°†å›¾æ•°æ®åˆ†è§£ä¸ºä¸åŒå±‚æ¬¡çš„æŠ½è±¡è¡¨ç¤º</li>
<li><strong>è·¨å±‚æ¬¡ä¿¡æ¯äº¤äº’</strong>ï¼šåœ¨ä¸åŒå±‚æ¬¡é—´å»ºç«‹æ³¨æ„åŠ›è¿æ¥</li>
<li><strong>è‡ªé€‚åº”æƒé‡åˆ†é…</strong>ï¼šè‡ªåŠ¨å­¦ä¹ å„å±‚æ¬¡å¯¹æœ€ç»ˆä»»åŠ¡çš„é‡è¦æ€§</li>
</ol>
<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•-2"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•-2" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="èŠ‚ç‚¹-è·¯å¾„åŒå±‚æ¬¡æ³¨æ„åŠ›"><a href="#èŠ‚ç‚¹-è·¯å¾„åŒå±‚æ¬¡æ³¨æ„åŠ›" class="headerlink" title="èŠ‚ç‚¹-è·¯å¾„åŒå±‚æ¬¡æ³¨æ„åŠ›"></a>èŠ‚ç‚¹-è·¯å¾„åŒå±‚æ¬¡æ³¨æ„åŠ›</h5><p>DAGNN(Liu et al. 2020)æå‡ºï¼š</p>
<ul>
<li><strong>èŠ‚ç‚¹çº§æ³¨æ„åŠ›</strong>ï¼šå­¦ä¹ å±€éƒ¨é‚»åŸŸå†…èŠ‚ç‚¹çš„é‡è¦æ€§ $h_i^{(l)} &#x3D; \sum_{j\in N_i} \alpha_{ij}^{(l)} h_j^{(l-1)}$</li>
<li><strong>è·¯å¾„çº§æ³¨æ„åŠ›</strong>ï¼šå­¦ä¹ ä¸åŒä¼ æ’­æ·±åº¦çš„é‡è¦æ€§ $z_i &#x3D; \sum_{l&#x3D;0}^L \beta_l h_i^{(l)}$</li>
</ul>
<h5 id="è‡ªé€‚åº”æ·±åº¦æ³¨æ„åŠ›"><a href="#è‡ªé€‚åº”æ·±åº¦æ³¨æ„åŠ›" class="headerlink" title="è‡ªé€‚åº”æ·±åº¦æ³¨æ„åŠ›"></a>è‡ªé€‚åº”æ·±åº¦æ³¨æ„åŠ›</h5><p>TDGNN(Wang and Derr 2021)è®¾è®¡ï¼š</p>
<ul>
<li>åŠ¨æ€è°ƒæ•´å„å±‚çš„æ³¨æ„åŠ›èŒƒå›´</li>
<li>åŸºäºæ ‘åˆ†è§£çš„å±‚æ¬¡åŒ–æ³¨æ„åŠ›</li>
<li>è·¨å±‚ä¿¡æ¯èåˆæœºåˆ¶</li>
</ul>
<h5 id="è·³è·ƒçŸ¥è¯†æ¶æ„"><a href="#è·³è·ƒçŸ¥è¯†æ¶æ„" class="headerlink" title="è·³è·ƒçŸ¥è¯†æ¶æ„"></a>è·³è·ƒçŸ¥è¯†æ¶æ„</h5><p>GAMLP(Zhang et al. 2022c)å®ç°ï¼š</p>
<ul>
<li>åº•å±‚å±€éƒ¨æ³¨æ„åŠ›</li>
<li>ä¸­å±‚åŒºåŸŸæ³¨æ„åŠ›</li>
<li>é«˜å±‚å…¨å±€æ³¨æ„åŠ›</li>
<li>è·³è·ƒè¿æ¥æ•´åˆå„å±‚ç‰¹å¾</li>
</ul>
<h3 id="å¤šé€šé“æ³¨æ„åŠ›-Multi-Channel-Attention"><a href="#å¤šé€šé“æ³¨æ„åŠ›-Multi-Channel-Attention" class="headerlink" title="å¤šé€šé“æ³¨æ„åŠ› (Multi-Channel Attention)"></a>å¤šé€šé“æ³¨æ„åŠ› (Multi-Channel Attention)</h3><p>å¤šé€šé“æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ„å»ºå¹¶è¡Œæ³¨æ„åŠ›é€šé“æ¥å¤„ç†å›¾æ•°æ®ä¸­çš„å¤šæ ·åŒ–ç‰¹å¾ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>é€šé“å¤šæ ·åŒ–</strong>ï¼šå°†è¾“å…¥ç‰¹å¾åˆ†è§£ä¸ºå¤šä¸ªç‰¹å¾é€šé“</li>
<li><strong>é€šé“ç‰¹å¼‚æ€§</strong>ï¼šä¸ºæ¯ä¸ªé€šé“è®¾è®¡ç‹¬ç«‹çš„æ³¨æ„åŠ›æœºåˆ¶</li>
<li><strong>é€šé“èåˆ</strong>ï¼šè‡ªé€‚åº”åœ°æ•´åˆä¸åŒé€šé“çš„ä¿¡æ¯</li>
</ol>
<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•-3"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•-3" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="é¢‘ç‡è‡ªé€‚åº”æ³¨æ„åŠ›"><a href="#é¢‘ç‡è‡ªé€‚åº”æ³¨æ„åŠ›" class="headerlink" title="é¢‘ç‡è‡ªé€‚åº”æ³¨æ„åŠ›"></a>é¢‘ç‡è‡ªé€‚åº”æ³¨æ„åŠ›</h5><p>FAGCN(Bo et al. 2021)æå‡ºï¼š</p>
<ul>
<li>ä½é¢‘é€šé“ï¼šæ•æ‰èŠ‚ç‚¹ç›¸ä¼¼æ€§ $h_{low} &#x3D; \sum_{j\in N_i} \frac{1}{\sqrt{d_i d_j}} h_j$</li>
<li>é«˜é¢‘é€šé“ï¼šæ•æ‰èŠ‚ç‚¹å·®å¼‚æ€§ $h_{high} &#x3D; \sum_{j\in N_i} -\frac{1}{\sqrt{d_i d_j}} h_j$</li>
<li>è‡ªé€‚åº”èåˆï¼š $h_i &#x3D; \alpha_{low} h_{low} + \alpha_{high} h_{high}$</li>
</ul>
<h5 id="è‡ªé€‚åº”é€šé“æ··åˆ"><a href="#è‡ªé€‚åº”é€šé“æ··åˆ" class="headerlink" title="è‡ªé€‚åº”é€šé“æ··åˆ"></a>è‡ªé€‚åº”é€šé“æ··åˆ</h5><p>ACM(Luan et al. 2021)è®¾è®¡ï¼š</p>
<ul>
<li>å¤šé€šé“ç‰¹å¾æå–</li>
<li>é€šé“é—´æ³¨æ„åŠ›äº¤äº’</li>
<li>åŠ¨æ€é€šé“æƒé‡åˆ†é…</li>
</ul>
<h5 id="ä¸ç¡®å®šæ€§æ„ŸçŸ¥é€šé“"><a href="#ä¸ç¡®å®šæ€§æ„ŸçŸ¥é€šé“" class="headerlink" title="ä¸ç¡®å®šæ€§æ„ŸçŸ¥é€šé“"></a>ä¸ç¡®å®šæ€§æ„ŸçŸ¥é€šé“</h5><p>UAG(Feng et al. 2021)å®ç°ï¼š</p>
<ul>
<li>é€šé“ä¸ç¡®å®šæ€§ä¼°è®¡</li>
<li>åŸºäºä¸ç¡®å®šæ€§çš„é€šé“æ³¨æ„åŠ›</li>
<li>é²æ£’æ€§é€šé“èåˆ</li>
</ul>
<h3 id="å¤šè§†è§’æ³¨æ„åŠ›-Multi-View-Attention"><a href="#å¤šè§†è§’æ³¨æ„åŠ›-Multi-View-Attention" class="headerlink" title="å¤šè§†è§’æ³¨æ„åŠ› (Multi-View Attention)"></a>å¤šè§†è§’æ³¨æ„åŠ› (Multi-View Attention)</h3><p>å¤šè§†è§’æ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ„å»ºå¹¶è¡Œæ³¨æ„åŠ›è§†è§’æ¥å¤„ç†å›¾æ•°æ®ä¸­çš„å¤šæ ·åŒ–ä¿¡æ¯ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li><strong>è§†è§’å¤šæ ·åŒ–</strong>ï¼šä»ä¸åŒè§’åº¦ï¼ˆå¦‚æ‹“æ‰‘ç»“æ„ã€èŠ‚ç‚¹ç‰¹å¾ã€æ—¶é—´åºåˆ—ç­‰ï¼‰æ„å»ºå¤šä¸ªè§†è§’</li>
<li><strong>è§†è§’ç‰¹å¼‚æ€§</strong>ï¼šä¸ºæ¯ä¸ªè§†è§’è®¾è®¡ç‹¬ç«‹çš„æ³¨æ„åŠ›æœºåˆ¶</li>
<li><strong>è§†è§’èåˆ</strong>ï¼šè‡ªé€‚åº”åœ°æ•´åˆä¸åŒè§†è§’çš„ä¿¡æ¯</li>
</ol>
<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•-4"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•-4" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="ç»“æ„-ç‰¹å¾åŒè§†è§’æ³¨æ„åŠ›"><a href="#ç»“æ„-ç‰¹å¾åŒè§†è§’æ³¨æ„åŠ›" class="headerlink" title="ç»“æ„-ç‰¹å¾åŒè§†è§’æ³¨æ„åŠ›"></a>ç»“æ„-ç‰¹å¾åŒè§†è§’æ³¨æ„åŠ›</h5><p>AM-GCN(Wang et al. 2020b)æå‡ºï¼š</p>
<ul>
<li>æ‹“æ‰‘è§†è§’ï¼šåŸºäºå›¾ç»“æ„çš„é‚»æ¥çŸ©é˜µ $A_{topo} &#x3D; A$</li>
<li>ç‰¹å¾è§†è§’ï¼šåŸºäºèŠ‚ç‚¹ç‰¹å¾çš„ç›¸ä¼¼åº¦çŸ©é˜µ $A_{feat} &#x3D; \text{sim}(X,X^T)$</li>
<li>æ³¨æ„åŠ›èåˆï¼š $A_{final} &#x3D; \sum_{v\in{topo,feat}} w_v A_v$</li>
</ul>
<h3 id="æ—¶ç©ºæ³¨æ„åŠ›-Spatio-Temporal-Attention"><a href="#æ—¶ç©ºæ³¨æ„åŠ›-Spatio-Temporal-Attention" class="headerlink" title="æ—¶ç©ºæ³¨æ„åŠ› (Spatio-Temporal Attention)"></a>æ—¶ç©ºæ³¨æ„åŠ› (Spatio-Temporal Attention)</h3><p>æ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶é€šè¿‡æ„å»ºå¹¶è¡Œæ³¨æ„åŠ›æ¨¡å—æ¥å¤„ç†å›¾æ•°æ®ä¸­çš„ç©ºé—´å’Œæ—¶é—´ä¾èµ–æ€§ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š</p>
<ol>
<li>ç©ºé—´ä¾èµ–æ€§ï¼šæ•æ‰èŠ‚ç‚¹é—´çš„æ‹“æ‰‘å…³ç³»</li>
<li>æ—¶é—´ä¾èµ–æ€§ï¼šå»ºæ¨¡åŠ¨æ€å›¾ä¸­çš„æ—¶åºæ¼”åŒ–æ¨¡å¼</li>
<li>æ—¶ç©ºäº¤äº’ï¼šè”åˆå»ºæ¨¡æ—¶ç©ºç»´åº¦çš„ç›¸äº’å½±å“</li>
</ol>
<h4 id="å…³é”®æŠ€æœ¯æ–¹æ³•-5"><a href="#å…³é”®æŠ€æœ¯æ–¹æ³•-5" class="headerlink" title="å…³é”®æŠ€æœ¯æ–¹æ³•"></a>å…³é”®æŠ€æœ¯æ–¹æ³•</h4><h5 id="ç©ºé—´-æ—¶é—´åŒæ³¨æ„åŠ›"><a href="#ç©ºé—´-æ—¶é—´åŒæ³¨æ„åŠ›" class="headerlink" title="ç©ºé—´-æ—¶é—´åŒæ³¨æ„åŠ›"></a>ç©ºé—´-æ—¶é—´åŒæ³¨æ„åŠ›</h5><p>DySAT(Sankar et al. 2018)æå‡ºï¼š</p>
<ul>
<li>ç©ºé—´æ³¨æ„åŠ›ï¼šåŸºäºå½“å‰å¿«ç…§çš„å›¾ç»“æ„ $A_{spatial} &#x3D; \text{softmax}(Q_s K_s^T&#x2F;\sqrt{d})$</li>
<li>æ—¶é—´æ³¨æ„åŠ›ï¼šåŸºäºèŠ‚ç‚¹çš„æ—¶é—´åºåˆ— $A_{temporal} &#x3D; \text{softmax}(Q_t K_t^T&#x2F;\sqrt{d})$</li>
<li>è”åˆå»ºæ¨¡ï¼š $Z &#x3D; (A_{spatial} \oplus A_{temporal})V$</li>
</ul>
<h3 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h3><p><a href="/paper/Lee ç­‰ - 2018 - Attention Models in Graphs A Survey.pdf" target="_blank">ğŸ“„ Lee ç­‰ - 2018 - Attention Models in Graphs A Survey</a></p>
<a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/github.svg" alt="github" style="height: 1.3em; vertical-align: middle; margin-top: 16px;">
  </span>
  External-Attention-pytorch
</a>

<p><a href="/paper/Sun ç­‰ - 2023 - Attention-based graph neural networks a survey.pdf" target="_blank">ğŸ“„ Sun ç­‰ - 2023 - Attention-based graph neural networks a survey</a></p>
<a href="https://disassemble-channel.com/graph-attention-network-gat/" target="_blank">
  <span style="display: inline-block; vertical-align: middle;">
    <img src="/icon/google.svg" alt="github" style="height: 1.3em; vertical-align: middle; margin-top: 16px;">
  </span>
  ã€æ·±å±¤å­¦ç¿’ã€‘Graph Attention Networks(GAT)ã‚’ç†è§£ã™ã‚‹
</a> 
]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
        <category>graph</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
        <tag>PyTorch</tag>
        <tag>graph theory</tag>
      </tags>
  </entry>
  <entry>
    <title>CDR Input Data Analysis</title>
    <url>/2025/07/09/CDR-data-analysis/</url>
    <content><![CDATA[<h1 id="CDR-æ•°æ®æºåˆ†æ"><a href="#CDR-æ•°æ®æºåˆ†æ" class="headerlink" title="CDR æ•°æ®æºåˆ†æ"></a>CDR æ•°æ®æºåˆ†æ</h1><p>æœ¬æ–‡ä¸»è¦æ˜¯ä»‹ç»ä¸€ä¸‹ <strong>æ·±åº¦å­¦ä¹ </strong> åœ¨ <em>è¯ç‰©ååº”é¢„æµ‹</em> ä¸­è¿ç”¨åˆ°çš„æ•°æ®æºã€‚<del>ä½†ç”±äºæœ¬äººæ¯”è¾ƒæ</del> æœ¬æ–‡ä¸»è¦ä» <strong>æ·±åº¦å­¦ä¹ </strong> è§’åº¦æ¥çœ‹å¾…è¿™äº›æ•°æ®æºï¼Œå¯¹å…¶åœ¨åŒ»å­¦æ–¹é¢çš„æ„ä¹‰<del>ï¼ˆä¸»è¦æ˜¯é¼ é¼ ä¹Ÿä¸ä¼šæï¼‰</del>ä¸ä¼šæœ‰å¤ªå¤šçš„æè¿°</p>
<span id="more"></span>

<h2 id="CDR-Cancer-Drug-Response"><a href="#CDR-Cancer-Drug-Response" class="headerlink" title="CDR &#x3D; Cancer Drug Response"></a>CDR &#x3D; Cancer Drug Response</h2><p>æˆ‘ä»¬çš„æ•°æ®æºæœ‰ä¸‰ç§ï¼š</p>
<ul>
<li><em>Cancer Representations</em>ï¼ˆç™Œç—‡ç‰¹å¾çš„è¡¨ç¤ºï¼‰</li>
<li><em>Representations of Drug Compounds</em>ï¼ˆè¯ç‰©ç‰¹å¾çš„è¡¨ç¤ºï¼‰</li>
<li><em>Representations of Treatment Response</em>ï¼ˆæ²»ç–—å“åº”çš„è¡¨ç¤ºï¼‰</li>
</ul>
<p>æ¥ä¸‹æ¥ä¼šæŒ‰é¡ºåºè¿›è¡Œè¯´æ˜</p>
<hr>
<h3 id="Cancer-Representations"><a href="#Cancer-Representations" class="headerlink" title="Cancer Representations"></a>Cancer Representations</h3><p>ç™Œç—‡çš„ç‰¹å¾æ˜¯å¤šç»„å­¦çš„ <del>è¿™ä¸æ˜¯ç†æ‰€åº”å½“å—</del></p>
<h4 id="å¤šç»„å­¦ç±»å‹"><a href="#å¤šç»„å­¦ç±»å‹" class="headerlink" title="å¤šç»„å­¦ç±»å‹"></a>å¤šç»„å­¦ç±»å‹</h4><p>é€šå¸¸åŸºäºä»¥ä¸‹å››ç±»ç»„å­¦æ•°æ®ï¼š</p>
<ul>
<li><p>åŸºå› ç»„ï¼ˆGenomicï¼‰</p>
<ul>
<li>çªå˜ï¼ˆMutationï¼‰ï¼šä½“ç»†èƒçªå˜ï¼ˆå¦‚å•æ ¸è‹·é…¸å˜å¼‚ SNVsï¼‰å¯èƒ½é©±åŠ¨ç™Œç—‡è¿›å±•ï¼Œå¹¶å½±å“è¯ç‰©é¶ç‚¹ã€‚</li>
<li>æ‹·è´æ•°å˜å¼‚ï¼ˆCNVï¼‰ï¼šåŸºå› æ‹·è´æ•°çš„å¢åŠ æˆ–ç¼ºå¤±å¯èƒ½å½±å“è¯ç‰©æ•æ„Ÿæ€§ï¼ˆå¦‚ HER2 æ‰©å¢ä¸æ›²å¦¥ç å•æŠ—ç–—æ•ˆç›¸å…³ï¼‰ã€‚</li>
</ul>
</li>
<li><p>è½¬å½•ç»„ï¼ˆTranscriptomicï¼‰</p>
<ul>
<li>åŸºå› è¡¨è¾¾ï¼ˆGene Expressionï¼‰ï¼šé€šè¿‡å¾®é˜µåˆ—æˆ– RNA æµ‹åºï¼ˆRNA-Seqï¼‰é‡åŒ–åŸºå› çš„ mRNA æ°´å¹³ã€‚ä¾‹å¦‚ï¼Œé«˜è¡¨è¾¾çš„è€è¯åŸºå› å¯èƒ½é¢„ç¤ºæ²»ç–—å¤±è´¥ã€‚</li>
</ul>
</li>
<li><p>è¡¨è§‚ç»„ï¼ˆEpigenomicï¼‰</p>
<ul>
<li>DNA ç”²åŸºåŒ–ï¼ˆMethylationï¼‰ï¼šå¯åŠ¨å­åŒºåŸŸçš„ç”²åŸºåŒ–å¯èƒ½æ²‰é»˜æŠ‘ç™ŒåŸºå› ï¼Œå½±å“è¯ç‰©ååº”ã€‚</li>
</ul>
</li>
<li><p>è›‹ç™½è´¨ç»„ï¼ˆProteomicï¼‰</p>
<ul>
<li>è›‹ç™½è´¨è¡¨è¾¾ï¼ˆRPPA ç­‰ï¼‰ï¼šç›´æ¥æµ‹é‡è›‹ç™½è´¨ä¸°åº¦ï¼ˆå¦‚æ¿€é…¶æ´»æ€§ï¼‰ï¼Œæ›´æ¥è¿‘åŠŸèƒ½è¡¨å‹ã€‚</li>
</ul>
</li>
</ul>
<p>å¯¹äºåŒä¸€ç§ç»„å­¦æ•°æ®ï¼Œä»–ä»¬è¢«è¡¨ç¤ºæˆä¸€ç»„ <strong>ç»´æ•°ç›¸åŒçš„å‘é‡</strong></p>
<h4 id="é¢„å¤„ç†ä¸æ•´åˆ"><a href="#é¢„å¤„ç†ä¸æ•´åˆ" class="headerlink" title="é¢„å¤„ç†ä¸æ•´åˆ"></a>é¢„å¤„ç†ä¸æ•´åˆ</h4><ol>
<li>æ•°æ®é¢„å¤„ç†</li>
</ol>
<ul>
<li>åŒ…æ‹¬æ ‡å‡†åŒ–ï¼ˆnormalizationï¼‰ã€æ‰¹æ¬¡æ•ˆåº”æ ¡æ­£ï¼ˆbatch effect correctionï¼‰å’Œè´¨é‡æ§åˆ¶ï¼ˆQCï¼‰ã€‚ä¾‹å¦‚ï¼ŒRNA-Seq æ•°æ®éœ€é€šè¿‡ RPKM æˆ– TPM æ ‡å‡†åŒ–ã€‚</li>
</ul>
<ol start="2">
<li>å¤šç»„å­¦æ•´åˆæ–¹æ³• ï¼š<ul>
<li>æ—©æœŸæ•´åˆï¼ˆEarly Integrationï¼‰ï¼šç›´æ¥æ‹¼æ¥ä¸åŒç»„å­¦ç‰¹å¾ä¸ºå•ä¸€å‘é‡ï¼Œä½†å¯èƒ½å› ç»´åº¦ç¾éš¾ï¼ˆcurse of dimensionalityï¼‰å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li>
<li>æ™šæœŸæ•´åˆï¼ˆLate Integrationï¼‰ï¼šé€šè¿‡ç‹¬ç«‹å­ç½‘ç»œå¤„ç†æ¯ç»„å­¦æ•°æ®ï¼ˆå¦‚ CNN å¤„ç†çªå˜ï¼ŒGNN å¤„ç†è¡¨è¾¾æ•°æ®ï¼‰ï¼Œå†èåˆç‰¹å¾ã€‚ä¾‹å¦‚ï¼ŒMOLI æ¨¡å‹é€šè¿‡ä¸‰é‡æŸå¤±å‡½æ•°æ•´åˆå¤šç»„å­¦æ•°æ®ï¼Œæ˜¾è‘—æå‡è·¨ç™Œç—‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿"><a href="#åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿" class="headerlink" title="åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿"></a>åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿</h4><blockquote>
<p>2014 å¹´ NCI-DREAM æŒ‘æˆ˜èµ›è¡¨æ˜ï¼Œ åŸºå› è¡¨è¾¾æ•°æ®åœ¨é¢„æµ‹ä¹³è…ºç™Œç»†èƒç³»è¯ç‰©æ•æ„Ÿæ€§æ—¶æœ€å…·é¢„æµ‹åŠ›ï¼ˆä¼˜äºçªå˜æˆ– CNVï¼‰ã€‚å› æ­¤ï¼Œçº¦ 90%çš„ DRP æ¨¡å‹ä½¿ç”¨åŸºå› è¡¨è¾¾ï¼ˆå•ç‹¬æˆ–è”åˆå…¶ä»–ç»„å­¦ï¼‰<br><img src="/img/CDR-data-analysis/gene.png" alt="gene" width="50%"></p>
</blockquote>
<h5 id="æ–°å…´è¶‹åŠ¿"><a href="#æ–°å…´è¶‹åŠ¿" class="headerlink" title="æ–°å…´è¶‹åŠ¿"></a>æ–°å…´è¶‹åŠ¿</h5><ol>
<li><strong>ç»“æ„ç”Ÿç‰©å­¦æ•´åˆ</strong>ï¼šå¦‚åˆ©ç”¨è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ï¼ˆPPIï¼‰ç½‘ç»œï¼ˆSTRING æ•°æ®åº“ï¼‰æˆ–é€šè·¯ä¿¡æ¯ï¼ˆGSEAï¼‰æ„å»ºç”Ÿç‰©ç½‘ç»œï¼Œå¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§ã€‚</li>
<li><strong>å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰</strong>ï¼šå°†åŸºå› è§†ä¸ºèŠ‚ç‚¹ã€ç›¸äº’ä½œç”¨ä¸ºè¾¹ï¼Œå­¦ä¹ æ‹“æ‰‘ç‰¹å¾ï¼ˆå¦‚ GraOmicDRP æ¨¡å‹ï¼‰ã€‚</li>
</ol>
<hr>
<h3 id="Representations-of-Drug-Compounds"><a href="#Representations-of-Drug-Compounds" class="headerlink" title="Representations of Drug Compounds"></a>Representations of Drug Compounds</h3><p>å¯¹è¯ç‰©çš„è¡¨ç¤ºä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼Œä¸€èˆ¬åªé€‰å–å…¶ä¸­çš„ä¸€ç§ <del>è™½ç„¶ä¹Ÿæœ‰é€‰ç”¨å‡ ç§çš„ <strong>åˆ›æ–°</strong> æ–¹å¼</del>ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨é€‰å®šè¯ç‰©çš„è¡¨ç¤ºæ–¹å¼åï¼Œä¹‹åçš„ç‰¹å¾å·¥ç¨‹çš„æ–¹å¼ç›®å‰æ¥çœ‹éå¸¸çš„ç»Ÿä¸€ã€‚æ¥ä¸‹æ¥ä¸€ä¸€è¯´æ˜æ¯ä¸€ç§è¡¨ç¤ºæ–¹å¼ã€‚</p>
<h4 id="SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰"><a href="#SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰" class="headerlink" title="SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰"></a>SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰</h4><ol>
<li><em>å®šä¹‰</em>ï¼šSMILES æ˜¯ä¸€ç§<strong>çº¿æ€§å­—ç¬¦ä¸²</strong>è¡¨ç¤ºæ³•ï¼Œé€šè¿‡ç¬¦å·ç¼–ç åˆ†å­ç»“æ„ï¼ˆå¦‚<code>CCO</code>è¡¨ç¤ºä¹™é†‡ï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼š<ul>
<li>æ˜“äºå­˜å‚¨å’Œå¤„ç†ï¼Œå¹¿æ³›ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦å·¥å…·ï¼ˆå¦‚ RDKitï¼‰ã€‚</li>
<li>å¯ç›´æ¥ç”¨äºåºåˆ—æ¨¡å‹ï¼ˆå¦‚ RNNã€Transformerï¼‰æˆ–é€šè¿‡é¢„å¤„ç†è½¬æ¢ä¸ºå…¶ä»–è¡¨ç¤ºï¼ˆå¦‚å›¾ç»“æ„ï¼‰ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åˆ†å­æŒ‡çº¹ï¼ˆFingerprints-FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰"><a href="#åˆ†å­æŒ‡çº¹ï¼ˆFingerprints-FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰" class="headerlink" title="åˆ†å­æŒ‡çº¹ï¼ˆFingerprints, FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰"></a>åˆ†å­æŒ‡çº¹ï¼ˆFingerprints, FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰</h4><ol>
<li><p>åˆ†å­æŒ‡çº¹</p>
<ul>
<li><em>å®šä¹‰</em>ï¼š<strong>äºŒè¿›åˆ¶å‘é‡</strong>ï¼Œè¡¨ç¤ºåˆ†å­ä¸­æ˜¯å¦å­˜åœ¨ç‰¹å®šå­ç»“æ„ï¼ˆå¦‚è¯æ•ˆå›¢æˆ–å®˜èƒ½å›¢ï¼‰ã€‚</li>
<li><em>å¸¸ç”¨ç±»å‹</em>ï¼š<ul>
<li><strong>Morgan æŒ‡çº¹ï¼ˆECFPï¼‰</strong>ï¼šåŸºäºåŸå­é‚»åŸŸçš„åœ†å½¢æ‹“æ‰‘æŒ‡çº¹ï¼Œé•¿åº¦é€šå¸¸ä¸º 512 æˆ– 1024 ä½ã€‚</li>
<li><strong>RDKit æŒ‡çº¹</strong>ï¼šå¼€æºå·¥å…·ç”Ÿæˆçš„äºŒè¿›åˆ¶æŒ‡çº¹ã€‚</li>
</ul>
</li>
<li><em>ä¼˜åŠ¿</em>ï¼šå›ºå®šé•¿åº¦ï¼Œé€‚åˆä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚éšæœºæ£®æ—ï¼‰ã€‚</li>
</ul>
</li>
<li><p>åˆ†å­æè¿°ç¬¦</p>
<ul>
<li><em>å®šä¹‰</em>ï¼š<strong>æ•°å€¼å‘é‡</strong>ï¼Œç¼–ç ç‰©ç†åŒ–å­¦æ€§è´¨ï¼ˆå¦‚åˆ†å­é‡ã€ç–æ°´æ€§ã€ææ€§è¡¨é¢ç§¯ç­‰ï¼‰ã€‚</li>
<li><em>å·¥å…·</em>ï¼šPaDELã€Mordredã€Dragon ç­‰è½¯ä»¶å¯è‡ªåŠ¨è®¡ç®—æ•°ç™¾è‡³æ•°åƒä¸ªæè¿°ç¬¦ã€‚</li>
</ul>
</li>
</ol>
<h4 id="å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based-Representationsï¼‰"><a href="#å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based-Representationsï¼‰" class="headerlink" title="å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based Representationsï¼‰"></a>å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based Representationsï¼‰</h4><ol>
<li><em>å®šä¹‰</em> ï¼šå°†åˆ†å­è¡¨ç¤ºä¸º<strong>å›¾</strong>ï¼Œå…¶ä¸­åŸå­ä¸º<strong>èŠ‚ç‚¹</strong>ï¼ŒåŒ–å­¦é”®ä¸º<strong>è¾¹</strong>ï¼ŒèŠ‚ç‚¹å’Œè¾¹å¯é™„åŠ å±æ€§ï¼ˆå¦‚åŸå­ç±»å‹ã€é”®ç±»å‹ï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em> ï¼š<ul>
<li>æ›´è‡ªç„¶åœ°è¡¨å¾åˆ†å­æ‹“æ‰‘ç»“æ„ï¼Œé€‚åˆå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ã€‚</li>
<li>å¯æ•æ‰å±€éƒ¨å’Œå…¨å±€åˆ†å­ç‰¹å¾ï¼ˆå¦‚å®˜èƒ½å›¢ç›¸äº’ä½œç”¨ï¼‰ã€‚</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Representations-of-Treatment-Response"><a href="#Representations-of-Treatment-Response" class="headerlink" title="Representations of Treatment Response"></a>Representations of Treatment Response</h3><p>ä»æ„é€ æ¨¡å‹çš„è§’åº¦å‡ºå‘ï¼Œè¿™æ˜¯ DRP çš„æ ¸å¿ƒæ•°æ®æº</p>
<ul>
<li>å®ƒå†³å®šäº†æ¨¡å‹æœ€åå®Œæˆçš„<strong>ä»»åŠ¡ç±»å‹</strong>ï¼šè®­ç»ƒè¿ç»­å€¼çš„<strong>å›å½’ä»»åŠ¡</strong>å’Œè®­ç»ƒç¦»æ•£å€¼çš„<strong>åˆ†ç±»ä»»åŠ¡</strong></li>
<li>ä»–çš„æ•°æ®è´¨é‡å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†æ¨¡å‹çš„ç»“æœçš„ä¼˜åŠ£ï¼Œå³å¯¹è¯¥æ•°æ®æºå¯¹æ¨¡å‹çš„å¥½åå½±å“å¾ˆå¤§</li>
</ul>
<p>æ­¤å¤–ï¼Œå¾ˆå°‘æœ‰ä»æ•°æ®åˆ†æçš„è§’åº¦å‡ºå‘åˆ†æè¿™ä¸ªæ•°æ®æºçš„æ–‡çŒ®ï¼Œäºæ˜¯åœ¨è¿™é‡Œç»™å‡ºç®€è¦çš„è¯´æ˜</p>
<h4 id="è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous-Measuresï¼‰"><a href="#è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous-Measuresï¼‰" class="headerlink" title="è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous Measuresï¼‰"></a>è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous Measuresï¼‰</h4><ol>
<li><p><strong>IC50</strong></p>
<ul>
<li>åŠæ•°æŠ‘åˆ¶æµ“åº¦ï¼Œå³æŠ‘åˆ¶ 50%ç»†èƒæ´»åŠ›æ‰€éœ€çš„è¯ç‰©æµ“åº¦ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šç›´è§‚åæ˜ è¯ç‰©æ•ˆåŠ›ï¼Œå¹¿æ³›ç”¨äºå›å½’æ¨¡å‹ï¼ˆå¦‚é¢„æµ‹ IC50 çš„æ•°å€¼ï¼‰ã€‚</li>
<li><em>å±€é™æ€§</em>ï¼šä»…åæ˜ å•ä¸€æµ“åº¦ç‚¹çš„æ•ˆæœï¼Œå¯èƒ½å¿½ç•¥å‰‚é‡-ååº”æ›²çº¿çš„æ•´ä½“å½¢çŠ¶ã€‚</li>
</ul>
</li>
<li><p><strong>AUC&#x2F;AAC</strong></p>
<ul>
<li>å‰‚é‡-ååº”æ›²çº¿ä¸‹é¢ç§¯ï¼ˆArea Under the Curveï¼‰æˆ–æ›²çº¿ä¸Šé¢ç§¯ï¼ˆActivity Areaï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šå…¨å±€åº¦é‡ï¼Œç»¼åˆæ‰€æœ‰æµ“åº¦ç‚¹çš„æ•ˆæœï¼Œå¯¹å™ªå£°æ›´é²æ£’ã€‚</li>
<li><em>åº”ç”¨</em>ï¼šå¦‚ DeepCDR ç­‰æ¨¡å‹ä½¿ç”¨ AUC ä½œä¸ºå›å½’ç›®æ ‡ï¼Œå®è¯è¡¨æ˜å…¶æ³›åŒ–æ€§ä¼˜äº IC50ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical-Measuresï¼‰"><a href="#åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical-Measuresï¼‰" class="headerlink" title="åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical Measuresï¼‰"></a>åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical Measuresï¼‰</h4><ol>
<li><p><strong>äºŒåˆ†ç±»ï¼ˆæ•æ„Ÿ&#x2F;è€è¯ï¼‰</strong></p>
<ul>
<li>é€šè¿‡é˜ˆå€¼ï¼ˆå¦‚ç€‘å¸ƒç®—æ³•ã€LOBICOï¼‰å°†è¿ç»­ååº”ï¼ˆå¦‚ IC50ï¼‰è½¬åŒ–ä¸ºç¦»æ•£æ ‡ç­¾ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šæ›´è´´è¿‘ä¸´åºŠå†³ç­–éœ€æ±‚ï¼ˆå¦‚é€‰æ‹©æ•æ„Ÿè¯ç‰©ï¼‰ã€‚</li>
<li><em>ç¤ºä¾‹</em>ï¼šSharifi-Noghabi et al. (2021) ä½¿ç”¨äºŒåˆ†ç±»è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼Œé¢„æµ‹æ‚£è€…è‚¿ç˜¤çš„æ•æ„Ÿæ€§ã€‚</li>
</ul>
</li>
<li><p><strong>å¤šåˆ†ç±»</strong></p>
<ul>
<li>å¦‚ä½&#x2F;ä¸­&#x2F;é«˜ååº”æ€§ï¼Œé€‚ç”¨äºæ›´ç»†ç²’åº¦çš„ä¸´åºŠåˆ†çº§ã€‚</li>
</ul>
</li>
</ol>
<h4 id="æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰"><a href="#æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰" class="headerlink" title="æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰"></a>æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰</h4><ol>
<li><p><em>ç›®æ ‡</em></p>
<ul>
<li>ä¸ºä¸ªæ€§åŒ–æ²»ç–—æ¨èè¯ç‰©æ’åºï¼ˆå¦‚ Top-k æœ€æœ‰æ•ˆè¯ç‰©ï¼‰ã€‚</li>
</ul>
</li>
<li><p><em>æ–¹æ³•</em></p>
<ul>
<li>Prasse et al. (2022)ï¼šå°† IC50 è½¬åŒ–ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼Œè®¾è®¡å¯å¾®æ’åºæŸå¤±å‡½æ•°ã€‚</li>
<li>PPORankï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åŠ¨æ€ä¼˜åŒ–æ’åºï¼Œé€‚åº”æ–°å¢æ•°æ®ã€‚</li>
</ul>
</li>
<li><p><em>ä¼˜åŠ¿</em></p>
<ul>
<li>ç›´æ¥æ”¯æŒä¸´åºŠä¼˜å…ˆçº§æ’åºï¼Œä¼˜äºä¼ ç»Ÿå›å½’æˆ–åˆ†ç±»ã€‚</li>
</ul>
</li>
</ol>
<h4 id="æ•°æ®åˆ†æ"><a href="#æ•°æ®åˆ†æ" class="headerlink" title="æ•°æ®åˆ†æ"></a>æ•°æ®åˆ†æ</h4><p>ç”±äºæœ¬äººå¤§æ¦‚ç‡ä¼šåšä¸ªåˆ†ç±»æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šå°†ä¸»è¦åˆ†æçš„æ˜¯<strong>åˆ†ç±»è¡¨ç¤º</strong>çš„æ•°æ®åœ¨<strong>å›¾ç¥ç»ç½‘ç»œ</strong>ä¸­æ¯”è¾ƒé‡è§†çš„å‡ ä¸ªæŒ‡æ ‡ï¼Œè¿™é‡Œåˆ†æ <em>CCLE</em> å’Œ <em>GDSC</em> ä¸¤ä¸ªæ•°æ®é›†åœ¨é€‰ç”¨ä¸»æµé˜ˆå€¼é€‰å–æ–¹æ³•ä¹‹åçš„è¡¨ç¤ºã€‚</p>
<p>ç›´æ¥å…ˆçœ‹ç»“æœæï¼ˆè¿™é‡Œç”»äº†ä¸¤ä¸ªå°å›¾ï¼‰</p>
<ul>
<li>CCLE</li>
</ul>
<img src="/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png" alt="CCLE" style="max-width: 100%; height: auto;">

<ul>
<li>GDSC</li>
</ul>
<img src="/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png" alt="GDSC" style="max-width: 100%; height: auto;">

<p>
  ğŸ‘‰ <a href="/code/data_analysis/visualize_graph_analysis.py" target="_blank">æŸ¥çœ‹ç”¨äºç”Ÿæˆä¸Šè¿°å›¾è¡¨çš„æœ¬åœ° Python è„šæœ¬ï¼švisualize_graph_analysis.py</a>
</p>

<h5 id="ğŸ”-å…³é”®æ•°æ®å¯¹æ¯”"><a href="#ğŸ”-å…³é”®æ•°æ®å¯¹æ¯”" class="headerlink" title="ğŸ” å…³é”®æ•°æ®å¯¹æ¯”"></a>ğŸ” å…³é”®æ•°æ®å¯¹æ¯”</h5><table>
    <tr>
        <td>ç‰¹å¾</td>
        <td>CCLE</td>
        <td>GDSC</td>
        <td>å€æ•°å·®å¼‚</td>
    </tr>
    <tr>
        <td colspan="4" style="text-align: center;"><b>æ•°æ®è§„æ¨¡</b></td>
    </tr>
    <tr>
        <td>æ€»èŠ‚ç‚¹æ•°</td>
        <td>341</td>
        <td>783</td>
        <td>2.3Ã—</td>
    </tr>
    <tr>
        <td>ç¬¬ä¸€ç±»èŠ‚ç‚¹</td>
        <td>317</td>
        <td>561</td>
        <td>1.8Ã—</td>
    </tr>
    <tr>
        <td>ç¬¬äºŒç±»èŠ‚ç‚¹</td>
        <td>24</td>
        <td>222</td>
        <td>9.3Ã—</td>
    </tr>
    <tr>
        <td>æ€»è¾¹æ•°</td>
        <td>7,307</td>
        <td>100,572</td>
        <td>13.8Ã—</td>
    </tr>
    <tr>
        <td colspan="4" style="text-align: center;"><b>å›¾ç»“æ„</b></td>
    </tr>
    <tr>
        <td>å¯†åº¦</td>
        <td>0.9604</td>
        <td>0.8075</td>
        <td>0.84Ã—</td>
    </tr>
    <tr>
        <td>ç¨€ç–æ€§</td>
        <td>0.0396</td>
        <td>0.1925</td>
        <td>4.9Ã—</td>
    </tr>
    <tr>
        <td>å¹³å‡åº¦</td>
        <td>42.86</td>
        <td>256.89</td>
        <td>6.0Ã—</td>
    </tr>
    <tr>
        <td>å›¾ç›´å¾„</td>
        <td>3</td>
        <td>4</td>
        <td>1.3Ã—</td>
    </tr>
    <tr>
        <td colspan="4" style="text-align: center;"><b>è¾¹åˆ†å¸ƒ</b></td>
    </tr>
    <tr>
        <td>æ­£è¾¹æ•°é‡</td>
        <td>1,375</td>
        <td>11,591</td>
        <td>8.4Ã—</td>
    </tr>
    <tr>
        <td>è´Ÿè¾¹æ•°é‡</td>
        <td>5,932</td>
        <td>88,981</td>
        <td>15.0Ã—</td>
    </tr>
    <tr>
        <td>æ­£è¾¹æ¯”ä¾‹</td>
        <td>18.8%</td>
        <td>11.5%</td>
        <td>0.61Ã—</td>
    </tr>
    <tr>
        <td>æ­£è´Ÿè¾¹æ¯”ä¾‹</td>
        <td>1:4.3</td>
        <td>1:7.7</td>
        <td>1.8Ã— ä¸å¹³è¡¡</td>
    </tr>
</table>

<h5 id="ğŸ“Š-GNN-è®­ç»ƒæŒ‘æˆ˜åˆ†æ"><a href="#ğŸ“Š-GNN-è®­ç»ƒæŒ‘æˆ˜åˆ†æ" class="headerlink" title="ğŸ“Š GNN è®­ç»ƒæŒ‘æˆ˜åˆ†æ"></a>ğŸ“Š GNN è®­ç»ƒæŒ‘æˆ˜åˆ†æ</h5><h6 id="è¿‡å¹³æ»‘é£é™©è¯„ä¼°"><a href="#è¿‡å¹³æ»‘é£é™©è¯„ä¼°" class="headerlink" title="è¿‡å¹³æ»‘é£é™©è¯„ä¼°"></a>è¿‡å¹³æ»‘é£é™©è¯„ä¼°</h6><ul>
<li><strong>CCLE</strong>: âš ï¸ é«˜é£é™© (å¹³å‡åº¦ 42.86)</li>
<li><strong>GDSC</strong>: ğŸš¨ æé«˜é£é™© (å¹³å‡åº¦ 256.89)</li>
</ul>
<h6 id="æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦"><a href="#æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦" class="headerlink" title="æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦"></a>æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦</h6><ul>
<li><strong>CCLE</strong>: æ­£è´Ÿè¾¹æ¯”ä¾‹ 1:4.3 (ä¸­ç­‰ä¸å¹³è¡¡)</li>
<li><strong>GDSC</strong>: æ­£è´Ÿè¾¹æ¯”ä¾‹ 1:7.7 (ä¸¥é‡ä¸å¹³è¡¡)</li>
</ul>
<h6 id="é‚»å±…ç›¸ä¼¼åº¦åˆ†æ"><a href="#é‚»å±…ç›¸ä¼¼åº¦åˆ†æ" class="headerlink" title="é‚»å±…ç›¸ä¼¼åº¦åˆ†æ"></a>é‚»å±…ç›¸ä¼¼åº¦åˆ†æ</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># é‚»å±…é‡å åº¦å¯¹æ¯”</span></span><br><span class="line">CCLE_similarity = &#123;</span><br><span class="line">    <span class="string">&quot;ç¬¬ä¸€ç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.9374</span>,  <span class="comment"># é«˜åº¦ç›¸ä¼¼</span></span><br><span class="line">    <span class="string">&quot;ç¬¬äºŒç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.9274</span>   <span class="comment"># é«˜åº¦ç›¸ä¼¼</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GDSC_similarity = &#123;</span><br><span class="line">    <span class="string">&quot;ç¬¬ä¸€ç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.7659</span>,  <span class="comment"># ä¸­ç­‰ç›¸ä¼¼</span></span><br><span class="line">    <span class="string">&quot;ç¬¬äºŒç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.7143</span>   <span class="comment"># ä¸­ç­‰ç›¸ä¼¼</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ç»“è®º</strong>: CCLE ç»“æ„æ›´å‡åŒ€ä½†å¤šæ ·æ€§ä¸è¶³ï¼ŒGDSC ç»“æ„æ›´å¤æ‚ä½†å¤šæ ·æ€§æ›´å¥½</p>
<h5 id="ğŸ¯-GNN-æ¶æ„å»ºè®®å¯¹æ¯”"><a href="#ğŸ¯-GNN-æ¶æ„å»ºè®®å¯¹æ¯”" class="headerlink" title="ğŸ¯ GNN æ¶æ„å»ºè®®å¯¹æ¯”"></a>ğŸ¯ GNN æ¶æ„å»ºè®®å¯¹æ¯”</h5><h6 id="æ¨èæ¶æ„ä¼˜å…ˆçº§"><a href="#æ¨èæ¶æ„ä¼˜å…ˆçº§" class="headerlink" title="æ¨èæ¶æ„ä¼˜å…ˆçº§"></a>æ¨èæ¶æ„ä¼˜å…ˆçº§</h6><ul>
<li><p>CCLE æ¨èæ¶æ„</p>
<ol>
<li><strong>Bipartite GNN</strong> + Signed GCN</li>
<li><strong>ç®€å•å¼‚æ„å›¾ GNN</strong> (HetGNN)</li>
<li><strong>æ ‡å‡† GCN</strong> + å¼ºæ­£åˆ™åŒ–</li>
</ol>
</li>
<li><p>GDSC æ¨èæ¶æ„</p>
<ol>
<li><strong>é‡‡æ ·å‹ GNN</strong> (GraphSAINT, FastGCN) + SGCN</li>
<li><strong>å¤§è§„æ¨¡å¼‚æ„å›¾ GNN</strong> (HGT, RGCN)</li>
<li><strong>å›¾ Transformer</strong> (å¤„ç†å¤æ‚ç»“æ„)</li>
</ol>
</li>
</ul>
<h6 id="å…·ä½“å‚æ•°å»ºè®®"><a href="#å…·ä½“å‚æ•°å»ºè®®" class="headerlink" title="å…·ä½“å‚æ•°å»ºè®®"></a>å…·ä½“å‚æ•°å»ºè®®</h6><table>
<thead>
<tr>
<th>å‚æ•°</th>
<th>CCLE</th>
<th>GDSC</th>
<th>åŸå› </th>
</tr>
</thead>
<tbody><tr>
<td><strong>ç½‘ç»œæ·±åº¦</strong></td>
<td>2-3 å±‚</td>
<td>ä¸¥æ ¼ 2 å±‚</td>
<td>GDSC è¿‡å¹³æ»‘é£é™©æ›´é«˜</td>
</tr>
<tr>
<td><strong>éšè—ç»´åº¦</strong></td>
<td>64-128</td>
<td>128-256</td>
<td>GDSC éœ€è¦æ›´å¤§å®¹é‡</td>
</tr>
<tr>
<td><strong>Dropout ç‡</strong></td>
<td>0.3-0.5</td>
<td>0.5-0.7</td>
<td>GDSC éœ€è¦æ›´å¼ºæ­£åˆ™åŒ–</td>
</tr>
<tr>
<td><strong>å­¦ä¹ ç‡</strong></td>
<td>0.001-0.01</td>
<td>0.0001-0.001</td>
<td>GDSC éœ€è¦æ›´ä¿å®ˆè®­ç»ƒ</td>
</tr>
<tr>
<td><strong>æ‰¹æ¬¡å¤§å°</strong></td>
<td>32-64 ä¸ªå­å›¾</td>
<td>16-32 ä¸ªå­å›¾</td>
<td>GDSC å†…å­˜é™åˆ¶</td>
</tr>
<tr>
<td><strong>é‡‡æ ·ç­–ç•¥</strong></td>
<td>å¯é€‰</td>
<td>å¿…é¡»</td>
<td>GDSC æ— æ³•å…¨å›¾è®­ç»ƒ</td>
</tr>
</tbody></table>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf" target="_blank">ğŸ“„ Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a></p>
]]></content>
      <categories>
        <category>CDR</category>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>graph theory</tag>
        <tag>Data Analysis</tag>
        <tag>å¯èƒ½æœ‰ç‚¹ç”¨</tag>
      </tags>
  </entry>
  <entry>
    <title>Trans?!and Former?!</title>
    <url>/2025/07/19/Graph-Transformer/</url>
    <content><![CDATA[<h1 id="Graph-Transformer"><a href="#Graph-Transformer" class="headerlink" title="Graph Transformer"></a>Graph Transformer</h1><p>Graph Transformer æ˜¯ä¼ ç»ŸTransformeræ¶æ„åœ¨å›¾æ•°æ®ä¸Šçš„æ³›åŒ–ï¼Œæ—¨åœ¨å¤„ç†ä»»æ„ç»“æ„çš„å›¾æ•°æ®ï¼ˆå¦‚ç¤¾äº¤ç½‘ç»œã€åˆ†å­ç»“æ„ç­‰ï¼‰ã€‚å…¶æ—¢ä¿ç•™äº†Transformerçš„å¼ºè¡¨ç¤ºèƒ½åŠ›ï¼Œåˆç»§æ‰¿äº†GNNå¯¹å›¾ç»“æ„çš„å½’çº³åç½®ï¼Œæˆä¸ºå›¾è¡¨ç¤ºå­¦ä¹ é¢†åŸŸçš„é‡è¦åŸºçº¿æ¨¡å‹ã€‚</p>
<span id="more"></span>

<p>åœ¨è¿‡å»ï¼ŒTransformerï¼ˆLinç­‰äººï¼Œ2021å¹´ï¼‰åœ¨è®¸å¤šNLPã€CVå’ŒGRLä»»åŠ¡ä¸­å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚Graph Transformerå°†Transformeræ¶æ„æ¨å¹¿åˆ°å›¾è¡¨ç¤ºå­¦ä¹ ä¸­ï¼Œæ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼ˆYingç­‰äººï¼Œ2021å¹´ï¼‰ã€‚ä¸ä¹‹å‰ä½¿ç”¨å±€éƒ¨æ³¨æ„åŠ›çš„æ–¹æ³•ä¸åŒï¼ŒGraph Transformeré€šè¿‡å…¨å±€æ³¨æ„åŠ›ç›´æ¥å­¦ä¹ é«˜é˜¶å›¾å±æ€§ã€‚Graph Transformeråœ¨å›¾æ·±åº¦å­¦ä¹ é¢†åŸŸå‘å±•è¿…é€Ÿï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­å°å‹å›¾çš„å›¾åˆ†ç±»ä»»åŠ¡ä¸­ã€‚è¿›ä¸€æ­¥å°†Graph Transformeråˆ†ä¸ºä¸¤ä¸ªå­ç±»åˆ«ï¼Œå³æ ‡å‡†Transformerï¼ˆYingç­‰äººï¼Œ2021å¹´ï¼‰å’ŒGNNTransformerï¼ˆNguyenç­‰äººï¼Œ2019å¹´ï¼‰ã€‚æ ‡å‡†Transformeré€šå¸¸å¯¹è¾“å…¥å›¾çš„æ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¿½ç•¥èŠ‚ç‚¹ä¹‹é—´çš„é‚»æ¥å…³ç³»ï¼Œè€ŒGNNTransformeråˆ™ä½¿ç”¨GNNå±‚æ¥è·å–é‚»æ¥ä¿¡æ¯ã€‚ </p>
<img src="/img/Attention/GraphTransformer.png" alt="GraphTransformer" width="60%" height="auto">

<p>ç°åœ¨ä»‹ç»Graph Transformerå±‚å’Œå…·æœ‰è¾¹ç‰¹å¾çš„Graph Transformerå±‚ã€‚è¯¥å±‚æ¶æ„ä¸Šå›¾æ‰€ç¤ºã€‚ç¬¬ä¸€ä¸ªæ¨¡å‹æ˜¯ä¸ºæ²¡æœ‰æ˜¾å¼è¾¹å±æ€§çš„å›¾è®¾è®¡çš„ï¼Œè€Œç¬¬äºŒä¸ªæ¨¡å‹åˆ™ä¿æŒä¸€ä¸ªæŒ‡å®šçš„è¾¹ç‰¹å¾ç®¡é“ï¼Œä»¥æ•´åˆå¯ç”¨çš„è¾¹ä¿¡æ¯ï¼Œå¹¶åœ¨æ¯ä¸€å±‚ä¸­ä¿æŒå®ƒä»¬çš„æŠ½è±¡è¡¨ç¤ºã€‚</p>
<h3 id="è¾“å…¥ç‰¹å¾çº¿æ€§æŠ•å½±å…¬å¼"><a href="#è¾“å…¥ç‰¹å¾çº¿æ€§æŠ•å½±å…¬å¼" class="headerlink" title="è¾“å…¥ç‰¹å¾çº¿æ€§æŠ•å½±å…¬å¼"></a>è¾“å…¥ç‰¹å¾çº¿æ€§æŠ•å½±å…¬å¼</h3><p>è¾“å…¥é¦–å…ˆï¼Œå‡†å¤‡å°†è¾“å…¥èŠ‚ç‚¹å’Œè¾¹åµŒå…¥ä¼ é€’åˆ°Graph Transformerå±‚ã€‚å¯¹äºä¸€ä¸ªå…·æœ‰æ¯ä¸ªèŠ‚ç‚¹içš„èŠ‚ç‚¹ç‰¹å¾ $\alpha_i \in \mathbb{R}^{d_n\times 1}$ å’Œæ¯ä¸ªèŠ‚ç‚¹$i$å’ŒèŠ‚ç‚¹$j$ä¹‹é—´çš„è¾¹ç‰¹å¾$\beta_{ij} \in \mathbb{R}^{d_e\times 1}$çš„å›¾Gï¼Œé€šè¿‡çº¿æ€§æŠ•å½±å°†è¾“å…¥èŠ‚ç‚¹ç‰¹å¾Î±iå’Œè¾¹ç‰¹å¾$\beta_{ij}$ä¼ é€’ä»¥åµŒå…¥åˆ°$d-$ç»´éšè—ç‰¹å¾$h^0_i$å’Œ$e^0_{ij}$ã€‚</p>
<p><strong>èŠ‚ç‚¹ç‰¹å¾æŠ•å½±</strong>ï¼š$\hat{h}_{i}^{0} &#x3D; A^{0}\alpha_{i} + a^{0}\qquad$ <strong>è¾¹ç‰¹å¾æŠ•å½±</strong>ï¼š$e_{ij}^{0} &#x3D; B^{0}\beta_{ij} + b^{0}$</p>
<p>å…¶ä¸­ï¼Œ$A^{0} \in \mathbb{R}^{d \times d_{n}}$ å’Œ $B^{0} \in \mathbb{R}^{d \times d_{e}}$ æ˜¯æŠ•å½±çŸ©é˜µï¼Œ$a^{0}, b^{0} \in \mathbb{R}^{d}$ æ˜¯åç½®ï¼Œ$\alpha_i$ å’Œ $\beta_{ij}$ åˆ†åˆ«æ˜¯åŸå§‹èŠ‚ç‚¹å’Œè¾¹ç‰¹å¾</p>
<h3 id="2-ä½ç½®ç¼–ç èåˆå…¬å¼"><a href="#2-ä½ç½®ç¼–ç èåˆå…¬å¼" class="headerlink" title="2. ä½ç½®ç¼–ç èåˆå…¬å¼"></a>2. ä½ç½®ç¼–ç èåˆå…¬å¼</h3><p>ç°åœ¨é€šè¿‡çº¿æ€§æŠ•å½±åµŒå…¥é¢„å…ˆè®¡ç®—çš„èŠ‚ç‚¹ä½ç½®ç¼–ç $k$ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°èŠ‚ç‚¹ç‰¹å¾$\hat{h}^0_i$ã€‚</p>
<p><strong>ä½ç½®ç¼–ç æŠ•å½±</strong>$\lambda_{i}^{0} &#x3D; C^{0}\lambda_{i} + c^{0}\qquad$ <strong>èŠ‚ç‚¹ç‰¹å¾æ›´æ–°</strong>$h_{i}^{0} &#x3D; \hat{h}_{i}^{0} + \lambda_{i}^{0}$</p>
<p>å…¶ä¸­ï¼Œ$C^{0} \in \mathbb{R}^{d \times k}$ æ˜¯ä½ç½®ç¼–ç æŠ•å½±çŸ©é˜µï¼Œ$c^{0} \in \mathbb{R}^{d}$ æ˜¯åç½®é¡¹ï¼Œ$\lambda_i$ æ˜¯é¢„è®¡ç®—çš„Laplacianç‰¹å¾å‘é‡ã€‚è¯·æ³¨æ„ï¼Œæ‹‰æ™®æ‹‰æ–¯ä½ç½®ç¼–ç ä»…åœ¨è¾“å…¥å±‚æ·»åŠ åˆ°èŠ‚ç‚¹ç‰¹å¾ï¼Œè€Œä¸æ˜¯åœ¨ä¸­é—´çš„Graph Transformerå±‚ã€‚</p>
<h3 id="3-åŸºç¡€å›¾Transformerå±‚å…¬å¼"><a href="#3-åŸºç¡€å›¾Transformerå±‚å…¬å¼" class="headerlink" title="3. åŸºç¡€å›¾Transformerå±‚å…¬å¼"></a>3. åŸºç¡€å›¾Transformerå±‚å…¬å¼</h3><p>ä¸æœ€åˆåœ¨(Vaswaniç­‰äººï¼Œ2017)ä¸­æå‡ºçš„Transformeræ¶æ„éå¸¸ç›¸ä¼¼ã€‚ç°åœ¨å¼€å§‹å®šä¹‰ä¸€å±‚çš„èŠ‚ç‚¹æ›´æ–°æ–¹ç¨‹ã€‚</p>
<p><strong>å¤šå¤´æ³¨æ„åŠ›è¾“å‡º</strong>$\hat{h}_{i}^{\ell+1} &#x3D; O_{h}^{\ell} |_{k&#x3D;1}^{H} \left( \sum_{j \in \mathcal{N}_{i}} w_{ij}^{kï¼Œ\ell} V^{kï¼Œ\ell} h_{j}^{\ell} \right)$</p>
<p><strong>æ³¨æ„åŠ›æƒé‡è®¡ç®—</strong>$w_{ij}^{kï¼Œ\ell} &#x3D; \text{softmax}_{j} \left( \frac{Q^{kï¼Œ\ell} h_{i}^{\ell} \cdot K^{kï¼Œ\ell} h_{j}^{\ell}}{\sqrt{d_{k}}} \right)$</p>
<p>å…¶ä¸­ï¼Œ$|$ è¡¨ç¤ºæ‹¼æ¥æ“ä½œï¼Œ$Q^{kï¼Œ\ell}, K^{kï¼Œ\ell}, V^{kï¼Œ\ell} \in \mathbb{R}^{d_{k} \times d}$ æ˜¯å„å¤´çš„æŸ¥è¯¢ã€é”®ã€å€¼çŸ©é˜µï¼Œ$O_{h}^{\ell} \in \mathbb{R}^{d \times d}$ æ˜¯è¾“å‡ºæŠ•å½±çŸ©é˜µ</p>
<h3 id="4-å‰é¦ˆç½‘ç»œä¸å½’ä¸€åŒ–"><a href="#4-å‰é¦ˆç½‘ç»œä¸å½’ä¸€åŒ–" class="headerlink" title="4. å‰é¦ˆç½‘ç»œä¸å½’ä¸€åŒ–"></a>4. å‰é¦ˆç½‘ç»œä¸å½’ä¸€åŒ–</h3><p>ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼Œsoftmaxå†…éƒ¨é¡¹çš„æŒ‡æ•°è¾“å‡ºè¢«å¤¹åœ¨$âˆ’5$åˆ°$+5$ä¹‹é—´ã€‚ç„¶åå°†æ³¨æ„åŠ›è¾“å‡º$\hat{h}^{\ell +1}_i$ä¼ é€’ç»™ä¸€ä¸ªå‰æ¥å’Œåæ¥æ®‹å·®è¿æ¥å’Œè§„èŒƒåŒ–å±‚çš„å‰é¦ˆç½‘ç»œ(FFN)ï¼Œå¦‚ä¸‹æ‰€ç¤º:</p>
<p><strong>å½’ä¸€åŒ–æ­¥éª¤</strong>$\hat{\hat{h}}_{i}^{\ell+1} &#x3D; \text{Norm}(h_{i}^{\ell} + \hat{h}_{i}^{\ell+1})\quad$ <strong>å‰é¦ˆç½‘ç»œ</strong>$\hat{\hat{\hat{h}}}_{i}^{\ell+1} &#x3D; W_{2}^{\ell} \text{ReLU}(W_{1}^{\ell} \hat{\hat{h}}_{i}^{\ell+1})\quad$ <strong>æœ€ç»ˆè¾“å‡º</strong>$h_{i}^{\ell+1} &#x3D; \text{Norm}(\hat{\hat{h}}_{i}^{\ell+1} + \hat{\hat{\hat{h}}}_{i}^{\ell+1})$</p>
<p>å…¶ä¸­ï¼Œ$W_{1}^{\ell} \in \mathbb{R}^{2d \times d}$ å’Œ $W_{2}^{\ell} \in \mathbb{R}^{d \times 2d}$ æ˜¯å‰é¦ˆç½‘ç»œå‚æ•°ï¼ŒNormå¯ä»¥æ˜¯BatchNormæˆ–LayerNorm.ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œçœç•¥äº†åå·®é¡¹ã€‚</p>
<h3 id="5-å¸¦è¾¹ç‰¹å¾çš„å›¾Transformerå±‚"><a href="#5-å¸¦è¾¹ç‰¹å¾çš„å›¾Transformerå±‚" class="headerlink" title="5. å¸¦è¾¹ç‰¹å¾çš„å›¾Transformerå±‚"></a>5. å¸¦è¾¹ç‰¹å¾çš„å›¾Transformerå±‚</h3><p>å¸¦æœ‰è¾¹ç‰¹å¾çš„Graph Transformerå±‚å¸¦æœ‰è¾¹ç‰¹å¾çš„Graph Transformeræ˜¯ä¸ºæ›´å¥½åœ°åˆ©ç”¨å¤šç§å›¾æ•°æ®é›†ä¸­çš„ä¸°å¯Œç‰¹å¾ä¿¡æ¯è€Œè®¾è®¡çš„ï¼Œè¿™äº›ä¿¡æ¯ä»¥è¾¹å±æ€§çš„å½¢å¼å­˜åœ¨ã€‚ç”±äºçš„ç›®æ ‡ä»ç„¶æ˜¯æ›´å¥½åœ°åˆ©ç”¨è¾¹ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ˜¯å¯¹åº”äºèŠ‚ç‚¹å¯¹çš„æˆå¯¹å¾—åˆ†ï¼Œå°†è¿™äº›å¯ç”¨çš„è¾¹ç‰¹å¾ä¸é€šè¿‡æˆå¯¹æ³¨æ„åŠ›è®¡ç®—çš„éšå¼è¾¹å¾—åˆ†è”ç³»èµ·æ¥ã€‚</p>
<p>æ¢å¥è¯è¯´ï¼Œå½“ä¸€ä¸ªèŠ‚ç‚¹$i$åœ¨ <em>query</em> å’Œ <em>key</em> ç‰¹å¾æŠ•å½±ç›¸ä¹˜åå…³æ³¨èŠ‚ç‚¹$j$æ—¶ï¼Œä¸­é—´æ³¨æ„åŠ›å¾—åˆ†$\hat{w}_{ij}$åœ¨softmaxä¹‹å‰è¢«è®¡ç®—å‡ºæ¥ã€‚è®©å°†è¿™ä¸ªå¾—åˆ†$\hat{w}_{ij}$è§†ä¸ºå…³äºè¾¹$&lt;iï¼Œj&gt;$çš„éšå¼ä¿¡æ¯ã€‚ç°åœ¨å°è¯•æ³¨å…¥è¾¹$&lt;iï¼Œj&gt;$çš„å¯ç”¨è¾¹ä¿¡æ¯ï¼Œå¹¶æ”¹è¿›å·²ç»è®¡ç®—å‡ºçš„éšå¼æ³¨æ„åŠ›å¾—åˆ†$\hat{w}_{ij}$ã€‚</p>
<p>è¿™æ˜¯é€šè¿‡ç®€å•åœ°å°†ä¸¤ä¸ªå€¼$\hat{w}_{ij}$å’Œ$e_{ij}$ç›¸ä¹˜æ¥å®Œæˆçš„ã€‚è¿™ç§ä¿¡æ¯æ³¨å…¥åœ¨NLPTransformerä¸­å¹¶æ²¡æœ‰è¢«å¹¿æ³›æ¢ç´¢æˆ–åº”ç”¨ï¼Œå› ä¸ºåœ¨ä¸¤ä¸ªå•è¯ä¹‹é—´é€šå¸¸æ²¡æœ‰å¯ç”¨çš„ç‰¹å¾ä¿¡æ¯ã€‚</p>
<p>ç„¶è€Œï¼Œåœ¨åˆ†å­å›¾æˆ–ç¤¾äº¤åª’ä½“å›¾ç­‰å›¾æ•°æ®é›†ä¸­ï¼Œè¾¹äº¤äº’ä¸Šå¾€å¾€æœ‰ä¸€äº›å¯ç”¨çš„ç‰¹å¾ä¿¡æ¯ï¼Œå› æ­¤è®¾è®¡ä¸€ç§æ¶æ„æ¥åˆ©ç”¨è¿™äº›ä¿¡æ¯å˜å¾—è‡ªç„¶ã€‚å¯¹äºè¾¹ï¼Œè¿˜ç»´æŠ¤äº†ä¸€ä¸ªæŒ‡å®šçš„èŠ‚ç‚¹å¯¹ç§°è¾¹ç‰¹å¾è¡¨ç¤ºç®¡é“ï¼Œç”¨äºä»ä¸€å±‚åˆ°å¦ä¸€å±‚ä¼ æ’­è¾¹å±æ€§ã€‚ç°åœ¨ç»§ç»­å®šä¹‰ä¸€å±‚çš„å±‚æ›´æ–°æ–¹ç¨‹ã€‚</p>
<p><strong>æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—</strong>$\hat{w}_{ij}^{kï¼Œ\ell} &#x3D; \left( \frac{Q^{kï¼Œ\ell} h_{i}^{\ell} \cdot K^{kï¼Œ\ell} h_{j}^{\ell}}{\sqrt{d_{k}}} \right) \cdot E^{kï¼Œ\ell} e_{ij}^{\ell}\quad$ <strong>è¾¹ç‰¹å¾æ›´æ–°</strong>$\hat{e}_{ij}^{\ell+1} &#x3D; O_{e}^{\ell} \prod_{k&#x3D;1}^{H} (\hat{w}_{ij}^{kï¼Œ\ell})$</p>
<p>å…¶ä¸­ï¼Œ$E^{kï¼Œ\ell} \in \mathbb{R}^{d_{k} \times d}$ æ˜¯è¾¹ç‰¹å¾æŠ•å½±çŸ©é˜µï¼Œ$O_{e}^{\ell} \in \mathbb{R}^{d \times d}$ æ˜¯è¾¹ç‰¹å¾è¾“å‡ºæŠ•å½±çŸ©é˜µ</p>
<h3 id="6-è¾¹ç‰¹å¾çš„å‰é¦ˆç½‘ç»œ"><a href="#6-è¾¹ç‰¹å¾çš„å‰é¦ˆç½‘ç»œ" class="headerlink" title="6. è¾¹ç‰¹å¾çš„å‰é¦ˆç½‘ç»œ"></a>6. è¾¹ç‰¹å¾çš„å‰é¦ˆç½‘ç»œ</h3><p><strong>è¾¹ç‰¹å¾å½’ä¸€åŒ–</strong>$\hat{\hat{e}}_{ij}^{\ell+1} &#x3D; \text{Norm}(e_{ij}^{\ell} + \hat{e}_{ij}^{\ell+1})\quad$ <strong>è¾¹ç‰¹å¾å˜æ¢</strong>$\hat{\hat{\hat{e}}}_{ij}^{\ell+1} &#x3D; W_{eï¼Œ2}^{\ell} \text{ReLU}(W_{eï¼Œ1}^{\ell} \hat{\hat{e}}_{ij}^{\ell+1})\quad$ <strong>æœ€ç»ˆè¾¹è¾“å‡º</strong>$e_{ij}^{\ell+1} &#x3D; \text{Norm}(\hat{\hat{e}}_{ij}^{\ell+1} + \hat{\hat{\hat{e}}}_{ij}^{\ell+1})\quad$</p>
<p>å…¶ä¸­ï¼Œ$W_{eï¼Œ1}^{\ell} \in \mathbb{R}^{2d \times d}$ å’Œ $W_{eï¼Œ2}^{\ell} \in \mathbb{R}^{d \times 2d}$ æ˜¯è¾¹ç‰¹å¾å‰é¦ˆç½‘ç»œå‚æ•°</p>
<h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><p>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå°†Transformerç½‘ç»œæ¨å¹¿åˆ°ä»»æ„å›¾ä¸Šï¼Œå¹¶å¼•å…¥äº†ç›¸åº”çš„æ¶æ„ã€‚</p>
<p>å®éªŒä¸€è‡´è¡¨æ˜ï¼Œå­˜åœ¨ï¼š</p>
<ul>
<li>Laplacianç‰¹å¾å‘é‡ä½œä¸ºèŠ‚ç‚¹ä½ç½®ç¼–ç </li>
<li>batch normalizationï¼Œä»£æ›¿å±‚å½’ä¸€åŒ–ï¼Œ<br>åˆ™åœ¨Transformerå‰é¦ˆå±‚å‘¨å›´å¢å¼ºäº†Transformeråœ¨æ‰€æœ‰å®éªŒä¸­çš„æ™®éæ€§ã€‚</li>
</ul>
<p>é‰´äºè¿™ä¸ªæ¶æ„çš„ç®€å•æ€§å’Œé€šç”¨æ€§ä»¥åŠä¸æ ‡å‡†GNNç›¸æ¯”çš„ç«äº‰æ€§èƒ½ï¼Œæå‡ºçš„æ¨¡å‹å¯ä»¥ä½œä¸ºè¿›ä¸€æ­¥æ”¹è¿›è·¨å›¾åº”ç”¨ä¸­ä½¿ç”¨èŠ‚ç‚¹æ³¨æ„åŠ›çš„åŸºçº¿ã€‚</p>
<h1 id="ğŸ“šğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“šğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“šğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“šğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1>]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
        <category>graph</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>PyTorch</tag>
        <tag>deeplearning</tag>
        <tag>graphtheory</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title>Gugugu Neralashun</title>
    <url>/2025/07/16/General-Attention/</url>
    <content><![CDATA[<h1 id="å…·æœ‰ä¸€èˆ¬æ€§çš„-Attention"><a href="#å…·æœ‰ä¸€èˆ¬æ€§çš„-Attention" class="headerlink" title="å…·æœ‰ä¸€èˆ¬æ€§çš„ Attention"></a>å…·æœ‰ä¸€èˆ¬æ€§çš„ Attention</h1><div style="display: flex; align-items: center;">
  <img src="\img\Attention\Gugugu Neralashun.png" style="width: 200px; margin-right: 20px;">
  <p>è¯¦ç»†è®¨è®ºäº†å¯ä»¥åº”ç”¨äºä»»ä½•ç±»å‹æ³¨æ„åŠ›æ¨¡å‹çš„åŸºç¡€æœºåˆ¶ï¼Œè¿™äº›æœºåˆ¶ä¸ä¾èµ–äºç‰¹å®šçš„ç‰¹å¾æ¨¡å‹æˆ–æŸ¥è¯¢æ¨¡å‹ã€‚è¿™ä¸€éƒ¨åˆ†æ„æˆäº†æ³¨æ„åŠ›æ¨¡å‹çš„æ ¸å¿ƒè®¡ç®—æ¡†æ¶ï¼Œä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªå…³é”®å­æ–¹é¢ï¼šæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°(Attention Scoring)ã€æ³¨æ„åŠ›å¯¹é½(Attention Alignment)å’Œæ³¨æ„åŠ›ç»´åº¦(Attention Dimensionality)ã€‚</p>
</div>



<p>åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» <a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a></p>
<span id="more"></span>

<h2 id="å›é¡¾"><a href="#å›é¡¾" class="headerlink" title="å›é¡¾"></a>å›é¡¾</h2><img src="/img/Attention/GeneralAttentionModule.png" alt="GeneralAttentionModule" width="50%" height="auto">

<p>å¦‚æœè¿˜è®°å¾—è¿™å¼ å›¾çš„è¯ï¼Œé‚£ä¾¿æ˜¯æå¥½çš„æ <del>ä¸è®°å¾—äº†å°±å›å»çœ‹æ</del> æœ¬æ–‡ä¸»è¦å°±æ˜¯åœ¨è¯´æ˜æ¯ä¸€ä¸ªæ¨¡å—å¸¸è§çš„å…·ä½“å®ç°æœ‰ä»€ä¹ˆ</p>
<h2 id="æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°-Attention-Scoring"><a href="#æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°-Attention-Scoring" class="headerlink" title="æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°(Attention Scoring)"></a>æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°(Attention Scoring)</h2><p>æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°æ˜¯è®¡ç®—æŸ¥è¯¢å‘é‡$\mathbf{q}$ä¸é”®å‘é‡$\mathbf{k}_l$ä¹‹é—´ç›¸å…³æ€§å¾—åˆ†çš„æ ¸å¿ƒç»„ä»¶ï¼š</p>
<ol>
<li><p><strong>åŠ æ€§è¯„åˆ†(Additive&#x2F;Concatenate)</strong>ï¼š</p>
<p>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \mathbf{w}^\top \text{act}(\mathbf{W}_1\mathbf{q} + \mathbf{W}_2\mathbf{k}_l + \mathbf{b})<br>$$</p>
<p>å…¶ä¸­$\mathbf{w} \in \mathbb{R}^{d_w}$, $\mathbf{W}_1 \in \mathbb{R}^{d_w \times d_q}$, $\mathbf{W}_2 \in \mathbb{R}^{d_w \times d_k}$å’Œ$\mathbf{b} \in \mathbb{R}^{d_w}$æ˜¯å¯è®­ç»ƒå‚æ•°ã€‚</p>
</li>
<li><p><strong>ä¹˜æ€§è¯„åˆ†(Multiplicative&#x2F;Dot-Product)</strong>ï¼š</p>
<p>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \mathbf{q}^\top \mathbf{k}_l<br>$$</p>
</li>
<li><p><strong>ç¼©æ”¾ä¹˜æ€§è¯„åˆ†(Scaled Multiplicative)</strong>ï¼š</p>
<p>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \frac{\mathbf{q}^\top \mathbf{k}_l}{\sqrt{d_k}}<br>$$</p>
</li>
<li><p><strong>é€šç”¨è¯„åˆ†(General)</strong>ï¼š</p>
<p>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \mathbf{k}_l^\top \mathbf{W} \mathbf{q}<br>$$</p>
<p>å…¶ä¸­$\mathbf{W} \in \mathbb{R}^{d_k \times d_q}$æ˜¯æƒé‡çŸ©é˜µã€‚</p>
</li>
<li><p><strong>å¸¦åç½®çš„é€šç”¨è¯„åˆ†(Biased General)</strong>ï¼š</p>
<p>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \mathbf{k}_l^\top (\mathbf{W}\mathbf{q} + \mathbf{b})<br>$$</p>
</li>
<li><p><strong>æ¿€æ´»é€šç”¨è¯„åˆ†(Activated General)</strong>ï¼š<br>$$<br>\text{score}(\mathbf{q},\mathbf{k}_l) &#x3D; \text{act}(\mathbf{k}_l^\top \mathbf{W} \mathbf{q} + b)<br>$$</p>
</li>
</ol>
<h2 id="æ³¨æ„åŠ›å¯¹é½-Attention-Alignment"><a href="#æ³¨æ„åŠ›å¯¹é½-Attention-Alignment" class="headerlink" title="æ³¨æ„åŠ›å¯¹é½(Attention Alignment)"></a>æ³¨æ„åŠ›å¯¹é½(Attention Alignment)</h2><p>å¯¹é½å‡½æ•°å°†åŸå§‹æ³¨æ„åŠ›åˆ†æ•°$\mathbf{e} &#x3D; [e_1, \ldots, e_{n_f}]$è½¬æ¢ä¸ºæ ‡å‡†åŒ–æƒé‡ï¼š</p>
<ol>
<li><p><strong>è½¯å¯¹é½&#x2F;å…¨å±€å¯¹é½(Soft&#x2F;Global Alignment)</strong>ï¼š</p>
<p>$$<br>a_l &#x3D; \frac{\exp(e_l)}{\sum_{j&#x3D;1}^{n_f} \exp(e_j)}<br>$$</p>
</li>
<li><p><strong>ç¡¬å¯¹é½(Hard Alignment)</strong>ï¼š<br>ä»å¤šé¡¹å¼åˆ†å¸ƒé‡‡æ ·ï¼š</p>
<p>$$<br>m \sim \text{Multinomial}(a_1, \ldots, a_{n_f})<br>$$</p>
<p>ç„¶åï¼š</p>
<p>$$<br>\mathbf{c} &#x3D; \mathbf{v}_m<br>$$</p>
</li>
<li><p><strong>å±€éƒ¨å¯¹é½(Local Alignment)</strong>ï¼š<br>çª—å£ä½ç½®$p$çš„ç¡®å®šï¼š<br>$$<br>p &#x3D; S \times \text{sigmoid}(\mathbf{w}_p^\top \tanh(\mathbf{W}_p \mathbf{q}))<br>$$<br>ç„¶åè®¡ç®—ï¼š<br>$$<br>a_l &#x3D; \frac{\exp(e_l)}{\sum_{j&#x3D;p-D}^{p+D} \exp(e_j)} \exp\left(-\frac{(l-p)^2}{2\sigma^2}\right)<br>$$</p>
</li>
</ol>
<h2 id="æ³¨æ„åŠ›ç»´åº¦-Attention-Dimensionality"><a href="#æ³¨æ„åŠ›ç»´åº¦-Attention-Dimensionality" class="headerlink" title="æ³¨æ„åŠ›ç»´åº¦(Attention Dimensionality)"></a>æ³¨æ„åŠ›ç»´åº¦(Attention Dimensionality)</h2><ol>
<li><p><strong>å•ç»´æ³¨æ„åŠ›(Single-Dimensional Attention)</strong>ï¼š</p>
<p>$$<br>\mathbf{c} &#x3D; \sum_{l&#x3D;1}^{n_f} a_l \mathbf{v}_l<br>$$</p>
</li>
<li><p><strong>å¤šç»´æ³¨æ„åŠ›(Multi-Dimensional Attention)</strong>ï¼š<br>è°ƒæ•´è¯„åˆ†å‡½æ•°äº§ç”Ÿå‘é‡åˆ†æ•°ï¼š</p>
<p>$$<br>\mathbf{e}_l &#x3D; \mathbf{W}_d^\top \text{act}(\mathbf{W}_1 \mathbf{q} + \mathbf{W}_2 \mathbf{k}_l + \mathbf{b})<br>$$</p>
<p>ç„¶åè®¡ç®—ï¼š</p>
<p>$$<br>a_{l,i} &#x3D; \frac{\exp(e_{l,i})}{\sum_{j&#x3D;1}^{n_f} \exp(e_{j,i})}<br>$$</p>
<p>æœ€ç»ˆä¸Šä¸‹æ–‡å‘é‡ï¼š</p>
<p>$$<br>\mathbf{c} &#x3D; \sum_{l&#x3D;1}^{n_f} \mathbf{a}_l \circ \mathbf{v}_l<br>$$</p>
<p>å…¶ä¸­$\circ$è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚</p>
</li>
</ol>
<h2 id="4-å®é™…åº”ç”¨ä¸é€‰æ‹©å»ºè®®"><a href="#4-å®é™…åº”ç”¨ä¸é€‰æ‹©å»ºè®®" class="headerlink" title="4. å®é™…åº”ç”¨ä¸é€‰æ‹©å»ºè®®"></a>4. å®é™…åº”ç”¨ä¸é€‰æ‹©å»ºè®®</h2><p>è®ºæ–‡æä¾›äº†å…³äºä¸åŒæœºåˆ¶é€‰æ‹©çš„å®ç”¨å»ºè®®ï¼š</p>
<ol>
<li><p><strong>è¯„åˆ†å‡½æ•°é€‰æ‹©</strong>ï¼š</p>
<ul>
<li>è®¡ç®—æ•ˆç‡ä¼˜å…ˆï¼šä¹˜æ€§æˆ–ç¼©æ”¾ä¹˜æ€§è¯„åˆ†</li>
<li>æ€§èƒ½ä¼˜å…ˆï¼šåŠ æ€§è¯„åˆ†æˆ–é€šç”¨è¯„åˆ†</li>
<li>å¤§ç»´åº¦é”®å‘é‡ï¼šå¿…é¡»ä½¿ç”¨ç¼©æ”¾ä¹˜æ€§è¯„åˆ†é˜²æ­¢æ¢¯åº¦é—®é¢˜</li>
</ul>
</li>
<li><p><strong>å¯¹é½æ–¹å¼é€‰æ‹©</strong>ï¼š</p>
<ul>
<li>æ ‡å‡†æƒ…å†µï¼šè½¯å¯¹é½</li>
<li>éœ€è¦ä¸¥æ ¼ç¨€ç–æ€§ï¼šç¡¬å¯¹é½ï¼ˆä½†è¦æ³¨æ„è®­ç»ƒéš¾åº¦ï¼‰</li>
<li>åºåˆ—æ•°æ®ï¼šè€ƒè™‘å±€éƒ¨å¯¹é½</li>
<li>éœ€è¦åŠ¨æ€é€‰æ‹©å…³æ³¨åŒºåŸŸï¼šå¼ºåŒ–å¯¹é½</li>
</ul>
</li>
<li><p><strong>ç»´åº¦é€‰æ‹©</strong>ï¼š</p>
<ul>
<li>å¤§å¤šæ•°æƒ…å†µï¼šå•ç»´æ³¨æ„åŠ›è¶³å¤Ÿ</li>
<li>éœ€è¦ç»†ç²’åº¦æ§åˆ¶ï¼šè€ƒè™‘å¤šç»´æ³¨æ„åŠ›</li>
</ul>
</li>
</ol>
<p>è¿™äº›é€šç”¨æœºåˆ¶å¯ä»¥è‡ªç”±ç»„åˆï¼Œä¾‹å¦‚å¯ä»¥è®¾è®¡ä¸€ä¸ªä½¿ç”¨åŠ æ€§è¯„åˆ†ã€è½¯å¯¹é½å’Œå¤šç»´æ³¨æ„åŠ›çš„æ¨¡å‹ã€‚è®ºæ–‡ç‰¹åˆ«æŒ‡å‡ºï¼ŒTransformer æ¨¡å‹æˆåŠŸçš„å…³é”®åœ¨äºå·§å¦™åœ°ç»„åˆäº†ç¼©æ”¾ä¹˜æ€§è¯„åˆ†ã€è½¯å¯¹é½å’Œå•ç»´æ³¨æ„åŠ›ï¼ˆé€šè¿‡å¤šå¤´æœºåˆ¶å®ç°ç±»ä¼¼å¤šç»´æ³¨æ„åŠ›çš„æ•ˆæœï¼‰ã€‚</p>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
<a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a>
]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
        <category>category</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Hypergraph</title>
    <url>/2025/07/19/Hypergraph/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><span id="more"></span>


<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1>]]></content>
  </entry>
  <entry>
    <title>Fufufu Relashinala</title>
    <url>/2025/07/14/Feature-Related-Attention/</url>
    <content><![CDATA[<h1 id="åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„-Attention"><a href="#åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„-Attention" class="headerlink" title="åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention"></a>åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention</h1><p>æœ¬æ–‡å°†æ¥ç€è¯¦ç»†è¯´æ˜ä¸€ç§åŸºäºè¾“å…¥ç‰¹å¾åˆ†ç±» Attention çš„æ–¹å¼ï¼Œå¹¶ä»‹ç»åœ¨è¿™ç§åˆ†ç±»æ–¹å¼ä¸‹å…³æ³¨åˆ°çš„ä¸åŒçš„ Attention çš„æ¶æ„ã€‚</p>
<div style="display: flex; align-items: center;">
  <img src="\img\Attention\Fufufu Relashinala.png" style="width: 200px; margin-right: 20px;">
  <p>
  å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä¸»è¦æ¢è®¨äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚æœ¬èŠ‚æ ¹æ®è¾“å…¥ç‰¹å¾çš„ä¸åŒç‰¹æ€§ï¼Œå°†ç‰¹å¾ç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)ã€ç‰¹å¾å±‚çº§(Levels of Features)å’Œç‰¹å¾è¡¨ç¤º(Feature Representations)ã€‚
  </p>
</div>



<p>åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» <a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a></p>
<span id="more"></span>

<h2 id="ç‰¹å¾å¤šé‡æ€§-Multiplicity-of-Features"><a href="#ç‰¹å¾å¤šé‡æ€§-Multiplicity-of-Features" class="headerlink" title="ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)"></a>ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å¤šä¸ªè¾“å…¥æºçš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€ç‰¹å¾æ³¨æ„åŠ›å’Œå¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
<h3 id="å•ä¸€ç‰¹å¾æ³¨æ„åŠ›-Singular-Features-Attention"><a href="#å•ä¸€ç‰¹å¾æ³¨æ„åŠ›-Singular-Features-Attention" class="headerlink" title="å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)"></a>å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)</h3><p>å¤§å¤šæ•°ä»»åŠ¡æ¨¡å‹åªå¤„ç†å•ä¸€è¾“å…¥(å¦‚å›¾åƒã€å¥å­æˆ–å£°éŸ³åºåˆ—)ï¼Œä½¿ç”¨å•ä¸€ç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ç›´æ¥å¯¹å•ä¸ªè¾“å…¥çš„ç‰¹å¾å‘é‡è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<h3 id="å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶"><a href="#å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶"></a>å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶</h3><p>å½“æ¨¡å‹éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æºæ—¶ï¼Œéœ€è¦ç‰¹æ®Šçš„å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
<p><strong>ååŒæ³¨æ„åŠ›(Co-attention)</strong></p>
<ul>
<li>åˆ†ä¸º <strong>ç²—ç§‘ç²’åº¦(Coarse-grained)</strong> å’Œ <strong>ç»†é¢—ç²’åº¦(Fine-grained)</strong> ä¸¤ç§</li>
<li><strong>ç²—é¢—ç²’åº¦ååŒ</strong>æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„<em>ç´§å‡‘è¡¨ç¤º</em>ä½œä¸ºæŸ¥è¯¢æ¥å…³æ³¨å¦ä¸€ä¸ªè¾“å…¥</li>
<li><strong>ç»†é¢—ç²’åº¦ååŒ</strong>æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„æ‰€æœ‰ç‰¹å¾å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
</ul>
<h4 id="ç²—é¢—ç²’åº¦ååŒ"><a href="#ç²—é¢—ç²’åº¦ååŒ" class="headerlink" title="ç²—é¢—ç²’åº¦ååŒ"></a>ç²—é¢—ç²’åº¦ååŒ</h4><p>è®ºæ–‡ç»™å‡ºçš„ç²—é¢—ç²’åº¦ååŒçš„å®ä¾‹æ˜¯<strong>alternating co-attention</strong></p>
<h5 id="alternating-co-attention"><a href="#alternating-co-attention" class="headerlink" title="alternating co-attention"></a>alternating co-attention</h5><img src="/img/Attention/AlternatingCo-Attention.png" alt="alternating co-attention" width="60%" height="auto">

<p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™æ˜¯ alternating co-attention çš„æ¶æ„å›¾ï¼Œè¯¥æœºåˆ¶äº¤æ›¿ä½¿ç”¨ä¸¤ä¸ªè¾“å…¥çš„ç‰¹å¾çŸ©é˜µï¼Œå…ˆè®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œå°†å…¶ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºæŸ¥è¯¢è®¡ç®—ç¬¬äºŒä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œç„¶åå†ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„ä¸Šä¸‹æ–‡å‘é‡é‡æ–°è®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ã€‚</p>
<p>è¿™é‡Œç°ç»™å‡ºä»–çš„ score å‡½æ•°</p>
<p>å¯¹äºæœ‰åºåˆ—è¾“å…¥çš„ Attentionï¼š</p>
<p>$$<br>\mathrm{score}(\underset{d_{q}\times1}{\boldsymbol{q}},\underset{d_{k}\times1}{\boldsymbol{k}_{l}})&#x3D;\underset{1\times d_{w}}{\boldsymbol{w}^{T}}\times\mathrm{act}(\underset{d_{w}\times d_{q}}{\boldsymbol{W}_{1}}\times\underset{d_{q}\times1}{\boldsymbol{q}}+\underset{d_{w}\times d_{k}}{\boldsymbol{W}_{2}}\times\underset{d_{k}\times1}{\boldsymbol{k}_{l}}+\underset{d_{w}\times1}{\boldsymbol{b}})<br>$$</p>
<p>å¯¹äºæ— åºåˆ—è¾“å…¥çš„ Attention <del>ï¼ˆè¿™æ˜¯ä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œåé¢ä¼šæåˆ°ï¼‰</del> ï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(0)}}&#x3D;\underset{1\times d_{w}}{\boldsymbol{w}^{(1)T}}\times\operatorname{act}(\underset{d_{w}\times d_{k}^{(1)}}{\boldsymbol{W}^{(1)}}\times\underset{d_{k}^{(1)}\times1}{\boldsymbol{k}_{l}^{(1)}}+\underset{d_{w}\times1}{\boldsymbol{b}^{(1)}})<br>$$</p>
<p>å¯¹äºç¬¬äºŒå±‚ Attentionï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(2)}}&#x3D;\mathrm{score}(\underset{d_{v}^{(1)}\times 1}{\boldsymbol{c}^{(0)}},\underset{d_{k}^{(2)}\times1}{\boldsymbol{k}_{l}^{(2)}})<br>$$</p>
<p>å¯¹äºç¬¬ä¸‰å±‚ Attentionï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(1)}}&#x3D;\mathrm{score}(\underset{d_{v}^{(2)}\times 1}{\boldsymbol{c}^{(2)}},\underset{d_{k}^{(1)}\times1}{\boldsymbol{k}_{l}^{(1)}})<br>$$</p>
<p>ç”Ÿæˆçš„ä¸Šä¸‹æ–‡å‘é‡$\boldsymbol{c}^{(1)}$å’Œ$\boldsymbol{c}^{(2)}$è¢«è¿æ¥èµ·æ¥ï¼Œå¹¶åœ¨è¾“å‡ºæ¨¡å‹ä¸­ç”¨äºé¢„æµ‹ã€‚äº¤æ›¿ååŒæ³¨æ„åŠ›ç”±äºéœ€è¦ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è®¡ç®—ä¸Šä¸‹æ–‡å‘é‡ï¼Œå› æ­¤æœ¬è´¨ä¸ŠåŒ…å«äº†<em>ä¸€ç§é¡ºåºæ€§</em>ã€‚è¿™å¯èƒ½ä¼šå¸¦æ¥è®¡ç®—ä¸Šçš„åŠ£åŠ¿ï¼Œå› ä¸º<em>æ— æ³•å¹¶è¡Œ</em>åŒ–ã€‚</p>
<h5 id="interactive-co-attention"><a href="#interactive-co-attention" class="headerlink" title="interactive co-attention"></a>interactive co-attention</h5><img src="/img/Attention/InteractiveCo-Attention.png" alt="interactive co-attention" width="60%" height="auto">

<ul>
<li>å¹¶è¡Œè®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›</li>
<li>ä½¿ç”¨æœªåŠ æƒå¹³å‡çš„å…³é”®å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
<li>è®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†</li>
</ul>
<p>$$<br>\underset{d_k^{(i)}\times1}{\bar{\boldsymbol{k}}^{(i)}}&#x3D;\frac{1}{n_f^{(i)}}\sum\limits_{l&#x3D;1}^{n_f^{(i)}}\underset{d_k^{(i)}\times1}{\boldsymbol{k}_l^{(i)}}, \quad \underset{1\times1}{e_{l}^{(i)}}&#x3D;\mathrm{score}(\underset{d_{k}^{(3-i)}\times1}{\bar{\boldsymbol{k}}^{(3-i)}},\underset{d_{k}^{(i)}\times1}{\boldsymbol{k}_{l}^{(i)}}) , \qquad i&#x3D;1,2<br>$$</p>
<h4 id="ç»†é¢—ç²’åº¦ååŒ"><a href="#ç»†é¢—ç²’åº¦ååŒ" class="headerlink" title="ç»†é¢—ç²’åº¦ååŒ"></a>ç»†é¢—ç²’åº¦ååŒ</h4><p>è™½ç„¶ç²—ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„ç´§å‡‘è¡¨ç¤ºä½œä¸ºæŸ¥è¯¢ï¼Œä»¥è®¡ç®—å¦ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œä½†ç»†ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°æ—¶ä¼šå•ç‹¬è€ƒè™‘æ¯ä¸ªè¾“å…¥çš„æ¯ä¸ªå…ƒç´ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŸ¥è¯¢å˜æˆäº†ä¸€ä¸ªçŸ©é˜µã€‚</p>
<h5 id="å¹¶è¡ŒååŒæ³¨æ„åŠ›-Parallel-Co-attention"><a href="#å¹¶è¡ŒååŒæ³¨æ„åŠ›-Parallel-Co-attention" class="headerlink" title="å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)"></a>å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)</h5><img src="/img/Attention/ParallelCo-Attention.png" alt="parallel co-attention" width="60%" height="auto">

<ul>
<li>åŒæ—¶è®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›</li>
<li>ä½¿ç”¨äº²å’ŒçŸ©é˜µ(Affinity Matrix)è½¬æ¢å…³é”®å‘é‡ç©ºé—´</li>
<li>é€šè¿‡èšåˆå½¢å¼è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°</li>
</ul>
<p>æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼ç”ŸæˆçŸ©é˜µ $\mathbf{A}$</p>
<p>$$<br>\underset{n_{f}^{(1)}\times n_{f}^{(2)}}{\mathbf{A}}&#x3D;\operatorname{act}(\underset{n_{f}^{(1)}\times d_{k}^{(1)}}{\begin{array}{c}K^{(1)^{T}}\end{array}}\times\underset{d_{k}^{(1)}\times d_{k}^{(2)}}{\begin{array}{c}W_{A}\end{array}}\times\underset{d_{k}^{(2)}\times n_{f}^{(2)}}{\begin{array}{c}K^{(2)}\end{array}})<br>$$</p>
<p>$$<br>\underset{1\times1}{A_{i,j}}&#x3D;\underset{1\times3d_{k}}{\boldsymbol{w}_{A}^{T}}\times\mathrm{concat}(\underset{d_{k}\times1}{\boldsymbol{k}_{i}^{(1)}},\underset{d_{k}\times1}{\boldsymbol{k}_{j}^{(2)}},\underset{d_{k}\times1}{\boldsymbol{k}_{i}^{(1)}}\circ\underset{d_{k}\times1}{\boldsymbol{k}_{j}^{(2)}})<br>$$</p>
<p>å…¶ä¸­ï¼Œ$\circ$è¡¨ç¤ºå“ˆå¾·æ›¼ç§¯</p>
<p>Affinity Matrix å¯ä»¥è§£é‡Šä¸ºä¸¤ä¸ªé”®çŸ©é˜µåˆ—çš„ç›¸ä¼¼æ€§çŸ©é˜µï¼Œå¹¶æœ‰åŠ©äºå°†å›¾åƒé”®è½¬æ¢åˆ°ä¸å¥å­ä¸­å•è¯çš„é”®ç›¸åŒçš„ç©ºé—´ï¼Œåä¹‹äº¦ç„¶ã€‚</p>
<p>ç”±äºç°åœ¨æŸ¥è¯¢ç”±å‘é‡å˜æˆäº†çŸ©é˜µï¼Œå› æ­¤ score å‡½æ•°ä¹Ÿå‘ç”Ÿäº†å˜åŒ–</p>
<p>$$<br>e^{(1)} &#x3D;\boldsymbol{w}_{1}\times\mathrm{act}(\boldsymbol{W}_{2}\times\boldsymbol{K}^{(2)}\times\boldsymbol{A}^{T}+\boldsymbol{W}_{1}\times\boldsymbol{K}^{(1)})<br>$$</p>
<p>$$<br>e^{(2)} &#x3D;\boldsymbol{w}_{2}\times\mathrm{act}(\boldsymbol{W}_{1}\times\boldsymbol{K}^{(1)}\times\boldsymbol{A}^{::}+\boldsymbol{W}_{2}\times\boldsymbol{K}^{(2)})<br>$$</p>
<p>å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä¹‹å‰çš„ score å‡½æ•°å®é™…æ˜¯ç°åœ¨è¿™ä¸€å½¢å¼çš„ç‰¹æ®Šè¡¨è¾¾ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªè¡¨è¾¾æ›´å…·ä¸€èˆ¬æ€§</p>
<p>å¦‚å‰æ‰€è¿°ï¼Œäº²å’ŒçŸ©é˜µæœ¬è´¨ä¸Šæ˜¯ä¸¤ä¸ªæ³¨æ„åŠ›æ¨¡å— 1 å’Œ 2 çš„å…³é”®å‘é‡çš„ç›¸ä¼¼æ€§çŸ©é˜µã€‚è¿™ä¸ªæ„å‘³ç€ä¸€ç§ä¸åŒçš„ç¡®å®šæ³¨æ„åŠ›åˆ†æ•°çš„æ–¹æ³•ã€‚å³ï¼Œå¯ä»¥å°†ä¸€è¡Œæˆ–ä¸€åˆ—ä¸­çš„æœ€å¤§ç›¸ä¼¼åº¦å€¼ä½œä¸ºæ³¨æ„åŠ›åˆ†æ•°ã€‚</p>
<p>$$<br>e_{i}^{(1)}&#x3D;\max_{j&#x3D;1,\ldots,n_{f}^{(2)}}A_{i,j},\quad e_{j}^{(2)}&#x3D;\max_{i&#x3D;1,\ldots,n_{f}^{(1)}}A_{i,j}.<br>$$</p>
<h5 id="æ—‹è½¬æ³¨æ„åŠ›-Rotatory-Attention"><a href="#æ—‹è½¬æ³¨æ„åŠ›-Rotatory-Attention" class="headerlink" title="æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)"></a>æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)</h5><p>Rotatory Attention æ˜¯ä¸€ç§ç”¨äºå¤„ç†å¤šè¾“å…¥æ•°æ®çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹åˆ«é€‚ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­åŒæ—¶è€ƒè™‘ç›®æ ‡çŸ­è¯­ã€å·¦ä¸Šä¸‹æ–‡å’Œå³ä¸Šä¸‹æ–‡çš„åœºæ™¯ã€‚è¯¥æœºåˆ¶é€šè¿‡äº¤æ›¿å…³æ³¨ä¸åŒè¾“å…¥æ¥æ„å»ºæ›´ä¸°å¯Œçš„è¡¨ç¤ºã€‚</p>
<ul>
<li>ä¸»è¦ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡</li>
<li>å¤„ç†ä¸‰ä¸ªè¾“å…¥ï¼šç›®æ ‡çŸ­è¯­ $\boldsymbol{F}^{t} &#x3D; [ \boldsymbol{f}_{1}^{t}, \ldots , \boldsymbol{f}_{n_{f}^{t}}^{t}] \in \mathbb{R} ^{d_{f}^{t}\times n_{f}^{t}}$ ã€å·¦ä¸Šä¸‹æ–‡ $\boldsymbol{F^{l}} &#x3D; [ \boldsymbol{f_{1}^{l}}, \ldots , \boldsymbol{f_{n_{f}^{l}}^{l}}]\in\mathbb{R} ^{d_{f}^{l}\times n_{f}^{l}}$ å’Œå³ä¸Šä¸‹æ–‡ $\boldsymbol{F^{r}} &#x3D; [ \boldsymbol{f_{1}^{r}}, \ldots , \boldsymbol{f_{n_{f}^{r}}^{r}}]\in\mathbb{R}^{d_f^r\times n_f^r}$</li>
<li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿­ä»£æ”¹è¿›è¡¨ç¤º</li>
</ul>
<p>å…¶å¤§è‡´çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li><p><strong>åˆå§‹ç‰¹å¾æå–</strong></p>
<p>é¦–å…ˆï¼Œæ¨¡å‹ä»ä¸‰ä¸ªè¾“å…¥ä¸­æå–ç‰¹å¾å‘é‡ç›®æ ‡çŸ­è¯­ç‰¹å¾çŸ©é˜µ $\boldsymbol{F}^{t}$ å·¦ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µ $\boldsymbol{F^{l}}$ å³ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µ $\boldsymbol{F^{r}}$ </p>
</li>
<li><p><strong>ç›®æ ‡çŸ­è¯­åˆå§‹è¡¨ç¤º</strong></p>
<p>è®¡ç®—ç›®æ ‡çŸ­è¯­çš„åˆå§‹è¡¨ç¤ºå‘é‡$r^{t}$ï¼Œé€šè¿‡å¯¹ç‰¹å¾å‘é‡å–å¹³å‡ï¼š</p>
<p>$$<br>r^{t}&#x3D;\frac{1}{n_{f}^{t}}\sum_{i&#x3D;1}^{n_{f}^{t}} f_{i}^{t}<br>$$</p>
</li>
<li><p><strong>å·¦ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—</strong></p>
<p>ä½¿ç”¨$r^{t}$ä½œä¸ºæŸ¥è¯¢ï¼Œè®¡ç®—å·¦ä¸Šä¸‹æ–‡çš„æ³¨æ„åŠ›ï¼š</p>
<ol>
<li><p>æå–é”®å‘é‡ $k_{1}^{l},\ldots,k_{n_{f}^{l}}^{l}\in \mathbb{R}^{d_{k}^{l}}$ å’Œå€¼å‘é‡ $v_{1}^{l},\ldots,v_{n_{f}^{l}}^{l}\in \mathbb{R}^{d_{v}^{l}}$</p>
</li>
<li><p>è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{i}^{l}&#x3D;\operatorname{score}\left(r^{t}, k_{i}^{l}\right)$</p>
</li>
<li><p>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{l}$</p>
</li>
<li><p>è®¡ç®—å·¦ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{l}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{l}} a_{i}^{l}v_{i}^{l}$</p>
</li>
</ol>
</li>
<li><p><strong>å³ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—</strong></p>
<p>ç±»ä¼¼åœ°ï¼Œè®¡ç®—å³ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºå‘é‡$r^{r}$ï¼š</p>
<ol>
<li><p>æå–é”®å‘é‡ $k_{1}^{r},\ldots,k_{n_{f}^{r}}^{r}\in \mathbb{R}^{d_{k}^{r}}$ å’Œå€¼å‘é‡ $v_{1}^{r},\ldots,v_{n_{f}^{r}}^{r}\in \mathbb{R}^{d_{v}^{r}}$</p>
</li>
<li><p>è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{i}^{r}&#x3D;\operatorname{score}\left(r^{t}, k_{i}^{r}\right)$</p>
</li>
<li><p>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{r}$</p>
</li>
<li><p>è®¡ç®—å³ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{r}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{r}} a_{i}^{r}v_{i}^{r}$</p>
</li>
</ol>
</li>
<li><p><strong>ç›®æ ‡çŸ­è¯­æ›´æ–°è¡¨ç¤º</strong></p>
<p>ä½¿ç”¨å·¦ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{l}$å’Œå³ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{r}$æ¥æ›´æ–°ç›®æ ‡çŸ­è¯­çš„è¡¨ç¤ºï¼š</p>
<ol>
<li><p>æå–ç›®æ ‡çŸ­è¯­çš„é”®å‘é‡ $k_{1}^{t},\ldots,k_{n_{f}^{t}}^{t}\in \mathbb{R}^{d_{k}^{t}}$ å’Œå€¼å‘é‡ $v_{1}^{t},\ldots,v_{n_{f}^{t}}^{t}\in \mathbb{R}^{d_{v}^{t}}$</p>
</li>
<li><p>è®¡ç®—å·¦æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º $r^{l_{t}}$ï¼š</p>
<ul>
<li>æ³¨æ„åŠ›åˆ†æ•°ï¼š$e_{i}^{l_{t}}&#x3D;\operatorname{score}\left(r^{l}, k_{i}^{t}\right)$</li>
<li>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡ $a_{i}^{l_{t}}$</li>
<li>è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{l_{t}}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{l_{t}}v_{i}^{t}$</li>
</ul>
</li>
<li><p>è®¡ç®—å³æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º $r^{r_{t}}$ï¼š</p>
<ul>
<li>æ³¨æ„åŠ›åˆ†æ•°ï¼š$e_{i}^{r_{t}}&#x3D;\operatorname{score}\left(r^{r}, k_{i}^{t}\right)$</li>
<li>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡ $a_{i}^{r_{t}}$</li>
<li>è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{r_{t}}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{r_{t}}v_{i}^{t}$</li>
</ul>
</li>
</ol>
</li>
<li><p>æœ€ç»ˆè¡¨ç¤ºä¸º $r&#x3D;\operatorname{concat}\left(r^{l},r^{r},r^{l_{t}},r^{r_{t}}\right)$</p>
</li>
</ol>
<p>Rotatory Attention å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p>
<ol>
<li><p><strong>åŒå‘ä¿¡æ¯æµåŠ¨</strong>ï¼šé€šè¿‡ä»ç›®æ ‡çŸ­è¯­åˆ°ä¸Šä¸‹æ–‡ï¼Œå†ä»ä¸Šä¸‹æ–‡å›åˆ°ç›®æ ‡çŸ­è¯­çš„ä¿¡æ¯æµåŠ¨ï¼Œå®ç°äº†åŒå‘çš„ä¿¡æ¯äº¤äº’ã€‚</p>
</li>
<li><p><strong>å±‚æ¬¡åŒ–è¡¨ç¤º</strong>ï¼šæ„å»ºäº†å¤šå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»åŸå§‹ç‰¹å¾åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾ã€‚</p>
</li>
<li><p><strong>ç‰¹å®šä»»åŠ¡ä¼˜åŒ–</strong>ï¼šç‰¹åˆ«é€‚åˆæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œèƒ½å¤Ÿæ•æ‰ç›®æ ‡çŸ­è¯­ä¸ä¸Šä¸‹æ–‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚</p>
</li>
</ol>
<p>Rotatory Attention é€šè¿‡è¿™ç§äº¤æ›¿å…³æ³¨çš„æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç›®æ ‡çŸ­è¯­åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼Œä»è€Œæé«˜äº†æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚</p>
<h2 id="ç‰¹å¾å±‚çº§-Levels-of-Features"><a href="#ç‰¹å¾å±‚çº§-Levels-of-Features" class="headerlink" title="ç‰¹å¾å±‚çº§(Levels of Features)"></a>ç‰¹å¾å±‚çº§(Levels of Features)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å…·æœ‰å±‚çº§ç»“æ„çš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•å±‚çº§æ³¨æ„åŠ›å’Œå¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶ã€‚å¤šå±‚çº§æ³¨æ„åŠ›èƒ½å¤Ÿæ•æ‰<strong>ä¸åŒç²’åº¦</strong>ä¸Šçš„é‡è¦ä¿¡æ¯ã€‚</p>
<h3 id="å•å±‚çº§æ³¨æ„åŠ›-Single-Level-Attention"><a href="#å•å±‚çº§æ³¨æ„åŠ›-Single-Level-Attention" class="headerlink" title="å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)"></a>å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)</h3><p>ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶é€šå¸¸åœ¨å•ä¸€å±‚çº§ä¸Šå¤„ç†ç‰¹å¾ï¼Œå¦‚åªå…³æ³¨å•è¯çº§åˆ«æˆ–å¥å­çº§åˆ«ã€‚</p>
<h3 id="å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶"><a href="#å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶"></a>å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶</h3><ol>
<li><strong>æ³¨æ„åŠ›å åŠ (Attention-via-Attention)</strong></li>
</ol>
<img src="/img/Attention/AttentionViaAttention.png" alt="attention-via-attention" width="60%" height="auto">

<ul>
<li>åŒæ—¶å¤„ç†å­—ç¬¦çº§å’Œè¯çº§ç‰¹å¾</li>
<li>å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”¨å…¶ä¸Šä¸‹æ–‡å‘é‡è¾…åŠ©è®¡ç®—å­—ç¬¦çº§æ³¨æ„åŠ›</li>
<li>æœ€ç»ˆæ‹¼æ¥ä¸¤ä¸ªå±‚çº§çš„ä¸Šä¸‹æ–‡å‘é‡</li>
</ul>
<p>ç”¨äºæœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼ŒåŒæ—¶åˆ©ç”¨å­—ç¬¦çº§å’Œè¯çº§ä¿¡æ¯ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨é¢„æµ‹å­—ç¬¦æ—¶ï¼Œå…ˆé€šè¿‡è¯çº§æ³¨æ„åŠ›ç¡®å®šé‡è¦è¯è¯­ï¼Œå†åœ¨è¿™äº›è¯è¯­å¯¹åº”çš„å­—ç¬¦ä¸Šæ–½åŠ æ³¨æ„åŠ›ã€‚</p>
<p>å…¶å¤§è‡´è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li><p>è¾“å…¥å¥å­è¢«ç¼–ç ä¸ºå­—ç¬¦çº§ç‰¹å¾çŸ©é˜µ $F^{(c)}\in \mathbb{R}^{d_{f}^{(c)}\times n_{f}^{(c)}}$ å’Œè¯çº§ç‰¹å¾çŸ©é˜µ $F^{(w)}\in \mathbb{R}^{d_{f}^{(w)}\times n_{f}^{(w)}}$</p>
</li>
<li><p>å­—ç¬¦çº§æŸ¥è¯¢ $q^{(c)}\in \mathbb{R}^{d_{q}}$ é€šè¿‡æŸ¥è¯¢æ¨¡å‹ç”Ÿæˆ</p>
</li>
<li><p>å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”Ÿæˆè¯çº§ä¸Šä¸‹æ–‡å‘é‡ $c^{(w)}\in \mathbb{R}^{d_{v}^{(w)}}$</p>
</li>
<li><p>å°† $q^{(c)}$ å’Œ $c^{(w)}$ æ‹¼æ¥ä½œä¸ºå­—ç¬¦çº§æ³¨æ„åŠ›çš„æŸ¥è¯¢</p>
</li>
<li><p>æœ€ç»ˆè¾“å‡ºæ˜¯å­—ç¬¦çº§å’Œè¯çº§ä¸Šä¸‹æ–‡å‘é‡çš„æ‹¼æ¥</p>
</li>
<li><p><strong>å±‚çº§æ³¨æ„åŠ›(Hierarchical Attention)</strong></p>
</li>
</ol>
<img src="/img/Attention/HierarchicalAttention.png" alt="hierarchical attention" width="60%" height="auto">

<ul>
<li>ä»æœ€ä½å±‚çº§å¼€å§‹ï¼Œé€æ­¥æ„å»ºé«˜å±‚çº§è¡¨ç¤º</li>
<li>å¸¸ç”¨äºæ–‡æ¡£åˆ†ç±»ï¼šè¯ â†’ å¥ â†’ æ–‡æ¡£</li>
<li>æ¯ä¸ªå±‚çº§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç”Ÿæˆæ‘˜è¦è¡¨ç¤º</li>
</ul>
<p>ç”¨äºæ–‡æ¡£åˆ†ç±»ã€‚è¯¥æ–¹æ³•è‡ªåº•å‘ä¸Šæ„å»ºå±‚çº§è¡¨ç¤ºï¼šä»è¯çº§è¡¨ç¤ºæ„å»ºå¥çº§è¡¨ç¤ºï¼Œå†ä»å¥çº§è¡¨ç¤ºæ„å»ºæ–‡æ¡£çº§è¡¨ç¤ºã€‚</p>
<p>å…¶å¤§è‡´è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li><p>æ–‡æ¡£åŒ…å« $n_S$ ä¸ªå¥å­ï¼Œç¬¬ $s$ ä¸ªå¥å­åŒ…å« $n_s$ ä¸ªè¯</p>
</li>
<li><p>å¯¹æ¯ä¸ªå¥å­è®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”Ÿæˆå¥è¡¨ç¤º $c^{(s)}\in \mathbb{R}^{d_{v}^{(S)}}$</p>
</li>
<li><p>å°†æ‰€æœ‰å¥è¡¨ç¤º $C&#x3D;[c^{(1)},\ldots,c^{(n_{S})}]\in \mathbb{R}^{d_{v}^{(S)} \times n_{S}}$ ä½œä¸ºæ–‡æ¡£çº§æ³¨æ„åŠ›çš„è¾“å…¥</p>
</li>
<li><p>æ–‡æ¡£çº§æ³¨æ„åŠ›è¾“å‡º $c^{(D)}\in \mathbb{R}^{d_{v}^{(D)}}$ ç”¨äºåˆ†ç±»</p>
</li>
</ol>
<h4 id="åº”ç”¨é¢†åŸŸ"><a href="#åº”ç”¨é¢†åŸŸ" class="headerlink" title="åº”ç”¨é¢†åŸŸ"></a>åº”ç”¨é¢†åŸŸ</h4><p>å¤šå±‚çº§æ³¨æ„åŠ›å·²æˆåŠŸåº”ç”¨äº <del>æ‡’å¾—åšé“¾æ¥äº†æï¼Œå¯ä»¥å»åŸæ–‡æ‰¾æ</del> ï¼š</p>
<ul>
<li>æ¨èç³»ç»Ÿï¼šå»ºæ¨¡ç”¨æˆ·é•¿çŸ­æœŸåå¥½(Ying et al., 2018)</li>
<li>è§†é¢‘åŠ¨ä½œè¯†åˆ«ï¼šæ•æ‰ä¸åŒæ—¶é—´å°ºåº¦çš„è¿åŠ¨ä¿¡æ¯(Wang et al., 2016)</li>
<li>è·¨é¢†åŸŸæƒ…æ„Ÿåˆ†ç±»ï¼šå­¦ä¹ é¢†åŸŸå…±äº«å’Œç‰¹å®šç‰¹å¾(Li et al., 2018)</li>
<li>èŠå¤©æœºå™¨äººï¼šç”Ÿæˆæ›´è¿è´¯çš„å“åº”(Xing et al., 2018)</li>
<li>äººç¾¤è®¡æ•°ï¼šå¤„ç†ä¸åŒå°ºåº¦çš„äººç¾¤å¯†åº¦(Sindagi &amp; Patel, 2019)</li>
</ul>
<h2 id="ç‰¹å¾è¡¨ç¤º-Feature-Representations"><a href="#ç‰¹å¾è¡¨ç¤º-Feature-Representations" class="headerlink" title="ç‰¹å¾è¡¨ç¤º(Feature Representations)"></a>ç‰¹å¾è¡¨ç¤º(Feature Representations)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†ç‰¹å¾è¡¨ç¤ºç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆFeature Representationsï¼‰ï¼Œä¸»è¦å…³æ³¨å¦‚ä½•åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥å¤„ç†å’Œç»„åˆä¸åŒçš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™éƒ¨åˆ†å†…å®¹å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šå•è¡¨ç¤ºæ³¨æ„åŠ›ï¼ˆSingle-representational attentionï¼‰å’Œå¤šè¡¨ç¤ºæ³¨æ„åŠ›ï¼ˆMulti-representational attentionï¼‰ã€‚</p>
<h3 id="å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›-Single-Representational-Attention"><a href="#å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›-Single-Representational-Attention" class="headerlink" title="å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)"></a>å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)</h3><p>å•è¡¨ç¤ºæ³¨æ„åŠ›æ˜¯æœ€åŸºç¡€çš„æ³¨æ„åŠ›å½¢å¼ï¼Œå®ƒä½¿ç”¨å•ä¸€çš„ç‰¹å¾è¡¨ç¤ºæ¨¡å‹ï¼ˆå¦‚è¯åµŒå…¥ã€CNNç‰¹å¾æå–å™¨ç­‰ï¼‰æ¥ç”Ÿæˆç‰¹å¾å‘é‡ã€‚è¿™äº›ç‰¹å¾å‘é‡éšåè¢«é€å…¥æ³¨æ„åŠ›æ¨¡å—è¿›è¡Œå¤„ç†ã€‚</p>
<h3 id="å¤šè¡¨ç¤ºæ³¨æ„åŠ›-Multi-Representational-Attention"><a href="#å¤šè¡¨ç¤ºæ³¨æ„åŠ›-Multi-Representational-Attention" class="headerlink" title="å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)"></a>å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)</h3><p>å¤šè¡¨ç¤ºæ³¨æ„åŠ›æ˜¯ä¸€ç§æ›´é«˜çº§çš„æŠ€æœ¯ï¼Œå®ƒå…è®¸æ¨¡å‹åŒæ—¶è€ƒè™‘å¤šç§ä¸åŒçš„ç‰¹å¾è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æ¥å­¦ä¹ å¦‚ä½•æœ€ä¼˜åœ°ç»„åˆè¿™äº›è¡¨ç¤ºã€‚</p>
<h4 id="å…ƒåµŒå…¥-Meta-embeddings"><a href="#å…ƒåµŒå…¥-Meta-embeddings" class="headerlink" title="å…ƒåµŒå…¥(Meta-embeddings)"></a>å…ƒåµŒå…¥(Meta-embeddings)</h4><p>è¿™ç§æ–¹æ³•å¯ä»¥åˆ›å»ºæ‰€è°“çš„â€å…ƒåµŒå…¥â€ï¼ˆmeta-embeddingsï¼‰ã€‚</p>
<ul>
<li>æ•´åˆå¤šä¸ªåµŒå…¥è¡¨ç¤º</li>
<li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ æƒå¹³å‡ä¸åŒè¡¨ç¤º</li>
<li>ç”Ÿæˆæ›´é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤º</li>
</ul>
<p>å…ƒåµŒå…¥çš„åˆ›å»ºè¿‡ç¨‹å¤§è‡´å¦‚ä¸‹ï¼š</p>
<ol>
<li><p><strong>è¾“å…¥è¡¨ç¤º</strong>ï¼šå¯¹äºä¸€ä¸ªè¾“å…¥ $x$ ï¼ˆå¦‚ä¸€ä¸ªè¯ï¼‰ï¼Œæˆ‘ä»¬æœ‰ $E$ ç§ä¸åŒçš„åµŒå…¥è¡¨ç¤ºï¼š $x^{(e_1)}, \ldots, x^{(e_E)}$ , å…¶ä¸­æ¯ç§åµŒå…¥ $x^{(e_i)}$ çš„ç»´åº¦ä¸º $d_{e_i}$ï¼ˆ$i&#x3D;1,\ldots,E$ ï¼‰ã€‚</p>
</li>
<li><p><strong>ç»´åº¦æ ‡å‡†åŒ–</strong>ï¼šç”±äºä¸åŒåµŒå…¥å¯èƒ½æœ‰ä¸åŒç»´åº¦ï¼Œé¦–å…ˆé€šè¿‡çº¿æ€§å˜æ¢å°†å®ƒä»¬æ˜ å°„åˆ°ç»Ÿä¸€ç»´åº¦ $d_t$ ï¼š $x^{(t_i)} &#x3D; W_{e_i} \times x^{(e_i)} + b_{e_i}$ ï¼Œ å…¶ä¸­ $W_{e_i} \in \mathbb{R}^{d_t \times d_{e_i}}$ å’Œ $b_{e_i} \in \mathbb{R}^{d_t}$ æ˜¯å¯è®­ç»ƒçš„å‚æ•°ã€‚</p>
</li>
<li><p><strong>æ³¨æ„åŠ›åŠ æƒç»„åˆ</strong>ï¼šæœ€ç»ˆçš„å…ƒåµŒå…¥æ˜¯è¿™äº›æ ‡å‡†åŒ–è¡¨ç¤ºçš„åŠ æƒå’Œï¼š $x^{(e)} &#x3D; \sum_{i&#x3D;1}^E a_i \times x^{(t_i)}$ å…¶ä¸­æƒé‡ $a_i$ é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—å¾—åˆ°ã€‚</p>
</li>
</ol>
<h5 id="æ³¨æ„åŠ›è®¡ç®—"><a href="#æ³¨æ„åŠ›è®¡ç®—" class="headerlink" title="æ³¨æ„åŠ›è®¡ç®—"></a>æ³¨æ„åŠ›è®¡ç®—</h5><p>åœ¨å¤šè¡¨ç¤ºæ³¨æ„åŠ›ä¸­ï¼Œæ³¨æ„åŠ›æƒé‡çš„è®¡ç®—å¯ä»¥è§†ä¸ºä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶æŸ¥è¯¢å¯ä»¥ç†è§£ä¸ºâ€å“ªäº›è¡¨ç¤ºå¯¹å½“å‰ä»»åŠ¡æœ€é‡è¦â€ã€‚å…·ä½“è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li>å°†æ ‡å‡†åŒ–åçš„è¡¨ç¤º $x^{(t_1)}, \ldots, x^{(t_E)}$ ä½œä¸ºç‰¹å¾çŸ©é˜µFçš„åˆ—å‘é‡</li>
<li>ç”±äºæ²¡æœ‰æ˜¾å¼æŸ¥è¯¢ï¼Œè¿™ç›¸å½“äºè‡ªæ³¨æ„åŠ›æœºåˆ¶</li>
<li>ä½¿ç”¨é€‚å½“çš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°è®¡ç®—æƒé‡</li>
<li>é€šè¿‡å¯¹é½å‡½æ•°ï¼ˆå¦‚softmaxï¼‰å¾—åˆ°å½’ä¸€åŒ–çš„æ³¨æ„åŠ›æƒé‡</li>
</ol>
<h3 id="æŠ€æœ¯ä¼˜åŠ¿"><a href="#æŠ€æœ¯ä¼˜åŠ¿" class="headerlink" title="æŠ€æœ¯ä¼˜åŠ¿"></a>æŠ€æœ¯ä¼˜åŠ¿</h3><ol>
<li><strong>çµæ´»æ€§</strong>ï¼šå¯ä»¥æ•´åˆæ¥è‡ªä¸åŒæ¥æºæˆ–ä¸åŒç²’åº¦çš„ç‰¹å¾è¡¨ç¤º</li>
<li><strong>é€‚åº”æ€§</strong>ï¼šé€šè¿‡æ³¨æ„åŠ›æƒé‡è‡ªåŠ¨å­¦ä¹ ä¸åŒè¡¨ç¤ºçš„é‡è¦æ€§</li>
<li><strong>å¯è§£é‡Šæ€§</strong>ï¼šæ³¨æ„åŠ›æƒé‡å¯ä»¥æä¾›å…³äºå“ªäº›ç‰¹å¾è¡¨ç¤ºå¯¹ä»»åŠ¡æ›´é‡è¦çš„è§è§£</li>
</ol>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
<a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a>
]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
        <category>category</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>PEP 8</title>
    <url>/2025/07/08/PEP-8/</url>
    <content><![CDATA[<h1 id="Style-Guide-for-Python-Code"><a href="#Style-Guide-for-Python-Code" class="headerlink" title="Style Guide for Python Code"></a>Style Guide for Python Code</h1><blockquote>
<p><a href="https://peps.python.org/pep-0008/">PEP8</a> æ˜¯ Python ç¤¾ç¾¤å…±é€šçš„é¢¨æ ¼æŒ‡å—ï¼Œä¸€é–‹å§‹æ˜¯ Python ä¹‹çˆ¶ Guido van Rossum è‡ªå·±çš„æ’°ç¢¼é¢¨æ ¼ï¼Œæ…¢æ…¢å¾Œä¾†æ¼”è®Šè‡³ä»Šï¼Œç›®çš„åœ¨æ–¼å¹«åŠ©é–‹ç™¼è€…å¯«å‡ºå¯è®€æ€§é«˜ä¸”é¢¨æ ¼ä¸€è‡´çš„ç¨‹å¼ã€‚è¨±å¤šé–‹æºè¨ˆç•«ï¼Œä¾‹å¦‚ Django ã€ OpenStack ç­‰éƒ½æ˜¯ä»¥ PEP8 ç‚ºåŸºç¤å†åŠ ä¸Šè‡ªå·±çš„é¢¨æ ¼å»ºè­°ã€‚</p>
</blockquote>
<p>è¿™ç¯‡åšå®¢ä¸»è¦æ˜¯ä¸ºäº†åœ¨æ­å»ºè‡ªå·±çš„æ¨¡å‹ä¹‹å‰å­¦ä¹ ä¸€ä¸‹ä¸€äº›ç»Ÿä¸€çš„è§„èŒƒæ˜¯åšçš„è®°å½• <del>ä¸»è¦æ˜¯ç›®å‰è¯»åˆ°çš„å¤§å¤šæ•°è®ºæ–‡çš„æºç ç›®å‘½åæ²¡æœ‰è§„å¾‹</del> ï¼Œä»¥åŠ å¼ºä¹‹åæ­å»ºæ¨¡å‹æ—¶ä»£ç çš„å¯è¯»æ€§</p>
<p>å¦å¤–ï¼Œæœ¬åšå®¢åªå±•ç¤ºæœ¬äººä¸å¤ªç†Ÿæ‚‰çš„æ</p>
<span id="more"></span>

<h2 id="ä»£ç å¸ƒå±€"><a href="#ä»£ç å¸ƒå±€" class="headerlink" title="ä»£ç å¸ƒå±€"></a>ä»£ç å¸ƒå±€</h2><h3 id="ç¼©è¿›"><a href="#ç¼©è¿›" class="headerlink" title="ç¼©è¿›"></a>ç¼©è¿›</h3><p><strong>æ¯ä¸ªç¼©è¿›çº§åˆ«ä½¿ç”¨ 4 ä¸ªç©ºæ ¼</strong></p>
<p>å¯¹äºæ¯”è¾ƒè‡­é•¿çš„å‡½æ•°ï¼Œå¯ä»¥ä½¿ç”¨<em>æ‚¬æŒ‚ç¼©è¿›</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Correct:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Aligned with opening delimiter.</span></span><br><span class="line">foo = long_function_name(var_one, var_two,</span><br><span class="line">                         var_three, var_four)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">long_function_name</span>(<span class="params"></span></span><br><span class="line"><span class="params">        var_one, var_two, var_three,</span></span><br><span class="line"><span class="params">        var_four</span>):</span><br><span class="line">    <span class="built_in">print</span>(var_one)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hanging indents should add a level.</span></span><br><span class="line">foo = long_function_name(</span><br><span class="line">    var_one, var_two,</span><br><span class="line">    var_three, var_four)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Wrong:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Arguments on first line forbidden when not using vertical alignment.</span></span><br><span class="line">foo = long_function_name(var_one, var_two,</span><br><span class="line">    var_three, var_four)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Further indentation required as indentation is not distinguishable.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">long_function_name</span>(<span class="params"></span></span><br><span class="line"><span class="params">    var_one, var_two, var_three,</span></span><br><span class="line"><span class="params">    var_four</span>):</span><br><span class="line">    <span class="built_in">print</span>(var_one)</span><br></pre></td></tr></table></figure>

<p>ä¼˜å…ˆä½¿ç”¨ <em>Tabs</em> è¿›è¡Œç¼©è¿›ï¼Œ <em>Tabs</em> å’Œ <em>Spaces</em> ä¸èƒ½æ··ç”¨</p>
<h3 id="æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡"><a href="#æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡" class="headerlink" title="æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡"></a>æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡</h3><p><strong>79</strong> ä¸ª</p>
<p>åˆç†ä½¿ç”¨åæ–œæ </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;/path/to/some/file/you/want/to/read&#x27;</span>) <span class="keyword">as</span> file_1, \</span><br><span class="line">     <span class="built_in">open</span>(<span class="string">&#x27;/path/to/some/file/being/written&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file_2:</span><br><span class="line">    file_2.write(file_1.read())</span><br></pre></td></tr></table></figure>

<h3 id="äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ"><a href="#äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ" class="headerlink" title="äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ"></a>äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ</h3><p>ä¸ºäº†æ›´å¥½çš„ç¡®å®šè¯¥ <code>item</code> é‡‡å–çš„æ˜¯ä»€ä¹ˆè¿ç®—</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Wrong:</span></span><br><span class="line"><span class="comment"># operators sit far away from their operands</span></span><br><span class="line">income = (gross_wages +</span><br><span class="line">          taxable_interest +</span><br><span class="line">          (dividends - qualified_dividends) -</span><br><span class="line">          ira_deduction -</span><br><span class="line">          student_loan_interest)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Correct:</span></span><br><span class="line"><span class="comment"># easy to match operators with operands</span></span><br><span class="line">income = (gross_wages</span><br><span class="line">          + taxable_interest</span><br><span class="line">          + (dividends - qualified_dividends)</span><br><span class="line">          - ira_deduction</span><br><span class="line">          - student_loan_interest)</span><br></pre></td></tr></table></figure>

<h3 id="å¦‚ä½•ç©ºè¡Œï¼ˆBlank-Linesï¼‰"><a href="#å¦‚ä½•ç©ºè¡Œï¼ˆBlank-Linesï¼‰" class="headerlink" title="å¦‚ä½•ç©ºè¡Œï¼ˆBlank Linesï¼‰"></a>å¦‚ä½•ç©ºè¡Œï¼ˆBlank Linesï¼‰</h3><p><em>é¡¶çº§å‡½æ•°</em> å’Œ <em>ç±»</em> ä¹‹é—´ç©º <strong>2</strong> è¡Œ</p>
<p><em>ç±»ä¸­çš„å‡½æ•°</em> ç©º <strong>1</strong> è¡Œ</p>
<h3 id="import"><a href="#import" class="headerlink" title="import"></a>import</h3><ul>
<li>é€šå¸¸æ¯ä¸€ä¸ªåº“ <strong>å•ç‹¬ä¸€è¡Œ</strong>ï¼ˆä¹Ÿæœ‰ä¾‹å¤–ï¼‰</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> subprocess <span class="keyword">import</span> Popen, PIPE</span><br></pre></td></tr></table></figure>

<ul>
<li>æŒ‰ä»¥ä¸‹é¡ºåºåˆ†ç»„ï¼Œæ¯ç»„é—´ç©ºè¡Œ<ol>
<li><strong>æ ‡å‡†åº“</strong>å¯¼å…¥</li>
<li><strong>ç›¸å…³ç¬¬ä¸‰æ–¹åº“</strong>å¯¼å…¥</li>
<li><strong>ç‰¹å®šçš„æœ¬åœ°åº“</strong>å¯¼å…¥</li>
</ol>
</li>
</ul>
<h2 id="æ³¨é‡Š"><a href="#æ³¨é‡Š" class="headerlink" title="æ³¨é‡Š"></a>æ³¨é‡Š</h2><blockquote>
<p>Comments that contradict the code are worse than no comments.</p>
</blockquote>
<h2 id="å‘½åçº¦å®š"><a href="#å‘½åçº¦å®š" class="headerlink" title="å‘½åçº¦å®š"></a>å‘½åçº¦å®š</h2><ol>
<li><p><strong>ç±»å</strong> ç”¨ <strong>å¤§é©¼å³°</strong></p>
</li>
<li><p><strong>å‡½æ•°å</strong> ç”¨ <strong>å°å†™ä¸‹åˆ’çº¿</strong></p>
</li>
<li><p>å…³äº <em>ä¸‹åˆ’çº¿</em></p>
<ul>
<li><em>å•ä¸‹åˆ’çº¿</em> ç”¨äºå ä½</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(random.randint(<span class="number">1</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><em>å•ä¸‹åˆ’çº¿</em> ç”¨äºå˜é‡å‰è¡¨ç¤ºè¯¥å˜é‡ä¸º <strong>å¼±ç§æœ‰</strong> ï¼ˆè¯­ä¹‰ä¸Šçš„ privateï¼‰ï¼Œèƒ½è°ƒç”¨ä½†ä¸èƒ½ import</li>
<li><em>åŒä¸‹åˆ’çº¿</em> ç”¨äºå˜é‡å‰è¡¨ç¤ºè¯¥å˜é‡ä¸º <strong>å¼ºç§æœ‰</strong> ï¼ˆå®é™…ä¸Šä¹Ÿä¸èƒ½è°ƒç”¨<del>å®ç°æ–¹å¼æ˜¯é‡åå</del>ï¼‰<br>ä¸ºäº†æ›´å¥½çš„è¯´æ˜è¿™ä¸¤ç‚¹ï¼Œç»™å‡ºä»¥ä¸‹ä¸¤ä¸ªæµ‹è¯•ç¨‹åº</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">test_private_vars.py</span></span><br><span class="line"><span class="string">This file is used to test the private variables in Python.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestClass</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.public_var = <span class="string">&quot;è¿™æ˜¯å…¬æœ‰å˜é‡&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>._weak_private = <span class="string">&quot;è¿™æ˜¯å¼±ç§æœ‰å˜é‡&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.__strong_private = <span class="string">&quot;è¿™æ˜¯å¼ºç§æœ‰å˜é‡&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_all_vars</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ä»å†…éƒ¨è®¿é—®:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å…¬æœ‰å˜é‡: <span class="subst">&#123;self.public_var&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;self._weak_private&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;self.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæµ‹è¯•å®ä¾‹</span></span><br><span class="line">test = TestClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. æµ‹è¯•ä»ç±»å†…éƒ¨è®¿é—®ï¼ˆé€šè¿‡æ–¹æ³•ï¼‰</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===&quot;</span>)</span><br><span class="line">test.print_all_vars()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. æµ‹è¯•ä»å¤–éƒ¨ç›´æ¥è®¿é—®</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å…¬æœ‰å˜é‡: <span class="subst">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;test._weak_private&#125;</span>&quot;</span>)  <span class="comment"># èƒ½è®¿é—®ï¼Œä½†IDEä¼šè­¦å‘Š</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. æµ‹è¯•åç§°æ”¹å†™æœºåˆ¶</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===&quot;</span>)</span><br><span class="line"><span class="comment"># å®é™…ä¸ŠPythonä¼šå°†__strong_privateæ”¹å†™ä¸º_TestClass__strong_private</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. æµ‹è¯•å¯¼å…¥è¡Œä¸º</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•4: åˆ›å»ºç¬¬äºŒä¸ªæ–‡ä»¶å¹¶å°è¯•å¯¼å…¥ ===&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;è¯·åˆ›å»º test_import.py å¹¶è¿è¡Œæ¥æµ‹è¯•å¯¼å…¥è¡Œä¸º&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">test_import.py</span></span><br><span class="line"><span class="string">This file is used to test the import of private variables in Python.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> test_private_vars <span class="keyword">import</span> TestClass</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=== æµ‹è¯•å¯¼å…¥åçš„è®¿é—®è¡Œä¸º ===&quot;</span>)</span><br><span class="line">test = TestClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å…¬æœ‰å˜é‡</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å…¬æœ‰å˜é‡: <span class="subst">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å¼±ç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;test._weak_private&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;æ³¨æ„ï¼šè™½ç„¶èƒ½è®¿é—®å¼±ç§æœ‰å˜é‡ï¼Œä½†è¿™è¿åäº†Pythonçš„çº¦å®š&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å¼ºç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;æ³¨æ„ï¼šè™½ç„¶èƒ½é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªä¸æ¨èçš„åšæ³•&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åç§°è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>ä»¥ä¸‹æ˜¯è¿è¡Œ <code>python test_private_vars.py</code> çš„ç»“æœ</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===</span><br><span class="line">ä»å†…éƒ¨è®¿é—®:</span><br><span class="line">å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===</span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•4: åˆ›å»ºç¬¬äºŒä¸ªæ–‡ä»¶å¹¶å°è¯•å¯¼å…¥ ===</span><br><span class="line">è¯·åˆ›å»º test_import.py å¹¶è¿è¡Œæ¥æµ‹è¯•å¯¼å…¥è¡Œä¸º</span><br></pre></td></tr></table></figure>

<p>ä»¥ä¸‹æ˜¯è¿è¡Œ <code>python test_import.py</code> çš„ç»“æœ</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===</span><br><span class="line">ä»å†…éƒ¨è®¿é—®:</span><br><span class="line">å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===</span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line">=== æµ‹è¯•å¯¼å…¥åçš„è®¿é—®è¡Œä¸º ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">æ³¨æ„ï¼šè™½ç„¶èƒ½è®¿é—®å¼±ç§æœ‰å˜é‡ï¼Œä½†è¿™è¿åäº†Pythonçš„çº¦å®š</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line">æ³¨æ„ï¼šè™½ç„¶èƒ½é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªä¸æ¨èçš„åšæ³•</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>Python</tag>
        <tag>PEP</tag>
        <tag>é—²ğŸ‰æ— èŠ</tag>
        <tag>å¤§æ¦‚ç‡æ²¡ç”¨</tag>
      </tags>
  </entry>
  <entry>
    <title>Quaqua Rishinala</title>
    <url>/2025/07/17/Query-Related-Attention/</url>
    <content><![CDATA[<h1 id="åœ¨æŸ¥è¯¢ä¸Šåšæ–‡ç« çš„-Attention"><a href="#åœ¨æŸ¥è¯¢ä¸Šåšæ–‡ç« çš„-Attention" class="headerlink" title="åœ¨æŸ¥è¯¢ä¸Šåšæ–‡ç« çš„ Attention"></a>åœ¨æŸ¥è¯¢ä¸Šåšæ–‡ç« çš„ Attention</h1><div style="display: flex; align-items: center;">
  <img src="\img\Attention\Quaqua Rishinala.png" style="width: 200px; margin-right: 20px;">
  <p>æŸ¥è¯¢æ˜¯ä»»ä½•æ³¨æ„åŠ›æ¨¡å‹çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå› ä¸ºå®ƒä»¬ç›´æ¥å†³å®šäº†ä»ç‰¹å¾å‘é‡ä¸­æå–å“ªäº›ä¿¡æ¯ã€‚è¿™äº›æŸ¥è¯¢åŸºäºä»»åŠ¡æ¨¡å‹çš„æœŸæœ›è¾“å‡ºï¼Œå¹¶å¯ä»¥è§£é‡Šä¸ºå­—é¢é—®é¢˜ã€‚ä¸€äº›æŸ¥è¯¢å…·æœ‰ç‰¹å®šçš„ç‰¹å¾ï¼Œéœ€è¦ç‰¹å®šç±»å‹çš„æœºåˆ¶æ¥å¤„ç†å®ƒä»¬ã€‚å› æ­¤ï¼Œè¿™ä¸€ç±»åˆ«å°è£…äº†å¤„ç†ç‰¹å®šç±»å‹æŸ¥è¯¢ç‰¹å¾çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ä¸€ç±»åˆ«çš„æœºåˆ¶å¤„ç†ä»¥ä¸‹ä¸¤ç§æŸ¥è¯¢ç‰¹å¾ä¹‹ä¸€ï¼šæŸ¥è¯¢çš„ç±»å‹æˆ–æŸ¥è¯¢çš„å¤šé‡æ€§ã€‚</p>
</div>

<p>åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» <a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a></p>
<span id="more"></span>

<h2 id="æŸ¥è¯¢ç±»å‹æœºåˆ¶-Query-Type-Mechanisms"><a href="#æŸ¥è¯¢ç±»å‹æœºåˆ¶-Query-Type-Mechanisms" class="headerlink" title="æŸ¥è¯¢ç±»å‹æœºåˆ¶(Query Type Mechanisms)"></a>æŸ¥è¯¢ç±»å‹æœºåˆ¶(Query Type Mechanisms)</h2><h3 id="åŸºæœ¬æŸ¥è¯¢ä¸ç‰¹æ®ŠæŸ¥è¯¢"><a href="#åŸºæœ¬æŸ¥è¯¢ä¸ç‰¹æ®ŠæŸ¥è¯¢" class="headerlink" title="åŸºæœ¬æŸ¥è¯¢ä¸ç‰¹æ®ŠæŸ¥è¯¢"></a>åŸºæœ¬æŸ¥è¯¢ä¸ç‰¹æ®ŠæŸ¥è¯¢</h3><p>æŸ¥è¯¢(Query)åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œå®ƒå†³å®šäº†æ¨¡å‹å…³æ³¨è¾“å…¥æ•°æ®çš„å“ªäº›éƒ¨åˆ†ã€‚3.3 èŠ‚é¦–å…ˆåŒºåˆ†äº†ä¸¤ç§åŸºæœ¬æŸ¥è¯¢ç±»å‹ï¼š</p>
<ol>
<li><p><strong>åŸºæœ¬æŸ¥è¯¢(Basic Queries)</strong>ï¼šè¿™ç±»æŸ¥è¯¢é€šå¸¸ç›´æ¥æ¥æºäºæ¨¡å‹ç»“æ„æˆ–æ•°æ®ç‰¹å¾ã€‚ä¾‹å¦‚ï¼š</p>
<ul>
<li>RNN ä¸­çš„éšè—çŠ¶æ€ä½œä¸ºåºåˆ—ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æŸ¥è¯¢</li>
<li>è¾…åŠ©å˜é‡ï¼ˆå¦‚åŒ»ç–—å›¾åƒåˆ†ç±»ä¸­çš„æ‚£è€…ç‰¹å¾ï¼‰ä½œä¸ºæŸ¥è¯¢</li>
<li>å›¾åƒå¤„ç†ä¸­ CNN æå–çš„ç‰¹å¾å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
</ul>
</li>
<li><p><strong>ç‰¹æ®ŠæŸ¥è¯¢(Specialized Queries)</strong>ï¼šç”¨äºç‰¹å®šæ³¨æ„åŠ›æ¶æ„çš„æŸ¥è¯¢ï¼Œå¦‚ï¼š</p>
<ul>
<li>æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)ä¸­ä½¿ç”¨ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
<li>äº¤äº’å¼ååŒæ³¨æ„åŠ›(Interactive Co-attention)ä¸­ä½¿ç”¨å¹³å‡é”®å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
<li>æ³¨æ„åŠ›å †å (Attention-over-Attention)ä¸­çš„å¤šå±‚æŸ¥è¯¢</li>
</ul>
</li>
</ol>
<h3 id="è‡ªæ³¨æ„åŠ›æœºåˆ¶-Self-Attention"><a href="#è‡ªæ³¨æ„åŠ›æœºåˆ¶-Self-Attention" class="headerlink" title="è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-Attention)"></a>è‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-Attention)</h3><p>è‡ªæ³¨æ„åŠ›ï¼ˆæˆ–ç§°å†…éƒ¨æ³¨æ„åŠ›ï¼‰æ˜¯æŸ¥è¯¢ç›¸å…³æœºåˆ¶ä¸­æœ€é‡è¦çš„åˆ›æ–°ä¹‹ä¸€ï¼Œå®ƒå…è®¸æ¨¡å‹é€šè¿‡æ•°æ®è‡ªèº«ç”ŸæˆæŸ¥è¯¢ï¼š</p>
<ol>
<li><p><strong>è‡ªæ³¨æ„åŠ›çš„ä¸¤ç§è§£é‡Š</strong>ï¼š</p>
<ul>
<li><strong>æ’å®šæŸ¥è¯¢è§£é‡Š</strong>ï¼šå°†æŸ¥è¯¢è§†ä¸ºå›ºå®šé—®é¢˜ï¼ˆå¦‚â€æ–‡æ¡£å±äºå“ªç±»ï¼Ÿâ€ï¼‰</li>
<li><strong>å¯å­¦ä¹ æŸ¥è¯¢è§£é‡Š</strong>ï¼šå°†æŸ¥è¯¢ä½œä¸ºå¯è®­ç»ƒå‚æ•°ï¼Œéšæ¨¡å‹ä¼˜åŒ–</li>
</ul>
</li>
<li><p><strong>æŠ€æœ¯å®ç°</strong>ï¼š<br>è‡ªæ³¨æ„åŠ›é€šè¿‡çº¿æ€§å˜æ¢ä»ç‰¹å¾çŸ©é˜µ F ç”ŸæˆæŸ¥è¯¢çŸ©é˜µ Qï¼š</p>
<p>$$<br>Q &#x3D; W_Q \times F<br>$$</p>
<p>å…¶ä¸­ $W_Q \in \mathbb{R}^{d_q \times d_f}$ æ˜¯å¯è®­ç»ƒæƒé‡çŸ©é˜µã€‚</p>
</li>
<li><p><strong>è‡ªæ³¨æ„åŠ›çš„åº”ç”¨ä»·å€¼</strong>ï¼š</p>
<ul>
<li><p>æ­ç¤ºç‰¹å¾å‘é‡é—´çš„å…³ç³»ï¼ˆå¦‚è¯è¯­ä¾èµ–ã€å›¾åƒåŒºåŸŸå…³è”ï¼‰</p>
</li>
<li><p>ç”Ÿæˆæ”¹è¿›çš„ç‰¹å¾è¡¨ç¤ºï¼Œå¯é€šè¿‡ä¸¤ç§æ–¹å¼ï¼š</p>
<p>$$<br>f^{(new)} &#x3D; c \quad \text{æˆ–} \quad f^{(new)} &#x3D; \text{Normalize}(f^{(old)} + c)<br>$$</p>
</li>
<li><p>åœ¨ Transformer æ¶æ„ä¸­ä½œä¸ºæ ¸å¿ƒç»„ä»¶</p>
</li>
</ul>
</li>
<li><p><strong>é¢†åŸŸåº”ç”¨</strong>ï¼š</p>
<ul>
<li>è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒè¯†åˆ«ã€GANs ä¸­çš„åŒºåŸŸèšç„¦</li>
<li>è§†é¢‘å¤„ç†ï¼šæ—¶ç©ºå…³ç³»å»ºæ¨¡</li>
<li>è¯­éŸ³å¤„ç†ï¼šè¯­éŸ³è¯†åˆ«</li>
<li>è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘</li>
<li>å›¾ç½‘ç»œï¼šèŠ‚ç‚¹å…³ç³»å»ºæ¨¡</li>
</ul>
</li>
</ol>
<h2 id="å¤šé‡æŸ¥è¯¢æœºåˆ¶-Multi-Query-Mechanisms"><a href="#å¤šé‡æŸ¥è¯¢æœºåˆ¶-Multi-Query-Mechanisms" class="headerlink" title="å¤šé‡æŸ¥è¯¢æœºåˆ¶(Multi-Query Mechanisms)"></a>å¤šé‡æŸ¥è¯¢æœºåˆ¶(Multi-Query Mechanisms)</h2><h3 id="å¤šå¤´æ³¨æ„åŠ›-Multi-Head-Attention"><a href="#å¤šå¤´æ³¨æ„åŠ›-Multi-Head-Attention" class="headerlink" title="å¤šå¤´æ³¨æ„åŠ›(Multi-Head Attention)"></a>å¤šå¤´æ³¨æ„åŠ›(Multi-Head Attention)</h3><img src="/img/Attention/MultiheadAttention.png" alt="Multi-head Attention" width="60%" height="auto">

<p>å¤šå¤´æ³¨æ„åŠ›æ˜¯å¤„ç†å¤šé‡æŸ¥è¯¢çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œå…¶å…³é”®ç‰¹ç‚¹åŒ…æ‹¬ï¼š</p>
<ol>
<li><p><strong>å¹¶è¡Œæ³¨æ„åŠ›å¤´</strong>ï¼š</p>
<ul>
<li>æ¯ä¸ªå¤´æœ‰ç‹¬ç«‹çš„$W_Q^{(j)}, W_K^{(j)}, W_V^{(j)}$çŸ©é˜µ</li>
<li>ç”Ÿæˆä¸åŒçš„æŸ¥è¯¢è¡¨ç¤ºï¼š$q^{(j)} &#x3D; W_Q^{(j)} \times q$</li>
<li>å…è®¸æ¨¡å‹åŒæ—¶å…³æ³¨ä¸åŒæ–¹é¢çš„ä¿¡æ¯</li>
</ul>
</li>
<li><p><strong>å®ç°ç»†èŠ‚</strong>ï¼š</p>
<ul>
<li>æ¯ä¸ªå¤´äº§ç”Ÿç‹¬ç«‹çš„ä¸Šä¸‹æ–‡å‘é‡$c^{(j)}$</li>
<li>æœ€ç»ˆè¾“å‡ºé€šè¿‡çº¿æ€§å˜æ¢åˆå¹¶ $c &#x3D; W_O \times \text{concat}(c^{(1)},â€¦,c^{(d)})$</li>
</ul>
</li>
<li><p><strong>ä¼˜åŠ¿</strong>ï¼š</p>
<ul>
<li>å¢å¼ºæ¨¡å‹æ•æ‰å¤šæ ·åŒ–å…³ç³»çš„èƒ½åŠ›</li>
<li>åœ¨ Transformer ä¸­å®ç°å¹¶è¡Œè®¡ç®—</li>
<li>å¯è§£é‡Šæ€§å¼ºï¼ˆä¸åŒå¤´å¯å­¦ä¹ ä¸åŒå…³æ³¨æ¨¡å¼ï¼‰</li>
</ul>
</li>
</ol>
<h3 id="å¤šè·³æ³¨æ„åŠ›-Multi-Hop-Attention"><a href="#å¤šè·³æ³¨æ„åŠ›-Multi-Hop-Attention" class="headerlink" title="å¤šè·³æ³¨æ„åŠ›(Multi-Hop Attention)"></a>å¤šè·³æ³¨æ„åŠ›(Multi-Hop Attention)</h3><img src="/img/Attention/MultihopAttention.png" alt="Multi-hop Attention" width="60%" height="auto">

<p>å¤šè·³æ³¨æ„åŠ›é€šè¿‡åºåˆ—åŒ–å¤„ç†é€æ­¥ç²¾ç‚¼æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡ï¼š</p>
<ol>
<li><p><strong>å·¥ä½œæœºåˆ¶</strong>ï¼š</p>
<ul>
<li>è¿­ä»£æ›´æ–°æŸ¥è¯¢ï¼š$q^{(s+1)} &#x3D; \text{transform}(q^{(s)}, c^{(s)})$</li>
<li>é€æ­¥ç§¯ç´¯ä¿¡æ¯ï¼šä½¿ç”¨$[q^{(s+1)}, c^{(s)}]$ä½œä¸ºæ–°æŸ¥è¯¢</li>
<li>å¯è§†ä¸ºä¿¡æ¯ä¼ é€’çš„â€æ·±åº¦â€å¤„ç†</li>
</ul>
</li>
<li><p><strong>ä¸å¤šå¤´æ³¨æ„åŠ›çš„åŒºåˆ«</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>ç‰¹æ€§</th>
<th>å¤šå¤´æ³¨æ„åŠ›</th>
<th>å¤šè·³æ³¨æ„åŠ›</th>
</tr>
</thead>
<tbody><tr>
<td>å¤„ç†æ–¹å¼</td>
<td>å¹¶è¡Œ</td>
<td>ä¸²è¡Œ</td>
</tr>
<tr>
<td>è®¡ç®—æ•ˆç‡</td>
<td>é«˜</td>
<td>è¾ƒä½</td>
</tr>
<tr>
<td>ä¿¡æ¯æ•´åˆ</td>
<td>æ‹¼æ¥</td>
<td>è¿­ä»£ç²¾ç‚¼</td>
</tr>
<tr>
<td>å…¸å‹åº”ç”¨</td>
<td>Transformer ç¼–ç å±‚</td>
<td>Transformer è§£ç å±‚</td>
</tr>
</tbody></table>
</li>
<li><p><strong>å˜ä½“å®ç°</strong>ï¼š</p>
<ul>
<li>ä½¿ç”¨ç›¸åŒæƒé‡çŸ©é˜µçš„è½»é‡çº§ç‰ˆæœ¬</li>
<li>ç»“åˆè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å¢å¼ºç‰ˆæœ¬</li>
<li>åœ¨ LCR-Rot-hop ç­‰æ¨¡å‹ä¸­çš„åº”ç”¨</li>
</ul>
</li>
</ol>
<h4 id="èƒ¶å›Šæ³¨æ„åŠ›-Capsule-Based-Attention"><a href="#èƒ¶å›Šæ³¨æ„åŠ›-Capsule-Based-Attention" class="headerlink" title="èƒ¶å›Šæ³¨æ„åŠ›(Capsule-Based Attention)"></a>èƒ¶å›Šæ³¨æ„åŠ›(Capsule-Based Attention)</h4><img src="/img/Attention/CapsuleAttention.png" alt="Capsule Attention" width="60%" height="auto">

<p>Capsule-based attentioné€šè¿‡å°†æ³¨æ„åŠ›æœºåˆ¶ä¸èƒ¶å›Šç½‘ç»œç›¸ç»“åˆï¼Œåœ¨å¤šåˆ†ç±»ä»»åŠ¡ä¸­å±•ç°å‡ºç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¯è§£é‡Šæ€§å’Œç»†ç²’åº¦åˆ†ç±»çš„åœºæ™¯ä¸­ã€‚å…¶æ¨¡å—åŒ–è®¾è®¡ä¹Ÿä¾¿äºæ‰©å±•å’Œè°ƒæ•´ï¼Œæ˜¯æ³¨æ„åŠ›æœºåˆ¶ç ”ç©¶ä¸­çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚</p>
<h5 id="åŸºæœ¬æ¦‚å¿µä¸æ ¸å¿ƒæ€æƒ³"><a href="#åŸºæœ¬æ¦‚å¿µä¸æ ¸å¿ƒæ€æƒ³" class="headerlink" title="åŸºæœ¬æ¦‚å¿µä¸æ ¸å¿ƒæ€æƒ³"></a>åŸºæœ¬æ¦‚å¿µä¸æ ¸å¿ƒæ€æƒ³</h5><p>Capsule-based attentionæ˜¯ä¸€ç§ç‰¹æ®Šçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒé€šè¿‡ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºç‹¬ç«‹çš„â€èƒ¶å›Šâ€(capsule)æ¥å¤„ç†å¤šåˆ†ç±»é—®é¢˜ã€‚æ¯ä¸ªèƒ¶å›Šæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œä¸“é—¨è´Ÿè´£è¯†åˆ«å’Œæå–ä¸è¯¥ç±»åˆ«ç›¸å…³çš„ç‰¹å¾ä¿¡æ¯ã€‚</p>
<h6 id="èƒ¶å›Šç½‘ç»œåŸºç¡€"><a href="#èƒ¶å›Šç½‘ç»œåŸºç¡€" class="headerlink" title="èƒ¶å›Šç½‘ç»œåŸºç¡€"></a>èƒ¶å›Šç½‘ç»œåŸºç¡€</h6><p>Capsule-based attentionæºè‡ªèƒ¶å›Šç½‘ç»œ(Capsule Networks)çš„æ¦‚å¿µï¼Œç”±Hintonç­‰äººäº2017å¹´æå‡ºã€‚ä¸ä¼ ç»Ÿç¥ç»ç½‘ç»œä½¿ç”¨æ ‡é‡ç¥ç»å…ƒä¸åŒï¼Œèƒ¶å›Šç½‘ç»œä½¿ç”¨å‘é‡å½¢å¼çš„â€èƒ¶å›Šâ€æ¥è¡¨ç¤ºå®ä½“åŠå…¶å±æ€§ã€‚è¿™ç§è¡¨ç¤ºæ–¹å¼èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ç‰¹å¾é—´çš„ç©ºé—´å±‚æ¬¡å…³ç³»ã€‚</p>
<h6 id="æ³¨æ„åŠ›æœºåˆ¶çš„ç»“åˆ"><a href="#æ³¨æ„åŠ›æœºåˆ¶çš„ç»“åˆ" class="headerlink" title="æ³¨æ„åŠ›æœºåˆ¶çš„ç»“åˆ"></a>æ³¨æ„åŠ›æœºåˆ¶çš„ç»“åˆ</h6><p>å°†æ³¨æ„åŠ›æœºåˆ¶ä¸èƒ¶å›Šç½‘ç»œç»“åˆï¼Œå½¢æˆäº†capsule-based attentionã€‚è¿™ç§æœºåˆ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p>
<ul>
<li>æ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªç‹¬ç«‹çš„æ³¨æ„åŠ›æ¨¡å—(èƒ¶å›Š)</li>
<li>æ¯ä¸ªèƒ¶å›Šå­¦ä¹ è‡ªå·±ç‹¬ç‰¹çš„â€æŸ¥è¯¢â€(query)ï¼Œç”¨äºä»è¾“å…¥ç‰¹å¾ä¸­æå–ç›¸å…³ä¿¡æ¯</li>
<li>é€šè¿‡æ³¨æ„åŠ›æƒé‡æ˜ç¡®æ˜¾ç¤ºå“ªäº›ç‰¹å¾å¯¹åˆ†ç±»å†³ç­–æœ€é‡è¦</li>
</ul>
<h5 id="æ¶æ„ä¸å·¥ä½œæµç¨‹"><a href="#æ¶æ„ä¸å·¥ä½œæµç¨‹" class="headerlink" title="æ¶æ„ä¸å·¥ä½œæµç¨‹"></a>æ¶æ„ä¸å·¥ä½œæµç¨‹</h5><p>Capsule-based attentionæ¨¡å‹é€šå¸¸ç”±ä¸‰ä¸ªä¸»è¦ç»„ä»¶æ„æˆï¼š</p>
<ol>
<li><p><strong>æ³¨æ„åŠ›æ¨¡å—</strong></p>
<p> æ¯ä¸ªèƒ¶å›Šcçš„æ³¨æ„åŠ›æ¨¡å—è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li><p><strong>é”®å€¼ç”Ÿæˆ</strong>ï¼šå°†è¾“å…¥ç‰¹å¾å‘é‡ $f_l$ è½¬æ¢ä¸ºé”® $k_l$ å’Œå€¼ $v_l$ ï¼š $k_l &#x3D; W_K^{(c)} f_l, \quad v_l &#x3D; W_V^{(c)} f_l$<br> å…¶ä¸­$W_K^{(c)}$å’Œ$W_V^{(c)}$æ˜¯ç±»åˆ«ç‰¹å®šçš„å¯è®­ç»ƒæƒé‡çŸ©é˜µ</p>
</li>
<li><p><strong>æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—</strong>ï¼šä½¿ç”¨æŸ¥è¯¢å‘é‡ $q_l$ è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{c,l} &#x3D; q_c^T k_l$</p>
</li>
<li><p><strong>æ³¨æ„åŠ›æƒé‡è®¡ç®—</strong>ï¼šé€šè¿‡softmaxå½’ä¸€åŒ– $a_{c,l} &#x3D; \frac{\exp(e_{c,l})}{\sum_j \exp(e_{c,j})}$</p>
</li>
<li><p><strong>ä¸Šä¸‹æ–‡å‘é‡ç”Ÿæˆ</strong>ï¼šåŠ æƒæ±‚å’Œå¾—åˆ°ç±»åˆ«ç‰¹å®šçš„ä¸Šä¸‹æ–‡å‘é‡ $<br> c_c &#x3D; \sum_l a_{c,l} v_l$</p>
</li>
</ol>
</li>
<li><p><strong>æ¦‚ç‡æ¨¡å—</strong></p>
<p> ä¸Šä¸‹æ–‡å‘é‡ç»è¿‡ä¸€ä¸ªç®€å•çš„åˆ†ç±»å±‚ï¼Œè¾“å‡ºè¯¥ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ $p_c &#x3D; \sigma(w_c^T c_c + b_c)$ ,å…¶ä¸­ $\sigma$ æ˜¯sigmoidæ¿€æ´»å‡½æ•°ï¼Œ $w_c$ å’Œ $b_c$ æ˜¯å¯è®­ç»ƒå‚æ•°ã€‚</p>
</li>
<li><p><strong>é‡æ„æ¨¡å—</strong></p>
<p> æœ€åå°†æ¦‚ç‡ä¸ä¸Šä¸‹æ–‡å‘é‡ç»“åˆï¼Œç”Ÿæˆç±»åˆ«è¡¨ç¤ºå‘é‡ $r_c &#x3D; p_c \times c_c$</p>
</li>
</ol>
<h5 id="è®­ç»ƒæœºåˆ¶ä¸æŸå¤±å‡½æ•°"><a href="#è®­ç»ƒæœºåˆ¶ä¸æŸå¤±å‡½æ•°" class="headerlink" title="è®­ç»ƒæœºåˆ¶ä¸æŸå¤±å‡½æ•°"></a>è®­ç»ƒæœºåˆ¶ä¸æŸå¤±å‡½æ•°</h5><p>Capsule-based attentioné‡‡ç”¨è”åˆè®­ç»ƒç­–ç•¥ï¼Œä¼˜åŒ–ä¸¤ä¸ªç›®æ ‡ï¼š</p>
<ol>
<li><p><strong>åˆ†ç±»æŸå¤±</strong></p>
<p> ä½¿ç”¨æ ‡å‡†çš„äº¤å‰ç†µæŸå¤±å‡½æ•°ç¡®ä¿åˆ†ç±»å‡†ç¡®æ€§ $\mathcal{L}_{cls} &#x3D; -\sum_c y_c \log p_c$ ï¼Œå…¶ä¸­ $y_c$ æ˜¯ç±»åˆ« $c$ çš„çœŸå®æ ‡ç­¾ã€‚</p>
</li>
<li><p><strong>é‡æ„æŸå¤±</strong></p>
<p> å¼•å…¥é‡æ„æŸå¤±ä¿ƒä½¿æ¨¡å‹å­¦ä¹ æœ‰æ„ä¹‰çš„è¡¨ç¤º $\mathcal{L}_{rec} &#x3D; \sum_c |r_c - \bar{f}|^2$ ï¼Œå…¶ä¸­$\bar{f}$æ˜¯æ‰€æœ‰è¾“å…¥ç‰¹å¾å‘é‡çš„å¹³å‡å€¼ã€‚</p>
</li>
<li><p><strong>è”åˆè®­ç»ƒ</strong></p>
<p> æ€»æŸå¤±å‡½æ•°æ˜¯ä¸¤è€…çš„åŠ æƒå’Œ $\mathcal{L} &#x3D; \mathcal{L}_{cls} + \lambda \mathcal{L}_{rec}$ ï¼Œå…¶ä¸­ $\lambda$ æ˜¯è¶…å‚æ•°ï¼Œæ§åˆ¶é‡æ„æŸå¤±çš„é‡è¦æ€§ã€‚</p>
</li>
</ol>
<h5 id="æŠ€æœ¯ç‰¹ç‚¹ä¸ä¼˜åŠ¿"><a href="#æŠ€æœ¯ç‰¹ç‚¹ä¸ä¼˜åŠ¿" class="headerlink" title="æŠ€æœ¯ç‰¹ç‚¹ä¸ä¼˜åŠ¿"></a>æŠ€æœ¯ç‰¹ç‚¹ä¸ä¼˜åŠ¿</h5><ol>
<li><p><strong>å¤šæŸ¥è¯¢æœºåˆ¶</strong>ï¼šä¸ä¼ ç»Ÿæ³¨æ„åŠ›ä¸åŒï¼Œcapsule-based attentionä¸ºæ¯ä¸ªç±»åˆ«å­¦ä¹ ç‹¬ç«‹çš„æŸ¥è¯¢å‘é‡ $q_c$ ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå¹¶è¡Œå¤„ç†å¤šä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œæ•æ‰ä¸åŒç±»åˆ«å…³æ³¨çš„ä¸åŒç‰¹å¾ï¼Œå‡å°‘ç±»åˆ«é—´çš„å¹²æ‰°ã€‚</p>
</li>
<li><p><strong>å¯è§£é‡Šæ€§</strong>ï¼šé€šè¿‡åˆ†ææ³¨æ„åŠ›æƒé‡a_{c,l}ï¼Œå¯ä»¥ç›´è§‚ç†è§£å“ªäº›è¾“å…¥ç‰¹å¾å¯¹ç‰¹å®šç±»åˆ«æœ€é‡è¦ã€æ¨¡å‹åšå‡ºå†³ç­–çš„ä¾æ®ä»¥åŠä¸åŒç±»åˆ«å…³æ³¨çš„ç‰¹å¾å·®å¼‚</p>
</li>
<li><p><strong>é²æ£’æ€§</strong>ï¼šé‡æ„æŸå¤±é¡¹ä½¿æ¨¡å‹å­¦ä¹ åˆ°çš„è¡¨ç¤ºæ›´åŠ é²æ£’ï¼Œè¿«ä½¿èƒ¶å›Šå­¦ä¹ æœ‰æ„ä¹‰çš„ç‰¹å¾ç»„åˆï¼Œå‡å°‘å¯¹å™ªå£°ç‰¹å¾çš„ä¾èµ–ï¼Œæé«˜å¯¹æŠ—æ ·æœ¬çš„æŠµæŠ—åŠ›</p>
</li>
</ol>
<h5 id="å˜ä½“ä¸æ‰©å±•"><a href="#å˜ä½“ä¸æ‰©å±•" class="headerlink" title="å˜ä½“ä¸æ‰©å±•"></a>å˜ä½“ä¸æ‰©å±•</h5><ol>
<li><p><strong>åŠ¨æ€è·¯ç”±capsule</strong></p>
<p> å¼•å…¥åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œè¿­ä»£è°ƒæ•´èƒ¶å›Šé—´çš„è¿æ¥å¼ºåº¦ï¼š</p>
<p> $$<br> \text{for iteration } t:<br> \quad b_{i,j} \leftarrow b_{i,j} + \hat{v}_j^T u_{j|i}<br> \quad c_{i,j} &#x3D; \text{softmax}(b_{i,j})<br> \quad s_j &#x3D; \sum_i c_{i,j} u_{j|i}<br> \quad v_j &#x3D; \text{squash}(s_j)<br> $$</p>
</li>
<li><p><strong>å¤šå¤´capsule</strong></p>
</li>
</ol>
<p>æ¯ä¸ªèƒ¶å›Šä½¿ç”¨å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œæ•è·ä¸åŒæ–¹é¢çš„ä¿¡æ¯ $r_c &#x3D; \text{concat}(r_c^{(1)}, â€¦, r_c^{(h)})$</p>
<ol start="3">
<li><strong>å±‚æ¬¡åŒ–capsule</strong></li>
</ol>
<p>æ„å»ºå¤šçº§èƒ¶å›Šç»“æ„ï¼Œä»ä½çº§ç‰¹å¾åˆ°é«˜çº§è¯­ä¹‰é€æ­¥æŠ½è±¡ï¼š</p>
<p>$$<br>\text{ä½çº§èƒ¶å›Š} \rightarrow \text{ä¸­çº§èƒ¶å›Š} \rightarrow \text{é«˜çº§èƒ¶å›Š}<br>$$</p>
<h5 id="ä¸å…¶ä»–æ³¨æ„åŠ›æœºåˆ¶çš„æ¯”è¾ƒ"><a href="#ä¸å…¶ä»–æ³¨æ„åŠ›æœºåˆ¶çš„æ¯”è¾ƒ" class="headerlink" title="ä¸å…¶ä»–æ³¨æ„åŠ›æœºåˆ¶çš„æ¯”è¾ƒ"></a>ä¸å…¶ä»–æ³¨æ„åŠ›æœºåˆ¶çš„æ¯”è¾ƒ</h5><table>
<thead>
<tr>
<th>ç‰¹æ€§</th>
<th>Capsule-based Attention</th>
<th>ä¼ ç»Ÿæ³¨æ„åŠ›</th>
<th>å¤šå¤´æ³¨æ„åŠ›</th>
</tr>
</thead>
<tbody><tr>
<td>æŸ¥è¯¢æ•°é‡</td>
<td>æ¯ä¸ªç±»åˆ«ä¸€ä¸ª</td>
<td>é€šå¸¸ä¸€ä¸ª</td>
<td>å›ºå®šæ•°é‡</td>
</tr>
<tr>
<td>å‚æ•°å…±äº«</td>
<td>èƒ¶å›Šé—´ä¸å…±äº«</td>
<td>å®Œå…¨å…±äº«</td>
<td>å¤´é—´å…±äº«</td>
</tr>
<tr>
<td>å¯è§£é‡Šæ€§</td>
<td>é«˜</td>
<td>ä¸­ç­‰</td>
<td>ä½</td>
</tr>
<tr>
<td>è®¡ç®—æˆæœ¬</td>
<td>è¾ƒé«˜</td>
<td>ä½</td>
<td>ä¸­ç­‰</td>
</tr>
<tr>
<td>é€‚ç”¨ä»»åŠ¡</td>
<td>å¤šåˆ†ç±»&#x2F;å¤šæ ‡ç­¾</td>
<td>é€šç”¨</td>
<td>åºåˆ—å¤„ç†</td>
</tr>
</tbody></table>
<h2 id="Transformer-æ¶æ„ä¸­çš„æŸ¥è¯¢æœºåˆ¶"><a href="#Transformer-æ¶æ„ä¸­çš„æŸ¥è¯¢æœºåˆ¶" class="headerlink" title="Transformer æ¶æ„ä¸­çš„æŸ¥è¯¢æœºåˆ¶"></a>Transformer æ¶æ„ä¸­çš„æŸ¥è¯¢æœºåˆ¶</h2><p>3.3 èŠ‚ç‰¹åˆ«å¼ºè°ƒäº† Transformer æ¨¡å‹å¦‚ä½•æ•´åˆå¤šç§æŸ¥è¯¢æœºåˆ¶ï¼š</p>
<ol>
<li><p><strong>å…³é”®æ•´åˆ</strong>ï¼š</p>
<ul>
<li>å¤šå¤´è‡ªæ³¨æ„åŠ›å¹¶è¡Œå¤„ç†</li>
<li>å±‚é—´å¤šè·³å¼ä¿¡æ¯ä¼ é€’</li>
<li>æŸ¥è¯¢-é”®-å€¼åˆ†ç¦»çš„çµæ´»è®¾è®¡</li>
</ul>
</li>
<li><p><strong>å˜ä½“å‘å±•</strong>ï¼š</p>
<ul>
<li><strong>Transformer-XL</strong>ï¼šé€šè¿‡å¾ªç¯æœºåˆ¶æ‰©å±•ä¸Šä¸‹æ–‡çª—å£</li>
<li><strong>Reformer</strong>ï¼šé€šè¿‡ LSH å“ˆå¸Œæå‡è®¡ç®—æ•ˆç‡</li>
<li><strong>Linformer</strong>ï¼šä½ç§©è¿‘ä¼¼å®ç°çº¿æ€§å¤æ‚åº¦</li>
<li><strong>Synthesizer</strong>ï¼šæ¢ç´¢éæˆå¯¹æ³¨æ„åŠ›æƒé‡</li>
</ul>
</li>
<li><p><strong>åº”ç”¨é¢†åŸŸæ‰©å±•</strong>ï¼š</p>
<ul>
<li>å›¾åƒæè¿°ç”Ÿæˆï¼ˆImage Captioningï¼‰</li>
<li>åŒ»å­¦å›¾åƒåˆ†å‰²</li>
<li>å¯¹è¯ç³»ç»Ÿå“åº”ç”Ÿæˆ</li>
<li>æ¨èç³»ç»Ÿï¼ˆå¦‚ BERT4Recï¼‰</li>
</ul>
</li>
</ol>
<h2 id="æŸ¥è¯¢æœºåˆ¶çš„é€‰æ‹©ä¸å®è·µå»ºè®®"><a href="#æŸ¥è¯¢æœºåˆ¶çš„é€‰æ‹©ä¸å®è·µå»ºè®®" class="headerlink" title="æŸ¥è¯¢æœºåˆ¶çš„é€‰æ‹©ä¸å®è·µå»ºè®®"></a>æŸ¥è¯¢æœºåˆ¶çš„é€‰æ‹©ä¸å®è·µå»ºè®®</h2><ol>
<li><p><strong>æœºåˆ¶é€‰æ‹©å‡†åˆ™</strong>ï¼š</p>
<table>
<thead>
<tr>
<th>ä»»åŠ¡éœ€æ±‚</th>
<th>æ¨èæœºåˆ¶</th>
<th>ä¼˜åŠ¿</th>
</tr>
</thead>
<tbody><tr>
<td>å¹¶è¡Œå¤„ç†</td>
<td>å¤šå¤´æ³¨æ„åŠ›</td>
<td>è®¡ç®—æ•ˆç‡é«˜</td>
</tr>
<tr>
<td>æ·±åº¦ç‰¹å¾äº¤äº’</td>
<td>å¤šè·³æ³¨æ„åŠ›</td>
<td>ä¿¡æ¯æ•´åˆæ·±å…¥</td>
</tr>
<tr>
<td>ç»†ç²’åº¦åˆ†ç±»</td>
<td>èƒ¶å›Šæ³¨æ„åŠ›</td>
<td>å¯è§£é‡Šæ€§å¼º</td>
</tr>
<tr>
<td>é•¿åºåˆ—å¤„ç†</td>
<td>Transformer-XL</td>
<td>ä¸Šä¸‹æ–‡æ‰©å±•</td>
</tr>
<tr>
<td>èµ„æºå—é™</td>
<td>Linformer</td>
<td>çº¿æ€§å¤æ‚åº¦</td>
</tr>
</tbody></table>
</li>
<li><p><strong>å®ç°æ³¨æ„äº‹é¡¹</strong>ï¼š</p>
<ul>
<li>æŸ¥è¯¢ç»´åº¦$d_q$åº”ä¸é”®ç»´åº¦$d_k$åŒ¹é…</li>
<li>å¤šå¤´æ³¨æ„åŠ›çš„å¤´æ•°éœ€å¹³è¡¡æ•ˆæœä¸è®¡ç®—æˆæœ¬</li>
<li>å¤šè·³æ³¨æ„åŠ›çš„æ·±åº¦å¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±</li>
<li>èƒ¶å›Šæ³¨æ„åŠ›é€‚åˆä¸­ç­‰è§„æ¨¡ç±»åˆ«æ•°</li>
</ul>
</li>
<li><p><strong>æ–°å…´ç ”ç©¶æ–¹å‘</strong>ï¼š</p>
<ul>
<li>åŠ¨æ€æŸ¥è¯¢è·¯ç”±æœºåˆ¶</li>
<li>æŸ¥è¯¢ç”Ÿæˆçš„æ¡ä»¶æ§åˆ¶</li>
<li>è·¨æ¨¡æ€æŸ¥è¯¢å¯¹é½</li>
<li>åŸºäºèƒ½é‡çš„æŸ¥è¯¢é€‰æ‹©</li>
</ul>
</li>
</ol>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
<a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a>
]]></content>
      <categories>
        <category>model</category>
        <category>attention</category>
        <category>category</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>K-ON</title>
    <url>/2025/07/19/K-ON/</url>
    <content><![CDATA[<p>ä¸çŸ¥é“å†™ä»€ä¹ˆï¼Œå…ˆæ”¾ä¸ªè¿™ä¸ªæ</p>
<table>
  <tr>
    <td><center><img src="\img\k-on\å±å¹•æˆªå›¾ 2025-07-19 220432.png" width="500"></center></td>
    <td><center><img src="\img\k-on\kingzhenen.jpg" width="500"></center></td>
  </tr>
</table>

<span id="more"></span>


<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1>]]></content>
      <categories>
        <category>Fun</category>
      </categories>
      <tags>
        <tag>ä¹å­</tag>
      </tags>
  </entry>
  <entry>
    <title>hwadee</title>
    <url>/2025/07/13/hwadee/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>å…ˆæ”¾åœ¨è¿™é‡Œï¼Œæ‡’å¾—å–·ï¼Œä»¥ä¸‹æ˜¯é¼ é¼ å’Œå®¤å‹åœ¨äº‰è®ºæŸé—®é¢˜æ—¶é—®çš„AI</p>
<span id="more"></span>

<h1 id="ç”²é†›æœ‰æ°”å‘³å—"><a href="#ç”²é†›æœ‰æ°”å‘³å—" class="headerlink" title="ç”²é†›æœ‰æ°”å‘³å—"></a>ç”²é†›æœ‰æ°”å‘³å—</h1><p>Qus:<br>ç”²é†›æœ‰æ°”å‘³å—<br>Ans:</p>
<ul>
<li>å¼•ç”¨ 7 ç¯‡èµ„æ–™ä½œä¸ºå‚è€ƒ<ol>
<li><a href="https://baike.baidu.com/item/%E7%94%B2%E9%86%9B/167033?fr=aladdin">ç”²é†›ï¼ˆæœ‰æœºåŒ–åˆç‰©ï¼‰_ç™¾åº¦ç™¾ç§‘</a></li>
<li><a href="http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink">æ±ï¼ˆæ˜¯å¸¸æ¸©å¸¸å‹ä¸‹å”¯ä¸€ä»¥æ¶²æ€å­˜åœ¨çš„é‡‘å±ï¼‰_ç™¾åº¦ç™¾ç§‘</a></li>
<li><a href="https://www.cndzys.com/ylcore/wendanew_info/11es473224.html">ã€ç”²é†›æœ‰å‘³å—ã€‘_å¾ä¿¡ç¾¤_ä¸»ä»»åŒ»å¸ˆ - å¤§ä¼—å…»ç”Ÿç½‘</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd">è£…ä¿®å®Œçš„æ–°å®¶é—»ä¸è§å‘³å„¿ï¼Œå°±æ˜¯æ²¡ç”²é†›äº†ï¼Ÿ</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd">ç”²é†›æœ‰å‘³é“å—ï¼Œç”²é†›çš„æ°”å‘³åƒä»€ä¹ˆï¼Ÿ</a></li>
<li><a href="https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html">ç”²é†›æœ‰å‘³è¿˜æ˜¯æ— å‘³-æœ‰æ¥åŒ»ç”Ÿ</a></li>
<li><a href="https://m.jia.com/zixun/article/1144566.html">è£…ä¿®çš„å‘³é“æ˜¯ç”²é†›å—_é½å®¶ç½‘</a><br>ç”²é†›çš„æ°”å‘³ç‰¹æ€§ä¸å…¶æµ“åº¦å¯†åˆ‡ç›¸å…³ï¼Œå…·ä½“è¡¨ç°å¦‚ä¸‹ï¼š</li>
</ol>
</li>
</ul>
<h3 id="1-ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³"><a href="#1-ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³" class="headerlink" title="1. ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³"></a>1. ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³</h3><ul>
<li>ç”²é†›åœ¨æä½æµ“åº¦ï¼ˆå¦‚ä½äº0.08æ¯«å…‹&#x2F;ç«‹æ–¹ç±³ï¼‰æ—¶ï¼Œæ˜¯ä¸€ç§æ— è‰²æ— å‘³çš„æ°”ä½“ï¼Œéš¾ä»¥é€šè¿‡å—…è§‰ç›´æ¥å¯Ÿè§‰ã€‚</li>
<li>è®¸å¤šäººè¯¯ä»¥ä¸ºâ€œæ²¡å‘³é“&#x3D;æ²¡ç”²é†›â€ï¼Œä½†å®é™…ä¸Šä½æµ“åº¦ç”²é†›å¯èƒ½ä»ç„¶å­˜åœ¨ï¼Œåªæ˜¯ä¸æ˜“è¢«é—»åˆ°ã€‚</li>
</ul>
<h3 id="2-é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³"><a href="#2-é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³" class="headerlink" title="2. é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³"></a>2. é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³</h3><ul>
<li>å½“ç”²é†›æµ“åº¦è¶…è¿‡0.1æ¯«å…‹&#x2F;ç«‹æ–¹ç±³æ—¶ï¼Œä¼šä¸ç©ºæ°”ä¸­çš„æ°´ã€æ°§æ°”ååº”ï¼Œç”Ÿæˆå…·æœ‰åˆºé¼»æ°”å‘³çš„åŒ–åˆç‰©ï¼Œå¸¸è¢«æè¿°ä¸ºï¼š<ul>
<li>ç±»ä¼¼ç‡ƒçƒ§å¡‘æ–™æˆ–åŒ–å­¦è¯å“çš„å‘³é“ï¼›</li>
<li>é”¯æœ¨å±‘æ··åˆé…¸å‘³ï¼ˆå®¶å…·ä¸­ç”²é†›ï¼‰ï¼›</li>
<li>æ±½æ²¹å‘³æˆ–çƒ§ç„¦å¡‘æ–™å‘³ï¼ˆå¸ƒæ–™ã€çª—å¸˜ä¸­ç”²é†›ï¼‰ï¼›</li>
<li>éƒ¨åˆ†äººå¯èƒ½æ„ŸçŸ¥åˆ°æ·¡æ·¡çš„ç”œå‘³ï¼Œä½†ä¸»è¦ä»æ˜¯åˆºæ¿€æ€§ã€‚</li>
</ul>
</li>
</ul>
<h3 id="3-ä¸ªä½“å·®å¼‚æ˜¾è‘—"><a href="#3-ä¸ªä½“å·®å¼‚æ˜¾è‘—" class="headerlink" title="3. ä¸ªä½“å·®å¼‚æ˜¾è‘—"></a>3. ä¸ªä½“å·®å¼‚æ˜¾è‘—</h3><ul>
<li>ä¸åŒäººå¯¹ç”²é†›æ°”å‘³çš„æ•æ„Ÿåº¦å·®å¼‚è¾ƒå¤§ï¼Œæœ‰äº›äººå¯èƒ½åœ¨è¾ƒä½æµ“åº¦å°±èƒ½å¯Ÿè§‰ï¼Œè€Œå¦ä¸€äº›äººéœ€è¦æ›´é«˜æµ“åº¦æ‰ä¼šæ„Ÿåˆ°ä¸é€‚ã€‚</li>
</ul>
<h3 id="4-ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«"><a href="#4-ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«" class="headerlink" title="4. ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«"></a>4. ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«</h3><ul>
<li>è£…ä¿®åçš„åˆºé¼»æ°”å‘³å¸¸è¢«è¯¯è®¤ä¸ºå…¨æ˜¯ç”²é†›ï¼Œä½†å®é™…ä¸Šå¯èƒ½æ··åˆäº†**è‹¯ç³»ç‰©ï¼ˆæ²¹æ¼†å‘³ï¼‰ã€æ°¨æ°”ï¼ˆå•æ‰€å‘³ï¼‰ã€TVOCï¼ˆåŒ–å­¦æº¶å‰‚å‘³ï¼‰**ç­‰ã€‚</li>
<li>ç”²é†›çš„åˆºæ¿€æ€§æ›´åå‘é»è†œååº”ï¼ˆå¦‚çœ¼ç—’ã€å–‰å’™ç—›ï¼‰ï¼Œè€Œè‹¯ç³»ç‰©ç­‰å¯èƒ½å¸¦æœ‰æ›´æ˜æ˜¾çš„â€œåŒ–å­¦é¦™å‘³â€ã€‚</li>
</ul>
<h3 id="5-æ³¨æ„äº‹é¡¹"><a href="#5-æ³¨æ„äº‹é¡¹" class="headerlink" title="5. æ³¨æ„äº‹é¡¹"></a>5. æ³¨æ„äº‹é¡¹</h3><ul>
<li>ä¸èƒ½ä¾èµ–å—…è§‰åˆ¤æ–­ç”²é†›å®‰å…¨æ€§ï¼šå³ä½¿é—»ä¸åˆ°ï¼Œç”²é†›ä»å¯èƒ½è¶…æ ‡ï¼ˆå°¤å…¶æ¥è‡ªäººé€ æ¿æçš„é•¿æœŸé‡Šæ”¾ï¼‰ã€‚</li>
<li>ç§‘å­¦æ£€æµ‹æ›´å¯é ï¼šå®¶ç”¨æ£€æµ‹ä»ªæ˜“å—ç¯å¢ƒå¹²æ‰°ï¼Œå»ºè®®é€šè¿‡ä¸“ä¸šæœºæ„æ£€æµ‹ã€‚<br>æ€»ç»“ï¼šç”²é†›åœ¨ä½æµ“åº¦ä¸‹æ— å‘³ï¼Œé«˜æµ“åº¦æ—¶å‘ˆç°åˆºé¼»æ°”å‘³ï¼Œä½†æ°”å‘³å¹¶éåˆ¤æ–­å…¶å­˜åœ¨çš„å”¯ä¸€æ ‡å‡†ï¼Œéœ€ç»“åˆä¸“ä¸šæ£€æµ‹å’Œé€šé£æªæ–½ä¿éšœå¥åº·ã€‚</li>
</ul>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1>]]></content>
      <categories>
        <category>sb</category>
      </categories>
      <tags>
        <tag>sb</tag>
        <tag>UESTC</tag>
      </tags>
  </entry>
</search>
