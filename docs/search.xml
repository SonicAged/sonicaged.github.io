<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Feature-Related Attention</title>
    <url>/2025/07/14/Feature-Related-Attention/</url>
    <content><![CDATA[<h1 id="åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„-Attention"><a href="#åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„-Attention" class="headerlink" title="åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention"></a>åœ¨è¾“å…¥ç‰¹å¾ä¸Šåšæ–‡ç« çš„ Attention</h1><p>æœ¬æ–‡å°†æ¥ç€è¯¦ç»†è¯´æ˜ä¸€ç§åŸºäºè¾“å…¥ç‰¹å¾åˆ†ç±» Attention çš„æ–¹å¼ï¼Œå¹¶ä»‹ç»åœ¨è¿™ç§åˆ†ç±»æ–¹å¼ä¸‹å…³æ³¨åˆ°çš„ä¸åŒçš„ Attention çš„æ¶æ„ã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä¸»è¦æ¢è®¨äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚æœ¬èŠ‚æ ¹æ®è¾“å…¥ç‰¹å¾çš„ä¸åŒç‰¹æ€§ï¼Œå°†ç‰¹å¾ç›¸å…³çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)ã€ç‰¹å¾å±‚çº§(Levels of Features)å’Œç‰¹å¾è¡¨ç¤º(Feature Representations)ã€‚</p>
<p>åœ¨é˜…è¯»è¿™ç¯‡åšå®¢å‰è¯·å…ˆé˜…è¯» <a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a></p>
<span id="more"></span>

<h2 id="ç‰¹å¾å¤šé‡æ€§-Multiplicity-of-Features"><a href="#ç‰¹å¾å¤šé‡æ€§-Multiplicity-of-Features" class="headerlink" title="ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)"></a>ç‰¹å¾å¤šé‡æ€§(Multiplicity of Features)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å¤šä¸ªè¾“å…¥æºçš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€ç‰¹å¾æ³¨æ„åŠ›å’Œå¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
<h3 id="å•ä¸€ç‰¹å¾æ³¨æ„åŠ›-Singular-Features-Attention"><a href="#å•ä¸€ç‰¹å¾æ³¨æ„åŠ›-Singular-Features-Attention" class="headerlink" title="å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)"></a>å•ä¸€ç‰¹å¾æ³¨æ„åŠ›(Singular Features Attention)</h3><p>å¤§å¤šæ•°ä»»åŠ¡æ¨¡å‹åªå¤„ç†å•ä¸€è¾“å…¥(å¦‚å›¾åƒã€å¥å­æˆ–å£°éŸ³åºåˆ—)ï¼Œä½¿ç”¨å•ä¸€ç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ç›´æ¥å¯¹å•ä¸ªè¾“å…¥çš„ç‰¹å¾å‘é‡è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<h3 id="å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶"><a href="#å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶"></a>å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶</h3><p>å½“æ¨¡å‹éœ€è¦åŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æºæ—¶ï¼Œéœ€è¦ç‰¹æ®Šçš„å¤šç‰¹å¾æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
<p><strong>ååŒæ³¨æ„åŠ›(Co-attention)</strong></p>
<ul>
<li>åˆ†ä¸º <strong>ç²—ç§‘ç²’åº¦(Coarse-grained)</strong> å’Œ <strong>ç»†é¢—ç²’åº¦(Fine-grained)</strong> ä¸¤ç§</li>
<li><strong>ç²—é¢—ç²’åº¦ååŒ</strong>æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„<em>ç´§å‡‘è¡¨ç¤º</em>ä½œä¸ºæŸ¥è¯¢æ¥å…³æ³¨å¦ä¸€ä¸ªè¾“å…¥</li>
<li><strong>ç»†é¢—ç²’åº¦ååŒ</strong>æ³¨æ„åŠ›ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„æ‰€æœ‰ç‰¹å¾å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
</ul>
<h4 id="ç²—é¢—ç²’åº¦ååŒ"><a href="#ç²—é¢—ç²’åº¦ååŒ" class="headerlink" title="ç²—é¢—ç²’åº¦ååŒ"></a>ç²—é¢—ç²’åº¦ååŒ</h4><p>è®ºæ–‡ç»™å‡ºçš„ç²—é¢—ç²’åº¦ååŒçš„å®ä¾‹æ˜¯<strong>alternating co-attention</strong></p>
<h5 id="alternating-co-attention"><a href="#alternating-co-attention" class="headerlink" title="alternating co-attention"></a>alternating co-attention</h5><img src="/img/Attention/AlternatingCo-Attention.png" alt="alternating co-attention" width="60%" height="auto">

<p>å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™æ˜¯ alternating co-attention çš„æ¶æ„å›¾ï¼Œè¯¥æœºåˆ¶äº¤æ›¿ä½¿ç”¨ä¸¤ä¸ªè¾“å…¥çš„ç‰¹å¾çŸ©é˜µï¼Œå…ˆè®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œå°†å…¶ä¸Šä¸‹æ–‡å‘é‡ä½œä¸ºæŸ¥è¯¢è®¡ç®—ç¬¬äºŒä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œç„¶åå†ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„ä¸Šä¸‹æ–‡å‘é‡é‡æ–°è®¡ç®—ç¬¬ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ã€‚</p>
<p>è¿™é‡Œç°ç»™å‡ºä»–çš„ score å‡½æ•°</p>
<p>å¯¹äºæœ‰åºåˆ—è¾“å…¥çš„ Attentionï¼š</p>
<p>$$<br>\mathrm{score}(\underset{d_{q}\times1}{\boldsymbol{q}},\underset{d_{k}\times1}{\boldsymbol{k}_{l}})&#x3D;\underset{1\times d_{w}}{\boldsymbol{w}^{T}}\times\mathrm{act}(\underset{d_{w}\times d_{q}}{\boldsymbol{W}_{1}}\times\underset{d_{q}\times1}{\boldsymbol{q}}+\underset{d_{w}\times d_{k}}{\boldsymbol{W}_{2}}\times\underset{d_{k}\times1}{\boldsymbol{k}_{l}}+\underset{d_{w}\times1}{\boldsymbol{b}})<br>$$</p>
<p>å¯¹äºæ— åºåˆ—è¾“å…¥çš„ Attention <del>ï¼ˆè¿™æ˜¯ä¸€ç§è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œåé¢ä¼šæåˆ°ï¼‰</del> ï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(0)}}&#x3D;\underset{1\times d_{w}}{\boldsymbol{w}^{(1)T}}\times\operatorname{act}(\underset{d_{w}\times d_{k}^{(1)}}{\boldsymbol{W}^{(1)}}\times\underset{d_{k}^{(1)}\times1}{\boldsymbol{k}_{l}^{(1)}}+\underset{d_{w}\times1}{\boldsymbol{b}^{(1)}})<br>$$</p>
<p>å¯¹äºç¬¬äºŒå±‚ Attentionï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(2)}}&#x3D;\mathrm{score}(\underset{d_{v}^{(1)}\times 1}{\boldsymbol{c}^{(0)}},\underset{d_{k}^{(2)}\times1}{\boldsymbol{k}_{l}^{(2)}})<br>$$</p>
<p>å¯¹äºç¬¬ä¸‰å±‚ Attentionï¼š</p>
<p>$$<br>\underset{1\times1}{e_{l}^{(1)}}&#x3D;\mathrm{score}(\underset{d_{v}^{(2)}\times 1}{\boldsymbol{c}^{(2)}},\underset{d_{k}^{(1)}\times1}{\boldsymbol{k}_{l}^{(1)}})<br>$$</p>
<p>ç”Ÿæˆçš„ä¸Šä¸‹æ–‡å‘é‡$\boldsymbol{c}^{(1)}$å’Œ$\boldsymbol{c}^{(2)}$è¢«è¿æ¥èµ·æ¥ï¼Œå¹¶åœ¨è¾“å‡ºæ¨¡å‹ä¸­ç”¨äºé¢„æµ‹ã€‚äº¤æ›¿ååŒæ³¨æ„åŠ›ç”±äºéœ€è¦ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è®¡ç®—ä¸Šä¸‹æ–‡å‘é‡ï¼Œå› æ­¤æœ¬è´¨ä¸ŠåŒ…å«äº†<em>ä¸€ç§é¡ºåºæ€§</em>ã€‚è¿™å¯èƒ½ä¼šå¸¦æ¥è®¡ç®—ä¸Šçš„åŠ£åŠ¿ï¼Œå› ä¸º<em>æ— æ³•å¹¶è¡Œ</em>åŒ–ã€‚</p>
<h5 id="interactive-co-attention"><a href="#interactive-co-attention" class="headerlink" title="interactive co-attention"></a>interactive co-attention</h5><img src="/img/Attention/InteractiveCo-Attention.png" alt="interactive co-attention" width="60%" height="auto">

<ul>
<li>å¹¶è¡Œè®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›</li>
<li>ä½¿ç”¨æœªåŠ æƒå¹³å‡çš„å…³é”®å‘é‡ä½œä¸ºæŸ¥è¯¢</li>
<li>è®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œå¯ä»¥å¹¶è¡Œå¤„ç†</li>
</ul>
<p>$$<br>\underset{d_k^{(i)}\times1}{\bar{\boldsymbol{k}}^{(i)}}&#x3D;\frac{1}{n_f^{(i)}}\sum\limits_{l&#x3D;1}^{n_f^{(i)}}\underset{d_k^{(i)}\times1}{\boldsymbol{k}_l^{(i)}}, \quad \underset{1\times1}{e_{l}^{(i)}}&#x3D;\mathrm{score}(\underset{d_{k}^{(3-i)}\times1}{\bar{\boldsymbol{k}}^{(3-i)}},\underset{d_{k}^{(i)}\times1}{\boldsymbol{k}_{l}^{(i)}}) , \qquad i&#x3D;1,2<br>$$</p>
<h4 id="ç»†é¢—ç²’åº¦ååŒ"><a href="#ç»†é¢—ç²’åº¦ååŒ" class="headerlink" title="ç»†é¢—ç²’åº¦ååŒ"></a>ç»†é¢—ç²’åº¦ååŒ</h4><p>è™½ç„¶ç²—ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›æœºåˆ¶ä½¿ç”¨ä¸€ä¸ªè¾“å…¥çš„ç´§å‡‘è¡¨ç¤ºä½œä¸ºæŸ¥è¯¢ï¼Œä»¥è®¡ç®—å¦ä¸€ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›ï¼Œä½†ç»†ç²’åº¦çš„å…±åŒæ³¨æ„åŠ›åœ¨è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°æ—¶ä¼šå•ç‹¬è€ƒè™‘æ¯ä¸ªè¾“å…¥çš„æ¯ä¸ªå…ƒç´ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒæŸ¥è¯¢å˜æˆäº†ä¸€ä¸ªçŸ©é˜µã€‚</p>
<h5 id="å¹¶è¡ŒååŒæ³¨æ„åŠ›-Parallel-Co-attention"><a href="#å¹¶è¡ŒååŒæ³¨æ„åŠ›-Parallel-Co-attention" class="headerlink" title="å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)"></a>å¹¶è¡ŒååŒæ³¨æ„åŠ›(Parallel Co-attention)</h5><img src="/img/Attention/ParallelCo-Attention.png" alt="parallel co-attention" width="60%" height="auto">

<ul>
<li>åŒæ—¶è®¡ç®—ä¸¤ä¸ªè¾“å…¥çš„æ³¨æ„åŠ›</li>
<li>ä½¿ç”¨äº²å’ŒçŸ©é˜µ(Affinity Matrix)è½¬æ¢å…³é”®å‘é‡ç©ºé—´</li>
<li>é€šè¿‡èšåˆå½¢å¼è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°</li>
</ul>
<p>æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼ç”ŸæˆçŸ©é˜µ $\mathbf{A}$</p>
<p>$$<br>\underset{n_{f}^{(1)}\times n_{f}^{(2)}}{\mathbf{A}}&#x3D;\operatorname{act}(\underset{n_{f}^{(1)}\times d_{k}^{(1)}}{\begin{array}{c}K^{(1)^{T}}\end{array}}\times\underset{d_{k}^{(1)}\times d_{k}^{(2)}}{\begin{array}{c}W_{A}\end{array}}\times\underset{d_{k}^{(2)}\times n_{f}^{(2)}}{\begin{array}{c}K^{(2)}\end{array}})<br>$$</p>
<p>$$<br>\underset{1\times1}{A_{i,j}}&#x3D;\underset{1\times3d_{k}}{\boldsymbol{w}_{A}^{T}}\times\mathrm{concat}(\underset{d_{k}\times1}{\boldsymbol{k}_{i}^{(1)}},\underset{d_{k}\times1}{\boldsymbol{k}_{j}^{(2)}},\underset{d_{k}\times1}{\boldsymbol{k}_{i}^{(1)}}\circ\underset{d_{k}\times1}{\boldsymbol{k}_{j}^{(2)}})<br>$$</p>
<p>å…¶ä¸­ï¼Œ$\circ$è¡¨ç¤ºå“ˆå¾·æ›¼ç§¯</p>
<p>Affinity Matrix å¯ä»¥è§£é‡Šä¸ºä¸¤ä¸ªé”®çŸ©é˜µåˆ—çš„ç›¸ä¼¼æ€§çŸ©é˜µï¼Œå¹¶æœ‰åŠ©äºå°†å›¾åƒé”®è½¬æ¢åˆ°ä¸å¥å­ä¸­å•è¯çš„é”®ç›¸åŒçš„ç©ºé—´ï¼Œåä¹‹äº¦ç„¶ã€‚</p>
<p>ç”±äºç°åœ¨æŸ¥è¯¢ç”±å‘é‡å˜æˆäº†çŸ©é˜µï¼Œå› æ­¤ score å‡½æ•°ä¹Ÿå‘ç”Ÿäº†å˜åŒ–</p>
<p>$$<br>e^{(1)} &#x3D;\boldsymbol{w}_{1}\times\mathrm{act}(\boldsymbol{W}_{2}\times\boldsymbol{K}^{(2)}\times\boldsymbol{A}^{T}+\boldsymbol{W}_{1}\times\boldsymbol{K}^{(1)})<br>$$</p>
<p>$$<br>e^{(2)} &#x3D;\boldsymbol{w}_{2}\times\mathrm{act}(\boldsymbol{W}_{1}\times\boldsymbol{K}^{(1)}\times\boldsymbol{A}^{::}+\boldsymbol{W}_{2}\times\boldsymbol{K}^{(2)})<br>$$</p>
<p>å€¼å¾—ä¸€æçš„æ˜¯ï¼Œä¹‹å‰çš„ score å‡½æ•°å®é™…æ˜¯ç°åœ¨è¿™ä¸€å½¢å¼çš„ç‰¹æ®Šè¡¨è¾¾ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªè¡¨è¾¾æ›´å…·ä¸€èˆ¬æ€§</p>
<p>å¦‚å‰æ‰€è¿°ï¼Œäº²å’ŒçŸ©é˜µæœ¬è´¨ä¸Šæ˜¯ä¸¤ä¸ªæ³¨æ„åŠ›æ¨¡å— 1 å’Œ 2 çš„å…³é”®å‘é‡çš„ç›¸ä¼¼æ€§çŸ©é˜µã€‚è¿™ä¸ªæ„å‘³ç€ä¸€ç§ä¸åŒçš„ç¡®å®šæ³¨æ„åŠ›åˆ†æ•°çš„æ–¹æ³•ã€‚å³ï¼Œå¯ä»¥å°†ä¸€è¡Œæˆ–ä¸€åˆ—ä¸­çš„æœ€å¤§ç›¸ä¼¼åº¦å€¼ä½œä¸ºæ³¨æ„åŠ›åˆ†æ•°ã€‚</p>
<p>$$<br>e_{i}^{(1)}&#x3D;\max_{j&#x3D;1,\ldots,n_{f}^{(2)}}A_{i,j},\quad e_{j}^{(2)}&#x3D;\max_{i&#x3D;1,\ldots,n_{f}^{(1)}}A_{i,j}.<br>$$</p>
<h5 id="æ—‹è½¬æ³¨æ„åŠ›-Rotatory-Attention"><a href="#æ—‹è½¬æ³¨æ„åŠ›-Rotatory-Attention" class="headerlink" title="æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)"></a>æ—‹è½¬æ³¨æ„åŠ›(Rotatory Attention)</h5><p>Rotatory Attention æ˜¯ä¸€ç§ç”¨äºå¤„ç†å¤šè¾“å…¥æ•°æ®çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç‰¹åˆ«é€‚ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸­åŒæ—¶è€ƒè™‘ç›®æ ‡çŸ­è¯­ã€å·¦ä¸Šä¸‹æ–‡å’Œå³ä¸Šä¸‹æ–‡çš„åœºæ™¯ã€‚è¯¥æœºåˆ¶é€šè¿‡äº¤æ›¿å…³æ³¨ä¸åŒè¾“å…¥æ¥æ„å»ºæ›´ä¸°å¯Œçš„è¡¨ç¤ºã€‚</p>
<ul>
<li>ä¸»è¦ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡</li>
<li>å¤„ç†ä¸‰ä¸ªè¾“å…¥ï¼šç›®æ ‡çŸ­è¯­ $\boldsymbol{F}^{t} &#x3D; [ \boldsymbol{f}_{1}^{t}, \ldots , \boldsymbol{f}_{n_{f}^{t}}^{t}] \in \mathbb{R} ^{d_{f}^{t}\times n_{f}^{t}}$ ã€å·¦ä¸Šä¸‹æ–‡ $F^{l} &#x3D; [ f_{1}^{l}, \ldots , f_{n_{f}^{l}}^{l}]\in\mathbb{R} ^{d_{f}^{l}\times n_{f}^{l}}$ å’Œå³ä¸Šä¸‹æ–‡ $F^{r} &#x3D; [ f_{1}^{r}, \ldots , f_{n_{f}^{r}}^{r}]\in\mathbb{R}^{d_f^r\times n_f^r}$</li>
<li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶è¿­ä»£æ”¹è¿›è¡¨ç¤º</li>
</ul>
<p>å…¶å¤§è‡´çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li><p><strong>åˆå§‹ç‰¹å¾æå–</strong></p>
<p>é¦–å…ˆï¼Œæ¨¡å‹ä»ä¸‰ä¸ªè¾“å…¥ä¸­æå–ç‰¹å¾å‘é‡ï¼š</p>
<ul>
<li>ç›®æ ‡çŸ­è¯­ç‰¹å¾çŸ©é˜µï¼š$F^{t}&#x3D;[f_{1}^{t},\ldots,f_{n_{f}^{t}}^{t}]\in R^{d_{f}^{t}\times n_{f}^{t}}$</li>
<li>å·¦ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µï¼š$F^{l}&#x3D;[f_{1}^{l},\ldots,f_{n_{f}^{l}}^{l}]\in R^{d_{f}^{l}\times n_{f}^{l}}$</li>
<li>å³ä¸Šä¸‹æ–‡ç‰¹å¾çŸ©é˜µï¼š$F^{r}&#x3D;[f_{1}^{r},\ldots,f_{n_{f}^{r}}^{r}]\in R^{d_{f}^{r}\times n_{f}^{r}}$</li>
</ul>
</li>
<li><p><strong>ç›®æ ‡çŸ­è¯­åˆå§‹è¡¨ç¤º</strong></p>
<p>è®¡ç®—ç›®æ ‡çŸ­è¯­çš„åˆå§‹è¡¨ç¤ºå‘é‡$r^{t}$ï¼Œé€šè¿‡å¯¹ç‰¹å¾å‘é‡å–å¹³å‡ï¼š</p>
<p>$$<br>r^{t}&#x3D;\frac{1}{n_{f}^{t}}\sum_{i&#x3D;1}^{n_{f}^{t}} f_{i}^{t}<br>$$</p>
</li>
<li><p><strong>å·¦ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—</strong></p>
<p>ä½¿ç”¨$r^{t}$ä½œä¸ºæŸ¥è¯¢ï¼Œè®¡ç®—å·¦ä¸Šä¸‹æ–‡çš„æ³¨æ„åŠ›ï¼š</p>
<ol>
<li><p>æå–é”®å‘é‡ $k_{1}^{l},\ldots,k_{n_{f}^{l}}^{l}\in R^{d_{k}^{l}}$ å’Œå€¼å‘é‡ $v_{1}^{l},\ldots,v_{n_{f}^{l}}^{l}\in R^{d_{v}^{l}}$</p>
</li>
<li><p>è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{i}^{l}&#x3D;\operatorname{score}\left(r^{t}, k_{i}^{l}\right)$</p>
</li>
<li><p>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{l}$</p>
</li>
<li><p>è®¡ç®—å·¦ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{l}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{l}} a_{i}^{l}v_{i}^{l}$</p>
</li>
</ol>
</li>
<li><p><strong>å³ä¸Šä¸‹æ–‡æ³¨æ„åŠ›è®¡ç®—</strong></p>
<p>ç±»ä¼¼åœ°ï¼Œè®¡ç®—å³ä¸Šä¸‹æ–‡çš„è¡¨ç¤ºå‘é‡$r^{r}$ï¼š</p>
<ol>
<li><p>æå–é”®å‘é‡ $k_{1}^{r},\ldots,k_{n_{f}^{r}}^{r}\in R^{d_{k}^{r}}$ å’Œå€¼å‘é‡ $v_{1}^{r},\ldots,v_{n_{f}^{r}}^{r}\in R^{d_{v}^{r}}$</p>
</li>
<li><p>è®¡ç®—æ³¨æ„åŠ›åˆ†æ•° $e_{i}^{r}&#x3D;\operatorname{score}\left(r^{t}, k_{i}^{r}\right)$</p>
</li>
<li><p>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{r}$</p>
</li>
<li><p>è®¡ç®—å³ä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡ $r^{r}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{r}} a_{i}^{r}v_{i}^{r}$</p>
</li>
</ol>
</li>
<li><p><strong>ç›®æ ‡çŸ­è¯­æ›´æ–°è¡¨ç¤º</strong></p>
<p>ä½¿ç”¨å·¦ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{l}$å’Œå³ä¸Šä¸‹æ–‡è¡¨ç¤º$r^{r}$æ¥æ›´æ–°ç›®æ ‡çŸ­è¯­çš„è¡¨ç¤ºï¼š</p>
<ol>
<li><p>æå–ç›®æ ‡çŸ­è¯­çš„é”®å‘é‡ $k_{1}^{t},\ldots,k_{n_{f}^{t}}^{t}\in R^{d_{k}^{t}}$ å’Œå€¼å‘é‡ $v_{1}^{t},\ldots,v_{n_{f}^{t}}^{t}\in R^{d_{v}^{t}}$</p>
</li>
<li><p>è®¡ç®—å·¦æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º$r^{l_{t}}$ï¼š</p>
<ul>
<li>æ³¨æ„åŠ›åˆ†æ•°ï¼š$e_{i}^{l_{t}}&#x3D;\operatorname{score}\left(r^{l}, k_{i}^{t}\right)$</li>
<li>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{l_{t}}$</li>
<li>è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{l_{t}}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{l_{t}}v_{i}^{t}$</li>
</ul>
</li>
<li><p>è®¡ç®—å³æ„ŸçŸ¥ç›®æ ‡è¡¨ç¤º$r^{r_{t}}$ï¼š</p>
<ul>
<li>æ³¨æ„åŠ›åˆ†æ•°ï¼š$e_{i}^{r_{t}}&#x3D;\operatorname{score}\left(r^{r}, k_{i}^{t}\right)$</li>
<li>ä½¿ç”¨ softmax å¯¹é½å‡½æ•°è®¡ç®—æ³¨æ„åŠ›æƒé‡$a_{i}^{r_{t}}$</li>
<li>è®¡ç®—è¡¨ç¤ºå‘é‡ï¼š$r^{r_{t}}&#x3D;\sum_{i&#x3D;1}^{n_{f}^{t}} a_{i}^{r_{t}}v_{i}^{t}$</li>
</ul>
</li>
</ol>
</li>
<li><p>æœ€ç»ˆè¡¨ç¤ºä¸º $r&#x3D;\operatorname{concat}\left(r^{l},r^{r},r^{l_{t}},r^{r_{t}}\right)$</p>
</li>
</ol>
<p>Rotatory Attention å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p>
<ol>
<li><p><strong>åŒå‘ä¿¡æ¯æµåŠ¨</strong>ï¼šé€šè¿‡ä»ç›®æ ‡çŸ­è¯­åˆ°ä¸Šä¸‹æ–‡ï¼Œå†ä»ä¸Šä¸‹æ–‡å›åˆ°ç›®æ ‡çŸ­è¯­çš„ä¿¡æ¯æµåŠ¨ï¼Œå®ç°äº†åŒå‘çš„ä¿¡æ¯äº¤äº’ã€‚</p>
</li>
<li><p><strong>å±‚æ¬¡åŒ–è¡¨ç¤º</strong>ï¼šæ„å»ºäº†å¤šå±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»åŸå§‹ç‰¹å¾åˆ°ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹å¾ã€‚</p>
</li>
<li><p><strong>ç‰¹å®šä»»åŠ¡ä¼˜åŒ–</strong>ï¼šç‰¹åˆ«é€‚åˆæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œèƒ½å¤Ÿæ•æ‰ç›®æ ‡çŸ­è¯­ä¸ä¸Šä¸‹æ–‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚</p>
</li>
</ol>
<p>Rotatory Attention é€šè¿‡è¿™ç§äº¤æ›¿å…³æ³¨çš„æ–¹å¼ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç›®æ ‡çŸ­è¯­åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼Œä»è€Œæé«˜äº†æƒ…æ„Ÿåˆ†ç±»çš„å‡†ç¡®æ€§ã€‚</p>
<h2 id="ç‰¹å¾å±‚çº§-Levels-of-Features"><a href="#ç‰¹å¾å±‚çº§-Levels-of-Features" class="headerlink" title="ç‰¹å¾å±‚çº§(Levels of Features)"></a>ç‰¹å¾å±‚çº§(Levels of Features)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†å¦‚ä½•å¤„ç†å…·æœ‰å±‚çº§ç»“æ„çš„ç‰¹å¾ï¼Œä¸»è¦åˆ†ä¸ºå•å±‚çº§æ³¨æ„åŠ›å’Œå¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
<h3 id="å•å±‚çº§æ³¨æ„åŠ›-Single-Level-Attention"><a href="#å•å±‚çº§æ³¨æ„åŠ›-Single-Level-Attention" class="headerlink" title="å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)"></a>å•å±‚çº§æ³¨æ„åŠ›(Single-Level Attention)</h3><p>ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶é€šå¸¸åœ¨å•ä¸€å±‚çº§ä¸Šå¤„ç†ç‰¹å¾ï¼Œå¦‚åªå…³æ³¨å•è¯çº§åˆ«æˆ–å¥å­çº§åˆ«ã€‚</p>
<h3 id="å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶"><a href="#å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶"></a>å¤šå±‚çº§æ³¨æ„åŠ›æœºåˆ¶</h3><ol>
<li><strong>æ³¨æ„åŠ›å åŠ (Attention-via-Attention)</strong></li>
</ol>
<img src="img/Attention/AttentionViaAttention.png" alt="attention-via-attention" width="60%" height="auto">

<ul>
<li>åŒæ—¶å¤„ç†å­—ç¬¦çº§å’Œè¯çº§ç‰¹å¾</li>
<li>å…ˆè®¡ç®—è¯çº§æ³¨æ„åŠ›ï¼Œç”¨å…¶ä¸Šä¸‹æ–‡å‘é‡è¾…åŠ©è®¡ç®—å­—ç¬¦çº§æ³¨æ„åŠ›</li>
<li>æœ€ç»ˆæ‹¼æ¥ä¸¤ä¸ªå±‚çº§çš„ä¸Šä¸‹æ–‡å‘é‡</li>
</ul>
<ol start="2">
<li><strong>å±‚çº§æ³¨æ„åŠ›(Hierarchical Attention)</strong></li>
</ol>
<img src="img/Attention/HierarchicalAttention.png" alt="hierarchical attention" width="60%" height="auto">

<ul>
<li>ä»æœ€ä½å±‚çº§å¼€å§‹ï¼Œé€æ­¥æ„å»ºé«˜å±‚çº§è¡¨ç¤º</li>
<li>å¸¸ç”¨äºæ–‡æ¡£åˆ†ç±»ï¼šè¯ â†’ å¥ â†’ æ–‡æ¡£</li>
<li>æ¯ä¸ªå±‚çº§é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ç”Ÿæˆæ‘˜è¦è¡¨ç¤º</li>
</ul>
<h2 id="ç‰¹å¾è¡¨ç¤º-Feature-Representations"><a href="#ç‰¹å¾è¡¨ç¤º-Feature-Representations" class="headerlink" title="ç‰¹å¾è¡¨ç¤º(Feature Representations)"></a>ç‰¹å¾è¡¨ç¤º(Feature Representations)</h2><p>è¿™éƒ¨åˆ†è®¨è®ºäº†ç‰¹å¾è¡¨ç¤ºæ–¹å¼çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ï¼Œä¸»è¦åˆ†ä¸ºå•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›å’Œå¤šè¡¨ç¤ºæ³¨æ„åŠ›ã€‚</p>
<h3 id="å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›-Single-Representational-Attention"><a href="#å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›-Single-Representational-Attention" class="headerlink" title="å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)"></a>å•ä¸€è¡¨ç¤ºæ³¨æ„åŠ›(Single-Representational Attention)</h3><p>ä¼ ç»Ÿæ–¹æ³•ä½¿ç”¨å•ä¸€åµŒå…¥æˆ–è¡¨ç¤ºæ¨¡å‹ç”Ÿæˆç‰¹å¾è¡¨ç¤ºã€‚</p>
<h3 id="å¤šè¡¨ç¤ºæ³¨æ„åŠ›-Multi-Representational-Attention"><a href="#å¤šè¡¨ç¤ºæ³¨æ„åŠ›-Multi-Representational-Attention" class="headerlink" title="å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)"></a>å¤šè¡¨ç¤ºæ³¨æ„åŠ›(Multi-Representational Attention)</h3><ol>
<li><p><strong>å…ƒåµŒå…¥(Meta-embeddings)</strong></p>
<ul>
<li>æ•´åˆå¤šä¸ªåµŒå…¥è¡¨ç¤º</li>
<li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ æƒå¹³å‡ä¸åŒè¡¨ç¤º</li>
<li>ç”Ÿæˆæ›´é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤º</li>
</ul>
</li>
<li><p><strong>è‡ªæ³¨æ„åŠ›æœºåˆ¶</strong></p>
<ul>
<li>å­¦ä¹ ç‰¹å¾å‘é‡ä¹‹é—´çš„å…³ç³»</li>
<li>é€šè¿‡æ³¨æ„åŠ›æ”¹è¿›ç‰¹å¾è¡¨ç¤º</li>
<li>å¸¸ç”¨äº Transformer æ¶æ„ä¸­</li>
</ul>
</li>
</ol>
<h2 id="åº”ç”¨é¢†åŸŸ"><a href="#åº”ç”¨é¢†åŸŸ" class="headerlink" title="åº”ç”¨é¢†åŸŸ"></a>åº”ç”¨é¢†åŸŸ</h2><p>3.1 èŠ‚è®¨è®ºçš„ç‰¹å¾ç›¸å…³æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤šä¸ªé¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ï¼š</p>
<ul>
<li>åŒ»å­¦æ•°æ®åˆ†æ(å¤šç‰¹å¾ååŒæ³¨æ„åŠ›)</li>
<li>æ¨èç³»ç»Ÿ(å¤šå±‚çº§æ³¨æ„åŠ›)</li>
<li>æƒ…æ„Ÿåˆ†æ(æ—‹è½¬æ³¨æ„åŠ›)</li>
<li>æ–‡æ¡£åˆ†ç±»(å±‚çº§æ³¨æ„åŠ›)</li>
<li>å¤šè¯­è¨€å¤„ç†(å¤šè¡¨ç¤ºæ³¨æ„åŠ›)</li>
</ul>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>3.1 èŠ‚ç³»ç»Ÿæ€§åœ°åˆ†ç±»äº†åŸºäºè¾“å…¥ç‰¹å¾ç‰¹æ€§çš„æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ï¼Œä¸ºç ”ç©¶è€…æä¾›äº†æ¸…æ™°çš„æ¡†æ¶æ¥é€‰æ‹©é€‚åˆç‰¹å®šä»»åŠ¡å’Œæ•°æ®ç±»å‹çš„æœ€ä½³æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™äº›æœºåˆ¶é€šè¿‡å……åˆ†åˆ©ç”¨è¾“å…¥ç‰¹å¾çš„å¤šé‡æ€§ã€å±‚çº§ç»“æ„å’Œè¡¨ç¤ºå¤šæ ·æ€§ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</p>
<p>å›¾ 3 å±•ç¤ºäº†å®Œæ•´çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†ç±»ä½“ç³»ï¼Œå…¶ä¸­ 3.1 èŠ‚è®¨è®ºçš„ç‰¹å¾ç›¸å…³æ³¨æ„åŠ›æœºåˆ¶æ˜¯è¯¥ä½“ç³»çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚</p>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwers å’Œ Frasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
<a href="/2025/07/10/Attention/" title="Attention Overview">Attention Overview</a>
]]></content>
      <categories>
        <category>CDR</category>
        <category>model</category>
        <category>attention</category>
        <category>feature related</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
        <tag>è¿˜æ²¡å†™å®Œæ</tag>
      </tags>
  </entry>
  <entry>
    <title>What Is GNN and GCN ?</title>
    <url>/2025/07/10/GNN-and-GCN/</url>
    <content><![CDATA[<h1 id="GNN-ä¸-GCN"><a href="#GNN-ä¸-GCN" class="headerlink" title="GNN ä¸ GCN"></a>GNN ä¸ GCN</h1><blockquote>
<p>å›¾ç¥ç»ç½‘ç»œï¼ˆGraph Neural Networks, GNNï¼‰å’Œå›¾å·ç§¯ç½‘ç»œï¼ˆGraph Convolutional Networks, GCNï¼‰æ˜¯å¤„ç†å›¾æ•°æ®çš„å¼ºå¤§å·¥å…·ã€‚æœ¬æ–‡å°†ä»ç†è®ºåˆ°å®è·µï¼Œå…¨é¢ä»‹ç»è¿™ä¸¤ç§é‡è¦çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</p>
</blockquote>
<p>æœ¬æ–‡ä¸»è¦ä»‹ç»äº†<em>GNNå’ŒGCNçš„å¤§è‡´åŸç†</em>ï¼Œ<em>GCNåœ¨PyGå’ŒPyTorchçš„å®ç°</em> ä»¥åŠå®ƒä»¬åœ¨<em>DRPä¸­çš„åº”ç”¨</em></p>
<span id="more"></span>

<h2 id="ğŸ¯-Intro"><a href="#ğŸ¯-Intro" class="headerlink" title="ğŸ¯ Intro"></a>ğŸ¯ Intro</h2><p>åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œå¤„ç†å›¾ç»“æ„æ•°æ®ä¸€ç›´æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚CNNã€RNNï¼‰åœ¨å¤„ç†æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æ•°æ®è¡¨ç°å‡ºè‰²ï¼Œä½†å¯¹äºå›¾è¿™ç§éæ¬§å‡ é‡Œå¾—ç»“æ„çš„æ•°æ®å´æ˜¾å¾—åŠ›ä¸ä»å¿ƒã€‚GNNå’ŒGCNçš„å‡ºç°ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†å¤„ç†å›¾æ•°æ®çš„æœ‰åŠ›å·¥å…·ã€‚</p>
<p>è€Œåœ¨DRPé¢†åŸŸï¼Œç”±äºæ¶‰åŠåˆ°å¤§é‡çš„Embeddingï¼ŒGCNç°åœ¨å‡ ä¹å·²ç»æˆä¸ºäº†å¿…ä¸å¯å°‘çš„æ¨¡å—ã€‚</p>
<p>ä½†åœ¨å¼€å§‹å„ç§å„æ ·çš„å¥‡å½¢æ€ªçŠ¶çš„GCNä¹‹å‰ï¼Œäº†è§£GNNå’ŒGCNæœ¬èº«çš„å®ç°ä»ç„¶æ˜¯éå¸¸å¿…è¦çš„ã€‚<del>äºé¼ é¼ è€Œè¨€</del>å¤§è‡´æœ‰ä»¥ä¸‹ç†ç”±ï¼š</p>
<ol>
<li>éƒ¨åˆ†æŠ½è±¡çš„åŸºäºGCNçš„æ¨¡å—ç¬¬ä¸‰æ–¹åº“ä¸ä¸€å®šæ”¯æŒ</li>
<li>ç”±äºååº”è¡¨ç¤ºæ•°æ®çš„ä¸å¹³è¡¡ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºçš„æ¨¡å‹çš„å±‚æ•°æ˜¯éå¸¸æœ‰é™çš„ï¼ˆå› ä¸ºä¼šè¿‡å¹³æ»‘ï¼‰ã€‚å› æ­¤å¯¹å±‚å†…çš„æ”¹é€ å°±æ˜¾å¾—éå¸¸å¿…è¦äº†ã€‚è€Œè¿™ä¸€åˆ‡çš„å‰æä¾¿æ˜¯ç†è§£åŸç†æ</li>
</ol>
<p>åœ¨è¿™é‡Œå¼ºçƒˆå»ºè®®å»çœ‹ä¸€ä¸‹<a href="https://distill.pub/">Distill</a>çš„ä¸¤ç¯‡æœ‰å…³å›¾ç¥ç»ç½‘ç»œçš„åšå®¢ï¼Œéå¸¸æ˜“æ‡‚ã€‚</p>
<hr>
<h2 id="ğŸ“š-ç†è®ºåŸºç¡€"><a href="#ğŸ“š-ç†è®ºåŸºç¡€" class="headerlink" title="ğŸ“š ç†è®ºåŸºç¡€"></a>ğŸ“š ç†è®ºåŸºç¡€</h2><h3 id="å›¾çš„åŸºæœ¬æ¦‚å¿µ"><a href="#å›¾çš„åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="å›¾çš„åŸºæœ¬æ¦‚å¿µ"></a>å›¾çš„åŸºæœ¬æ¦‚å¿µ</h3><p>åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£å›¾çš„åŸºæœ¬è¡¨ç¤ºï¼š</p>
<ul>
<li>å›¾ $G &#x3D; (V, E)$ï¼Œå…¶ä¸­ $V$ æ˜¯èŠ‚ç‚¹é›†åˆï¼Œ$E$ æ˜¯è¾¹é›†åˆ</li>
<li>é‚»æ¥çŸ©é˜µ $A \in \mathbb{R}^{n \times n}$</li>
<li>åº¦çŸ©é˜µ $D &#x3D; diag(d_1,â€¦,d_n)$ï¼Œå…¶ä¸­ $d_i &#x3D; \sum_j A_{ij}$</li>
<li>èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ $X \in \mathbb{R}^{n \times d}$</li>
</ul>
<h3 id="GNNæ¡†æ¶"><a href="#GNNæ¡†æ¶" class="headerlink" title="GNNæ¡†æ¶"></a>GNNæ¡†æ¶</h3><p>GNNçš„åŸºæœ¬æ¡†æ¶éµå¾ªæ¶ˆæ¯ä¼ é€’èŒƒå¼ï¼ˆMessage Passing Neural Network, MPNNï¼‰ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹æ•°å­¦å…¬å¼è¡¨ç¤ºï¼š</p>
<ol>
<li><p><strong>æ¶ˆæ¯ä¼ é€’é˜¶æ®µ</strong>ï¼ˆMessage Passingï¼‰ï¼š</p>
<p>å¯¹äºèŠ‚ç‚¹ $v$ï¼Œä»å…¶é‚»å±…èŠ‚ç‚¹ $u \in \mathcal{N}(v)$ æ”¶é›†ä¿¡æ¯ï¼š</p>
<p>$$m_v^{(l)} &#x3D; \sum_{u \in \mathcal{N}(v)} M_l(h_v^{(l-1)}, h_u^{(l-1)}, e_{uv})$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$h_v^{(l-1)}$ æ˜¯èŠ‚ç‚¹ $v$ åœ¨ç¬¬ $l-1$ å±‚çš„ç‰¹å¾</li>
<li>$e_{uv}$ æ˜¯è¾¹ $(u,v)$ çš„ç‰¹å¾</li>
<li>$M_l$ æ˜¯å¯å­¦ä¹ çš„æ¶ˆæ¯å‡½æ•°</li>
</ul>
</li>
<li><p><strong>æ¶ˆæ¯èšåˆé˜¶æ®µ</strong>ï¼ˆAggregationï¼‰ï¼š</p>
<p>å°†æ”¶é›†åˆ°çš„æ¶ˆæ¯è¿›è¡Œèšåˆï¼š</p>
<p>$$a_v^{(l)} &#x3D; AGG({m_v^{(l)} | u \in \mathcal{N}(v)})$$</p>
<p>å¸¸è§çš„èšåˆå‡½æ•°åŒ…æ‹¬ï¼š</p>
<ul>
<li>æ±‚å’Œï¼š$AGG_{sum} &#x3D; \sum_{u \in \mathcal{N}(v)} m_u$</li>
<li>å¹³å‡ï¼š$AGG_{mean} &#x3D; \frac{1}{|\mathcal{N}(v)|} \sum_{u \in \mathcal{N}(v)} m_u$</li>
<li>æœ€å¤§ï¼š$AGG_{max} &#x3D; max_{u \in \mathcal{N}(v)} m_u$</li>
</ul>
</li>
<li><p><strong>èŠ‚ç‚¹æ›´æ–°é˜¶æ®µ</strong>ï¼ˆUpdateï¼‰ï¼š</p>
<p>æ›´æ–°èŠ‚ç‚¹çš„è¡¨ç¤ºï¼š</p>
<p>$$h_v^{(l)} &#x3D; U_l(h_v^{(l-1)}, a_v^{(l)})$$</p>
<p>å…¶ä¸­ $U_l$ æ˜¯å¯å­¦ä¹ çš„æ›´æ–°å‡½æ•°ï¼Œé€šå¸¸æ˜¯MLPæˆ–å…¶ä»–ç¥ç»ç½‘ç»œã€‚</p>
</li>
</ol>
<h3 id="GCNå®ç°"><a href="#GCNå®ç°" class="headerlink" title="GCNå®ç°"></a>GCNå®ç°</h3><h4 id="æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ-ğŸ”"><a href="#æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ-ğŸ”" class="headerlink" title="æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ ğŸ”"></a>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ ğŸ”</h4><p>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µæ˜¯å›¾ä¿¡å·å¤„ç†ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼Œæœ‰å¤šç§å½¢å¼ï¼š</p>
<ol>
<li><p><strong>ç»„åˆæ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L &#x3D; D - A$</p>
</li>
<li><p><strong>æ ‡å‡†åŒ–æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L_{sym} &#x3D; D^{-\frac{1}{2}}LD^{-\frac{1}{2}} &#x3D; I - D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$</p>
</li>
<li><p><strong>éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>ï¼š$L_{rw} &#x3D; D^{-1}L &#x3D; I - D^{-1}A$</p>
</li>
</ol>
<p>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹æ€§ï¼š</p>
<ul>
<li>å¯¹ç§°æ€§ï¼š$L &#x3D; L^T$</li>
<li>åŠæ­£å®šæ€§ï¼šæ‰€æœ‰ç‰¹å¾å€¼éè´Ÿ</li>
<li>æœ€å°ç‰¹å¾å€¼ä¸º0ï¼Œå¯¹åº”çš„ç‰¹å¾å‘é‡æ˜¯å¸¸æ•°å‘é‡</li>
<li>ç‰¹å¾å€¼çš„é‡æ•°å¯¹åº”å›¾çš„è¿é€šåˆ†é‡æ•°</li>
</ul>
<h4 id="ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯-ğŸ”„"><a href="#ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯-ğŸ”„" class="headerlink" title="ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯ ğŸ”„"></a>ä»ä¼ ç»Ÿå·ç§¯åˆ°å›¾å·ç§¯ ğŸ”„</h4><h5 id="ä¼ ç»Ÿå·ç§¯å›é¡¾"><a href="#ä¼ ç»Ÿå·ç§¯å›é¡¾" class="headerlink" title="ä¼ ç»Ÿå·ç§¯å›é¡¾"></a>ä¼ ç»Ÿå·ç§¯å›é¡¾</h5><p>åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­ï¼Œå·ç§¯æ“ä½œå®šä¹‰ä¸ºï¼š</p>
<p>$$(f * g)(p) &#x3D; \sum_{q \in \mathcal{N}(p)} f(q) \cdot g(p-q)$$</p>
<p>è¿™é‡Œçš„å…³é”®ç‰¹ç‚¹æ˜¯ï¼š</p>
<ul>
<li>å¹³ç§»ä¸å˜æ€§</li>
<li>å±€éƒ¨æ€§</li>
<li>å‚æ•°å…±äº«</li>
</ul>
<h5 id="å›¾ä¸Šçš„å·ç§¯å®šä¹‰"><a href="#å›¾ä¸Šçš„å·ç§¯å®šä¹‰" class="headerlink" title="å›¾ä¸Šçš„å·ç§¯å®šä¹‰"></a>å›¾ä¸Šçš„å·ç§¯å®šä¹‰</h5><p>åœ¨å›¾åŸŸä¸­ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°å®šä¹‰è¿™äº›ç‰¹æ€§ï¼š</p>
<ol>
<li><p><strong>ç©ºé—´åŸŸå·ç§¯</strong>ï¼š<br>$$h_v &#x3D; \sum_{u \in \mathcal{N}(v)} W(e_{u,v})h_u$$<br>å…¶ä¸­ $W(e_{u,v})$ æ˜¯è¾¹çš„æƒé‡å‡½æ•°</p>
</li>
<li><p><strong>è°±åŸŸå·ç§¯</strong>ï¼š<br>$$g_\theta * x &#x3D; Ug_\theta U^T x$$<br>å…¶ä¸­ $U$ æ˜¯æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹å¾å‘é‡çŸ©é˜µ</p>
</li>
</ol>
<h4 id="GCNçš„æ•°å­¦æ¨å¯¼-âš™ï¸"><a href="#GCNçš„æ•°å­¦æ¨å¯¼-âš™ï¸" class="headerlink" title="GCNçš„æ•°å­¦æ¨å¯¼ âš™ï¸"></a>GCNçš„æ•°å­¦æ¨å¯¼ âš™ï¸</h4><p>Kipf &amp; Wellingæå‡ºçš„GCNæ¨¡å‹ä¸­ï¼Œå•å±‚ä¼ æ’­è§„åˆ™ä¸ºï¼š</p>
<p>$$H^{(l+1)} &#x3D; \sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})$$</p>
<p>å…¶ä¸­ï¼š</p>
<ul>
<li>$\tilde{A} &#x3D; A + I_N$ æ˜¯æ·»åŠ äº†è‡ªç¯çš„é‚»æ¥çŸ©é˜µ</li>
<li>$\tilde{D}_{ii} &#x3D; \sum_{j} \tilde{A}_{ij}$ æ˜¯å¯¹åº”çš„åº¦çŸ©é˜µ</li>
<li>$H^{(l)}$ æ˜¯ç¬¬ $l$ å±‚çš„æ¿€æ´»å€¼</li>
<li>$W^{(l)}$ æ˜¯å¯å­¦ä¹ çš„æƒé‡çŸ©é˜µ</li>
<li>$\sigma$ æ˜¯éçº¿æ€§æ¿€æ´»å‡½æ•°</li>
</ul>
<p><del>ä¸€äº›è‡ªå·±çš„ç†è§£</del></p>
<ol>
<li>å¼•å…¥$L_{sym} &#x3D; \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ä½œä¸ºèšåˆï¼ˆAGGï¼‰éƒ¨åˆ†<ul>
<li>æ·»åŠ è‡ªç¯ï¼š$\tilde{A} &#x3D; A + I_N$</li>
<li>è®¡ç®—å½’ä¸€åŒ–ç³»æ•°ï¼š$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$</li>
</ul>
</li>
<li>ç‰¹å¾å˜æ¢ï¼š$H^{(l)}W^{(l)}$</li>
<li>é‚»åŸŸèšåˆï¼š$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)}$</li>
<li>éçº¿æ€§å˜æ¢ï¼š$\sigma(\cdot)$</li>
</ol>
<hr>
<h2 id="ğŸ’»-å®ç°ç»†èŠ‚"><a href="#ğŸ’»-å®ç°ç»†èŠ‚" class="headerlink" title="ğŸ’» å®ç°ç»†èŠ‚"></a>ğŸ’» å®ç°ç»†èŠ‚</h2><p>åŸºäºè¿™ä¸ªç†è®ºæ¡†æ¶çš„ç®€å•å®ç°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">message_passing</span>(<span class="params">nodes, edges</span>):</span><br><span class="line">    messages = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> edge <span class="keyword">in</span> edges:</span><br><span class="line">        src, dst = edge</span><br><span class="line">        msg = compute_message(nodes[src], nodes[dst])</span><br><span class="line">        messages.setdefault(dst, []).append(msg)</span><br><span class="line">    <span class="keyword">return</span> messages</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">aggregate_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    aggregated = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> node, msgs <span class="keyword">in</span> messages.items():</span><br><span class="line">        aggregated[node] = <span class="built_in">sum</span>(msgs) / <span class="built_in">len</span>(msgs)  <span class="comment"># å¹³å‡èšåˆ</span></span><br><span class="line">    <span class="keyword">return</span> aggregated</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update_nodes</span>(<span class="params">nodes, aggregated</span>):</span><br><span class="line">    updated = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> node, agg_msg <span class="keyword">in</span> aggregated.items():</span><br><span class="line">        updated[node] = nodes[node] + agg_msg  <span class="comment"># æ®‹å·®è¿æ¥</span></span><br><span class="line">    <span class="keyword">return</span> updated</span><br></pre></td></tr></table></figure>

<h3 id="PyTorch-Geometricå®ç°-ğŸš€"><a href="#PyTorch-Geometricå®ç°-ğŸš€" class="headerlink" title="PyTorch Geometricå®ç° ğŸš€"></a>PyTorch Geometricå®ç° ğŸš€</h3><blockquote>
<p>æœ¬èŠ‚ä»£ç åŸºäº PyTorch 2.1.0 å’Œ PyTorch Geometric 2.4.0 ç‰ˆæœ¬</p>
</blockquote>
<p>ä½¿ç”¨PyTorch Geometricåº“çš„GCNå®ç°ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = GCNConv(num_features, <span class="number">16</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = GCNConv(<span class="number">16</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x, edge_index)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.dropout(x, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="åŸç”ŸPyTorchå®ç°-ğŸ”§"><a href="#åŸç”ŸPyTorchå®ç°-ğŸ”§" class="headerlink" title="åŸç”ŸPyTorchå®ç° ğŸ”§"></a>åŸç”ŸPyTorchå®ç° ğŸ”§</h3><blockquote>
<p>æœ¬èŠ‚ä»£ç åŸºäº PyTorch 2.1.0ã€NumPy 1.24.0 å’Œ SciPy 1.11.0 ç‰ˆæœ¬</p>
</blockquote>
<p>ä¸ä½¿ç”¨PyGï¼Œæ‰‹åŠ¨å®ç°GCN<del>ä¸»è¦æ˜¯ç›®å‰ä¸å¤ªæ¸…æ¥šä¸»æµçš„HGCNçš„å®ç°æ–¹å¼æ</del>ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, out_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCNLayer, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.W = nn.Parameter(torch.FloatTensor(in_features, out_features))</span><br><span class="line">        <span class="variable language_">self</span>.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        nn.init.kaiming_uniform_(<span class="variable language_">self</span>.W)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        <span class="comment"># adj: å½’ä¸€åŒ–çš„é‚»æ¥çŸ©é˜µ</span></span><br><span class="line">        support = torch.mm(x, <span class="variable language_">self</span>.W)</span><br><span class="line">        output = torch.sparse.mm(adj, support)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nfeat, nhid, nclass, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gc1 = GCNLayer(nfeat, nhid)</span><br><span class="line">        <span class="variable language_">self</span>.gc2 = GCNLayer(nhid, nclass)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.gc1(x, adj))</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.gc2(x, adj)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize_adj</span>(<span class="params">adj</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ&quot;&quot;&quot;</span></span><br><span class="line">    adj = sp.coo_matrix(adj)</span><br><span class="line">    rowsum = np.array(adj.<span class="built_in">sum</span>(<span class="number">1</span>))</span><br><span class="line">    d_inv_sqrt = np.power(rowsum, -<span class="number">0.5</span>).flatten()</span><br><span class="line">    d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class="number">0.</span></span><br><span class="line">    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class="line">    <span class="keyword">return</span> adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="ğŸ®-åº”ç”¨åœºæ™¯"><a href="#ğŸ®-åº”ç”¨åœºæ™¯" class="headerlink" title="ğŸ® åº”ç”¨åœºæ™¯"></a>ğŸ® åº”ç”¨åœºæ™¯</h2><p><del>ç”±äºé¼ é¼ å°±æ˜¯ä¸ªè‡­å†™DRPçš„æ</del> è¿™é‡Œåªç»™å‡ºGNNåœ¨DRPä¸­çš„åº”ç”¨</p>
<ol>
<li><p><strong>è¯ç‰©è¡¨ç¤º</strong></p>
<ul>
<li><em>åˆ†å­å›¾æ„å»º</em>ï¼šå°†è¯ç‰©SMILESå­—ç¬¦ä¸²è½¬æ¢ä¸ºå›¾ç»“æ„ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºåŸå­ï¼ˆå«åŸå­ç±»å‹ã€ç”µè·ç­‰ç‰¹å¾ï¼‰ï¼Œè¾¹è¡¨ç¤ºåŒ–å­¦é”®ï¼ˆå¦‚é”®ç±»å‹ã€è·ç¦»ï¼‰ã€‚  </li>
<li><em>GNNç¼–ç </em>ï¼šä½¿ç”¨å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰ã€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰æˆ–å›¾åŒæ„ç½‘ç»œï¼ˆGINï¼‰ç­‰å±‚è¿­ä»£èšåˆé‚»åŸŸä¿¡æ¯ï¼Œç”Ÿæˆè¯ç‰©åµŒå…¥ï¼ˆembeddingï¼‰ã€‚ä¾‹å¦‚ï¼ŒGraTransDRPï¼ˆ2022ï¼‰ç»“åˆGATå’ŒTransformeræå‡è¯ç‰©è¡¨å¾èƒ½åŠ›ã€‚</li>
</ul>
</li>
<li><p><strong>ç™Œç—‡è¡¨ç¤º</strong></p>
<ul>
<li><em>ç”Ÿç‰©ç½‘ç»œæ„å»º</em>ï¼šåŸºäºåŸºå› äº’ä½œï¼ˆå¦‚STRINGæ•°æ®åº“çš„è›‹ç™½-è›‹ç™½äº’ä½œï¼‰ã€åŸºå› å…±è¡¨è¾¾æˆ–é€šè·¯ä¿¡æ¯æ„å»ºå¼‚è´¨å›¾ã€‚ä¾‹å¦‚ï¼ŒAGMIï¼ˆ2021ï¼‰æ•´åˆå¤šç»„å­¦æ•°æ®å’ŒPPIç½‘ç»œï¼Œé€šè¿‡GNNå­¦ä¹ ç™Œç—‡æ ·æœ¬çš„è”åˆè¡¨å¾ã€‚  </li>
<li><em>å¤šç»„å­¦èåˆ</em>ï¼šéƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚TGSAï¼‰åˆ©ç”¨GNNæ•´åˆåŸºå› ç»„ã€è½¬å½•ç»„ç­‰æ•°æ®ï¼Œé€šè¿‡è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç‰¹å¾äº¤äº’ã€‚</li>
</ul>
</li>
<li><p><strong>å¼‚æ„å›¾ä¸è”åˆå»ºæ¨¡</strong></p>
<ul>
<li><em>ç»†èƒç³»-è¯ç‰©å¼‚æ„å›¾</em>ï¼šå¦‚GraphCDRï¼ˆ2021ï¼‰å°†ç»†èƒç³»å’Œè¯ç‰©ä½œä¸ºä¸¤ç±»èŠ‚ç‚¹ï¼Œé€šè¿‡è¾¹è¿æ¥å·²çŸ¥å“åº”å¯¹ï¼Œç›´æ¥å­¦ä¹ è·¨å®ä½“å…³ç³»ã€‚  </li>
<li><em>çŸ¥è¯†å¢å¼º</em>ï¼šé¢„è®­ç»ƒGNNäºå¤§è§„æ¨¡ç”Ÿç‰©åŒ–å­¦å±æ€§é¢„æµ‹ï¼ˆå¦‚Zhu et al., 2021ï¼‰ï¼Œå†è¿ç§»è‡³DRPä»»åŠ¡ï¼Œæå‡æ³›åŒ–æ€§ã€‚</li>
</ul>
</li>
</ol>
<h2 id="ğŸ¯-æ€»ç»“ä¸å±•æœ›"><a href="#ğŸ¯-æ€»ç»“ä¸å±•æœ›" class="headerlink" title="ğŸ¯ æ€»ç»“ä¸å±•æœ›"></a>ğŸ¯ æ€»ç»“ä¸å±•æœ›</h2><ul>
<li><strong>åŠ¨æ€å›¾å»ºæ¨¡</strong>ï¼šæ•æ‰æ²»ç–—è¿‡ç¨‹ä¸­åŠ¨æ€å˜åŒ–çš„ç”Ÿç‰©ç½‘ç»œã€‚  </li>
<li><strong>ä¸‰ç»´åˆ†å­å›¾</strong>ï¼šç»“åˆå‡ ä½•æ·±åº¦å­¦ä¹ ï¼ˆå¦‚SchNetï¼‰æå‡ç«‹ä½“åŒ–å­¦æ„ŸçŸ¥ã€‚  </li>
<li><strong>åŸºå‡†æµ‹è¯•</strong>ï¼šéœ€ç»Ÿä¸€è¯„ä¼°åè®®ï¼ˆå¦‚å›ºå®šæ•°æ®é›†å’ŒæŒ‡æ ‡ï¼‰ä»¥å…¬å¹³æ¯”è¾ƒGNNä¸å…¶ä»–æ–¹æ³•ã€‚</li>
</ul>
<p><del>ä¹‹ååº”è¯¥ä¼šå†™ä¸€äº›å…·ä½“æ¨¡å‹çš„åšå®¢ï¼Œæœ‰ç›¸å…³çš„ä¼šç›´æ¥ä¸Šé“¾æ¥çš„æjrm</del></p>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/1609.02907v4.pdf" target="_blank">ğŸ“„ Thomas - SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a><br><a href="https://pytorch-geometric.readthedocs.io/" target="_blank">PyTorch Geometric å®˜æ–¹æ–‡æ¡£</a><br><a href="https://distill.pub/2021/gnn-intro/" target="_blank">Distill: A Gentle Introduction to Graph Neural Networks</a><br><a href="https://distill.pub/2021/understanding-gnns/" target="_blank">Distill: Understanding Convolutions on Graphs</a><br><a href="https://www.zhihu.com/tardis/zm/art/107162772" target="_blank">çŸ¥ä¹ï¼šå›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å…¥é—¨è¯¦è§£</a><br><a href="https://github.com/tkipf/gcn" target="_blank">GCN è®ºæ–‡å®˜æ–¹ä»£ç ï¼ˆGitHubï¼‰</a></p>
]]></content>
      <categories>
        <category>CDR</category>
        <category>model</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>embedding</tag>
        <tag>PyTorch</tag>
        <tag>graph theory</tag>
      </tags>
  </entry>
  <entry>
    <title>Attention Overview</title>
    <url>/2025/07/10/Attention/</url>
    <content><![CDATA[<h1 id="Is-Attention-All-My-Need"><a href="#Is-Attention-All-My-Need" class="headerlink" title="Is Attention All My Need ?"></a>Is Attention All My Need ?</h1><blockquote>
<p>æ³¨æ„åŠ›æœºåˆ¶åœ¨å›¾ç¥ç»ç½‘ç»œä¸­æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ã€‚<del>ä½†é¼ é¼ ç°åœ¨è¿æ­£å¸¸çš„Attentionæœ‰å“ªäº›éƒ½ä¸æ¸…æ¥šæ</del>æœ¬æ–‡é¼ é¼ å°†ä»ä¸€èˆ¬çš„Attentionå‡ºå‘ï¼Œç»™å‡ºAttentionçš„æ€»ä½“ç»“æ„ï¼Œç„¶åæŒ‰åˆ†ç±»ä»‹ç»ç°æœ‰çš„ä¸»è¦çš„Attention</p>
</blockquote>
<p>æœ¬æ–‡ä¸»è¦æ¥è‡ªäºä¸€ç¯‡è®ºæ–‡ï¼ŒåŸºæœ¬å¯ä»¥çœ‹ä½œ<a href="/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf">é‚£ç¯‡è®ºæ–‡</a>çš„é˜…è¯»ç¬”è®°</p>
<span id="more"></span>

<h2 id="ğŸ¯-å¼•è¨€"><a href="#ğŸ¯-å¼•è¨€" class="headerlink" title="ğŸ¯ å¼•è¨€"></a>ğŸ¯ å¼•è¨€</h2><p>åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œæ³¨æ„åŠ›æœºåˆ¶å·²ç»æˆä¸ºä¸€ä¸ªé©å‘½æ€§çš„åˆ›æ–°ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†åºåˆ—æ•°æ®å’Œå›¾åƒæ•°æ®æ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚è€Œåœ¨å›¾ç¥ç»ç½‘ç»œä¸­ï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥ä¸ä»…æé«˜äº†æ¨¡å‹çš„è¡¨ç°åŠ›ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚</p>
<p>åœ¨å›¾ç»“æ„æ•°æ®ä¸­åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¸»è¦æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š</p>
<ol>
<li>è‡ªé€‚åº”æ€§ï¼šèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡åŠ¨æ€è°ƒæ•´ä¸åŒé‚»å±…èŠ‚ç‚¹çš„é‡è¦æ€§</li>
<li>å¯è§£é‡Šæ€§ï¼šé€šè¿‡æ³¨æ„åŠ›æƒé‡å¯ä»¥ç›´è§‚ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹</li>
<li>é•¿ç¨‹ä¾èµ–ï¼šæœ‰æ•ˆç¼“è§£äº†ä¼ ç»ŸGNNä¸­çš„è¿‡å¹³æ»‘é—®é¢˜</li>
<li>å¼‚è´¨æ€§å¤„ç†ï¼šæ›´å¥½åœ°å¤„ç†å¼‚è´¨å›¾ä¸­çš„ä¸åŒç±»å‹èŠ‚ç‚¹å’Œè¾¹</li>
</ol>
<h2 id="ğŸ“š-æ€»è§ˆAttention"><a href="#ğŸ“š-æ€»è§ˆAttention" class="headerlink" title="ğŸ“š æ€»è§ˆAttention"></a>ğŸ“š æ€»è§ˆAttention</h2><p>æœ¬ç« èŠ‚ä¸»è¦å‚è€ƒäº†è®ºæ–‡<a href="/paper/Brauwers%E5%92%8CFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf">ğŸ“„ Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a>æœ‰å…´è¶£çš„è¯å¯ä»¥çœ‹çœ‹åŸæ–‡æ</p>
<embed src="/paper/Brauwerså’ŒFrasincar%20-%202023%20-%20A%20General%20Survey%20on%20Attention%20Mechanisms%20in%20Deep%20Learning.pdf" width="45%" height="400" type="application/pdf">

<h3 id="Attentionçš„ä¸€èˆ¬ç»“æ„"><a href="#Attentionçš„ä¸€èˆ¬ç»“æ„" class="headerlink" title="Attentionçš„ä¸€èˆ¬ç»“æ„"></a>Attentionçš„ä¸€èˆ¬ç»“æ„</h3><img src="/img/Attention/TotalModel.png" alt="TotalModel" width="60%" height="auto">

<p>ä¸Šå›¾æ˜¯ä»æ€»ä½“ä¸Šçœ‹Attentionåœ¨æ•´ä¸ªä»»åŠ¡æ¨¡å‹æ¡†æ¶ä¸­çš„ä½ç½®</p>
<p>æ¡†æ¶åŒ…å«å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š</p>
<ol>
<li><strong>ç‰¹å¾æ¨¡å‹</strong>ï¼šè´Ÿè´£è¾“å…¥æ•°æ®çš„ç‰¹å¾æå–</li>
<li><strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼šç”Ÿæˆæ³¨æ„åŠ›æŸ¥è¯¢å‘é‡</li>
<li><strong>æ³¨æ„åŠ›æ¨¡å‹</strong>ï¼šè®¡ç®—æ³¨æ„åŠ›æƒé‡</li>
<li><strong>è¾“å‡ºæ¨¡å‹</strong>ï¼šç”Ÿæˆæœ€ç»ˆé¢„æµ‹ç»“æœ</li>
</ol>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¼šä» <em>è¾“å…¥</em> çš„è§’åº¦æ¥çœ‹<strong>ç‰¹å¾æ¨¡å‹</strong>å’Œ<strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼Œä» <em>è¾“å‡º</em> çš„è§’åº¦æ¥çœ‹<strong>æ³¨æ„åŠ›æ¨¡å‹</strong>å’Œ<strong>è¾“å‡ºæ¨¡å‹</strong></p>
<h4 id="è¾“å…¥å¤„ç†æœºåˆ¶"><a href="#è¾“å…¥å¤„ç†æœºåˆ¶" class="headerlink" title="è¾“å…¥å¤„ç†æœºåˆ¶"></a>è¾“å…¥å¤„ç†æœºåˆ¶</h4><ol>
<li><p><strong>ç‰¹å¾æ¨¡å‹</strong>ï¼Œå³å°†ä»»åŠ¡çš„è¾“å…¥è¿›è¡Œembedding</p>
<p> å¯¹äºè¾“å…¥çŸ©é˜µ$ X \in \mathbb{R}^{d_x \times n_x} $ï¼Œç‰¹å¾æ¨¡å‹æå–ç‰¹å¾å‘é‡ï¼š$\boldsymbol{F} &#x3D; [f_1, \ldots, f_{n_f}] \in \mathbb{R}^{d_f \times n_f}$</p>
</li>
<li><p><strong>æŸ¥è¯¢æ¨¡å‹</strong>ï¼ŒæŸ¥è¯¢æ¨¡å‹äº§ç”ŸæŸ¥è¯¢å‘é‡$ \boldsymbol{q} \in \mathbb{R}^{d_q} $ï¼Œç”¨ä»¥å‘Šè¯‰æ³¨æ„åŠ›æ¨¡å‹å“ªä¸€ä¸ªç‰¹å¾æ˜¯é‡è¦çš„</p>
</li>
</ol>
<p>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹å¯ä»¥ç”¨CNNæˆ–RNN</p>
<h4 id="è¾“å‡ºè®¡ç®—æœºåˆ¶"><a href="#è¾“å‡ºè®¡ç®—æœºåˆ¶" class="headerlink" title="è¾“å‡ºè®¡ç®—æœºåˆ¶"></a>è¾“å‡ºè®¡ç®—æœºåˆ¶</h4><img src="/img/Attention/GeneralAttentionModule.png" alt="GeneralAttentionModule" width="50%" height="auto">

<p>ä¸Šå›¾æ˜¯Attentionæ¨¡å‹æ€»ä½“ç»“æ„çš„è¯´æ˜ï¼Œä¸‹é¢å¯¹è¿™å¼ å›¾è¿›è¡Œè¯¦ç»†çš„è¯´æ˜</p>
<ol>
<li>ç‰¹å¾çŸ©é˜µ$\boldsymbol{F} &#x3D; [\boldsymbol{f}_1, \ldots, \boldsymbol{f}_{n_f}] \in \mathbb{R}^{d_f \times n_f}$ï¼Œé€šè¿‡<em>æŸäº›æ–¹æ³•</em>å°†å…¶åˆ†ä¸ºKeysçŸ©é˜µ$\boldsymbol{K} &#x3D; [\boldsymbol{k}_1, \ldots, \boldsymbol{k}_{n_f}] \in \mathbb{R}^{d_k \times n_f}$å’ŒValuesçŸ©é˜µ$\boldsymbol{V} &#x3D; [\boldsymbol{v}_1, \ldots, \boldsymbol{v}_{n_f}] \in \mathbb{R}^{d_v \times n_f}$ï¼Œè¿™é‡Œçš„<em>æŸäº›æ–¹æ³•</em>ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒæŒ‰ä»¥ä¸‹çš„æ–¹å¼é€šè¿‡<strong>çº¿æ€§å˜æ¢</strong>å¾—åˆ°ï¼š</li>
</ol>
<p>$$<br>\underset{d_{k} \times n_{f}}{\boldsymbol{K}}&#x3D;\underset{d_{k} \times d_{f}}{\boldsymbol{W}_{K}} \times \underset{d_{f} \times n_{f}}{\boldsymbol{F}}, \quad \underset{d_{v} \times n_{f}}{\boldsymbol{V}}&#x3D;\underset{d_{v} \times d_{f}}{\boldsymbol{W}_{V}} \times \underset{d_{f} \times n_{f}}{\boldsymbol{F}} .<br>$$</p>
<ol start="2">
<li><p><code>Attention Scores</code>æ¨¡å—æ ¹æ® $\boldsymbol{q}$ è®¡ç®—æ¯ä¸€ä¸ªkeyå‘é‡å¯¹åº”çš„åˆ†æ•°$\boldsymbol{e} &#x3D; [e_1, \ldots, e_{n_f}] \in \mathbb{R}^{n_f}$ï¼š</p>
<p> $$<br> \underset{1\times 1}{e_l} &#x3D; \text{score}(\underset{d_q \times 1}{\boldsymbol{q}}, \underset{d_k \times 1}{\boldsymbol{k}_l})<br> $$</p>
<p> å¦‚å‰æ‰€è¿°ï¼ŒæŸ¥è¯¢è±¡å¾ç€å¯¹ä¿¡æ¯çš„è¯·æ±‚ã€‚æ³¨æ„åŠ›åˆ†æ•°$e_l$è¡¨ç¤ºæ ¹æ®æŸ¥è¯¢ï¼Œå…³é”®å‘é‡$\boldsymbol{k}_l$ä¸­åŒ…å«çš„ä¿¡æ¯çš„é‡è¦æ€§ã€‚å¦‚æœæŸ¥è¯¢å’Œå…³é”®å‘é‡çš„ç»´åº¦ç›¸åŒï¼Œåˆ™å¾—åˆ†å‡½æ•°çš„ä¸€ä¸ªä¾‹å­æ˜¯å–å‘é‡çš„ç‚¹ç§¯ã€‚</p>
</li>
<li><p>ç”±äºç»è¿‡è¿™ä¹ˆä¸€å †æ“ä½œä¹‹åï¼Œåˆ†æ•°æœ‰å¾ˆå¤§çš„å¯èƒ½å·²ç»é£èµ·æ¥äº†æï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦<code>Attention Alignment</code>æ¨¡å—å¯¹å…¶è¿›è¡Œ<strong>å½’ä¸€åŒ–</strong>ä¹‹ç±»çš„æ“ä½œäº†æ</p>
<p> $$<br> \underset{1\times 1}{a_l} &#x3D; \text{align}(\underset{d_q \times 1}{\boldsymbol{e_l}}, \underset{n_f \times 1}{\boldsymbol{e}})<br> $$</p>
</li>
</ol>
<p>æ³¨æ„åŠ›æƒé‡$\boldsymbol{a} &#x3D; [a_1, \ldots, a_{n_f}] \in \mathbb{R}^{n_f}$ä¸ºæ³¨æ„åŠ›æ¨¡å—æä¾›äº†ä¸€ä¸ªç›¸å½“ç›´è§‚çš„è§£é‡Šã€‚æ¯ä¸ªæƒé‡ç›´æ¥è¡¨æ˜äº†æ¯ä¸ªç‰¹å¾å‘é‡ç›¸å¯¹äºå…¶ä»–ç‰¹å¾å‘é‡å¯¹äºè¿™ä¸ªé—®é¢˜çš„é‡è¦æ€§ã€‚ </p>
<ol start="4">
<li><p>åœ¨<code>Weight Average</code>æ¨¡å—å®Œæˆ<strong>ä¸Šä¸‹æ–‡ç”Ÿæˆ</strong>ï¼š</p>
<p> $$<br> \underset{d_v \times 1}{\boldsymbol{c}} &#x3D; \sum_{l &#x3D; 1}^{n_f} \underset{1 \times 1}{a_l}\times \underset{d_v \times 1}{\boldsymbol{v}_l}<br> $$</p>
</li>
<li><p>è¾“å‡ºå¤„ç†å°±æƒ³æ€ä¹ˆæå°±æ€ä¹ˆæäº†æï¼Œä¾‹å¦‚ ç”¨äºåˆ†ç±»</p>
<p> $$<br> \underset{d_y \times 1}{\hat{\boldsymbol{y}}} &#x3D; \text{softmax}( \underset{d_y \times d_v}{\boldsymbol{W}_c}\times \underset{d_v \times 1}{\boldsymbol{c}} + \underset{d_y \times 1}{\boldsymbol{b}_c})<br> $$</p>
</li>
</ol>
<h3 id="Attentionåˆ†ç±»"><a href="#Attentionåˆ†ç±»" class="headerlink" title="Attentionåˆ†ç±»"></a>Attentionåˆ†ç±»</h3><img src="/img/Attention/Taxonomy.png" style="max-width: 100%; height: auto;">

<p>è®ºæ–‡æŒ‰ç…§ä¸Šå›¾çš„æ–¹å¼ç»™Attentionè¿›è¡Œäº†åˆ†ç±»</p>
<p>ç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¿™é‡Œå†³å®šé‡å¼€å‡ ä¸ªåšæ–‡æ¥åˆ†åˆ«ä»‹ç»è¿™äº›Attentionï¼Œé“¾æ¥å¦‚ä¸‹ï¼š</p>
<a href="/2025/07/14/Feature-Related-Attention/" title="Feature-Related Attention">Feature-Related Attention</a>





<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning.pdf" target="_blank">ğŸ“„ Brauwerså’ŒFrasincar - 2023 - A General Survey on Attention Mechanisms in Deep Learning</a></p>
]]></content>
      <categories>
        <category>CDR</category>
        <category>model</category>
        <category>attention</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>model</tag>
        <tag>Basic</tag>
        <tag>deep learning</tag>
        <tag>è¿˜æ²¡å†™å®Œæ</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PEP 8</title>
    <url>/2025/07/08/PEP-8/</url>
    <content><![CDATA[<h1 id="Style-Guide-for-Python-Code"><a href="#Style-Guide-for-Python-Code" class="headerlink" title="Style Guide for Python Code"></a>Style Guide for Python Code</h1><blockquote>
<p><a href="https://peps.python.org/pep-0008/">PEP8</a> æ˜¯ Python ç¤¾ç¾¤å…±é€šçš„é¢¨æ ¼æŒ‡å—ï¼Œä¸€é–‹å§‹æ˜¯ Python ä¹‹çˆ¶ Guido van Rossum è‡ªå·±çš„æ’°ç¢¼é¢¨æ ¼ï¼Œæ…¢æ…¢å¾Œä¾†æ¼”è®Šè‡³ä»Šï¼Œç›®çš„åœ¨æ–¼å¹«åŠ©é–‹ç™¼è€…å¯«å‡ºå¯è®€æ€§é«˜ä¸”é¢¨æ ¼ä¸€è‡´çš„ç¨‹å¼ã€‚è¨±å¤šé–‹æºè¨ˆç•«ï¼Œä¾‹å¦‚ Django ã€ OpenStack ç­‰éƒ½æ˜¯ä»¥ PEP8 ç‚ºåŸºç¤å†åŠ ä¸Šè‡ªå·±çš„é¢¨æ ¼å»ºè­°ã€‚</p>
</blockquote>
<p>è¿™ç¯‡åšå®¢ä¸»è¦æ˜¯ä¸ºäº†åœ¨æ­å»ºè‡ªå·±çš„æ¨¡å‹ä¹‹å‰å­¦ä¹ ä¸€ä¸‹ä¸€äº›ç»Ÿä¸€çš„è§„èŒƒæ˜¯åšçš„è®°å½• <del>ä¸»è¦æ˜¯ç›®å‰è¯»åˆ°çš„å¤§å¤šæ•°è®ºæ–‡çš„æºç ç›®å‘½åæ²¡æœ‰è§„å¾‹</del> ï¼Œä»¥åŠ å¼ºä¹‹åæ­å»ºæ¨¡å‹æ—¶ä»£ç çš„å¯è¯»æ€§</p>
<p>å¦å¤–ï¼Œæœ¬åšå®¢åªå±•ç¤ºæœ¬äººä¸å¤ªç†Ÿæ‚‰çš„æ</p>
<span id="more"></span>

<h2 id="ä»£ç å¸ƒå±€"><a href="#ä»£ç å¸ƒå±€" class="headerlink" title="ä»£ç å¸ƒå±€"></a>ä»£ç å¸ƒå±€</h2><h3 id="ç¼©è¿›"><a href="#ç¼©è¿›" class="headerlink" title="ç¼©è¿›"></a>ç¼©è¿›</h3><p><strong>æ¯ä¸ªç¼©è¿›çº§åˆ«ä½¿ç”¨ 4 ä¸ªç©ºæ ¼</strong></p>
<p>å¯¹äºæ¯”è¾ƒè‡­é•¿çš„å‡½æ•°ï¼Œå¯ä»¥ä½¿ç”¨<em>æ‚¬æŒ‚ç¼©è¿›</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Correct:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Aligned with opening delimiter.</span></span><br><span class="line">foo = long_function_name(var_one, var_two,</span><br><span class="line">                         var_three, var_four)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add 4 spaces (an extra level of indentation) to distinguish arguments from the rest.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">long_function_name</span>(<span class="params"></span></span><br><span class="line"><span class="params">        var_one, var_two, var_three,</span></span><br><span class="line"><span class="params">        var_four</span>):</span><br><span class="line">    <span class="built_in">print</span>(var_one)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hanging indents should add a level.</span></span><br><span class="line">foo = long_function_name(</span><br><span class="line">    var_one, var_two,</span><br><span class="line">    var_three, var_four)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Wrong:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Arguments on first line forbidden when not using vertical alignment.</span></span><br><span class="line">foo = long_function_name(var_one, var_two,</span><br><span class="line">    var_three, var_four)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Further indentation required as indentation is not distinguishable.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">long_function_name</span>(<span class="params"></span></span><br><span class="line"><span class="params">    var_one, var_two, var_three,</span></span><br><span class="line"><span class="params">    var_four</span>):</span><br><span class="line">    <span class="built_in">print</span>(var_one)</span><br></pre></td></tr></table></figure>

<p>ä¼˜å…ˆä½¿ç”¨ <em>Tabs</em> è¿›è¡Œç¼©è¿›ï¼Œ <em>Tabs</em> å’Œ <em>Spaces</em> ä¸èƒ½æ··ç”¨</p>
<h3 id="æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡"><a href="#æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡" class="headerlink" title="æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡"></a>æ¯è¡Œæœ€å¤šå­—ç¬¦æ•°é‡</h3><p><strong>79</strong> ä¸ª</p>
<p>åˆç†ä½¿ç”¨åæ–œæ </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;/path/to/some/file/you/want/to/read&#x27;</span>) <span class="keyword">as</span> file_1, \</span><br><span class="line">     <span class="built_in">open</span>(<span class="string">&#x27;/path/to/some/file/being/written&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file_2:</span><br><span class="line">    file_2.write(file_1.read())</span><br></pre></td></tr></table></figure>

<h3 id="äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ"><a href="#äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ" class="headerlink" title="äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ"></a>äºŒå…ƒè¿ç®—ç¬¦ä¹‹å‰æ¢è¡Œ</h3><p>ä¸ºäº†æ›´å¥½çš„ç¡®å®šè¯¥ <code>item</code> é‡‡å–çš„æ˜¯ä»€ä¹ˆè¿ç®—</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Wrong:</span></span><br><span class="line"><span class="comment"># operators sit far away from their operands</span></span><br><span class="line">income = (gross_wages +</span><br><span class="line">          taxable_interest +</span><br><span class="line">          (dividends - qualified_dividends) -</span><br><span class="line">          ira_deduction -</span><br><span class="line">          student_loan_interest)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Correct:</span></span><br><span class="line"><span class="comment"># easy to match operators with operands</span></span><br><span class="line">income = (gross_wages</span><br><span class="line">          + taxable_interest</span><br><span class="line">          + (dividends - qualified_dividends)</span><br><span class="line">          - ira_deduction</span><br><span class="line">          - student_loan_interest)</span><br></pre></td></tr></table></figure>

<h3 id="å¦‚ä½•ç©ºè¡Œï¼ˆBlank-Linesï¼‰"><a href="#å¦‚ä½•ç©ºè¡Œï¼ˆBlank-Linesï¼‰" class="headerlink" title="å¦‚ä½•ç©ºè¡Œï¼ˆBlank Linesï¼‰"></a>å¦‚ä½•ç©ºè¡Œï¼ˆBlank Linesï¼‰</h3><p><em>é¡¶çº§å‡½æ•°</em> å’Œ <em>ç±»</em> ä¹‹é—´ç©º <strong>2</strong> è¡Œ</p>
<p><em>ç±»ä¸­çš„å‡½æ•°</em> ç©º <strong>1</strong> è¡Œ</p>
<h3 id="import"><a href="#import" class="headerlink" title="import"></a>import</h3><ul>
<li>é€šå¸¸æ¯ä¸€ä¸ªåº“ <strong>å•ç‹¬ä¸€è¡Œ</strong>ï¼ˆä¹Ÿæœ‰ä¾‹å¤–ï¼‰</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> subprocess <span class="keyword">import</span> Popen, PIPE</span><br></pre></td></tr></table></figure>

<ul>
<li>æŒ‰ä»¥ä¸‹é¡ºåºåˆ†ç»„ï¼Œæ¯ç»„é—´ç©ºè¡Œ<ol>
<li><strong>æ ‡å‡†åº“</strong>å¯¼å…¥</li>
<li><strong>ç›¸å…³ç¬¬ä¸‰æ–¹åº“</strong>å¯¼å…¥</li>
<li><strong>ç‰¹å®šçš„æœ¬åœ°åº“</strong>å¯¼å…¥</li>
</ol>
</li>
</ul>
<h2 id="æ³¨é‡Š"><a href="#æ³¨é‡Š" class="headerlink" title="æ³¨é‡Š"></a>æ³¨é‡Š</h2><blockquote>
<p>Comments that contradict the code are worse than no comments.</p>
</blockquote>
<h2 id="å‘½åçº¦å®š"><a href="#å‘½åçº¦å®š" class="headerlink" title="å‘½åçº¦å®š"></a>å‘½åçº¦å®š</h2><ol>
<li><p><strong>ç±»å</strong> ç”¨ <strong>å¤§é©¼å³°</strong></p>
</li>
<li><p><strong>å‡½æ•°å</strong> ç”¨ <strong>å°å†™ä¸‹åˆ’çº¿</strong></p>
</li>
<li><p>å…³äº <em>ä¸‹åˆ’çº¿</em></p>
<ul>
<li><em>å•ä¸‹åˆ’çº¿</em> ç”¨äºå ä½</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(random.randint(<span class="number">1</span>, <span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><em>å•ä¸‹åˆ’çº¿</em> ç”¨äºå˜é‡å‰è¡¨ç¤ºè¯¥å˜é‡ä¸º <strong>å¼±ç§æœ‰</strong> ï¼ˆè¯­ä¹‰ä¸Šçš„ privateï¼‰ï¼Œèƒ½è°ƒç”¨ä½†ä¸èƒ½ import</li>
<li><em>åŒä¸‹åˆ’çº¿</em> ç”¨äºå˜é‡å‰è¡¨ç¤ºè¯¥å˜é‡ä¸º <strong>å¼ºç§æœ‰</strong> ï¼ˆå®é™…ä¸Šä¹Ÿä¸èƒ½è°ƒç”¨<del>å®ç°æ–¹å¼æ˜¯é‡åå</del>ï¼‰<br>ä¸ºäº†æ›´å¥½çš„è¯´æ˜è¿™ä¸¤ç‚¹ï¼Œç»™å‡ºä»¥ä¸‹ä¸¤ä¸ªæµ‹è¯•ç¨‹åº</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">test_private_vars.py</span></span><br><span class="line"><span class="string">This file is used to test the private variables in Python.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestClass</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.public_var = <span class="string">&quot;è¿™æ˜¯å…¬æœ‰å˜é‡&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>._weak_private = <span class="string">&quot;è¿™æ˜¯å¼±ç§æœ‰å˜é‡&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.__strong_private = <span class="string">&quot;è¿™æ˜¯å¼ºç§æœ‰å˜é‡&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_all_vars</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ä»å†…éƒ¨è®¿é—®:&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å…¬æœ‰å˜é‡: <span class="subst">&#123;self.public_var&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;self._weak_private&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;self.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºæµ‹è¯•å®ä¾‹</span></span><br><span class="line">test = TestClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. æµ‹è¯•ä»ç±»å†…éƒ¨è®¿é—®ï¼ˆé€šè¿‡æ–¹æ³•ï¼‰</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===&quot;</span>)</span><br><span class="line">test.print_all_vars()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. æµ‹è¯•ä»å¤–éƒ¨ç›´æ¥è®¿é—®</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å…¬æœ‰å˜é‡: <span class="subst">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;test._weak_private&#125;</span>&quot;</span>)  <span class="comment"># èƒ½è®¿é—®ï¼Œä½†IDEä¼šè­¦å‘Š</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. æµ‹è¯•åç§°æ”¹å†™æœºåˆ¶</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===&quot;</span>)</span><br><span class="line"><span class="comment"># å®é™…ä¸ŠPythonä¼šå°†__strong_privateæ”¹å†™ä¸º_TestClass__strong_private</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. æµ‹è¯•å¯¼å…¥è¡Œä¸º</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== æµ‹è¯•4: åˆ›å»ºç¬¬äºŒä¸ªæ–‡ä»¶å¹¶å°è¯•å¯¼å…¥ ===&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;è¯·åˆ›å»º test_import.py å¹¶è¿è¡Œæ¥æµ‹è¯•å¯¼å…¥è¡Œä¸º&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">test_import.py</span></span><br><span class="line"><span class="string">This file is used to test the import of private variables in Python.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> test_private_vars <span class="keyword">import</span> TestClass</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=== æµ‹è¯•å¯¼å…¥åçš„è®¿é—®è¡Œä¸º ===&quot;</span>)</span><br><span class="line">test = TestClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å…¬æœ‰å˜é‡</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å…¬æœ‰å˜é‡: <span class="subst">&#123;test.public_var&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å¼±ç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡: <span class="subst">&#123;test._weak_private&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;æ³¨æ„ï¼šè™½ç„¶èƒ½è®¿é—®å¼±ç§æœ‰å˜é‡ï¼Œä½†è¿™è¿åäº†Pythonçš„çº¦å®š&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼±ç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•è®¿é—®å¼ºç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test.__strong_private&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æµ‹è¯•é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: <span class="subst">&#123;test._TestClass__strong_private&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;æ³¨æ„ï¼šè™½ç„¶èƒ½é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªä¸æ¨èçš„åšæ³•&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;é€šè¿‡æ”¹å†™åç§°è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>ä»¥ä¸‹æ˜¯è¿è¡Œ <code>python test_private_vars.py</code> çš„ç»“æœ</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===</span><br><span class="line">ä»å†…éƒ¨è®¿é—®:</span><br><span class="line">å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===</span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•4: åˆ›å»ºç¬¬äºŒä¸ªæ–‡ä»¶å¹¶å°è¯•å¯¼å…¥ ===</span><br><span class="line">è¯·åˆ›å»º test_import.py å¹¶è¿è¡Œæ¥æµ‹è¯•å¯¼å…¥è¡Œä¸º</span><br></pre></td></tr></table></figure>

<p>ä»¥ä¸‹æ˜¯è¿è¡Œ <code>python test_import.py</code> çš„ç»“æœ</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">=== æµ‹è¯•1: ä»ç±»å†…éƒ¨è®¿é—®æ‰€æœ‰å˜é‡ ===</span><br><span class="line">ä»å†…éƒ¨è®¿é—®:</span><br><span class="line">å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•2: ä»å¤–éƒ¨è®¿é—®å˜é‡ ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line"></span><br><span class="line">=== æµ‹è¯•3: éªŒè¯å¼ºç§æœ‰å˜é‡çš„åç§°æ”¹å†™æœºåˆ¶ ===</span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line">=== æµ‹è¯•å¯¼å…¥åçš„è®¿é—®è¡Œä¸º ===</span><br><span class="line">è®¿é—®å…¬æœ‰å˜é‡: è¿™æ˜¯å…¬æœ‰å˜é‡</span><br><span class="line">è®¿é—®å¼±ç§æœ‰å˜é‡: è¿™æ˜¯å¼±ç§æœ‰å˜é‡</span><br><span class="line">æ³¨æ„ï¼šè™½ç„¶èƒ½è®¿é—®å¼±ç§æœ‰å˜é‡ï¼Œä½†è¿™è¿åäº†Pythonçš„çº¦å®š</span><br><span class="line">è®¿é—®å¼ºç§æœ‰å˜é‡å¤±è´¥: <span class="string">&#x27;TestClass&#x27;</span> object has no attribute <span class="string">&#x27;__strong_private&#x27;</span></span><br><span class="line">é€šè¿‡æ”¹å†™åçš„åç§°è®¿é—®å¼ºç§æœ‰å˜é‡: è¿™æ˜¯å¼ºç§æœ‰å˜é‡</span><br><span class="line">æ³¨æ„ï¼šè™½ç„¶èƒ½é€šè¿‡åç§°æ”¹å†™è®¿é—®å¼ºç§æœ‰å˜é‡ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªä¸æ¨èçš„åšæ³•</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>Python</tag>
        <tag>PEP</tag>
        <tag>é—²ğŸ‰æ— èŠ</tag>
        <tag>å¤§æ¦‚ç‡æ²¡ç”¨</tag>
      </tags>
  </entry>
  <entry>
    <title>hwadee</title>
    <url>/2025/07/13/hwadee/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>å…ˆæ”¾åœ¨è¿™é‡Œï¼Œæ‡’å¾—å–·ï¼Œä»¥ä¸‹æ˜¯é¼ é¼ å’Œå®¤å‹åœ¨äº‰è®ºæŸé—®é¢˜æ—¶é—®çš„AI</p>
<span id="more"></span>

<h1 id="ç”²é†›æœ‰æ°”å‘³å—"><a href="#ç”²é†›æœ‰æ°”å‘³å—" class="headerlink" title="ç”²é†›æœ‰æ°”å‘³å—"></a>ç”²é†›æœ‰æ°”å‘³å—</h1><p>Qus:<br>ç”²é†›æœ‰æ°”å‘³å—<br>Ans:</p>
<ul>
<li>å¼•ç”¨ 7 ç¯‡èµ„æ–™ä½œä¸ºå‚è€ƒ<ol>
<li><a href="https://baike.baidu.com/item/%E7%94%B2%E9%86%9B/167033?fr=aladdin">ç”²é†›ï¼ˆæœ‰æœºåŒ–åˆç‰©ï¼‰_ç™¾åº¦ç™¾ç§‘</a></li>
<li><a href="http://baike.baidu.com/item/%E6%B0%B4%E9%93%B6/572967?fromModule=lemma_inlink">æ±ï¼ˆæ˜¯å¸¸æ¸©å¸¸å‹ä¸‹å”¯ä¸€ä»¥æ¶²æ€å­˜åœ¨çš„é‡‘å±ï¼‰_ç™¾åº¦ç™¾ç§‘</a></li>
<li><a href="https://www.cndzys.com/ylcore/wendanew_info/11es473224.html">ã€ç”²é†›æœ‰å‘³å—ã€‘_å¾ä¿¡ç¾¤_ä¸»ä»»åŒ»å¸ˆ - å¤§ä¼—å…»ç”Ÿç½‘</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA4ODA4MjY4MA==&mid=2650899715&idx=2&sn=19f245dad403038c8fcbd5cc242b82c6&chksm=8a413842f16d27e52c9809f4dc290c194d4bdd131d46559db9eb9591a59757398eea9bb2a724#rd">è£…ä¿®å®Œçš„æ–°å®¶é—»ä¸è§å‘³å„¿ï¼Œå°±æ˜¯æ²¡ç”²é†›äº†ï¼Ÿ</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzA5MDY2NTMzNg==&mid=2676835975&idx=3&sn=f0b45599c2c3427a8824a0f99159cc71&chksm=8bbb6131ad4acdd4f1b70ed654da5089241c06a940b56adc749d86160352f04e1d9f6b41e620#rd">ç”²é†›æœ‰å‘³é“å—ï¼Œç”²é†›çš„æ°”å‘³åƒä»€ä¹ˆï¼Ÿ</a></li>
<li><a href="https://m.youlai.cn/sjingbian/article/5B3495gV5qk.html">ç”²é†›æœ‰å‘³è¿˜æ˜¯æ— å‘³-æœ‰æ¥åŒ»ç”Ÿ</a></li>
<li><a href="https://m.jia.com/zixun/article/1144566.html">è£…ä¿®çš„å‘³é“æ˜¯ç”²é†›å—_é½å®¶ç½‘</a><br>ç”²é†›çš„æ°”å‘³ç‰¹æ€§ä¸å…¶æµ“åº¦å¯†åˆ‡ç›¸å…³ï¼Œå…·ä½“è¡¨ç°å¦‚ä¸‹ï¼š</li>
</ol>
</li>
</ul>
<h3 id="1-ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³"><a href="#1-ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³" class="headerlink" title="1. ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³"></a>1. ä½æµ“åº¦æ—¶é€šå¸¸æ— å‘³</h3><ul>
<li>ç”²é†›åœ¨æä½æµ“åº¦ï¼ˆå¦‚ä½äº0.08æ¯«å…‹&#x2F;ç«‹æ–¹ç±³ï¼‰æ—¶ï¼Œæ˜¯ä¸€ç§æ— è‰²æ— å‘³çš„æ°”ä½“ï¼Œéš¾ä»¥é€šè¿‡å—…è§‰ç›´æ¥å¯Ÿè§‰ã€‚</li>
<li>è®¸å¤šäººè¯¯ä»¥ä¸ºâ€œæ²¡å‘³é“&#x3D;æ²¡ç”²é†›â€ï¼Œä½†å®é™…ä¸Šä½æµ“åº¦ç”²é†›å¯èƒ½ä»ç„¶å­˜åœ¨ï¼Œåªæ˜¯ä¸æ˜“è¢«é—»åˆ°ã€‚</li>
</ul>
<h3 id="2-é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³"><a href="#2-é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³" class="headerlink" title="2. é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³"></a>2. é«˜æµ“åº¦æ—¶æœ‰å¼ºçƒˆåˆºæ¿€æ€§æ°”å‘³</h3><ul>
<li>å½“ç”²é†›æµ“åº¦è¶…è¿‡0.1æ¯«å…‹&#x2F;ç«‹æ–¹ç±³æ—¶ï¼Œä¼šä¸ç©ºæ°”ä¸­çš„æ°´ã€æ°§æ°”ååº”ï¼Œç”Ÿæˆå…·æœ‰åˆºé¼»æ°”å‘³çš„åŒ–åˆç‰©ï¼Œå¸¸è¢«æè¿°ä¸ºï¼š<ul>
<li>ç±»ä¼¼ç‡ƒçƒ§å¡‘æ–™æˆ–åŒ–å­¦è¯å“çš„å‘³é“ï¼›</li>
<li>é”¯æœ¨å±‘æ··åˆé…¸å‘³ï¼ˆå®¶å…·ä¸­ç”²é†›ï¼‰ï¼›</li>
<li>æ±½æ²¹å‘³æˆ–çƒ§ç„¦å¡‘æ–™å‘³ï¼ˆå¸ƒæ–™ã€çª—å¸˜ä¸­ç”²é†›ï¼‰ï¼›</li>
<li>éƒ¨åˆ†äººå¯èƒ½æ„ŸçŸ¥åˆ°æ·¡æ·¡çš„ç”œå‘³ï¼Œä½†ä¸»è¦ä»æ˜¯åˆºæ¿€æ€§ã€‚</li>
</ul>
</li>
</ul>
<h3 id="3-ä¸ªä½“å·®å¼‚æ˜¾è‘—"><a href="#3-ä¸ªä½“å·®å¼‚æ˜¾è‘—" class="headerlink" title="3. ä¸ªä½“å·®å¼‚æ˜¾è‘—"></a>3. ä¸ªä½“å·®å¼‚æ˜¾è‘—</h3><ul>
<li>ä¸åŒäººå¯¹ç”²é†›æ°”å‘³çš„æ•æ„Ÿåº¦å·®å¼‚è¾ƒå¤§ï¼Œæœ‰äº›äººå¯èƒ½åœ¨è¾ƒä½æµ“åº¦å°±èƒ½å¯Ÿè§‰ï¼Œè€Œå¦ä¸€äº›äººéœ€è¦æ›´é«˜æµ“åº¦æ‰ä¼šæ„Ÿåˆ°ä¸é€‚ã€‚</li>
</ul>
<h3 id="4-ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«"><a href="#4-ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«" class="headerlink" title="4. ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«"></a>4. ä¸å…¶ä»–è£…ä¿®æ°”å‘³çš„åŒºåˆ«</h3><ul>
<li>è£…ä¿®åçš„åˆºé¼»æ°”å‘³å¸¸è¢«è¯¯è®¤ä¸ºå…¨æ˜¯ç”²é†›ï¼Œä½†å®é™…ä¸Šå¯èƒ½æ··åˆäº†**è‹¯ç³»ç‰©ï¼ˆæ²¹æ¼†å‘³ï¼‰ã€æ°¨æ°”ï¼ˆå•æ‰€å‘³ï¼‰ã€TVOCï¼ˆåŒ–å­¦æº¶å‰‚å‘³ï¼‰**ç­‰ã€‚</li>
<li>ç”²é†›çš„åˆºæ¿€æ€§æ›´åå‘é»è†œååº”ï¼ˆå¦‚çœ¼ç—’ã€å–‰å’™ç—›ï¼‰ï¼Œè€Œè‹¯ç³»ç‰©ç­‰å¯èƒ½å¸¦æœ‰æ›´æ˜æ˜¾çš„â€œåŒ–å­¦é¦™å‘³â€ã€‚</li>
</ul>
<h3 id="5-æ³¨æ„äº‹é¡¹"><a href="#5-æ³¨æ„äº‹é¡¹" class="headerlink" title="5. æ³¨æ„äº‹é¡¹"></a>5. æ³¨æ„äº‹é¡¹</h3><ul>
<li>ä¸èƒ½ä¾èµ–å—…è§‰åˆ¤æ–­ç”²é†›å®‰å…¨æ€§ï¼šå³ä½¿é—»ä¸åˆ°ï¼Œç”²é†›ä»å¯èƒ½è¶…æ ‡ï¼ˆå°¤å…¶æ¥è‡ªäººé€ æ¿æçš„é•¿æœŸé‡Šæ”¾ï¼‰ã€‚</li>
<li>ç§‘å­¦æ£€æµ‹æ›´å¯é ï¼šå®¶ç”¨æ£€æµ‹ä»ªæ˜“å—ç¯å¢ƒå¹²æ‰°ï¼Œå»ºè®®é€šè¿‡ä¸“ä¸šæœºæ„æ£€æµ‹ã€‚<br>æ€»ç»“ï¼šç”²é†›åœ¨ä½æµ“åº¦ä¸‹æ— å‘³ï¼Œé«˜æµ“åº¦æ—¶å‘ˆç°åˆºé¼»æ°”å‘³ï¼Œä½†æ°”å‘³å¹¶éåˆ¤æ–­å…¶å­˜åœ¨çš„å”¯ä¸€æ ‡å‡†ï¼Œéœ€ç»“åˆä¸“ä¸šæ£€æµ‹å’Œé€šé£æªæ–½ä¿éšœå¥åº·ã€‚</li>
</ul>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1>]]></content>
  </entry>
  <entry>
    <title>GAT</title>
    <url>/2025/07/14/GAT/</url>
    <content><![CDATA[<h1 id=""><a href="#" class="headerlink" title=""></a></h1><span id="more"></span>

<h3 id="å›¾æ³¨æ„åŠ›æœºåˆ¶"><a href="#å›¾æ³¨æ„åŠ›æœºåˆ¶" class="headerlink" title="å›¾æ³¨æ„åŠ›æœºåˆ¶"></a>å›¾æ³¨æ„åŠ›æœºåˆ¶</h3><h4 id="GATï¼ˆGraph-Attention-Networksï¼‰"><a href="#GATï¼ˆGraph-Attention-Networksï¼‰" class="headerlink" title="GATï¼ˆGraph Attention Networksï¼‰"></a>GATï¼ˆGraph Attention Networksï¼‰</h4><p>GATé€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ æƒé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾ã€‚å¯¹äºèŠ‚ç‚¹iï¼Œå…¶æ›´æ–°å…¬å¼ä¸ºï¼š</p>
<p>$$h_i^{(l+1)} &#x3D; \sigma(\sum_{j \in \mathcal{N}_i} \alpha_{ij}W^{(l)}h_j^{(l)})$$</p>
<p>å…¶ä¸­æ³¨æ„åŠ›ç³»æ•°$\alpha_{ij}$çš„è®¡ç®—ï¼š</p>
<p>$$\alpha_{ij} &#x3D; \frac{exp(LeakyReLU(a^T[Wh_i || Wh_j]))}{\sum_{k \in \mathcal{N}_i} exp(LeakyReLU(a^T[Wh_i || Wh_k]))}$$</p>
<h4 id="å¤šå¤´æ³¨æ„åŠ›"><a href="#å¤šå¤´æ³¨æ„åŠ›" class="headerlink" title="å¤šå¤´æ³¨æ„åŠ›"></a>å¤šå¤´æ³¨æ„åŠ›</h4><p>ä¸ºäº†æé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œè¡¨è¾¾èƒ½åŠ›ï¼ŒGATä½¿ç”¨äº†å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
<p>$$h_i^{(l+1)} &#x3D; \sigma(\frac{1}{K} \sum_{k&#x3D;1}^K \sum_{j \in \mathcal{N}_i} \alpha_{ij}^k W^k h_j^{(l)})$$</p>
<h3 id="å˜ä½“ä¸æ‰©å±•"><a href="#å˜ä½“ä¸æ‰©å±•" class="headerlink" title="å˜ä½“ä¸æ‰©å±•"></a>å˜ä½“ä¸æ‰©å±•</h3><h4 id="è¾¹æ³¨æ„åŠ›"><a href="#è¾¹æ³¨æ„åŠ›" class="headerlink" title="è¾¹æ³¨æ„åŠ›"></a>è¾¹æ³¨æ„åŠ›</h4><p>é™¤äº†èŠ‚ç‚¹ä¹‹é—´çš„æ³¨æ„åŠ›ï¼Œä¸€äº›æ¨¡å‹è¿˜å¼•å…¥äº†è¾¹æ³¨æ„åŠ›æœºåˆ¶ï¼š</p>
<p>$$e_{ij} &#x3D; a^T[Wh_i || Wh_j || We_{ij}]$$</p>
<p>å…¶ä¸­$e_{ij}$æ˜¯è¾¹çš„ç‰¹å¾ã€‚</p>
<h4 id="å…¨å±€æ³¨æ„åŠ›"><a href="#å…¨å±€æ³¨æ„åŠ›" class="headerlink" title="å…¨å±€æ³¨æ„åŠ›"></a>å…¨å±€æ³¨æ„åŠ›</h4><p>é€šè¿‡å¼•å…¥å…¨å±€èŠ‚ç‚¹æˆ–æ± åŒ–æ“ä½œï¼Œå¯ä»¥å®ç°å…¨å±€æ³¨æ„åŠ›ï¼š</p>
<p>$$g &#x3D; \sum_{i \in V} \beta_i h_i$$</p>
<p>å…¶ä¸­$\beta_i$æ˜¯å…¨å±€æ³¨æ„åŠ›æƒé‡ã€‚</p>
<h2 id="ğŸ’»-å®ç°ç»†èŠ‚"><a href="#ğŸ’»-å®ç°ç»†èŠ‚" class="headerlink" title="ğŸ’» å®ç°ç»†èŠ‚"></a>ğŸ’» å®ç°ç»†èŠ‚</h2><h3 id="PyTorchå®ç°çš„GATå±‚"><a href="#PyTorchå®ç°çš„GATå±‚" class="headerlink" title="PyTorchå®ç°çš„GATå±‚"></a>PyTorchå®ç°çš„GATå±‚</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GATLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, out_features, dropout, alpha, concat=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GATLayer, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.in_features = in_features</span><br><span class="line">        <span class="variable language_">self</span>.out_features = out_features</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line">        <span class="variable language_">self</span>.alpha = alpha</span><br><span class="line">        <span class="variable language_">self</span>.concat = concat</span><br><span class="line"></span><br><span class="line">        <span class="comment"># å˜æ¢çŸ©é˜µ</span></span><br><span class="line">        <span class="variable language_">self</span>.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))</span><br><span class="line">        nn.init.xavier_uniform_(<span class="variable language_">self</span>.W.data, gain=<span class="number">1.414</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ³¨æ„åŠ›å‘é‡</span></span><br><span class="line">        <span class="variable language_">self</span>.a = nn.Parameter(torch.zeros(size=(<span class="number">2</span>*out_features, <span class="number">1</span>)))</span><br><span class="line">        nn.init.xavier_uniform_(<span class="variable language_">self</span>.a.data, gain=<span class="number">1.414</span>)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.leakyrelu = nn.LeakyReLU(<span class="variable language_">self</span>.alpha)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        <span class="comment"># x: èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ [N, in_features]</span></span><br><span class="line">        <span class="comment"># adj: é‚»æ¥çŸ©é˜µ [N, N]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># çº¿æ€§å˜æ¢</span></span><br><span class="line">        h = torch.mm(x, <span class="variable language_">self</span>.W)  <span class="comment"># [N, out_features]</span></span><br><span class="line">        N = h.size()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°</span></span><br><span class="line">        a_input = torch.cat([h.repeat(<span class="number">1</span>, N).view(N * N, -<span class="number">1</span>), h.repeat(N, <span class="number">1</span>)], dim=<span class="number">1</span>)</span><br><span class="line">        a_input = a_input.view(N, N, <span class="number">2</span> * <span class="variable language_">self</span>.out_features)</span><br><span class="line">        e = <span class="variable language_">self</span>.leakyrelu(torch.matmul(a_input, <span class="variable language_">self</span>.a).squeeze(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># æ©ç æœºåˆ¶</span></span><br><span class="line">        zero_vec = -<span class="number">9e15</span> * torch.ones_like(e)</span><br><span class="line">        attention = torch.where(adj &gt; <span class="number">0</span>, e, zero_vec)</span><br><span class="line">        attention = F.softmax(attention, dim=<span class="number">1</span>)</span><br><span class="line">        attention = F.dropout(attention, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># èšåˆç‰¹å¾</span></span><br><span class="line">        h_prime = torch.matmul(attention, h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.concat:</span><br><span class="line">            <span class="keyword">return</span> F.elu(h_prime)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> h_prime</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GAT</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nfeat, nhid, nclass, dropout, alpha, nheads</span>):</span><br><span class="line">        <span class="built_in">super</span>(GAT, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.dropout = dropout</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># å¤šå¤´æ³¨æ„åŠ›å±‚</span></span><br><span class="line">        <span class="variable language_">self</span>.attentions = nn.ModuleList([</span><br><span class="line">            GATLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=<span class="literal">True</span>) </span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(nheads)</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è¾“å‡ºå±‚</span></span><br><span class="line">        <span class="variable language_">self</span>.out_att = GATLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj</span>):</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        <span class="comment"># å¤šå¤´æ³¨æ„åŠ›</span></span><br><span class="line">        x = torch.cat([att(x, adj) <span class="keyword">for</span> att <span class="keyword">in</span> <span class="variable language_">self</span>.attentions], dim=<span class="number">1</span>)</span><br><span class="line">        x = F.dropout(x, <span class="variable language_">self</span>.dropout, training=<span class="variable language_">self</span>.training)</span><br><span class="line">        x = <span class="variable language_">self</span>.out_att(x, adj)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="å®é™…åº”ç”¨ç¤ºä¾‹"><a href="#å®é™…åº”ç”¨ç¤ºä¾‹" class="headerlink" title="å®é™…åº”ç”¨ç¤ºä¾‹"></a>å®é™…åº”ç”¨ç¤ºä¾‹</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># æ¨¡å‹åˆå§‹åŒ–</span></span><br><span class="line">model = GAT(nfeat=input_dim,</span><br><span class="line">           nhid=<span class="number">8</span>,</span><br><span class="line">           nclass=num_classes,</span><br><span class="line">           dropout=<span class="number">0.6</span>,</span><br><span class="line">           alpha=<span class="number">0.2</span>,</span><br><span class="line">           nheads=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.005</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®­ç»ƒå¾ªç¯</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    model.train()</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output = model(features, adj)</span><br><span class="line">    loss = F.nll_loss(output[idx_train], labels[idx_train])</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> loss.item()</span><br></pre></td></tr></table></figure>

<h2 id="ğŸ”-æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ"><a href="#ğŸ”-æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ" class="headerlink" title="ğŸ” æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ"></a>ğŸ” æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ</h2><h2 id="ğŸ“ˆ-æœªæ¥å±•æœ›"><a href="#ğŸ“ˆ-æœªæ¥å±•æœ›" class="headerlink" title="ğŸ“ˆ æœªæ¥å±•æœ›"></a>ğŸ“ˆ æœªæ¥å±•æœ›</h2><h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Lee ç­‰ - 2018 - Attention Models in Graphs A Survey.pdf" target="_blank">ğŸ“„ Lee ç­‰ - 2018 - Attention Models in Graphs A Survey</a><br><a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch" target="_blank">github: External-Attention-pytorch</a> </p>
]]></content>
  </entry>
  <entry>
    <title>CDR Input Data Analysis</title>
    <url>/2025/07/09/CDR-data-analysis/</url>
    <content><![CDATA[<h1 id="CDR-æ•°æ®æºåˆ†æ"><a href="#CDR-æ•°æ®æºåˆ†æ" class="headerlink" title="CDR æ•°æ®æºåˆ†æ"></a>CDR æ•°æ®æºåˆ†æ</h1><p>æœ¬æ–‡ä¸»è¦æ˜¯ä»‹ç»ä¸€ä¸‹ <strong>æ·±åº¦å­¦ä¹ </strong> åœ¨ <em>è¯ç‰©ååº”é¢„æµ‹</em> ä¸­è¿ç”¨åˆ°çš„æ•°æ®æºã€‚<del>ä½†ç”±äºæœ¬äººæ¯”è¾ƒæ</del> æœ¬æ–‡ä¸»è¦ä» <strong>æ·±åº¦å­¦ä¹ </strong> è§’åº¦æ¥çœ‹å¾…è¿™äº›æ•°æ®æºï¼Œå¯¹å…¶åœ¨åŒ»å­¦æ–¹é¢çš„æ„ä¹‰<del>ï¼ˆä¸»è¦æ˜¯é¼ é¼ ä¹Ÿä¸ä¼šæï¼‰</del>ä¸ä¼šæœ‰å¤ªå¤šçš„æè¿°</p>
<span id="more"></span>

<h2 id="CDR-Cancer-Drug-Response"><a href="#CDR-Cancer-Drug-Response" class="headerlink" title="CDR &#x3D; Cancer Drug Response"></a>CDR &#x3D; Cancer Drug Response</h2><p>æˆ‘ä»¬çš„æ•°æ®æºæœ‰ä¸‰ç§ï¼š</p>
<ul>
<li><em>Cancer Representations</em>ï¼ˆç™Œç—‡ç‰¹å¾çš„è¡¨ç¤ºï¼‰</li>
<li><em>Representations of Drug Compounds</em>ï¼ˆè¯ç‰©ç‰¹å¾çš„è¡¨ç¤ºï¼‰</li>
<li><em>Representations of Treatment Response</em>ï¼ˆæ²»ç–—å“åº”çš„è¡¨ç¤ºï¼‰</li>
</ul>
<p>æ¥ä¸‹æ¥ä¼šæŒ‰é¡ºåºè¿›è¡Œè¯´æ˜</p>
<hr>
<h3 id="Cancer-Representations"><a href="#Cancer-Representations" class="headerlink" title="Cancer Representations"></a>Cancer Representations</h3><p>ç™Œç—‡çš„ç‰¹å¾æ˜¯å¤šç»„å­¦çš„ <del>è¿™ä¸æ˜¯ç†æ‰€åº”å½“å—</del></p>
<h4 id="å¤šç»„å­¦ç±»å‹"><a href="#å¤šç»„å­¦ç±»å‹" class="headerlink" title="å¤šç»„å­¦ç±»å‹"></a>å¤šç»„å­¦ç±»å‹</h4><p>é€šå¸¸åŸºäºä»¥ä¸‹å››ç±»ç»„å­¦æ•°æ®ï¼š</p>
<ul>
<li><p>åŸºå› ç»„ï¼ˆGenomicï¼‰</p>
<ul>
<li>çªå˜ï¼ˆMutationï¼‰ï¼šä½“ç»†èƒçªå˜ï¼ˆå¦‚å•æ ¸è‹·é…¸å˜å¼‚ SNVsï¼‰å¯èƒ½é©±åŠ¨ç™Œç—‡è¿›å±•ï¼Œå¹¶å½±å“è¯ç‰©é¶ç‚¹ã€‚</li>
<li>æ‹·è´æ•°å˜å¼‚ï¼ˆCNVï¼‰ï¼šåŸºå› æ‹·è´æ•°çš„å¢åŠ æˆ–ç¼ºå¤±å¯èƒ½å½±å“è¯ç‰©æ•æ„Ÿæ€§ï¼ˆå¦‚ HER2 æ‰©å¢ä¸æ›²å¦¥ç å•æŠ—ç–—æ•ˆç›¸å…³ï¼‰ã€‚</li>
</ul>
</li>
<li><p>è½¬å½•ç»„ï¼ˆTranscriptomicï¼‰</p>
<ul>
<li>åŸºå› è¡¨è¾¾ï¼ˆGene Expressionï¼‰ï¼šé€šè¿‡å¾®é˜µåˆ—æˆ– RNA æµ‹åºï¼ˆRNA-Seqï¼‰é‡åŒ–åŸºå› çš„ mRNA æ°´å¹³ã€‚ä¾‹å¦‚ï¼Œé«˜è¡¨è¾¾çš„è€è¯åŸºå› å¯èƒ½é¢„ç¤ºæ²»ç–—å¤±è´¥ã€‚</li>
</ul>
</li>
<li><p>è¡¨è§‚ç»„ï¼ˆEpigenomicï¼‰</p>
<ul>
<li>DNA ç”²åŸºåŒ–ï¼ˆMethylationï¼‰ï¼šå¯åŠ¨å­åŒºåŸŸçš„ç”²åŸºåŒ–å¯èƒ½æ²‰é»˜æŠ‘ç™ŒåŸºå› ï¼Œå½±å“è¯ç‰©ååº”ã€‚</li>
</ul>
</li>
<li><p>è›‹ç™½è´¨ç»„ï¼ˆProteomicï¼‰</p>
<ul>
<li>è›‹ç™½è´¨è¡¨è¾¾ï¼ˆRPPA ç­‰ï¼‰ï¼šç›´æ¥æµ‹é‡è›‹ç™½è´¨ä¸°åº¦ï¼ˆå¦‚æ¿€é…¶æ´»æ€§ï¼‰ï¼Œæ›´æ¥è¿‘åŠŸèƒ½è¡¨å‹ã€‚</li>
</ul>
</li>
</ul>
<p>å¯¹äºåŒä¸€ç§ç»„å­¦æ•°æ®ï¼Œä»–ä»¬è¢«è¡¨ç¤ºæˆä¸€ç»„ <strong>ç»´æ•°ç›¸åŒçš„å‘é‡</strong></p>
<h4 id="é¢„å¤„ç†ä¸æ•´åˆ"><a href="#é¢„å¤„ç†ä¸æ•´åˆ" class="headerlink" title="é¢„å¤„ç†ä¸æ•´åˆ"></a>é¢„å¤„ç†ä¸æ•´åˆ</h4><ol>
<li>æ•°æ®é¢„å¤„ç†</li>
</ol>
<ul>
<li>åŒ…æ‹¬æ ‡å‡†åŒ–ï¼ˆnormalizationï¼‰ã€æ‰¹æ¬¡æ•ˆåº”æ ¡æ­£ï¼ˆbatch effect correctionï¼‰å’Œè´¨é‡æ§åˆ¶ï¼ˆQCï¼‰ã€‚ä¾‹å¦‚ï¼ŒRNA-Seq æ•°æ®éœ€é€šè¿‡ RPKM æˆ– TPM æ ‡å‡†åŒ–ã€‚</li>
</ul>
<ol start="2">
<li>å¤šç»„å­¦æ•´åˆæ–¹æ³• ï¼š<ul>
<li>æ—©æœŸæ•´åˆï¼ˆEarly Integrationï¼‰ï¼šç›´æ¥æ‹¼æ¥ä¸åŒç»„å­¦ç‰¹å¾ä¸ºå•ä¸€å‘é‡ï¼Œä½†å¯èƒ½å› ç»´åº¦ç¾éš¾ï¼ˆcurse of dimensionalityï¼‰å¯¼è‡´è¿‡æ‹Ÿåˆã€‚</li>
<li>æ™šæœŸæ•´åˆï¼ˆLate Integrationï¼‰ï¼šé€šè¿‡ç‹¬ç«‹å­ç½‘ç»œå¤„ç†æ¯ç»„å­¦æ•°æ®ï¼ˆå¦‚ CNN å¤„ç†çªå˜ï¼ŒGNN å¤„ç†è¡¨è¾¾æ•°æ®ï¼‰ï¼Œå†èåˆç‰¹å¾ã€‚ä¾‹å¦‚ï¼ŒMOLI æ¨¡å‹é€šè¿‡ä¸‰é‡æŸå¤±å‡½æ•°æ•´åˆå¤šç»„å­¦æ•°æ®ï¼Œæ˜¾è‘—æå‡è·¨ç™Œç—‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿"><a href="#åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿" class="headerlink" title="åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿"></a>åŸºå› ç‰¹å¾å…·æœ‰ä¼˜åŠ¿åŠæ–°å…´è¶‹åŠ¿</h4><blockquote>
<p>2014 å¹´ NCI-DREAM æŒ‘æˆ˜èµ›è¡¨æ˜ï¼Œ åŸºå› è¡¨è¾¾æ•°æ®åœ¨é¢„æµ‹ä¹³è…ºç™Œç»†èƒç³»è¯ç‰©æ•æ„Ÿæ€§æ—¶æœ€å…·é¢„æµ‹åŠ›ï¼ˆä¼˜äºçªå˜æˆ– CNVï¼‰ã€‚å› æ­¤ï¼Œçº¦ 90%çš„ DRP æ¨¡å‹ä½¿ç”¨åŸºå› è¡¨è¾¾ï¼ˆå•ç‹¬æˆ–è”åˆå…¶ä»–ç»„å­¦ï¼‰<br><img src="/img/CDR-data-analysis/gene.png" alt="gene" width="50%"></p>
</blockquote>
<h5 id="æ–°å…´è¶‹åŠ¿"><a href="#æ–°å…´è¶‹åŠ¿" class="headerlink" title="æ–°å…´è¶‹åŠ¿"></a>æ–°å…´è¶‹åŠ¿</h5><ol>
<li><strong>ç»“æ„ç”Ÿç‰©å­¦æ•´åˆ</strong>ï¼šå¦‚åˆ©ç”¨è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ï¼ˆPPIï¼‰ç½‘ç»œï¼ˆSTRING æ•°æ®åº“ï¼‰æˆ–é€šè·¯ä¿¡æ¯ï¼ˆGSEAï¼‰æ„å»ºç”Ÿç‰©ç½‘ç»œï¼Œå¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§ã€‚</li>
<li><strong>å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰</strong>ï¼šå°†åŸºå› è§†ä¸ºèŠ‚ç‚¹ã€ç›¸äº’ä½œç”¨ä¸ºè¾¹ï¼Œå­¦ä¹ æ‹“æ‰‘ç‰¹å¾ï¼ˆå¦‚ GraOmicDRP æ¨¡å‹ï¼‰ã€‚</li>
</ol>
<hr>
<h3 id="Representations-of-Drug-Compounds"><a href="#Representations-of-Drug-Compounds" class="headerlink" title="Representations of Drug Compounds"></a>Representations of Drug Compounds</h3><p>å¯¹è¯ç‰©çš„è¡¨ç¤ºä¸»è¦åˆ†ä¸ºä¸‰ç§ï¼Œä¸€èˆ¬åªé€‰å–å…¶ä¸­çš„ä¸€ç§ <del>è™½ç„¶ä¹Ÿæœ‰é€‰ç”¨å‡ ç§çš„ <strong>åˆ›æ–°</strong> æ–¹å¼</del>ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨é€‰å®šè¯ç‰©çš„è¡¨ç¤ºæ–¹å¼åï¼Œä¹‹åçš„ç‰¹å¾å·¥ç¨‹çš„æ–¹å¼ç›®å‰æ¥çœ‹éå¸¸çš„ç»Ÿä¸€ã€‚æ¥ä¸‹æ¥ä¸€ä¸€è¯´æ˜æ¯ä¸€ç§è¡¨ç¤ºæ–¹å¼ã€‚</p>
<h4 id="SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰"><a href="#SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰" class="headerlink" title="SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰"></a>SMILESï¼ˆç®€åŒ–åˆ†å­è¾“å…¥è¡Œæ¡ç›®ç³»ç»Ÿï¼‰</h4><ol>
<li><em>å®šä¹‰</em>ï¼šSMILES æ˜¯ä¸€ç§<strong>çº¿æ€§å­—ç¬¦ä¸²</strong>è¡¨ç¤ºæ³•ï¼Œé€šè¿‡ç¬¦å·ç¼–ç åˆ†å­ç»“æ„ï¼ˆå¦‚<code>CCO</code>è¡¨ç¤ºä¹™é†‡ï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼š<ul>
<li>æ˜“äºå­˜å‚¨å’Œå¤„ç†ï¼Œå¹¿æ³›ç”¨äºåŒ–å­¦ä¿¡æ¯å­¦å·¥å…·ï¼ˆå¦‚ RDKitï¼‰ã€‚</li>
<li>å¯ç›´æ¥ç”¨äºåºåˆ—æ¨¡å‹ï¼ˆå¦‚ RNNã€Transformerï¼‰æˆ–é€šè¿‡é¢„å¤„ç†è½¬æ¢ä¸ºå…¶ä»–è¡¨ç¤ºï¼ˆå¦‚å›¾ç»“æ„ï¼‰ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åˆ†å­æŒ‡çº¹ï¼ˆFingerprints-FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰"><a href="#åˆ†å­æŒ‡çº¹ï¼ˆFingerprints-FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰" class="headerlink" title="åˆ†å­æŒ‡çº¹ï¼ˆFingerprints, FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰"></a>åˆ†å­æŒ‡çº¹ï¼ˆFingerprints, FPsï¼‰å’Œæè¿°ç¬¦ï¼ˆDescriptorsï¼‰</h4><ol>
<li><p>åˆ†å­æŒ‡çº¹</p>
<ul>
<li><em>å®šä¹‰</em>ï¼š<strong>äºŒè¿›åˆ¶å‘é‡</strong>ï¼Œè¡¨ç¤ºåˆ†å­ä¸­æ˜¯å¦å­˜åœ¨ç‰¹å®šå­ç»“æ„ï¼ˆå¦‚è¯æ•ˆå›¢æˆ–å®˜èƒ½å›¢ï¼‰ã€‚</li>
<li><em>å¸¸ç”¨ç±»å‹</em>ï¼š<ul>
<li><strong>Morgan æŒ‡çº¹ï¼ˆECFPï¼‰</strong>ï¼šåŸºäºåŸå­é‚»åŸŸçš„åœ†å½¢æ‹“æ‰‘æŒ‡çº¹ï¼Œé•¿åº¦é€šå¸¸ä¸º 512 æˆ– 1024 ä½ã€‚</li>
<li><strong>RDKit æŒ‡çº¹</strong>ï¼šå¼€æºå·¥å…·ç”Ÿæˆçš„äºŒè¿›åˆ¶æŒ‡çº¹ã€‚</li>
</ul>
</li>
<li><em>ä¼˜åŠ¿</em>ï¼šå›ºå®šé•¿åº¦ï¼Œé€‚åˆä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚éšæœºæ£®æ—ï¼‰ã€‚</li>
</ul>
</li>
<li><p>åˆ†å­æè¿°ç¬¦</p>
<ul>
<li><em>å®šä¹‰</em>ï¼š<strong>æ•°å€¼å‘é‡</strong>ï¼Œç¼–ç ç‰©ç†åŒ–å­¦æ€§è´¨ï¼ˆå¦‚åˆ†å­é‡ã€ç–æ°´æ€§ã€ææ€§è¡¨é¢ç§¯ç­‰ï¼‰ã€‚</li>
<li><em>å·¥å…·</em>ï¼šPaDELã€Mordredã€Dragon ç­‰è½¯ä»¶å¯è‡ªåŠ¨è®¡ç®—æ•°ç™¾è‡³æ•°åƒä¸ªæè¿°ç¬¦ã€‚</li>
</ul>
</li>
</ol>
<h4 id="å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based-Representationsï¼‰"><a href="#å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based-Representationsï¼‰" class="headerlink" title="å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based Representationsï¼‰"></a>å›¾ç»“æ„è¡¨ç¤ºï¼ˆGraph-based Representationsï¼‰</h4><ol>
<li><em>å®šä¹‰</em> ï¼šå°†åˆ†å­è¡¨ç¤ºä¸º<strong>å›¾</strong>ï¼Œå…¶ä¸­åŸå­ä¸º<strong>èŠ‚ç‚¹</strong>ï¼ŒåŒ–å­¦é”®ä¸º<strong>è¾¹</strong>ï¼ŒèŠ‚ç‚¹å’Œè¾¹å¯é™„åŠ å±æ€§ï¼ˆå¦‚åŸå­ç±»å‹ã€é”®ç±»å‹ï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em> ï¼š<ul>
<li>æ›´è‡ªç„¶åœ°è¡¨å¾åˆ†å­æ‹“æ‰‘ç»“æ„ï¼Œé€‚åˆå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ã€‚</li>
<li>å¯æ•æ‰å±€éƒ¨å’Œå…¨å±€åˆ†å­ç‰¹å¾ï¼ˆå¦‚å®˜èƒ½å›¢ç›¸äº’ä½œç”¨ï¼‰ã€‚</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Representations-of-Treatment-Response"><a href="#Representations-of-Treatment-Response" class="headerlink" title="Representations of Treatment Response"></a>Representations of Treatment Response</h3><p>ä»æ„é€ æ¨¡å‹çš„è§’åº¦å‡ºå‘ï¼Œè¿™æ˜¯ DRP çš„æ ¸å¿ƒæ•°æ®æº</p>
<ul>
<li>å®ƒå†³å®šäº†æ¨¡å‹æœ€åå®Œæˆçš„<strong>ä»»åŠ¡ç±»å‹</strong>ï¼šè®­ç»ƒè¿ç»­å€¼çš„<strong>å›å½’ä»»åŠ¡</strong>å’Œè®­ç»ƒç¦»æ•£å€¼çš„<strong>åˆ†ç±»ä»»åŠ¡</strong></li>
<li>ä»–çš„æ•°æ®è´¨é‡å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†æ¨¡å‹çš„ç»“æœçš„ä¼˜åŠ£ï¼Œå³å¯¹è¯¥æ•°æ®æºå¯¹æ¨¡å‹çš„å¥½åå½±å“å¾ˆå¤§</li>
</ul>
<p>æ­¤å¤–ï¼Œå¾ˆå°‘æœ‰ä»æ•°æ®åˆ†æçš„è§’åº¦å‡ºå‘åˆ†æè¿™ä¸ªæ•°æ®æºçš„æ–‡çŒ®ï¼Œäºæ˜¯åœ¨è¿™é‡Œç»™å‡ºç®€è¦çš„è¯´æ˜</p>
<h4 id="è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous-Measuresï¼‰"><a href="#è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous-Measuresï¼‰" class="headerlink" title="è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous Measuresï¼‰"></a>è¿ç»­å€¼è¡¨ç¤ºï¼ˆContinuous Measuresï¼‰</h4><ol>
<li><p><strong>IC50</strong></p>
<ul>
<li>åŠæ•°æŠ‘åˆ¶æµ“åº¦ï¼Œå³æŠ‘åˆ¶ 50%ç»†èƒæ´»åŠ›æ‰€éœ€çš„è¯ç‰©æµ“åº¦ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šç›´è§‚åæ˜ è¯ç‰©æ•ˆåŠ›ï¼Œå¹¿æ³›ç”¨äºå›å½’æ¨¡å‹ï¼ˆå¦‚é¢„æµ‹ IC50 çš„æ•°å€¼ï¼‰ã€‚</li>
<li><em>å±€é™æ€§</em>ï¼šä»…åæ˜ å•ä¸€æµ“åº¦ç‚¹çš„æ•ˆæœï¼Œå¯èƒ½å¿½ç•¥å‰‚é‡-ååº”æ›²çº¿çš„æ•´ä½“å½¢çŠ¶ã€‚</li>
</ul>
</li>
<li><p><strong>AUC&#x2F;AAC</strong></p>
<ul>
<li>å‰‚é‡-ååº”æ›²çº¿ä¸‹é¢ç§¯ï¼ˆArea Under the Curveï¼‰æˆ–æ›²çº¿ä¸Šé¢ç§¯ï¼ˆActivity Areaï¼‰ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šå…¨å±€åº¦é‡ï¼Œç»¼åˆæ‰€æœ‰æµ“åº¦ç‚¹çš„æ•ˆæœï¼Œå¯¹å™ªå£°æ›´é²æ£’ã€‚</li>
<li><em>åº”ç”¨</em>ï¼šå¦‚ DeepCDR ç­‰æ¨¡å‹ä½¿ç”¨ AUC ä½œä¸ºå›å½’ç›®æ ‡ï¼Œå®è¯è¡¨æ˜å…¶æ³›åŒ–æ€§ä¼˜äº IC50ã€‚</li>
</ul>
</li>
</ol>
<h4 id="åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical-Measuresï¼‰"><a href="#åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical-Measuresï¼‰" class="headerlink" title="åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical Measuresï¼‰"></a>åˆ†ç±»è¡¨ç¤ºï¼ˆCategorical Measuresï¼‰</h4><ol>
<li><p><strong>äºŒåˆ†ç±»ï¼ˆæ•æ„Ÿ&#x2F;è€è¯ï¼‰</strong></p>
<ul>
<li>é€šè¿‡é˜ˆå€¼ï¼ˆå¦‚ç€‘å¸ƒç®—æ³•ã€LOBICOï¼‰å°†è¿ç»­ååº”ï¼ˆå¦‚ IC50ï¼‰è½¬åŒ–ä¸ºç¦»æ•£æ ‡ç­¾ã€‚</li>
<li><em>ä¼˜åŠ¿</em>ï¼šæ›´è´´è¿‘ä¸´åºŠå†³ç­–éœ€æ±‚ï¼ˆå¦‚é€‰æ‹©æ•æ„Ÿè¯ç‰©ï¼‰ã€‚</li>
<li><em>ç¤ºä¾‹</em>ï¼šSharifi-Noghabi et al. (2021) ä½¿ç”¨äºŒåˆ†ç±»è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼Œé¢„æµ‹æ‚£è€…è‚¿ç˜¤çš„æ•æ„Ÿæ€§ã€‚</li>
</ul>
</li>
<li><p><strong>å¤šåˆ†ç±»</strong></p>
<ul>
<li>å¦‚ä½&#x2F;ä¸­&#x2F;é«˜ååº”æ€§ï¼Œé€‚ç”¨äºæ›´ç»†ç²’åº¦çš„ä¸´åºŠåˆ†çº§ã€‚</li>
</ul>
</li>
</ol>
<h4 id="æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰"><a href="#æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰" class="headerlink" title="æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰"></a>æ’åºè¡¨ç¤ºï¼ˆRankingï¼‰</h4><ol>
<li><p><em>ç›®æ ‡</em></p>
<ul>
<li>ä¸ºä¸ªæ€§åŒ–æ²»ç–—æ¨èè¯ç‰©æ’åºï¼ˆå¦‚ Top-k æœ€æœ‰æ•ˆè¯ç‰©ï¼‰ã€‚</li>
</ul>
</li>
<li><p><em>æ–¹æ³•</em></p>
<ul>
<li>Prasse et al. (2022)ï¼šå°† IC50 è½¬åŒ–ä¸ºç›¸å…³æ€§åˆ†æ•°ï¼Œè®¾è®¡å¯å¾®æ’åºæŸå¤±å‡½æ•°ã€‚</li>
<li>PPORankï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åŠ¨æ€ä¼˜åŒ–æ’åºï¼Œé€‚åº”æ–°å¢æ•°æ®ã€‚</li>
</ul>
</li>
<li><p><em>ä¼˜åŠ¿</em></p>
<ul>
<li>ç›´æ¥æ”¯æŒä¸´åºŠä¼˜å…ˆçº§æ’åºï¼Œä¼˜äºä¼ ç»Ÿå›å½’æˆ–åˆ†ç±»ã€‚</li>
</ul>
</li>
</ol>
<h4 id="æ•°æ®åˆ†æ"><a href="#æ•°æ®åˆ†æ" class="headerlink" title="æ•°æ®åˆ†æ"></a>æ•°æ®åˆ†æ</h4><p>ç”±äºæœ¬äººå¤§æ¦‚ç‡ä¼šåšä¸ªåˆ†ç±»æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šå°†ä¸»è¦åˆ†æçš„æ˜¯<strong>åˆ†ç±»è¡¨ç¤º</strong>çš„æ•°æ®åœ¨<strong>å›¾ç¥ç»ç½‘ç»œ</strong>ä¸­æ¯”è¾ƒé‡è§†çš„å‡ ä¸ªæŒ‡æ ‡ï¼Œè¿™é‡Œåˆ†æ <em>CCLE</em> å’Œ <em>GDSC</em> ä¸¤ä¸ªæ•°æ®é›†åœ¨é€‰ç”¨ä¸»æµé˜ˆå€¼é€‰å–æ–¹æ³•ä¹‹åçš„è¡¨ç¤ºã€‚</p>
<p>ç›´æ¥å…ˆçœ‹ç»“æœæï¼ˆè¿™é‡Œç”»äº†ä¸¤ä¸ªå°å›¾ï¼‰</p>
<ul>
<li>CCLE</li>
</ul>
<img src="/img/CDR-data-analysis/comprehensive_bipartite_analysis_ccle.png" alt="CCLE" style="max-width: 100%; height: auto;">

<ul>
<li>GDSC</li>
</ul>
<img src="/img/CDR-data-analysis/comprehensive_bipartite_analysis_gdsc.png" alt="GDSC" style="max-width: 100%; height: auto;">

<p>
  ğŸ‘‰ <a href="/code/data_analysis/visualize_graph_analysis.py" target="_blank">æŸ¥çœ‹ç”¨äºç”Ÿæˆä¸Šè¿°å›¾è¡¨çš„æœ¬åœ° Python è„šæœ¬ï¼švisualize_graph_analysis.py</a>
</p>

<h5 id="ğŸ”-å…³é”®æ•°æ®å¯¹æ¯”"><a href="#ğŸ”-å…³é”®æ•°æ®å¯¹æ¯”" class="headerlink" title="ğŸ” å…³é”®æ•°æ®å¯¹æ¯”"></a>ğŸ” å…³é”®æ•°æ®å¯¹æ¯”</h5><table>
<thead>
<tr>
<th>ç‰¹å¾</th>
<th>CCLE</th>
<th>GDSC</th>
<th>å€æ•°å·®å¼‚</th>
</tr>
</thead>
<tbody><tr>
<td><strong>æ•°æ®è§„æ¨¡</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>æ€»èŠ‚ç‚¹æ•°</td>
<td>341</td>
<td>783</td>
<td>2.3Ã—</td>
</tr>
<tr>
<td>ç¬¬ä¸€ç±»èŠ‚ç‚¹</td>
<td>317</td>
<td>561</td>
<td>1.8Ã—</td>
</tr>
<tr>
<td>ç¬¬äºŒç±»èŠ‚ç‚¹</td>
<td>24</td>
<td>222</td>
<td>9.3Ã—</td>
</tr>
<tr>
<td>æ€»è¾¹æ•°</td>
<td>7,307</td>
<td>100,572</td>
<td>13.8Ã—</td>
</tr>
<tr>
<td><strong>å›¾ç»“æ„</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>å¯†åº¦</td>
<td>0.9604</td>
<td>0.8075</td>
<td>0.84Ã—</td>
</tr>
<tr>
<td>ç¨€ç–æ€§</td>
<td>0.0396</td>
<td>0.1925</td>
<td>4.9Ã—</td>
</tr>
<tr>
<td>å¹³å‡åº¦</td>
<td>42.86</td>
<td>256.89</td>
<td>6.0Ã—</td>
</tr>
<tr>
<td>å›¾ç›´å¾„</td>
<td>3</td>
<td>4</td>
<td>1.3Ã—</td>
</tr>
<tr>
<td><strong>è¾¹åˆ†å¸ƒ</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>æ­£è¾¹æ•°é‡</td>
<td>1,375</td>
<td>11,591</td>
<td>8.4Ã—</td>
</tr>
<tr>
<td>è´Ÿè¾¹æ•°é‡</td>
<td>5,932</td>
<td>88,981</td>
<td>15.0Ã—</td>
</tr>
<tr>
<td>æ­£è¾¹æ¯”ä¾‹</td>
<td>18.8%</td>
<td>11.5%</td>
<td>0.61Ã—</td>
</tr>
<tr>
<td>æ­£è´Ÿè¾¹æ¯”ä¾‹</td>
<td>1:4.3</td>
<td>1:7.7</td>
<td>1.8Ã— ä¸å¹³è¡¡</td>
</tr>
</tbody></table>
<h5 id="ğŸ“Š-GNN-è®­ç»ƒæŒ‘æˆ˜åˆ†æ"><a href="#ğŸ“Š-GNN-è®­ç»ƒæŒ‘æˆ˜åˆ†æ" class="headerlink" title="ğŸ“Š GNN è®­ç»ƒæŒ‘æˆ˜åˆ†æ"></a>ğŸ“Š GNN è®­ç»ƒæŒ‘æˆ˜åˆ†æ</h5><h6 id="è¿‡å¹³æ»‘é£é™©è¯„ä¼°"><a href="#è¿‡å¹³æ»‘é£é™©è¯„ä¼°" class="headerlink" title="è¿‡å¹³æ»‘é£é™©è¯„ä¼°"></a>è¿‡å¹³æ»‘é£é™©è¯„ä¼°</h6><ul>
<li><strong>CCLE</strong>: âš ï¸ é«˜é£é™© (å¹³å‡åº¦ 42.86)</li>
<li><strong>GDSC</strong>: ğŸš¨ æé«˜é£é™© (å¹³å‡åº¦ 256.89)</li>
</ul>
<h6 id="æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦"><a href="#æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦" class="headerlink" title="æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦"></a>æ ·æœ¬ä¸å¹³è¡¡ç¨‹åº¦</h6><ul>
<li><strong>CCLE</strong>: æ­£è´Ÿè¾¹æ¯”ä¾‹ 1:4.3 (ä¸­ç­‰ä¸å¹³è¡¡)</li>
<li><strong>GDSC</strong>: æ­£è´Ÿè¾¹æ¯”ä¾‹ 1:7.7 (ä¸¥é‡ä¸å¹³è¡¡)</li>
</ul>
<h6 id="é‚»å±…ç›¸ä¼¼åº¦åˆ†æ"><a href="#é‚»å±…ç›¸ä¼¼åº¦åˆ†æ" class="headerlink" title="é‚»å±…ç›¸ä¼¼åº¦åˆ†æ"></a>é‚»å±…ç›¸ä¼¼åº¦åˆ†æ</h6><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># é‚»å±…é‡å åº¦å¯¹æ¯”</span></span><br><span class="line">CCLE_similarity = &#123;</span><br><span class="line">    <span class="string">&quot;ç¬¬ä¸€ç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.9374</span>,  <span class="comment"># é«˜åº¦ç›¸ä¼¼</span></span><br><span class="line">    <span class="string">&quot;ç¬¬äºŒç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.9274</span>   <span class="comment"># é«˜åº¦ç›¸ä¼¼</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GDSC_similarity = &#123;</span><br><span class="line">    <span class="string">&quot;ç¬¬ä¸€ç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.7659</span>,  <span class="comment"># ä¸­ç­‰ç›¸ä¼¼</span></span><br><span class="line">    <span class="string">&quot;ç¬¬äºŒç±»èŠ‚ç‚¹&quot;</span>: <span class="number">0.7143</span>   <span class="comment"># ä¸­ç­‰ç›¸ä¼¼</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ç»“è®º</strong>: CCLE ç»“æ„æ›´å‡åŒ€ä½†å¤šæ ·æ€§ä¸è¶³ï¼ŒGDSC ç»“æ„æ›´å¤æ‚ä½†å¤šæ ·æ€§æ›´å¥½</p>
<h5 id="ğŸ¯-GNN-æ¶æ„å»ºè®®å¯¹æ¯”"><a href="#ğŸ¯-GNN-æ¶æ„å»ºè®®å¯¹æ¯”" class="headerlink" title="ğŸ¯ GNN æ¶æ„å»ºè®®å¯¹æ¯”"></a>ğŸ¯ GNN æ¶æ„å»ºè®®å¯¹æ¯”</h5><h6 id="æ¨èæ¶æ„ä¼˜å…ˆçº§"><a href="#æ¨èæ¶æ„ä¼˜å…ˆçº§" class="headerlink" title="æ¨èæ¶æ„ä¼˜å…ˆçº§"></a>æ¨èæ¶æ„ä¼˜å…ˆçº§</h6><ul>
<li><p>CCLE æ¨èæ¶æ„</p>
<ol>
<li><strong>Bipartite GNN</strong> + Signed GCN</li>
<li><strong>ç®€å•å¼‚æ„å›¾ GNN</strong> (HetGNN)</li>
<li><strong>æ ‡å‡† GCN</strong> + å¼ºæ­£åˆ™åŒ–</li>
</ol>
</li>
<li><p>GDSC æ¨èæ¶æ„</p>
<ol>
<li><strong>é‡‡æ ·å‹ GNN</strong> (GraphSAINT, FastGCN) + SGCN</li>
<li><strong>å¤§è§„æ¨¡å¼‚æ„å›¾ GNN</strong> (HGT, RGCN)</li>
<li><strong>å›¾ Transformer</strong> (å¤„ç†å¤æ‚ç»“æ„)</li>
</ol>
</li>
</ul>
<h6 id="å…·ä½“å‚æ•°å»ºè®®"><a href="#å…·ä½“å‚æ•°å»ºè®®" class="headerlink" title="å…·ä½“å‚æ•°å»ºè®®"></a>å…·ä½“å‚æ•°å»ºè®®</h6><table>
<thead>
<tr>
<th>å‚æ•°</th>
<th>CCLE</th>
<th>GDSC</th>
<th>åŸå› </th>
</tr>
</thead>
<tbody><tr>
<td><strong>ç½‘ç»œæ·±åº¦</strong></td>
<td>2-3 å±‚</td>
<td>ä¸¥æ ¼ 2 å±‚</td>
<td>GDSC è¿‡å¹³æ»‘é£é™©æ›´é«˜</td>
</tr>
<tr>
<td><strong>éšè—ç»´åº¦</strong></td>
<td>64-128</td>
<td>128-256</td>
<td>GDSC éœ€è¦æ›´å¤§å®¹é‡</td>
</tr>
<tr>
<td><strong>Dropout ç‡</strong></td>
<td>0.3-0.5</td>
<td>0.5-0.7</td>
<td>GDSC éœ€è¦æ›´å¼ºæ­£åˆ™åŒ–</td>
</tr>
<tr>
<td><strong>å­¦ä¹ ç‡</strong></td>
<td>0.001-0.01</td>
<td>0.0001-0.001</td>
<td>GDSC éœ€è¦æ›´ä¿å®ˆè®­ç»ƒ</td>
</tr>
<tr>
<td><strong>æ‰¹æ¬¡å¤§å°</strong></td>
<td>32-64 ä¸ªå­å›¾</td>
<td>16-32 ä¸ªå­å›¾</td>
<td>GDSC å†…å­˜é™åˆ¶</td>
</tr>
<tr>
<td><strong>é‡‡æ ·ç­–ç•¥</strong></td>
<td>å¯é€‰</td>
<td>å¿…é¡»</td>
<td>GDSC æ— æ³•å…¨å›¾è®­ç»ƒ</td>
</tr>
</tbody></table>
<h1 id="ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"><a href="#ğŸ“š-ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’" class="headerlink" title="ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’"></a>ğŸ“š ğ’¥ğ‘’ğ’»ğ‘’ğ“‡ğ‘’ğ“ƒğ’¸ğ‘’</h1><p><a href="/paper/Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends.pdf" target="_blank">ğŸ“„ Partin - Deep learning methods for drug response prediction in cancer Predominant and emerging trends</a></p>
]]></content>
      <categories>
        <category>CDR</category>
        <category>Data Analysis</category>
      </categories>
      <tags>
        <tag>CDR</tag>
        <tag>graph theory</tag>
        <tag>Data Analysis</tag>
        <tag>å¯èƒ½æœ‰ç‚¹ç”¨</tag>
      </tags>
  </entry>
</search>
